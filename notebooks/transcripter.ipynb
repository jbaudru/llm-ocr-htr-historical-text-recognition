{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import base64\n",
    "# from IPython.display import display, Image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parent directory of the current directory\n",
    "path = os.path.dirname(os.getcwd()) \n",
    "\n",
    "# Paths to the folders of example images and transcriptions\n",
    "image_folder = path+'/data/Archives_LLN_Nivelles_I_1921_REG 5193'\n",
    "text_folder = path+'/data/transcriptions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "openai_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_client = OpenAI(api_key=openai_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "anthropic_client = Anthropic(api_key=anthropic_API_KEY)\n",
    "MODEL_NAME = \"claude-3-5-sonnet-20240620\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# With Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#===========================================================================\n",
    "# LLM CALLS\n",
    "#===========================================================================\n",
    "\n",
    "def call(prompt, max_tokens=5000, base64_image=None, message=None, system=None):\n",
    "    if(\"claude\" in model):\n",
    "        res =  callAnthropic(prompt, max_tokens=max_tokens, base64_image=base64_image, message=message, system=system)\n",
    "    else:\n",
    "        res =  callOpenAI(prompt, max_tokens=max_tokens, base64_image=base64_image, message=message)\n",
    "    return res\n",
    "\n",
    "\n",
    "def callAnthropic(prompt, max_tokens=5000, base64_image=None, message=None, system=None):\n",
    "    client = Anthropic(api_key= anthropic_API_KEY)  \n",
    "    try:\n",
    "        if(message==None):\n",
    "            if(base64_image):\n",
    "                response = client.messages.create(\n",
    "                    model= model,\n",
    "                    max_tokens=max_tokens,\n",
    "                    system = system,\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                    \"type\": \"image\",\n",
    "                                    \"source\": {\n",
    "                                        \"type\": \"base64\",\n",
    "                                        \"media_type\": \"image/jpeg\",\n",
    "                                        \"data\": base64_image,\n",
    "                                    },\n",
    "                                },\n",
    "                                {\n",
    "                                    \"type\": \"text\",\n",
    "                                    \"text\": prompt,\n",
    "                                }\n",
    "                            ],\n",
    "                        }\n",
    "                    ],\n",
    "                    temperature=0,\n",
    "                )\n",
    "            else:\n",
    "                response = client.messages.create(\n",
    "                model=model,\n",
    "                max_tokens=max_tokens,\n",
    "                #system = system,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": prompt,\n",
    "                            }\n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0,\n",
    "            )\n",
    "        else:\n",
    "            response = client.messages.create(\n",
    "                model= model,\n",
    "                max_tokens=max_tokens,\n",
    "                #system = system,\n",
    "                messages=message,\n",
    "                temperature=0,\n",
    "            )\n",
    "        \n",
    "        return response.to_dict()[\"content\"][0][\"text\"]\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] callAnthropic failed! {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def callOpenAI(prompt, max_tokens=5000, base64_image=None, message=None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_API_KEY}\"\n",
    "    } \n",
    "    model_vision = \"gpt-4o\"\n",
    "    if(base64_image):  \n",
    "        if(message==None):\n",
    "            payload = {\n",
    "                \"model\": model_vision, # only gpt-4o can handle images\n",
    "                \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                    ]\n",
    "                }\n",
    "                ],\n",
    "                \"max_tokens\": max_tokens,\n",
    "                \"temperature\": 0\n",
    "            }\n",
    "        else:\n",
    "            payload = {\n",
    "                \"model\": model_vision, # only gpt-4o can handle images\n",
    "                \"messages\": message,\n",
    "                \"max_tokens\": max_tokens,\n",
    "                \"temperature\": 0\n",
    "            }\n",
    "    else:\n",
    "        payload = {\n",
    "            \"model\":  model,\n",
    "            \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                }\n",
    "                ]\n",
    "            }\n",
    "            ],\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    \n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    try:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] callOpenAI failed! {e}\")\n",
    "        print(response.json()[\"error\"][\"message\"])\n",
    "    #return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "def xlsx_to_string(filepath):\n",
    "    df = pd.read_excel(filepath)\n",
    "    \n",
    "    # Drop rows that don't have any information in any columns\n",
    "    df = df.dropna(how='all')\n",
    "    \n",
    "    # Fill NaN values with a whitespace\n",
    "    df = df.fillna(\" \")\n",
    "    \n",
    "    string = df.to_string(index=False, header=False)\n",
    "    string = re.sub(' +', ' ', string)  # Replace multiple spaces with a single space\n",
    "    string = string.replace(\"\\n\", \" \\n\")  # Ensure each new row starts on a new line\n",
    "    return string\n",
    "\n",
    "\n",
    "def resize_image(image_path):\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            # Calculate new dimensions\n",
    "            new_width = img.width // 3\n",
    "            new_height = img.height // 3\n",
    "            img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "            buffer = BytesIO()\n",
    "            img.save(buffer, format=\"JPEG\")\n",
    "            return buffer.getvalue()\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Resizing image: {e},  Path: {image_path}\")\n",
    "        return None\n",
    "\n",
    "        \n",
    "def exampleShot(image_path, NbExamples=1, model = \"claude\"):\n",
    "        # example\n",
    "        example_xlsx = path + \"/data/transcriptions/transcription_ex\" + str(2) + \".xlsx\"\n",
    "        example_text_1 = xlsx_to_string(example_xlsx)\n",
    "        example_image_1 = path + \"/data/Archives_LLN_Nivelles_I_1921_REG 5193/example2.jpeg\"\n",
    "        \n",
    "        if(NbExamples==2):\n",
    "            # example\n",
    "            example_xlsx2 = path + \"/data/transcriptions/transcription_ex\" + str(3) + \".xlsx\"\n",
    "            example_text_2 = xlsx_to_string(example_xlsx2)\n",
    "            example_image_2 = path + \"/data/Archives_LLN_Nivelles_I_1921_REG 5193/example3.jpeg\"\n",
    "            example_text = [example_text_1, example_text_2]\n",
    "        \n",
    "        if model == \"claude\":\n",
    "            resized_image = resize_image(image_path)\n",
    "            base64_image = base64.b64encode(resized_image).decode('utf-8')\n",
    "            image_1 = resize_image(example_image_1)\n",
    "            image_1 = base64.b64encode(image_1).decode('utf-8')\n",
    "            if(NbExamples==2):\n",
    "                image_2 = resize_image(example_image_2)\n",
    "                image_2 = base64.b64encode(image_2).decode('utf-8')\n",
    "        else:\n",
    "            base64_image = encode_image(image_path)\n",
    "            image_1 = encode_image(example_image_1)\n",
    "            if(NbExamples==2):\n",
    "                image_2 = encode_image(example_image_2)\n",
    "        \n",
    "        if model == \"claude\":\n",
    "            if(NbExamples==1):\n",
    "                message = [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [ \n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": image_1}\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example_text_1,\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": f\"\"\"\n",
    "                            The ```plaintext block is the example transcription of the example image you saw:\n",
    "\n",
    "                            Transcription:\n",
    "                            ```plaintext\n",
    "                            {example_text_1}\n",
    "                            ```\n",
    "                            Compare what you read initially and the solution key in ```plaintext block. Recreate the content of the table in this image. Only that, no other information from you.\n",
    "\n",
    "                            \"\"\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image\",\n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\",\n",
    "                                \"media_type\": \"image/jpeg\",\n",
    "                                \"data\": base64_image,\n",
    "                            },\n",
    "                        }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            \n",
    "            else:\n",
    "                message = [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [ \n",
    "    \n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": image_1}},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example_text_1,\n",
    "                        },\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": image_2}},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example_text_2,\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": f\"\"\"\n",
    "                            The ```plaintext block is the example transcription of the example image you saw:\n",
    "\n",
    "                            Transcription:\n",
    "                            ```plaintext\n",
    "                            {example_text}\n",
    "                            ```\n",
    "                            Compare what you read initially and the solution key in ```plaintext block. Recreate the content of the table in this image. Only that, no other information from you.\n",
    "\n",
    "                            \"\"\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image\",\n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\",\n",
    "                                \"media_type\": \"image/jpeg\",\n",
    "                                \"data\": base64_image,\n",
    "                            },\n",
    "                        }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            \n",
    "            system_prompt =  \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "            \n",
    "        else:\n",
    "            if(NbExamples==1):\n",
    "                message = [\n",
    "                    {\n",
    "                        \"role\": \"system\", \n",
    "                        \"content\": \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [ \n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{image_1}\"\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": f\"\"\"\n",
    "                            The ```plaintext block is the example transcription of the example image you saw:\n",
    "\n",
    "                            Transcription:\n",
    "                            ```plaintext\n",
    "                            {example_text_1}\n",
    "                            ```\n",
    "                            Compare what you read initially and the solution key in ```plaintext block. Recreate the content of the table in this image. Only that, no other information from you.\n",
    "                            \n",
    "                            Even if it is hard to read the texts from the image, return as much as you can. You must read something. Do not return an apologetic message.\n",
    "                            \"\"\"\n",
    "                        },\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            \n",
    "            else:\n",
    "                message = [\n",
    "                    {\n",
    "                        \"role\": \"system\", \n",
    "                        \"content\": \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [ \n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{image_1}\"\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example_text_2\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{image_2}\"\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": f\"\"\"\n",
    "                            The ```plaintext block is the example transcription of the example image you saw:\n",
    "\n",
    "                            Transcription:\n",
    "                            ```plaintext\n",
    "                            {example_text}\n",
    "                            ```\n",
    "                            Compare what you read initially and the solution key in ```plaintext block. Recreate the content of the table in this image. Only that, no other information from you.\n",
    "                            \n",
    "                            Even if it is hard to read the texts from the image, return as much as you can. You must read something. Do not return an apologetic message.\n",
    "                            \"\"\"\n",
    "                        },\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            system_prompt = None\n",
    "        return call(prompt=\"\", max_tokens=3000, base64_image=base64_image, message=message, system=system_prompt)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callPostProcessing(max_tokens=800, prompt_parameter = None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_API_KEY}\"\n",
    "    } \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"\"\"This is an output from you. Clean it such that we have no separators and no comment from you: {prompt_parameter}\n",
    "                \"\"\"\n",
    "            }\n",
    "            ]\n",
    "        }\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    try:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except:\n",
    "        print(response.json()[\"error\"][\"message\"])\n",
    "\n",
    "# use this when OpenAI credits are exhausted\n",
    "def callPostProcessing_anthropic(max_tokens=5000, prompt_parameter = None):\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=max_tokens,\n",
    "        system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"\"\"This is an output from you. Clean it such that we have no separators and no comment from you: {prompt_parameter}\n",
    "                \"\"\"\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.to_dict()[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Start processing file example1 -------\n",
      "Finished processing example1 in 141.41 seconds.\n",
      "------- Start processing file example10 -------\n",
      "Finished processing example10 in 63.03 seconds.\n",
      "------- Start processing file example11 -------\n",
      "Finished processing example11 in 53.10 seconds.\n",
      "Skipping /Users/serenekim/Desktop/PhD/img-analysis_seorin_project/data/Archives_LLN_Nivelles_I_1921_REG 5193/.DS_Store, does not end with '.jpeg'.\n",
      "------- Start processing file example7 -------\n",
      "Finished processing example7 in 63.47 seconds.\n",
      "------- Start processing file example16 -------\n",
      "Finished processing example16 in 71.95 seconds.\n",
      "------- Start processing file example20 -------\n",
      "Finished processing example20 in 51.69 seconds.\n",
      "------- Start processing file example17 -------\n",
      "Finished processing example17 in 56.43 seconds.\n",
      "------- Start processing file example6 -------\n",
      "Finished processing example6 in 35.79 seconds.\n",
      "------- Start processing file example14 -------\n",
      "Finished processing example14 in 47.69 seconds.\n",
      "------- Start processing file example5 -------\n",
      "Finished processing example5 in 57.27 seconds.\n",
      "------- Start processing file example18 -------\n",
      "Finished processing example18 in 36.93 seconds.\n",
      "------- Start processing file example9 -------\n",
      "Finished processing example9 in 175.37 seconds.\n",
      "------- Start processing file example8 -------\n",
      "Finished processing example8 in 53.68 seconds.\n",
      "------- Start processing file example19 -------\n",
      "Finished processing example19 in 39.07 seconds.\n",
      "------- Start processing file example4 -------\n",
      "Finished processing example4 in 35.14 seconds.\n",
      "------- Start processing file example15 -------\n",
      "Finished processing example15 in 88.49 seconds.\n",
      "Skipping /Users/serenekim/Desktop/PhD/img-analysis_seorin_project/data/Archives_LLN_Nivelles_I_1921_REG 5193/.ipynb_checkpoints, does not end with '.jpeg'.\n",
      "------- Start processing file example12 -------\n",
      "Finished processing example12 in 55.56 seconds.\n",
      "------- Start processing file example3 -------\n",
      "Finished processing example3 in 36.75 seconds.\n",
      "------- Start processing file example2 -------\n",
      "Finished processing example2 in 53.15 seconds.\n",
      "------- Start processing file example13 -------\n",
      "Finished processing example13 in 142.36 seconds.\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "progress_file = 'gpt_two_example_whole_output_progress.json'\n",
    "final_output_file = 'gpt_two_example_whole_output_final.json'\n",
    "\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "# Load progress if available\n",
    "try:\n",
    "    with open(progress_file, 'r') as file:\n",
    "        gpt_two_example_whole_output = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    gpt_two_example_whole_output = {}\n",
    "\n",
    "for image_path in os.listdir(image_folder):\n",
    "    image_path_new = os.path.join(image_folder, image_path)\n",
    "    image_id = os.path.splitext(image_path)[0]\n",
    "\n",
    "    # Skip already processed images\n",
    "    if image_id in gpt_two_example_whole_output:\n",
    "        print(f\"Skipping {image_id}, already processed.\")\n",
    "        continue\n",
    "\n",
    "    if image_path.endswith(\".jpeg\"):\n",
    "        start_time = time.time()\n",
    "        print(f'------- Start processing file {image_id} -------')\n",
    "\n",
    "        try:\n",
    "            output = exampleShot(image_path=image_path_new, NbExamples=2, model=\"gpt-4o\")\n",
    "            output_cleaned = callPostProcessing(prompt_parameter=output)\n",
    "\n",
    "            # Save the result\n",
    "            gpt_two_example_whole_output[image_id] = output_cleaned\n",
    "\n",
    "            # Update progress file after each processed image\n",
    "            with open(progress_file, 'w') as file:\n",
    "                json.dump(gpt_two_example_whole_output, file)\n",
    "\n",
    "            print(f\"Finished processing {image_id} in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_id}: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Skipping {image_path_new}, does not end with '.jpeg'.\")\n",
    "\n",
    "# Save the final output\n",
    "with open(final_output_file, 'w') as file:\n",
    "    json.dump(gpt_two_example_whole_output, file)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_two_example_whole_output_df = pd.DataFrame(claude_two_example_whole_output.items(), columns=['file', 'text'])\n",
    "claude_two_example_whole_output_df.to_csv('claude_two_example_whole_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_two_example_whole_output_df = pd.DataFrame(gpt_two_example_whole_output.items(), columns=['file', 'text'])\n",
    "gpt_two_example_whole_output_df.to_csv('gpt_two_example_whole_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "cer_metric =load(\"cer\")\n",
    "bleu_metric = load(\"bleu\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "gt_files = glob(os.path.join(path+'/data/transcriptions', '*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = {}\n",
    "\n",
    "for file in gt_files:\n",
    "    with open(file, 'r') as f:\n",
    "        name = os.path.basename(file).split('.')[0]\n",
    "        name = name.split('ex')[1]\n",
    "        gt[name] = f.read()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dés...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dés...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dés...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dés...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dés...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dés...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dés...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dés...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dés...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dési...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dés...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dés...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>N' d'ordre Date du dépôt des déclarations Dés...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file                                               text\n",
       "0    17   N' d'ordre Date du dépôt des déclarations Dés...\n",
       "1    16   N' d'ordre Date du dépôt des déclarations Dés...\n",
       "2    14   N' d'ordre Date du dépôt des déclarations Dés...\n",
       "3    15   N' d'ordre Date du dépôt des déclarations Dés...\n",
       "4    11   N' d'ordre Date du dépôt des déclarations Dés...\n",
       "5    10   N' d'ordre Date du dépôt des déclarations Dés...\n",
       "6    12   N' d'ordre Date du dépôt des déclarations Dés...\n",
       "7    13   N' d'ordre Date du dépôt des déclarations Dés...\n",
       "8     8    N' d'ordre Date du dépôt des déclarations Dé...\n",
       "9     9   N' d'ordre Date du dépôt des déclarations Dés...\n",
       "10    4    N' d'ordre Date du dépôt des déclarations Dé...\n",
       "11    5    N' d'ordre Date du dépôt des déclarations Dé...\n",
       "12    7    N' d'ordre Date du dépôt des déclarations Dé...\n",
       "13    6    N' d'ordre Date du dépôt des déclarations Dé...\n",
       "14    2    N' d'ordre Date du dépôt des déclarations Dé...\n",
       "15    3    N' d'ordre Date du dépôt des déclarations Dé...\n",
       "16    1  N' d'ordre Date du dépôt des déclarations Dési...\n",
       "17   20   N' d'ordre Date du dépôt des déclarations Dés...\n",
       "18   18   N' d'ordre Date du dépôt des déclarations Dés...\n",
       "19   19   N' d'ordre Date du dépôt des déclarations Dés..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = pd.DataFrame(gt.items(), columns=['file', 'text'])\n",
    "gt['text'] = gt['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
