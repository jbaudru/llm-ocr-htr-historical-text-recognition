{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c798e7-9579-4c02-88ca-0c57e52c2966",
   "metadata": {},
   "source": [
    "# per-line transcription with LLM & OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069d0fa8-6403-402b-954a-cbc05503eb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import base64\n",
    "import subprocess\n",
    "from IPython.display import display, Image\n",
    "from PIL import Image as PILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f521cad-9da9-4cdf-a63d-f5dd4ca3e4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "import pytesseract\n",
    "import keras_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "857d11aa-8fb9-4f32-a20c-5e418f5154e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = os.path.dirname(os.getcwd()) # Parent directory\n",
    "image_folder = path+'/data/lines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffd293ec-7b82-4145-820e-9e910c7d099d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OpenAI\n",
    "load_dotenv() #get the environment \n",
    "openai_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_client = OpenAI(api_key=openai_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9cc501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "anthropic_client = Anthropic(api_key=anthropic_API_KEY)\n",
    "MODEL_NAME = \"claude-3-5-sonnet-20240620\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4c585-70a5-466a-ac27-f730debebfba",
   "metadata": {},
   "source": [
    "## Read and encode the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e6f97e1-5798-4253-a324-58a38bae7f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b48666f-fd04-4f79-ba1a-8a254e9d81c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        images.append(image)\n",
    "\n",
    "rows = []\n",
    "for image in images:\n",
    "    name = image.split('.')[0]\n",
    "    name_split = name.split('_')[0]\n",
    "    file_name = name_split.split('example')[1]\n",
    "    line_name = name.split('_')[1]\n",
    "    encoded_value = encode_image(image_folder+'/'+image)\n",
    "    rows.append({'file': file_name, 'line': line_name, 'encoded': encoded_value})\n",
    "\n",
    "images_encoded = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c988074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>line</th>\n",
       "      <th>encoded</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/9j/4QZBRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>/9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>/9j/4QYvRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>/9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>/9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>/9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>/9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>/9j/4QWRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>/9j/4QZyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>/9j/4QZRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>/9j/4QZ1RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>/9j/4QVrRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>/9j/4QaFRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QcyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>/9j/4QVORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>/9j/4QX+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>/9j/4QY6RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>/9j/4QaQRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>/9j/4QVWRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>/9j/4QZ3RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>/9j/4QXbRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>/9j/4QaORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>/9j/4QWIRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>/9j/4QWARXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>/9j/4QZwRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>/9j/4QZlRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>/9j/4QV+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>/9j/4QbYRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QbPRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>3_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file  line                                            encoded    id\n",
       "0      1     0  /9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_0\n",
       "1      1     1  /9j/4QZBRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_1\n",
       "2      1     2  /9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_2\n",
       "3      1     3  /9j/4QYvRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_3\n",
       "4      1     4  /9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_4\n",
       "5      1     5  /9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_5\n",
       "6      1     6  /9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_6\n",
       "7      1     7  /9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_7\n",
       "8      1     8  /9j/4QWRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_8\n",
       "9      1     9  /9j/4QZyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_9\n",
       "10     1    10  /9j/4QZRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_10\n",
       "11     1    11  /9j/4QZ1RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_11\n",
       "12     1    12  /9j/4QVrRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_12\n",
       "13     1    13  /9j/4QaFRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_13\n",
       "14     2     0  /9j/4QcyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_0\n",
       "15     2     1  /9j/4QVORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_1\n",
       "16     2     2  /9j/4QX+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_2\n",
       "17     2     3  /9j/4QY6RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_3\n",
       "18     2     4  /9j/4QaQRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_4\n",
       "19     2     5  /9j/4QVWRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_5\n",
       "20     2     6  /9j/4QZ3RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_6\n",
       "21     2     7  /9j/4QXbRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_7\n",
       "22     2     8  /9j/4QaORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_8\n",
       "23     2     9  /9j/4QWIRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_9\n",
       "24     2    10  /9j/4QWARXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_10\n",
       "25     2    11  /9j/4QZwRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_11\n",
       "26     2    12  /9j/4QZlRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_12\n",
       "27     2    13  /9j/4QV+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_13\n",
       "28     2    14  /9j/4QbYRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_14\n",
       "29     3     0  /9j/4QbPRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...   3_0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_encoded['file'] = images_encoded['file'].astype('int')\n",
    "images_encoded['line'] = images_encoded['line'].astype('int')\n",
    "images_encoded = images_encoded.sort_values(by=['file', 'line']).reset_index(drop=True)\n",
    "images_encoded['id'] = images_encoded['file'].astype(str) + '_' + images_encoded['line'].astype(str)\n",
    "images_encoded.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa240d54",
   "metadata": {},
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd51de42-7ecf-4171-88fd-cc78fb803632",
   "metadata": {},
   "source": [
    "## General API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73f51be1-2815-4280-ab50-4a909baf7016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def callOpenAI(prompt, max_tokens=800, base64_image=None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_API_KEY}\"\n",
    "    } \n",
    "    model_vision = \"gpt-4o\"\n",
    "    payload = {\n",
    "        \"model\": model_vision, \n",
    "        \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "            \n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                }\n",
    "            }\n",
    "            ]\n",
    "        }\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    try:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except:\n",
    "        print(response.json()[\"error\"][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6be70b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callAnthropic(prompt, max_tokens=5000, base64_image=None):\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=max_tokens,\n",
    "        system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\", \n",
    "                            \"media_type\": \"image/jpeg\", \n",
    "                            \"data\": base64_image}},\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt,\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.to_dict()[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a94328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callPostProcessing(max_tokens=800, prompt_parameter = None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_API_KEY}\"\n",
    "    } \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"\"\"This is an output from you. Clean it such that we have no separators and no comment from you: {prompt_parameter}\n",
    "                \"\"\"\n",
    "            }\n",
    "            ]\n",
    "        }\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    try:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except:\n",
    "        print(response.json()[\"error\"][\"message\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b44a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this when OpenAI credits are exhausted\n",
    "def callPostProcessing_anthropic(max_tokens=5000, prompt_parameter = None):\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=max_tokens,\n",
    "        system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"\"\"This is an output from you. Clean it such that we have no separators and no comment from you: {prompt_parameter}\n",
    "                \"\"\"\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.to_dict()[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65f775",
   "metadata": {},
   "source": [
    "### Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56c01d37-e85d-45ee-b6c8-9e92b5078e87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/xy/r3gq5vtd7bx6qb966l0fhh9h0000gn/T/ipykernel_63694/818506988.py:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  prompt_complex = \"\"\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "    Recognize the text from the image:\n",
    "    ```plaintext\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_complex = \"\"\"\n",
    "    Context:\n",
    "        It's an old Belgian document. And you're getting one row of a table from it. It's written in French language and the names of the people are domiciles are Belgian.\n",
    "\n",
    "    Structure:\n",
    "        The table is structured with the two-level headers as follows:\n",
    "        [(\"N' d'ordre\", \" \"),\n",
    "                (\"Date du dépot des déclarations\", \" \"),\n",
    "                (\"Désignation des personnes décédées ou absentes.:\", \"Nom.\"),\n",
    "                (\"Désignation des personnes décédées ou absentes.:\", \"Prénoms\"),\n",
    "                (\"Désignation des personnes décédées ou absentes.:\", \"Domiciles\"), \n",
    "                (\"Date du décès ou du judgement d'envoi en possession, en cas d'absence.\", \" \"),\n",
    "                (\"Noms, Prénoms et demeures des parties déclarantes.\", \" \"),\n",
    "                (\"Droits de succession en ligne collatérale et de mutation en ligne directe.\", \"Actif. (2)\"),\n",
    "                (\"Droits de succession en ligne collatérale et de mutation en ligne directe.\", \"Passif. (2)\"),\n",
    "                (\"Droits de succession en ligne collatérale et de mutation en ligne directe.\", \"Restant NET. (2)\"),\n",
    "                (\"Droit de mutation par déces\", \"Valeur des immeubles. (2)\"), \n",
    "                (\"Numéros des déclarations\", \"Primitives.\"),\n",
    "                (\"Numéros des déclarations\", \"Supplémentaires.\"), \n",
    "                (\"Date\", \"de l'expiration du délai de rectification.\"),\n",
    "                (\"Date\", \"de l'exigibilité des droits.\"),\n",
    "                (\"Numéros de la consignation des droits au sommier n' 28\", \" \"),\n",
    "                (\"Recette des droits et amendes.\", \"Date\"),\n",
    "                (\"Recette des droits et amendes.\", \"N^03\"),\n",
    "                (\"Cautionnements. \", \"Numéros de la consignation au sommier n'30\"),\n",
    "                (\"Observations (les déclarations qui figurent à l'état n'413 doivent être émargées en conséquence, dans la présnete colonne.)\", \" \")] \n",
    "\n",
    "        Some image (hence, some rows) may start with \"Arrêté le \\d{2} \\w+ \\d{4}( \\w+)? servais\" or contain notes.\n",
    "\n",
    "    Task:\n",
    "        Recognize the text from the image. Pay attention to reading each word and number correctly. Return the text as you read it and you must read the text from the image since the image contains texts.\n",
    "    ```plaintext \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2bca041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Start processing file 6_1 -------\n",
      "------- Finished processing file 6_1 in 4.5775532722473145 seconds -------\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Load previous progress if available\n",
    "try:\n",
    "    with open('claude_complex_output_progress.json', 'r') as file:\n",
    "        claude_complex_output = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    claude_complex_output = {}\n",
    "\n",
    "# Loop through each unique id\n",
    "# for id in images_encoded['id'].unique():\n",
    "for id in unable_ids_1:\n",
    "    # Check if this ID is already processed (Skip this step if you want to re-process for unable_ids) ----------------\n",
    "    # if id in claude_complex_output:\n",
    "    #     print(f\"Skipping {id}, already processed.\")\n",
    "    #     continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        print(f'------- Start processing file {id} -------')\n",
    "        \n",
    "        # Call OpenAI/Anthropic and post-processing functions\n",
    "        prompt_complex += \"Even if it is hard to read the texts from the image, return as much as you can. You must read something. Do not return an apologetic message.\"\n",
    "        # output = callOpenAI(prompt=prompt_complex, max_tokens=800, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0])\n",
    "        output = callAnthropic(prompt=prompt_complex, max_tokens=800, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0])\n",
    "        output_cleaned = callPostProcessing(prompt_parameter=output)\n",
    "        \n",
    "        # Save the output\n",
    "        claude_complex_output[id] = output_cleaned\n",
    "        \n",
    "        # Save progress after each file\n",
    "        with open('claude_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_complex_output, file)\n",
    "        \n",
    "        print(f'------- Finished processing file {id} in {time.time() - start_time} seconds -------')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {id}: {str(e)}\")\n",
    "        # Save the progress and exit the loop in case of an error\n",
    "        with open('claude_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_complex_output, file)\n",
    "        break  # Exit the loop on error\n",
    "\n",
    "# Once all IDs are processed, save the final result\n",
    "with open('claude_complex_output_final.json', 'w') as file:\n",
    "    json.dump(claude_complex_output, file)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc31c4e8",
   "metadata": {},
   "source": [
    "### Few-shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24130132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'/data/transcription_perline_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95afd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = images_encoded[images_encoded['id'] == '1_1'].encoded.values[0]\n",
    "example2 = images_encoded[images_encoded['id'] == '1_2'].encoded.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c14ff3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_encoded_oneshot = images_encoded[~images_encoded['id'].isin(['1_1'])]\n",
    "images_encoded_twoshot = images_encoded[~images_encoded['id'].isin(['1_1', '1_2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbaa3fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "example1_text = df[df['id'] == '1_1'].text.values[0]\n",
    "example2_text = df[df['id'] == '1_2'].text.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "998fc479",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_texts =  [example1_text, df[df['id'] ==  '1_3'].text.values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b683c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_encoded_extexts = images_encoded[~images_encoded['id'].isin(['1_1', '1_3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d04a03ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_example =  \"\"\"\n",
    "    Recognize the texts from the image like the examples.\n",
    "    ```plaintext\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0bdb0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example1_text or exmple_texts\n",
    "prompt_example_text = f\"\"\"\n",
    "                        The ```plaintext block is the example transcription of the example image you saw:\n",
    "\n",
    "                        Transcription:\n",
    "                        ```plaintext\n",
    "                        {example_texts}\n",
    "                        ```\n",
    "                        Compare what you read initially and the solution key in ```plaintext block. Recreate the content of the table in this image. Only that, no other information from you.\n",
    "\n",
    "                        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "721c10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callOpenAI_example(prompt, example1, example2=None, NExample=1, base64_image=None, max_tokens=5000):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_API_KEY}\"\n",
    "    } \n",
    "    model_vision = \"gpt-4o\"\n",
    "\n",
    "    if NExample == 1:\n",
    "        payload = {\n",
    "            \"model\": model_vision, \n",
    "            \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "                \n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{example1}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": example1_text\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "                ]\n",
    "            }\n",
    "            ],\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    if NExample == 2:\n",
    "               payload = {\n",
    "            \"model\": model_vision, \n",
    "            \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "                \n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{example1}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": example1_text\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{example2}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": example2_text\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "                ]\n",
    "            }\n",
    "            ],\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    try:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except:\n",
    "        print(response.json()[\"error\"][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adc4a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callAnthropic_example(prompt, example1, example2=None, NExample=1, base64_image=None, max_tokens=5000):\n",
    "    if NExample == 1:\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=max_tokens,\n",
    "            system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": example1}},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example1_text,\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt,\n",
    "                        },\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": base64_image}}\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "        \n",
    "    if NExample == 2:\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=max_tokens,\n",
    "            system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": example1}},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example1_text,\n",
    "                        },\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": example2}},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example2_text,\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt,\n",
    "                        },\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": base64_image}}\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "    return response.to_dict()[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "81d26f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 1_0, already processed.\n",
      "Skipping 1_2, already processed.\n",
      "Skipping 1_4, already processed.\n",
      "Skipping 1_5, already processed.\n",
      "Skipping 1_6, already processed.\n",
      "Skipping 1_7, already processed.\n",
      "Skipping 1_8, already processed.\n",
      "Skipping 1_9, already processed.\n",
      "Skipping 1_10, already processed.\n",
      "Skipping 1_11, already processed.\n",
      "Skipping 1_12, already processed.\n",
      "Skipping 1_13, already processed.\n",
      "Skipping 2_0, already processed.\n",
      "Skipping 2_1, already processed.\n",
      "Skipping 2_2, already processed.\n",
      "Skipping 2_3, already processed.\n",
      "Skipping 2_4, already processed.\n",
      "Skipping 2_5, already processed.\n",
      "Skipping 2_6, already processed.\n",
      "Skipping 2_7, already processed.\n",
      "Skipping 2_8, already processed.\n",
      "Skipping 2_9, already processed.\n",
      "Skipping 2_10, already processed.\n",
      "Skipping 2_11, already processed.\n",
      "Skipping 2_12, already processed.\n",
      "Skipping 2_13, already processed.\n",
      "Skipping 2_14, already processed.\n",
      "Skipping 3_0, already processed.\n",
      "Skipping 3_1, already processed.\n",
      "Skipping 3_2, already processed.\n",
      "Skipping 3_3, already processed.\n",
      "Skipping 3_4, already processed.\n",
      "Skipping 3_5, already processed.\n",
      "Skipping 3_6, already processed.\n",
      "Skipping 3_7, already processed.\n",
      "Skipping 3_8, already processed.\n",
      "Skipping 3_9, already processed.\n",
      "Skipping 3_10, already processed.\n",
      "Skipping 3_11, already processed.\n",
      "Skipping 3_12, already processed.\n",
      "Skipping 3_13, already processed.\n",
      "Skipping 4_0, already processed.\n",
      "Skipping 4_1, already processed.\n",
      "Skipping 4_2, already processed.\n",
      "Skipping 4_3, already processed.\n",
      "Skipping 4_4, already processed.\n",
      "Skipping 4_5, already processed.\n",
      "Skipping 4_6, already processed.\n",
      "Skipping 4_7, already processed.\n",
      "Skipping 4_8, already processed.\n",
      "Skipping 4_9, already processed.\n",
      "Skipping 4_10, already processed.\n",
      "Skipping 4_11, already processed.\n",
      "Skipping 4_12, already processed.\n",
      "Skipping 4_13, already processed.\n",
      "Skipping 5_0, already processed.\n",
      "Skipping 5_1, already processed.\n",
      "Skipping 5_2, already processed.\n",
      "Skipping 5_3, already processed.\n",
      "Skipping 5_4, already processed.\n",
      "Skipping 5_5, already processed.\n",
      "Skipping 5_6, already processed.\n",
      "Skipping 5_7, already processed.\n",
      "Skipping 5_8, already processed.\n",
      "Skipping 5_9, already processed.\n",
      "Skipping 5_10, already processed.\n",
      "Skipping 5_11, already processed.\n",
      "Skipping 5_12, already processed.\n",
      "Skipping 5_13, already processed.\n",
      "Skipping 5_14, already processed.\n",
      "Skipping 6_0, already processed.\n",
      "Skipping 6_1, already processed.\n",
      "Skipping 6_2, already processed.\n",
      "Skipping 6_3, already processed.\n",
      "Skipping 6_4, already processed.\n",
      "Skipping 6_5, already processed.\n",
      "Skipping 6_6, already processed.\n",
      "Skipping 6_7, already processed.\n",
      "Skipping 6_8, already processed.\n",
      "Skipping 6_9, already processed.\n",
      "Skipping 6_10, already processed.\n",
      "Skipping 6_11, already processed.\n",
      "Skipping 6_12, already processed.\n",
      "Skipping 6_13, already processed.\n",
      "Skipping 6_14, already processed.\n",
      "Skipping 7_0, already processed.\n",
      "Skipping 7_1, already processed.\n",
      "Skipping 7_2, already processed.\n",
      "Skipping 7_3, already processed.\n",
      "Skipping 7_4, already processed.\n",
      "Skipping 7_5, already processed.\n",
      "Skipping 7_6, already processed.\n",
      "Skipping 7_7, already processed.\n",
      "Skipping 7_8, already processed.\n",
      "Skipping 7_9, already processed.\n",
      "Skipping 7_10, already processed.\n",
      "Skipping 7_11, already processed.\n",
      "Skipping 7_12, already processed.\n",
      "Skipping 7_13, already processed.\n",
      "Skipping 8_0, already processed.\n",
      "Skipping 8_1, already processed.\n",
      "Skipping 8_2, already processed.\n",
      "Skipping 8_3, already processed.\n",
      "Skipping 8_4, already processed.\n",
      "Skipping 8_5, already processed.\n",
      "Skipping 8_6, already processed.\n",
      "Skipping 8_7, already processed.\n",
      "Skipping 8_8, already processed.\n",
      "Skipping 8_9, already processed.\n",
      "Skipping 8_10, already processed.\n",
      "Skipping 8_11, already processed.\n",
      "Skipping 8_12, already processed.\n",
      "Skipping 8_13, already processed.\n",
      "Skipping 9_0, already processed.\n",
      "Skipping 9_1, already processed.\n",
      "Skipping 9_2, already processed.\n",
      "Skipping 9_3, already processed.\n",
      "Skipping 9_4, already processed.\n",
      "Skipping 9_5, already processed.\n",
      "Skipping 9_6, already processed.\n",
      "Skipping 9_7, already processed.\n",
      "Skipping 9_8, already processed.\n",
      "Skipping 9_9, already processed.\n",
      "Skipping 9_10, already processed.\n",
      "Skipping 9_11, already processed.\n",
      "Skipping 9_12, already processed.\n",
      "Skipping 9_13, already processed.\n",
      "Skipping 10_0, already processed.\n",
      "Skipping 10_1, already processed.\n",
      "Skipping 10_2, already processed.\n",
      "Skipping 10_3, already processed.\n",
      "Skipping 10_4, already processed.\n",
      "Skipping 10_5, already processed.\n",
      "Skipping 10_6, already processed.\n",
      "Skipping 10_7, already processed.\n",
      "Skipping 10_8, already processed.\n",
      "Skipping 10_9, already processed.\n",
      "Skipping 10_10, already processed.\n",
      "Skipping 10_11, already processed.\n",
      "Skipping 10_12, already processed.\n",
      "Skipping 10_13, already processed.\n",
      "Skipping 11_0, already processed.\n",
      "Skipping 11_1, already processed.\n",
      "Skipping 11_2, already processed.\n",
      "Skipping 11_3, already processed.\n",
      "Skipping 11_4, already processed.\n",
      "Skipping 11_5, already processed.\n",
      "Skipping 11_6, already processed.\n",
      "Skipping 11_7, already processed.\n",
      "Skipping 11_8, already processed.\n",
      "Skipping 11_9, already processed.\n",
      "Skipping 11_10, already processed.\n",
      "Skipping 11_11, already processed.\n",
      "Skipping 11_12, already processed.\n",
      "Skipping 11_13, already processed.\n",
      "Skipping 12_0, already processed.\n",
      "Skipping 12_1, already processed.\n",
      "Skipping 12_2, already processed.\n",
      "Skipping 12_3, already processed.\n",
      "Skipping 12_4, already processed.\n",
      "Skipping 12_5, already processed.\n",
      "Skipping 12_6, already processed.\n",
      "Skipping 12_7, already processed.\n",
      "Skipping 12_8, already processed.\n",
      "Skipping 12_9, already processed.\n",
      "Skipping 12_10, already processed.\n",
      "Skipping 12_11, already processed.\n",
      "Skipping 12_12, already processed.\n",
      "Skipping 12_13, already processed.\n",
      "Skipping 13_0, already processed.\n",
      "Skipping 13_1, already processed.\n",
      "Skipping 13_2, already processed.\n",
      "Skipping 13_3, already processed.\n",
      "Skipping 13_4, already processed.\n",
      "Skipping 13_5, already processed.\n",
      "Skipping 13_6, already processed.\n",
      "Skipping 13_7, already processed.\n",
      "Skipping 13_8, already processed.\n",
      "Skipping 13_9, already processed.\n",
      "Skipping 13_10, already processed.\n",
      "Skipping 13_11, already processed.\n",
      "Skipping 13_12, already processed.\n",
      "Skipping 13_13, already processed.\n",
      "Skipping 14_0, already processed.\n",
      "Skipping 14_1, already processed.\n",
      "Skipping 14_2, already processed.\n",
      "Skipping 14_3, already processed.\n",
      "Skipping 14_4, already processed.\n",
      "Skipping 14_5, already processed.\n",
      "Skipping 14_6, already processed.\n",
      "Skipping 14_7, already processed.\n",
      "Skipping 14_8, already processed.\n",
      "Skipping 14_9, already processed.\n",
      "Skipping 14_10, already processed.\n",
      "Skipping 14_11, already processed.\n",
      "Skipping 14_12, already processed.\n",
      "Skipping 14_13, already processed.\n",
      "Skipping 15_0, already processed.\n",
      "Skipping 15_1, already processed.\n",
      "Skipping 15_2, already processed.\n",
      "Skipping 15_3, already processed.\n",
      "Skipping 15_4, already processed.\n",
      "Skipping 15_5, already processed.\n",
      "Skipping 15_6, already processed.\n",
      "Skipping 15_7, already processed.\n",
      "Skipping 15_8, already processed.\n",
      "Skipping 15_9, already processed.\n",
      "Skipping 15_10, already processed.\n",
      "Skipping 15_11, already processed.\n",
      "Skipping 15_12, already processed.\n",
      "------- Start processing file 15_13 -------\n",
      "------- Finished processing file 15_13 in 5.94258189201355 seconds -------\n",
      "------- Start processing file 16_0 -------\n",
      "------- Finished processing file 16_0 in 21.157794713974 seconds -------\n",
      "------- Start processing file 16_1 -------\n",
      "------- Finished processing file 16_1 in 3.9067039489746094 seconds -------\n",
      "------- Start processing file 16_2 -------\n",
      "------- Finished processing file 16_2 in 4.106365203857422 seconds -------\n",
      "------- Start processing file 16_3 -------\n",
      "------- Finished processing file 16_3 in 5.1054980754852295 seconds -------\n",
      "------- Start processing file 16_4 -------\n",
      "------- Finished processing file 16_4 in 2.8676791191101074 seconds -------\n",
      "------- Start processing file 16_5 -------\n",
      "------- Finished processing file 16_5 in 2.6888859272003174 seconds -------\n",
      "------- Start processing file 16_6 -------\n",
      "------- Finished processing file 16_6 in 3.4551119804382324 seconds -------\n",
      "------- Start processing file 16_7 -------\n",
      "------- Finished processing file 16_7 in 3.0728671550750732 seconds -------\n",
      "------- Start processing file 16_8 -------\n",
      "------- Finished processing file 16_8 in 5.629395008087158 seconds -------\n",
      "------- Start processing file 16_9 -------\n",
      "------- Finished processing file 16_9 in 3.0722429752349854 seconds -------\n",
      "------- Start processing file 16_10 -------\n",
      "------- Finished processing file 16_10 in 3.3456568717956543 seconds -------\n",
      "------- Start processing file 16_11 -------\n",
      "------- Finished processing file 16_11 in 4.203572034835815 seconds -------\n",
      "------- Start processing file 16_12 -------\n",
      "------- Finished processing file 16_12 in 4.543591022491455 seconds -------\n",
      "------- Start processing file 16_13 -------\n",
      "------- Finished processing file 16_13 in 24.160643815994263 seconds -------\n",
      "------- Start processing file 17_0 -------\n",
      "------- Finished processing file 17_0 in 19.759528875350952 seconds -------\n",
      "------- Start processing file 17_1 -------\n",
      "------- Finished processing file 17_1 in 2.561187267303467 seconds -------\n",
      "------- Start processing file 17_2 -------\n",
      "------- Finished processing file 17_2 in 3.480400800704956 seconds -------\n",
      "------- Start processing file 17_3 -------\n",
      "------- Finished processing file 17_3 in 8.801753044128418 seconds -------\n",
      "------- Start processing file 17_4 -------\n",
      "------- Finished processing file 17_4 in 3.178851842880249 seconds -------\n",
      "------- Start processing file 17_5 -------\n",
      "------- Finished processing file 17_5 in 3.78898286819458 seconds -------\n",
      "------- Start processing file 17_6 -------\n",
      "------- Finished processing file 17_6 in 6.5768842697143555 seconds -------\n",
      "------- Start processing file 17_7 -------\n",
      "------- Finished processing file 17_7 in 4.889751672744751 seconds -------\n",
      "------- Start processing file 17_8 -------\n",
      "------- Finished processing file 17_8 in 2.7756271362304688 seconds -------\n",
      "------- Start processing file 17_9 -------\n",
      "------- Finished processing file 17_9 in 7.057153940200806 seconds -------\n",
      "------- Start processing file 17_10 -------\n",
      "------- Finished processing file 17_10 in 3.3230040073394775 seconds -------\n",
      "------- Start processing file 17_11 -------\n",
      "------- Finished processing file 17_11 in 3.6356852054595947 seconds -------\n",
      "------- Start processing file 17_12 -------\n",
      "------- Finished processing file 17_12 in 4.312853097915649 seconds -------\n",
      "------- Start processing file 17_13 -------\n",
      "------- Finished processing file 17_13 in 14.430537939071655 seconds -------\n",
      "------- Start processing file 18_0 -------\n",
      "------- Finished processing file 18_0 in 22.698765993118286 seconds -------\n",
      "------- Start processing file 18_1 -------\n",
      "------- Finished processing file 18_1 in 4.679064989089966 seconds -------\n",
      "------- Start processing file 18_2 -------\n",
      "------- Finished processing file 18_2 in 3.034050941467285 seconds -------\n",
      "------- Start processing file 18_3 -------\n",
      "------- Finished processing file 18_3 in 3.890913963317871 seconds -------\n",
      "------- Start processing file 18_4 -------\n",
      "------- Finished processing file 18_4 in 5.527997255325317 seconds -------\n",
      "------- Start processing file 18_5 -------\n",
      "------- Finished processing file 18_5 in 2.4563241004943848 seconds -------\n",
      "------- Start processing file 18_6 -------\n",
      "------- Finished processing file 18_6 in 5.429161071777344 seconds -------\n",
      "------- Start processing file 18_7 -------\n",
      "------- Finished processing file 18_7 in 4.493053197860718 seconds -------\n",
      "------- Start processing file 18_8 -------\n",
      "------- Finished processing file 18_8 in 4.743189096450806 seconds -------\n",
      "------- Start processing file 18_9 -------\n",
      "------- Finished processing file 18_9 in 3.406776189804077 seconds -------\n",
      "------- Start processing file 18_10 -------\n",
      "------- Finished processing file 18_10 in 3.740316867828369 seconds -------\n",
      "------- Start processing file 18_11 -------\n",
      "------- Finished processing file 18_11 in 3.7884230613708496 seconds -------\n",
      "------- Start processing file 18_12 -------\n",
      "------- Finished processing file 18_12 in 3.582716226577759 seconds -------\n",
      "------- Start processing file 18_13 -------\n",
      "------- Finished processing file 18_13 in 5.4292638301849365 seconds -------\n",
      "------- Start processing file 19_0 -------\n",
      "------- Finished processing file 19_0 in 27.38236904144287 seconds -------\n",
      "------- Start processing file 19_1 -------\n",
      "------- Finished processing file 19_1 in 5.07450795173645 seconds -------\n",
      "------- Start processing file 19_2 -------\n",
      "------- Finished processing file 19_2 in 4.918034076690674 seconds -------\n",
      "------- Start processing file 19_3 -------\n",
      "------- Finished processing file 19_3 in 2.516818046569824 seconds -------\n",
      "------- Start processing file 19_4 -------\n",
      "------- Finished processing file 19_4 in 3.219069004058838 seconds -------\n",
      "------- Start processing file 19_5 -------\n",
      "------- Finished processing file 19_5 in 3.270066976547241 seconds -------\n",
      "------- Start processing file 19_6 -------\n",
      "------- Finished processing file 19_6 in 5.635875225067139 seconds -------\n",
      "------- Start processing file 19_7 -------\n",
      "------- Finished processing file 19_7 in 3.2638959884643555 seconds -------\n",
      "------- Start processing file 19_8 -------\n",
      "------- Finished processing file 19_8 in 4.202173948287964 seconds -------\n",
      "------- Start processing file 19_9 -------\n",
      "------- Finished processing file 19_9 in 9.227932929992676 seconds -------\n",
      "------- Start processing file 19_10 -------\n",
      "------- Finished processing file 19_10 in 2.456164836883545 seconds -------\n",
      "------- Start processing file 19_11 -------\n",
      "------- Finished processing file 19_11 in 5.117528915405273 seconds -------\n",
      "------- Start processing file 19_12 -------\n",
      "------- Finished processing file 19_12 in 4.096599102020264 seconds -------\n",
      "------- Start processing file 19_13 -------\n",
      "------- Finished processing file 19_13 in 7.130596876144409 seconds -------\n",
      "------- Start processing file 20_0 -------\n",
      "------- Finished processing file 20_0 in 14.57844614982605 seconds -------\n",
      "------- Start processing file 20_1 -------\n",
      "------- Finished processing file 20_1 in 7.235894680023193 seconds -------\n",
      "------- Start processing file 20_2 -------\n",
      "------- Finished processing file 20_2 in 3.926284074783325 seconds -------\n",
      "------- Start processing file 20_3 -------\n",
      "------- Finished processing file 20_3 in 4.440130710601807 seconds -------\n",
      "------- Start processing file 20_4 -------\n",
      "------- Finished processing file 20_4 in 2.8315839767456055 seconds -------\n",
      "------- Start processing file 20_5 -------\n",
      "------- Finished processing file 20_5 in 5.014915704727173 seconds -------\n",
      "------- Start processing file 20_6 -------\n",
      "------- Finished processing file 20_6 in 4.401311159133911 seconds -------\n",
      "------- Start processing file 20_7 -------\n",
      "------- Finished processing file 20_7 in 3.838923931121826 seconds -------\n",
      "------- Start processing file 20_8 -------\n",
      "------- Finished processing file 20_8 in 2.8077399730682373 seconds -------\n",
      "------- Start processing file 20_9 -------\n",
      "------- Finished processing file 20_9 in 8.923868894577026 seconds -------\n",
      "------- Start processing file 20_10 -------\n",
      "------- Finished processing file 20_10 in 4.090374946594238 seconds -------\n",
      "------- Start processing file 20_11 -------\n",
      "------- Finished processing file 20_11 in 3.451416015625 seconds -------\n",
      "------- Start processing file 20_12 -------\n",
      "------- Finished processing file 20_12 in 5.149479866027832 seconds -------\n",
      "------- Start processing file 20_13 -------\n",
      "------- Finished processing file 20_13 in 6.9399333000183105 seconds -------\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Load previous progress if available\n",
    "try:\n",
    "    with open('gpt_two_text_example_output_progress.json', 'r') as file:\n",
    "        gpt_two_text_example_output = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    gpt_two_text_example_output = {}\n",
    "\n",
    "# Loop through each unique id\n",
    "for id in images_encoded_extexts['id'].unique():\n",
    "# for id in unable_ids:\n",
    "    # Check if this ID is already processed (Skip this step if you want to re-process for unable_ids) ----------------\n",
    "    if id in gpt_two_text_example_output:\n",
    "        print(f\"Skipping {id}, already processed.\")\n",
    "        continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        print(f'------- Start processing file {id} -------')\n",
    "        \n",
    "        # Call OpenAI/Anthropic and post-processing functions\n",
    "        prompt_example_text += \"Even if it is hard to read the texts from the image, return as much as you can. You must read something. Do not return an apologetic message.\"\n",
    "        output = callOpenAI(prompt=prompt_example_text, base64_image=images_encoded_extexts[(images_encoded_extexts['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        # output = callAnthropic(prompt=prompt_example_text, base64_image=images_encoded_oneshot[(images_encoded_oneshot['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        output_cleaned = callPostProcessing_anthropic(prompt_parameter=output)\n",
    "        \n",
    "        # Save the output\n",
    "        gpt_two_text_example_output[id] = output_cleaned\n",
    "        \n",
    "        # Save progress after each file\n",
    "        with open('gpt_two_text_example_output_progress.json', 'w') as file:\n",
    "            json.dump(gpt_two_text_example_output, file)\n",
    "        \n",
    "        print(f'------- Finished processing file {id} in {time.time() - start_time} seconds -------')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {id}: {str(e)}\")\n",
    "        # Save the progress and exit the loop in case of an error\n",
    "        with open('gpt_two_text_example_output_progress.json', 'w') as file:\n",
    "            json.dump(gpt_two_text_example_output, file)\n",
    "        break  # Exit the loop on error\n",
    "\n",
    "# Once all IDs are processed, save the final result\n",
    "with open('gpt_two_text_example_output_final.json', 'w') as file:\n",
    "    json.dump(gpt_two_text_example_output, file)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a122d9",
   "metadata": {},
   "source": [
    "### Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab11e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt_simple = pd.read_csv(path+'/results/postprocessed/gpt_perline_output.csv')\n",
    "# claude_simple =  pd.read_csv(path+'/results/postprocessed/claude_perline_output.csv')\n",
    "gpt_complex = pd.read_csv(path+'/results/postprocessed/gpt_complex_perline_output.csv')\n",
    "claude_complex =  pd.read_csv(path+'/results/postprocessed/claude_complex_perline_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "851ef214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Start processing file 1_0 -------\n",
      "------- Finished processing file 1_0 in 14.292288064956665 seconds -------\n",
      "------- Start processing file 1_1 -------\n",
      "------- Finished processing file 1_1 in 4.080657958984375 seconds -------\n",
      "------- Start processing file 1_2 -------\n",
      "------- Finished processing file 1_2 in 3.7222018241882324 seconds -------\n",
      "------- Start processing file 1_3 -------\n",
      "------- Finished processing file 1_3 in 3.800942897796631 seconds -------\n",
      "------- Start processing file 1_4 -------\n",
      "------- Finished processing file 1_4 in 4.857337236404419 seconds -------\n",
      "------- Start processing file 1_5 -------\n",
      "------- Finished processing file 1_5 in 2.8822901248931885 seconds -------\n",
      "------- Start processing file 1_6 -------\n",
      "------- Finished processing file 1_6 in 2.5544300079345703 seconds -------\n",
      "------- Start processing file 1_7 -------\n",
      "------- Finished processing file 1_7 in 2.7006161212921143 seconds -------\n",
      "------- Start processing file 1_8 -------\n",
      "------- Finished processing file 1_8 in 5.392026901245117 seconds -------\n",
      "------- Start processing file 1_9 -------\n",
      "------- Finished processing file 1_9 in 8.143219947814941 seconds -------\n",
      "------- Start processing file 1_10 -------\n",
      "------- Finished processing file 1_10 in 3.835000991821289 seconds -------\n",
      "------- Start processing file 1_11 -------\n",
      "------- Finished processing file 1_11 in 4.131396770477295 seconds -------\n",
      "------- Start processing file 1_12 -------\n",
      "------- Finished processing file 1_12 in 4.059167146682739 seconds -------\n",
      "------- Start processing file 1_13 -------\n",
      "------- Finished processing file 1_13 in 4.507644891738892 seconds -------\n",
      "------- Start processing file 2_0 -------\n",
      "------- Finished processing file 2_0 in 24.782336950302124 seconds -------\n",
      "------- Start processing file 2_1 -------\n",
      "------- Finished processing file 2_1 in 2.3025662899017334 seconds -------\n",
      "------- Start processing file 2_2 -------\n",
      "------- Finished processing file 2_2 in 3.4426071643829346 seconds -------\n",
      "------- Start processing file 2_3 -------\n",
      "------- Finished processing file 2_3 in 5.006137132644653 seconds -------\n",
      "------- Start processing file 2_4 -------\n",
      "------- Finished processing file 2_4 in 3.9956889152526855 seconds -------\n",
      "------- Start processing file 2_5 -------\n",
      "------- Finished processing file 2_5 in 3.682460069656372 seconds -------\n",
      "------- Start processing file 2_6 -------\n",
      "------- Finished processing file 2_6 in 4.404282808303833 seconds -------\n",
      "------- Start processing file 2_7 -------\n",
      "------- Finished processing file 2_7 in 5.307238340377808 seconds -------\n",
      "------- Start processing file 2_8 -------\n",
      "------- Finished processing file 2_8 in 5.141959190368652 seconds -------\n",
      "------- Start processing file 2_9 -------\n",
      "------- Finished processing file 2_9 in 2.644336223602295 seconds -------\n",
      "------- Start processing file 2_10 -------\n",
      "------- Finished processing file 2_10 in 2.673637866973877 seconds -------\n",
      "------- Start processing file 2_11 -------\n",
      "------- Finished processing file 2_11 in 3.8906359672546387 seconds -------\n",
      "------- Start processing file 2_12 -------\n",
      "------- Finished processing file 2_12 in 4.024163007736206 seconds -------\n",
      "------- Start processing file 2_13 -------\n",
      "------- Finished processing file 2_13 in 2.7351949214935303 seconds -------\n",
      "------- Start processing file 2_14 -------\n",
      "------- Finished processing file 2_14 in 4.3023388385772705 seconds -------\n",
      "------- Start processing file 3_0 -------\n",
      "------- Finished processing file 3_0 in 17.156383991241455 seconds -------\n",
      "------- Start processing file 3_1 -------\n",
      "------- Finished processing file 3_1 in 3.836911916732788 seconds -------\n",
      "------- Start processing file 3_2 -------\n",
      "------- Finished processing file 3_2 in 5.015352964401245 seconds -------\n",
      "------- Start processing file 3_3 -------\n",
      "------- Finished processing file 3_3 in 3.686422109603882 seconds -------\n",
      "------- Start processing file 3_4 -------\n",
      "------- Finished processing file 3_4 in 3.198350191116333 seconds -------\n",
      "------- Start processing file 3_5 -------\n",
      "------- Finished processing file 3_5 in 4.377466201782227 seconds -------\n",
      "------- Start processing file 3_6 -------\n",
      "------- Finished processing file 3_6 in 4.857439994812012 seconds -------\n",
      "------- Start processing file 3_7 -------\n",
      "------- Finished processing file 3_7 in 4.255990028381348 seconds -------\n",
      "------- Start processing file 3_8 -------\n",
      "------- Finished processing file 3_8 in 4.932600021362305 seconds -------\n",
      "------- Start processing file 3_9 -------\n",
      "------- Finished processing file 3_9 in 2.6447510719299316 seconds -------\n",
      "------- Start processing file 3_10 -------\n",
      "------- Finished processing file 3_10 in 5.632396221160889 seconds -------\n",
      "------- Start processing file 3_11 -------\n",
      "------- Finished processing file 3_11 in 9.7413330078125 seconds -------\n",
      "------- Start processing file 3_12 -------\n",
      "------- Finished processing file 3_12 in 5.309643030166626 seconds -------\n",
      "------- Start processing file 3_13 -------\n",
      "------- Finished processing file 3_13 in 2.9689300060272217 seconds -------\n",
      "------- Start processing file 4_0 -------\n",
      "------- Finished processing file 4_0 in 16.182488918304443 seconds -------\n",
      "------- Start processing file 4_1 -------\n",
      "------- Finished processing file 4_1 in 2.3116819858551025 seconds -------\n",
      "------- Start processing file 4_2 -------\n",
      "------- Finished processing file 4_2 in 4.853729009628296 seconds -------\n",
      "------- Start processing file 4_3 -------\n",
      "------- Finished processing file 4_3 in 4.812483072280884 seconds -------\n",
      "------- Start processing file 4_4 -------\n",
      "------- Finished processing file 4_4 in 3.8951330184936523 seconds -------\n",
      "------- Start processing file 4_5 -------\n",
      "------- Finished processing file 4_5 in 7.472905874252319 seconds -------\n",
      "------- Start processing file 4_6 -------\n",
      "------- Finished processing file 4_6 in 5.060561895370483 seconds -------\n",
      "------- Start processing file 4_7 -------\n",
      "------- Finished processing file 4_7 in 3.4361259937286377 seconds -------\n",
      "------- Start processing file 4_8 -------\n",
      "------- Finished processing file 4_8 in 2.3542799949645996 seconds -------\n",
      "------- Start processing file 4_9 -------\n",
      "------- Finished processing file 4_9 in 3.8909261226654053 seconds -------\n",
      "------- Start processing file 4_10 -------\n",
      "------- Finished processing file 4_10 in 2.9734511375427246 seconds -------\n",
      "------- Start processing file 4_11 -------\n",
      "------- Finished processing file 4_11 in 4.996173858642578 seconds -------\n",
      "------- Start processing file 4_12 -------\n",
      "------- Finished processing file 4_12 in 4.933241844177246 seconds -------\n",
      "------- Start processing file 4_13 -------\n",
      "------- Finished processing file 4_13 in 3.075183868408203 seconds -------\n",
      "------- Start processing file 5_0 -------\n",
      "------- Finished processing file 5_0 in 13.070978164672852 seconds -------\n",
      "------- Start processing file 5_1 -------\n",
      "------- Finished processing file 5_1 in 1.8178961277008057 seconds -------\n",
      "------- Start processing file 5_2 -------\n",
      "------- Finished processing file 5_2 in 3.845918893814087 seconds -------\n",
      "------- Start processing file 5_3 -------\n",
      "------- Finished processing file 5_3 in 4.254698038101196 seconds -------\n",
      "------- Start processing file 5_4 -------\n",
      "------- Finished processing file 5_4 in 3.4265449047088623 seconds -------\n",
      "------- Start processing file 5_5 -------\n",
      "------- Finished processing file 5_5 in 3.484309196472168 seconds -------\n",
      "------- Start processing file 5_6 -------\n",
      "------- Finished processing file 5_6 in 3.7221181392669678 seconds -------\n",
      "------- Start processing file 5_7 -------\n",
      "------- Finished processing file 5_7 in 2.990062713623047 seconds -------\n",
      "------- Start processing file 5_8 -------\n",
      "------- Finished processing file 5_8 in 4.138896226882935 seconds -------\n",
      "------- Start processing file 5_9 -------\n",
      "------- Finished processing file 5_9 in 4.3847880363464355 seconds -------\n",
      "------- Start processing file 5_10 -------\n",
      "------- Finished processing file 5_10 in 5.443472146987915 seconds -------\n",
      "------- Start processing file 5_11 -------\n",
      "------- Finished processing file 5_11 in 4.535132884979248 seconds -------\n",
      "------- Start processing file 5_12 -------\n",
      "------- Finished processing file 5_12 in 6.487512111663818 seconds -------\n",
      "------- Start processing file 5_13 -------\n",
      "------- Finished processing file 5_13 in 3.7703030109405518 seconds -------\n",
      "------- Start processing file 5_14 -------\n",
      "------- Finished processing file 5_14 in 4.100219964981079 seconds -------\n",
      "------- Start processing file 6_0 -------\n",
      "------- Finished processing file 6_0 in 14.487874269485474 seconds -------\n",
      "------- Start processing file 6_1 -------\n",
      "------- Finished processing file 6_1 in 3.383664131164551 seconds -------\n",
      "------- Start processing file 6_2 -------\n",
      "------- Finished processing file 6_2 in 6.374984264373779 seconds -------\n",
      "------- Start processing file 6_3 -------\n",
      "------- Finished processing file 6_3 in 3.1452269554138184 seconds -------\n",
      "------- Start processing file 6_4 -------\n",
      "------- Finished processing file 6_4 in 3.173130989074707 seconds -------\n",
      "------- Start processing file 6_5 -------\n",
      "------- Finished processing file 6_5 in 4.09555196762085 seconds -------\n",
      "------- Start processing file 6_6 -------\n",
      "------- Finished processing file 6_6 in 3.0738422870635986 seconds -------\n",
      "------- Start processing file 6_7 -------\n",
      "------- Finished processing file 6_7 in 3.7569799423217773 seconds -------\n",
      "------- Start processing file 6_8 -------\n",
      "------- Finished processing file 6_8 in 3.412485122680664 seconds -------\n",
      "------- Start processing file 6_9 -------\n",
      "------- Finished processing file 6_9 in 2.7617347240448 seconds -------\n",
      "------- Start processing file 6_10 -------\n",
      "------- Finished processing file 6_10 in 3.741211175918579 seconds -------\n",
      "------- Start processing file 6_11 -------\n",
      "------- Finished processing file 6_11 in 3.115867853164673 seconds -------\n",
      "------- Start processing file 6_12 -------\n",
      "------- Finished processing file 6_12 in 7.986600160598755 seconds -------\n",
      "------- Start processing file 6_13 -------\n",
      "------- Finished processing file 6_13 in 2.9722208976745605 seconds -------\n",
      "------- Start processing file 6_14 -------\n",
      "------- Finished processing file 6_14 in 5.169097900390625 seconds -------\n",
      "------- Start processing file 7_0 -------\n",
      "------- Finished processing file 7_0 in 15.822429895401001 seconds -------\n",
      "------- Start processing file 7_1 -------\n",
      "------- Finished processing file 7_1 in 3.8713200092315674 seconds -------\n",
      "------- Start processing file 7_2 -------\n",
      "------- Finished processing file 7_2 in 4.4904961585998535 seconds -------\n",
      "------- Start processing file 7_3 -------\n",
      "------- Finished processing file 7_3 in 3.2550389766693115 seconds -------\n",
      "------- Start processing file 7_4 -------\n",
      "------- Finished processing file 7_4 in 3.930737257003784 seconds -------\n",
      "------- Start processing file 7_5 -------\n",
      "------- Finished processing file 7_5 in 3.089859962463379 seconds -------\n",
      "------- Start processing file 7_6 -------\n",
      "------- Finished processing file 7_6 in 2.859560251235962 seconds -------\n",
      "------- Start processing file 7_7 -------\n",
      "------- Finished processing file 7_7 in 2.673551082611084 seconds -------\n",
      "------- Start processing file 7_8 -------\n",
      "------- Finished processing file 7_8 in 3.7802882194519043 seconds -------\n",
      "------- Start processing file 7_9 -------\n",
      "------- Finished processing file 7_9 in 2.384171962738037 seconds -------\n",
      "------- Start processing file 7_10 -------\n",
      "------- Finished processing file 7_10 in 2.7690517902374268 seconds -------\n",
      "------- Start processing file 7_11 -------\n",
      "------- Finished processing file 7_11 in 2.4256529808044434 seconds -------\n",
      "------- Start processing file 7_12 -------\n",
      "------- Finished processing file 7_12 in 6.34934401512146 seconds -------\n",
      "------- Start processing file 7_13 -------\n",
      "------- Finished processing file 7_13 in 3.8599178791046143 seconds -------\n",
      "------- Start processing file 8_0 -------\n",
      "------- Finished processing file 8_0 in 16.177182912826538 seconds -------\n",
      "------- Start processing file 8_1 -------\n",
      "------- Finished processing file 8_1 in 3.4178969860076904 seconds -------\n",
      "------- Start processing file 8_2 -------\n",
      "------- Finished processing file 8_2 in 3.8724498748779297 seconds -------\n",
      "------- Start processing file 8_3 -------\n",
      "------- Finished processing file 8_3 in 4.718119144439697 seconds -------\n",
      "------- Start processing file 8_4 -------\n",
      "------- Finished processing file 8_4 in 4.0422279834747314 seconds -------\n",
      "------- Start processing file 8_5 -------\n",
      "------- Finished processing file 8_5 in 7.129083156585693 seconds -------\n",
      "------- Start processing file 8_6 -------\n",
      "------- Finished processing file 8_6 in 3.744751214981079 seconds -------\n",
      "------- Start processing file 8_7 -------\n",
      "------- Finished processing file 8_7 in 3.9259331226348877 seconds -------\n",
      "------- Start processing file 8_8 -------\n",
      "------- Finished processing file 8_8 in 7.643607139587402 seconds -------\n",
      "------- Start processing file 8_9 -------\n",
      "------- Finished processing file 8_9 in 3.420839309692383 seconds -------\n",
      "------- Start processing file 8_10 -------\n",
      "------- Finished processing file 8_10 in 3.6880834102630615 seconds -------\n",
      "------- Start processing file 8_11 -------\n",
      "------- Finished processing file 8_11 in 4.009948253631592 seconds -------\n",
      "------- Start processing file 8_12 -------\n",
      "------- Finished processing file 8_12 in 2.2770466804504395 seconds -------\n",
      "------- Start processing file 8_13 -------\n",
      "------- Finished processing file 8_13 in 3.316261053085327 seconds -------\n",
      "------- Start processing file 9_0 -------\n",
      "------- Finished processing file 9_0 in 11.44200086593628 seconds -------\n",
      "------- Start processing file 9_1 -------\n",
      "------- Finished processing file 9_1 in 3.186462879180908 seconds -------\n",
      "------- Start processing file 9_2 -------\n",
      "------- Finished processing file 9_2 in 4.847403049468994 seconds -------\n",
      "------- Start processing file 9_3 -------\n",
      "------- Finished processing file 9_3 in 2.2909600734710693 seconds -------\n",
      "------- Start processing file 9_4 -------\n",
      "------- Finished processing file 9_4 in 2.536395788192749 seconds -------\n",
      "------- Start processing file 9_5 -------\n",
      "------- Finished processing file 9_5 in 4.709357023239136 seconds -------\n",
      "------- Start processing file 9_6 -------\n",
      "------- Finished processing file 9_6 in 4.283362865447998 seconds -------\n",
      "------- Start processing file 9_7 -------\n",
      "------- Finished processing file 9_7 in 3.175697088241577 seconds -------\n",
      "------- Start processing file 9_8 -------\n",
      "------- Finished processing file 9_8 in 3.293510913848877 seconds -------\n",
      "------- Start processing file 9_9 -------\n",
      "------- Finished processing file 9_9 in 9.406012058258057 seconds -------\n",
      "------- Start processing file 9_10 -------\n",
      "------- Finished processing file 9_10 in 2.5533080101013184 seconds -------\n",
      "------- Start processing file 9_11 -------\n",
      "------- Finished processing file 9_11 in 3.6922781467437744 seconds -------\n",
      "------- Start processing file 9_12 -------\n",
      "------- Finished processing file 9_12 in 4.963225841522217 seconds -------\n",
      "------- Start processing file 9_13 -------\n",
      "------- Finished processing file 9_13 in 2.738309860229492 seconds -------\n",
      "------- Start processing file 10_0 -------\n",
      "------- Finished processing file 10_0 in 13.519537210464478 seconds -------\n",
      "------- Start processing file 10_1 -------\n",
      "------- Finished processing file 10_1 in 2.9436228275299072 seconds -------\n",
      "------- Start processing file 10_2 -------\n",
      "------- Finished processing file 10_2 in 4.373887062072754 seconds -------\n",
      "------- Start processing file 10_3 -------\n",
      "------- Finished processing file 10_3 in 2.387533187866211 seconds -------\n",
      "------- Start processing file 10_4 -------\n",
      "------- Finished processing file 10_4 in 4.103327989578247 seconds -------\n",
      "------- Start processing file 10_5 -------\n",
      "------- Finished processing file 10_5 in 2.594688892364502 seconds -------\n",
      "------- Start processing file 10_6 -------\n",
      "------- Finished processing file 10_6 in 5.6579718589782715 seconds -------\n",
      "------- Start processing file 10_7 -------\n",
      "------- Finished processing file 10_7 in 3.3246657848358154 seconds -------\n",
      "------- Start processing file 10_8 -------\n",
      "------- Finished processing file 10_8 in 3.216653823852539 seconds -------\n",
      "------- Start processing file 10_9 -------\n",
      "------- Finished processing file 10_9 in 3.020280122756958 seconds -------\n",
      "------- Start processing file 10_10 -------\n",
      "------- Finished processing file 10_10 in 3.572442054748535 seconds -------\n",
      "------- Start processing file 10_11 -------\n",
      "------- Finished processing file 10_11 in 3.280470132827759 seconds -------\n",
      "------- Start processing file 10_12 -------\n",
      "------- Finished processing file 10_12 in 3.6762290000915527 seconds -------\n",
      "------- Start processing file 10_13 -------\n",
      "------- Finished processing file 10_13 in 3.180532932281494 seconds -------\n",
      "------- Start processing file 11_0 -------\n",
      "------- Finished processing file 11_0 in 15.365226030349731 seconds -------\n",
      "------- Start processing file 11_1 -------\n",
      "------- Finished processing file 11_1 in 2.371924877166748 seconds -------\n",
      "------- Start processing file 11_2 -------\n",
      "------- Finished processing file 11_2 in 2.3139100074768066 seconds -------\n",
      "------- Start processing file 11_3 -------\n",
      "------- Finished processing file 11_3 in 3.0143697261810303 seconds -------\n",
      "------- Start processing file 11_4 -------\n",
      "------- Finished processing file 11_4 in 2.2620747089385986 seconds -------\n",
      "------- Start processing file 11_5 -------\n",
      "------- Finished processing file 11_5 in 5.903280258178711 seconds -------\n",
      "------- Start processing file 11_6 -------\n",
      "------- Finished processing file 11_6 in 3.074493885040283 seconds -------\n",
      "------- Start processing file 11_7 -------\n",
      "------- Finished processing file 11_7 in 3.6848649978637695 seconds -------\n",
      "------- Start processing file 11_8 -------\n",
      "------- Finished processing file 11_8 in 3.0650980472564697 seconds -------\n",
      "------- Start processing file 11_9 -------\n",
      "------- Finished processing file 11_9 in 2.9978890419006348 seconds -------\n",
      "------- Start processing file 11_10 -------\n",
      "------- Finished processing file 11_10 in 2.9725217819213867 seconds -------\n",
      "------- Start processing file 11_11 -------\n",
      "------- Finished processing file 11_11 in 3.7668869495391846 seconds -------\n",
      "------- Start processing file 11_12 -------\n",
      "------- Finished processing file 11_12 in 2.47556209564209 seconds -------\n",
      "------- Start processing file 11_13 -------\n",
      "------- Finished processing file 11_13 in 2.4900450706481934 seconds -------\n",
      "------- Start processing file 12_0 -------\n",
      "------- Finished processing file 12_0 in 16.450401067733765 seconds -------\n",
      "------- Start processing file 12_1 -------\n",
      "------- Finished processing file 12_1 in 3.6842360496520996 seconds -------\n",
      "------- Start processing file 12_2 -------\n",
      "------- Finished processing file 12_2 in 3.187687873840332 seconds -------\n",
      "------- Start processing file 12_3 -------\n",
      "------- Finished processing file 12_3 in 2.735975980758667 seconds -------\n",
      "------- Start processing file 12_4 -------\n",
      "------- Finished processing file 12_4 in 3.7750000953674316 seconds -------\n",
      "------- Start processing file 12_5 -------\n",
      "------- Finished processing file 12_5 in 2.821646213531494 seconds -------\n",
      "------- Start processing file 12_6 -------\n",
      "------- Finished processing file 12_6 in 3.0273051261901855 seconds -------\n",
      "------- Start processing file 12_7 -------\n",
      "------- Finished processing file 12_7 in 5.1852171421051025 seconds -------\n",
      "------- Start processing file 12_8 -------\n",
      "------- Finished processing file 12_8 in 3.2146551609039307 seconds -------\n",
      "------- Start processing file 12_9 -------\n",
      "------- Finished processing file 12_9 in 3.681351900100708 seconds -------\n",
      "------- Start processing file 12_10 -------\n",
      "------- Finished processing file 12_10 in 3.119325876235962 seconds -------\n",
      "------- Start processing file 12_11 -------\n",
      "------- Finished processing file 12_11 in 4.599145889282227 seconds -------\n",
      "------- Start processing file 12_12 -------\n",
      "------- Finished processing file 12_12 in 3.420959234237671 seconds -------\n",
      "------- Start processing file 12_13 -------\n",
      "------- Finished processing file 12_13 in 5.31980299949646 seconds -------\n",
      "------- Start processing file 13_0 -------\n",
      "------- Finished processing file 13_0 in 15.285867929458618 seconds -------\n",
      "------- Start processing file 13_1 -------\n",
      "------- Finished processing file 13_1 in 3.2751150131225586 seconds -------\n",
      "------- Start processing file 13_2 -------\n",
      "------- Finished processing file 13_2 in 2.5623722076416016 seconds -------\n",
      "------- Start processing file 13_3 -------\n",
      "------- Finished processing file 13_3 in 3.9917640686035156 seconds -------\n",
      "------- Start processing file 13_4 -------\n",
      "------- Finished processing file 13_4 in 4.036224126815796 seconds -------\n",
      "------- Start processing file 13_5 -------\n",
      "------- Finished processing file 13_5 in 4.360788106918335 seconds -------\n",
      "------- Start processing file 13_6 -------\n",
      "------- Finished processing file 13_6 in 3.9949800968170166 seconds -------\n",
      "------- Start processing file 13_7 -------\n",
      "------- Finished processing file 13_7 in 3.9125099182128906 seconds -------\n",
      "------- Start processing file 13_8 -------\n",
      "------- Finished processing file 13_8 in 7.459411859512329 seconds -------\n",
      "------- Start processing file 13_9 -------\n",
      "------- Finished processing file 13_9 in 3.5810680389404297 seconds -------\n",
      "------- Start processing file 13_10 -------\n",
      "------- Finished processing file 13_10 in 6.619668960571289 seconds -------\n",
      "------- Start processing file 13_11 -------\n",
      "------- Finished processing file 13_11 in 4.323884010314941 seconds -------\n",
      "------- Start processing file 13_12 -------\n",
      "------- Finished processing file 13_12 in 4.254002809524536 seconds -------\n",
      "------- Start processing file 13_13 -------\n",
      "------- Finished processing file 13_13 in 2.709542989730835 seconds -------\n",
      "------- Start processing file 14_0 -------\n",
      "------- Finished processing file 14_0 in 13.317708015441895 seconds -------\n",
      "------- Start processing file 14_1 -------\n",
      "------- Finished processing file 14_1 in 3.279876232147217 seconds -------\n",
      "------- Start processing file 14_2 -------\n",
      "------- Finished processing file 14_2 in 3.6806068420410156 seconds -------\n",
      "------- Start processing file 14_3 -------\n",
      "------- Finished processing file 14_3 in 9.321499109268188 seconds -------\n",
      "------- Start processing file 14_4 -------\n",
      "------- Finished processing file 14_4 in 5.625046968460083 seconds -------\n",
      "------- Start processing file 14_5 -------\n",
      "------- Finished processing file 14_5 in 2.601818084716797 seconds -------\n",
      "------- Start processing file 14_6 -------\n",
      "------- Finished processing file 14_6 in 3.547405958175659 seconds -------\n",
      "------- Start processing file 14_7 -------\n",
      "------- Finished processing file 14_7 in 4.0787951946258545 seconds -------\n",
      "------- Start processing file 14_8 -------\n",
      "------- Finished processing file 14_8 in 5.755586862564087 seconds -------\n",
      "------- Start processing file 14_9 -------\n",
      "------- Finished processing file 14_9 in 4.19567084312439 seconds -------\n",
      "------- Start processing file 14_10 -------\n",
      "------- Finished processing file 14_10 in 2.618880033493042 seconds -------\n",
      "------- Start processing file 14_11 -------\n",
      "------- Finished processing file 14_11 in 4.3427817821502686 seconds -------\n",
      "------- Start processing file 14_12 -------\n",
      "------- Finished processing file 14_12 in 3.1475868225097656 seconds -------\n",
      "------- Start processing file 14_13 -------\n",
      "------- Finished processing file 14_13 in 2.6899259090423584 seconds -------\n",
      "------- Start processing file 15_0 -------\n",
      "------- Finished processing file 15_0 in 11.759368896484375 seconds -------\n",
      "------- Start processing file 15_1 -------\n",
      "------- Finished processing file 15_1 in 4.315078973770142 seconds -------\n",
      "------- Start processing file 15_2 -------\n",
      "------- Finished processing file 15_2 in 2.6640467643737793 seconds -------\n",
      "------- Start processing file 15_3 -------\n",
      "------- Finished processing file 15_3 in 2.661587953567505 seconds -------\n",
      "------- Start processing file 15_4 -------\n",
      "------- Finished processing file 15_4 in 2.665745258331299 seconds -------\n",
      "------- Start processing file 15_5 -------\n",
      "------- Finished processing file 15_5 in 2.8375706672668457 seconds -------\n",
      "------- Start processing file 15_6 -------\n",
      "------- Finished processing file 15_6 in 4.647324085235596 seconds -------\n",
      "------- Start processing file 15_7 -------\n",
      "------- Finished processing file 15_7 in 3.673201084136963 seconds -------\n",
      "------- Start processing file 15_8 -------\n",
      "------- Finished processing file 15_8 in 3.720092296600342 seconds -------\n",
      "------- Start processing file 15_9 -------\n",
      "------- Finished processing file 15_9 in 2.4282450675964355 seconds -------\n",
      "------- Start processing file 15_10 -------\n",
      "------- Finished processing file 15_10 in 3.27054500579834 seconds -------\n",
      "------- Start processing file 15_11 -------\n",
      "------- Finished processing file 15_11 in 2.3540279865264893 seconds -------\n",
      "------- Start processing file 15_12 -------\n",
      "------- Finished processing file 15_12 in 3.476871967315674 seconds -------\n",
      "------- Start processing file 15_13 -------\n",
      "------- Finished processing file 15_13 in 4.409656047821045 seconds -------\n",
      "------- Start processing file 16_0 -------\n",
      "------- Finished processing file 16_0 in 16.96969485282898 seconds -------\n",
      "------- Start processing file 16_1 -------\n",
      "------- Finished processing file 16_1 in 3.6117780208587646 seconds -------\n",
      "------- Start processing file 16_2 -------\n",
      "------- Finished processing file 16_2 in 3.3013858795166016 seconds -------\n",
      "------- Start processing file 16_3 -------\n",
      "------- Finished processing file 16_3 in 3.147390842437744 seconds -------\n",
      "------- Start processing file 16_4 -------\n",
      "------- Finished processing file 16_4 in 3.2943060398101807 seconds -------\n",
      "------- Start processing file 16_5 -------\n",
      "------- Finished processing file 16_5 in 2.3441989421844482 seconds -------\n",
      "------- Start processing file 16_6 -------\n",
      "------- Finished processing file 16_6 in 2.3484737873077393 seconds -------\n",
      "------- Start processing file 16_7 -------\n",
      "------- Finished processing file 16_7 in 3.692939043045044 seconds -------\n",
      "------- Start processing file 16_8 -------\n",
      "------- Finished processing file 16_8 in 3.068751096725464 seconds -------\n",
      "------- Start processing file 16_9 -------\n",
      "------- Finished processing file 16_9 in 2.453700065612793 seconds -------\n",
      "------- Start processing file 16_10 -------\n",
      "------- Finished processing file 16_10 in 3.2814300060272217 seconds -------\n",
      "------- Start processing file 16_11 -------\n",
      "------- Finished processing file 16_11 in 2.2578423023223877 seconds -------\n",
      "------- Start processing file 16_12 -------\n",
      "------- Finished processing file 16_12 in 4.77070689201355 seconds -------\n",
      "------- Start processing file 16_13 -------\n",
      "------- Finished processing file 16_13 in 3.226428985595703 seconds -------\n",
      "------- Start processing file 17_0 -------\n",
      "------- Finished processing file 17_0 in 12.110624074935913 seconds -------\n",
      "------- Start processing file 17_1 -------\n",
      "------- Finished processing file 17_1 in 2.8272440433502197 seconds -------\n",
      "------- Start processing file 17_2 -------\n",
      "------- Finished processing file 17_2 in 4.713968992233276 seconds -------\n",
      "------- Start processing file 17_3 -------\n",
      "------- Finished processing file 17_3 in 3.970731019973755 seconds -------\n",
      "------- Start processing file 17_4 -------\n",
      "------- Finished processing file 17_4 in 2.3562800884246826 seconds -------\n",
      "------- Start processing file 17_5 -------\n",
      "------- Finished processing file 17_5 in 3.117838144302368 seconds -------\n",
      "------- Start processing file 17_6 -------\n",
      "------- Finished processing file 17_6 in 1.939110279083252 seconds -------\n",
      "------- Start processing file 17_7 -------\n",
      "------- Finished processing file 17_7 in 3.4378061294555664 seconds -------\n",
      "------- Start processing file 17_8 -------\n",
      "------- Finished processing file 17_8 in 3.077167272567749 seconds -------\n",
      "------- Start processing file 17_9 -------\n",
      "------- Finished processing file 17_9 in 3.847076892852783 seconds -------\n",
      "------- Start processing file 17_10 -------\n",
      "------- Finished processing file 17_10 in 2.5991058349609375 seconds -------\n",
      "------- Start processing file 17_11 -------\n",
      "------- Finished processing file 17_11 in 2.532989025115967 seconds -------\n",
      "------- Start processing file 17_12 -------\n",
      "------- Finished processing file 17_12 in 3.3531851768493652 seconds -------\n",
      "------- Start processing file 17_13 -------\n",
      "------- Finished processing file 17_13 in 3.949138879776001 seconds -------\n",
      "------- Start processing file 18_0 -------\n",
      "------- Finished processing file 18_0 in 17.308522939682007 seconds -------\n",
      "------- Start processing file 18_1 -------\n",
      "------- Finished processing file 18_1 in 2.959472179412842 seconds -------\n",
      "------- Start processing file 18_2 -------\n",
      "------- Finished processing file 18_2 in 2.443629026412964 seconds -------\n",
      "------- Start processing file 18_3 -------\n",
      "------- Finished processing file 18_3 in 2.383298873901367 seconds -------\n",
      "------- Start processing file 18_4 -------\n",
      "------- Finished processing file 18_4 in 3.773872137069702 seconds -------\n",
      "------- Start processing file 18_5 -------\n",
      "------- Finished processing file 18_5 in 2.689749002456665 seconds -------\n",
      "------- Start processing file 18_6 -------\n",
      "------- Finished processing file 18_6 in 2.115467071533203 seconds -------\n",
      "------- Start processing file 18_7 -------\n",
      "------- Finished processing file 18_7 in 3.135512113571167 seconds -------\n",
      "------- Start processing file 18_8 -------\n",
      "------- Finished processing file 18_8 in 4.446070909500122 seconds -------\n",
      "------- Start processing file 18_9 -------\n",
      "------- Finished processing file 18_9 in 87.70019602775574 seconds -------\n",
      "------- Start processing file 18_10 -------\n",
      "------- Finished processing file 18_10 in 3.5398972034454346 seconds -------\n",
      "------- Start processing file 18_11 -------\n",
      "------- Finished processing file 18_11 in 3.2602591514587402 seconds -------\n",
      "------- Start processing file 18_12 -------\n",
      "------- Finished processing file 18_12 in 4.038646936416626 seconds -------\n",
      "------- Start processing file 18_13 -------\n",
      "------- Finished processing file 18_13 in 4.26774001121521 seconds -------\n",
      "------- Start processing file 19_0 -------\n",
      "------- Finished processing file 19_0 in 10.606456756591797 seconds -------\n",
      "------- Start processing file 19_1 -------\n",
      "------- Finished processing file 19_1 in 3.045487880706787 seconds -------\n",
      "------- Start processing file 19_2 -------\n",
      "------- Finished processing file 19_2 in 2.5859367847442627 seconds -------\n",
      "------- Start processing file 19_3 -------\n",
      "------- Finished processing file 19_3 in 2.2631208896636963 seconds -------\n",
      "------- Start processing file 19_4 -------\n",
      "------- Finished processing file 19_4 in 2.631321907043457 seconds -------\n",
      "------- Start processing file 19_5 -------\n",
      "------- Finished processing file 19_5 in 2.283992052078247 seconds -------\n",
      "------- Start processing file 19_6 -------\n",
      "------- Finished processing file 19_6 in 5.149626970291138 seconds -------\n",
      "------- Start processing file 19_7 -------\n",
      "------- Finished processing file 19_7 in 4.612558126449585 seconds -------\n",
      "------- Start processing file 19_8 -------\n",
      "------- Finished processing file 19_8 in 3.79118013381958 seconds -------\n",
      "------- Start processing file 19_9 -------\n",
      "------- Finished processing file 19_9 in 2.1526389122009277 seconds -------\n",
      "------- Start processing file 19_10 -------\n",
      "------- Finished processing file 19_10 in 2.5563833713531494 seconds -------\n",
      "------- Start processing file 19_11 -------\n",
      "------- Finished processing file 19_11 in 3.7358450889587402 seconds -------\n",
      "------- Start processing file 19_12 -------\n",
      "------- Finished processing file 19_12 in 3.3971590995788574 seconds -------\n",
      "------- Start processing file 19_13 -------\n",
      "------- Finished processing file 19_13 in 3.442180871963501 seconds -------\n",
      "------- Start processing file 20_0 -------\n",
      "------- Finished processing file 20_0 in 22.845421075820923 seconds -------\n",
      "------- Start processing file 20_1 -------\n",
      "------- Finished processing file 20_1 in 3.112173080444336 seconds -------\n",
      "------- Start processing file 20_2 -------\n",
      "------- Finished processing file 20_2 in 4.577476739883423 seconds -------\n",
      "------- Start processing file 20_3 -------\n",
      "------- Finished processing file 20_3 in 2.7288308143615723 seconds -------\n",
      "------- Start processing file 20_4 -------\n",
      "------- Finished processing file 20_4 in 2.925018072128296 seconds -------\n",
      "------- Start processing file 20_5 -------\n",
      "------- Finished processing file 20_5 in 3.745779037475586 seconds -------\n",
      "------- Start processing file 20_6 -------\n",
      "------- Finished processing file 20_6 in 3.512915849685669 seconds -------\n",
      "------- Start processing file 20_7 -------\n",
      "------- Finished processing file 20_7 in 2.781679153442383 seconds -------\n",
      "------- Start processing file 20_8 -------\n",
      "------- Finished processing file 20_8 in 3.184067964553833 seconds -------\n",
      "------- Start processing file 20_9 -------\n",
      "------- Finished processing file 20_9 in 3.6316888332366943 seconds -------\n",
      "------- Start processing file 20_10 -------\n",
      "------- Finished processing file 20_10 in 3.8735601902008057 seconds -------\n",
      "------- Start processing file 20_11 -------\n",
      "------- Finished processing file 20_11 in 3.0609829425811768 seconds -------\n",
      "------- Start processing file 20_12 -------\n",
      "------- Finished processing file 20_12 in 4.502066135406494 seconds -------\n",
      "------- Start processing file 20_13 -------\n",
      "------- Finished processing file 20_13 in 3.204785108566284 seconds -------\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Load previous progress if available\n",
    "try:\n",
    "    with open('gpt_refine_complex_output_progress.json', 'r') as file:\n",
    "        gpt_refine_complex_output = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    gpt_refine_complex_output = {}\n",
    "\n",
    "# Loop through each unique id\n",
    "for id in images_encoded['id'].unique():\n",
    "# for id in unable_ids:\n",
    "    # Check if this ID is already processed (Skip this step if you want to re-process for unable_ids) ----------------\n",
    "    if id in gpt_refine_complex_output:\n",
    "        print(f\"Skipping {id}, already processed.\")\n",
    "        continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        print(f'------- Start processing file {id} -------')\n",
    "        \n",
    "        # Call OpenAI/Anthropic and post-processing functions\n",
    "        response_text = gpt_complex[gpt_complex['id'] == id].text.values[0]\n",
    "        prompt_refine = f\"\"\"\n",
    "        \n",
    "        Your first draft:\n",
    "        ```plaintext\n",
    "        {response_text}\n",
    "        ```\n",
    "\n",
    "        Errors: \n",
    "        Your first transcription you made in ```plaintext block contains some errors.\n",
    "        \n",
    "        Task:\n",
    "        Refine your first trasncription in ```plaintext block. \n",
    "        Make sure to read the names of the people and the location as well as the dates and the numbers correctly.\n",
    "        Transcribe as you see in the image.\n",
    "        ```plaintext\n",
    "        \"\"\"\n",
    "\n",
    "        prompt_refine += \"Even if it is hard to read the texts from the image, return as much as you can. You must read something. Do not return an apologetic message.\"\n",
    "        output = callOpenAI(prompt=prompt_refine, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        # output = callAnthropic(prompt=prompt_refine, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        output_cleaned = callPostProcessing(prompt_parameter=output)\n",
    "        \n",
    "        # Save the output\n",
    "        gpt_refine_complex_output[id] = output_cleaned\n",
    "        \n",
    "        # Save progress after each file\n",
    "        with open('gpt_refine_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(gpt_refine_complex_output, file)\n",
    "        \n",
    "        print(f'------- Finished processing file {id} in {time.time() - start_time} seconds -------')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {id}: {str(e)}\")\n",
    "        # Save the progress and exit the loop in case of an error\n",
    "        with open('gpt_refine_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(gpt_refine_complex_output, file)\n",
    "        break  # Exit the loop on error\n",
    "\n",
    "# Once all IDs are processed, save the final result\n",
    "with open('gpt_refine_complex_output_final.json', 'w') as file:\n",
    "    json.dump(gpt_refine_complex_output, file)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b34c7",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "683579cb-2bae-4a69-8271-ce4e67519e52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1_0': \"N° d'ordre:  \\nDate du dépôt des déclarations:  \\nDésignation des personnes décédées ou absentes.:  \\nNoms:  \\nPrénoms:  \\nDomiciles:  \\nDate du décès ou du jugement d'envoi en possession, en cas d'absence.:  \\nNoms, Prénoms et demeures des parties déclarantes.:  \\nDroits de succession en ligne collatérale et de mutation en ligne directe.:  \\nActif. (2):  \\nPassif. (2):  \\nRestant NET. (2):  \\nDroit de mutation par décès:  \\nValeur des immeubles. (2):  \\nNuméros des déclarations:  \\nPrimitives.:  \\nSupplémentaires.:  \\nDate de l'expiration du délai de rectification.:  \\nDate de l'exigibilité des droits.:  \\nNuméros de la consignation des droits au sommier n° 28:  \\nRecette des droits et amendes.:  \\nDate:  \\nN°:  \\nCautionnements.:  \\nNuméros de la consignation au sommier n° 30:  \\nObservations:  \\n(Les déclarations qui figurent à l'état n° 11 doivent être chargées en conséquence, dans la présente colonne.)\",\n",
       " '1_1': 'Arrêté le vingt-huit octobre 1919 Servais',\n",
       " '1_2': 'Arrêté le vingt neuf octobre 1919 Servais',\n",
       " '1_3': '398 trente octobre Herrenx Alphonse Opheim 19 sept 1918 Heverent Henri et autres 2220 504 1716 3525 31 décembre 1919 Fascicule 365',\n",
       " '1_4': '398½ 2 Lefèvre Jules Bruxelles 8 janvier 1919 3000 2222 7778 236 1919',\n",
       " '1_5': 'Arrêté le trente octobre 1919 Servais',\n",
       " '1_6': 'Arrêté le trente un octobre 1929 Servais',\n",
       " '1_7': 'Arrêté le premier novembre 1919 Toussaint Servais',\n",
       " '1_8': 'Arrêté le deux novembre 1919 Dimanche Servais',\n",
       " '1_9': '399 6 août 1916 Desmedt Jeanne Nivelles 13 mai 1919 Willebeke Elisa sauter 9180 520 8690 15 février 1920 13 octobre 1924 10 février 1920',\n",
       " '1_10': '400 5 Monseur Raoul Oscar Latteur 1 8bre 1918 Alost pour Ostende 69998 21476 69998 15 7bre 1919',\n",
       " '1_11': '401 2 Bouly Henri Louvière 26 Février 1919 Bouly Marie Félix 2240 2046 19 2 1929 non passibles',\n",
       " '1_12': 'Arrêté le trois novembre 1919 Servais',\n",
       " '1_13': \"40% qualité qta Godart Renelde Praire d'Athlone 12 mai 1919 Charon Gustave 14437 14437 33^2 76 12 14 avril 1920 32\",\n",
       " '2_0': \"N° d'ordre: [empty]  \\nDate du dépôt des déclarations: [empty]  \\nDÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES:  \\nNOMS: [empty]  \\nPRÉNOMS: [empty]  \\nDOMICILES: [empty]  \\nDATE DU DÉCÈS ou du JUGEMENT D'ENVOI en possession, en cas d'absence: [empty]  \\nNOMS, PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES: [empty]  \\nDROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE:  \\nACTIF: [empty]  \\nPASSIF: [empty]  \\nRESTANT NET: [empty]  \\nDROIT DE MUTATION par décès:  \\nVALEUR des IMMEUBLES: [empty]  \\nNUMÉROS des DÉCLARATIONS:  \\nPrimitives: [empty]  \\nSupplémentaires: [empty]  \\nDATE de l'expiration du délai de rectification: [empty]  \\nDATE de l'exigibilité des droits: [empty]  \\nNUMÉROS de la consignation des droits au sommier n° 28: [empty]  \\nRECETTE des DROITS ET AMENDES:  \\nDATE: [empty]  \\nN°: [empty]  \\nCAUTIONNEMENTS:  \\nNUMÉROS de la consignation au sommier n° 30: [empty]  \\nOBSERVATIONS: [Les déclarations qui figurent à l'état n° 415 doivent être enrégistrées et envoyées, dans la présente colonne.]\",\n",
       " '2_1': '49',\n",
       " '2_2': '403 quatre qbre Payot Baudouries Mons 4 mars 1919 Payot Henri autres 16948 5233 11740 2350 16 mars 1920',\n",
       " '2_3': '403^2 30 Paulus Abelanis Nivelles 25 janvier 1919 Paulus François 1921 1921 191/1919 4 10 8bre 1922',\n",
       " '2_4': '404 5e Vandermeers Abauit Anna Elsberg 4 avril 1918 Bruxelles Bruxelles 500 500 16 2e janvier 1918 non fixée',\n",
       " '2_5': 'Arrêté le quatre novembre 1919 Servais',\n",
       " '2_6': '405 cinq q.be Lemoine Pierre Jh Etter 24 Août 1888 Lemoine Juliette et autres 1885 1885 12 Août 1891 non fixée',\n",
       " '2_7': \"406 Monnaye Julie Alostein 16 Sept 1911 Monnaye Aimé et autres Déclaration d'usufruit 16 Février 1912\",\n",
       " '2_8': '407 5 de Godeau née Painblanc Clément Orsigney 7 8bre 1919 Godeau Honsbeck haute 800 800 7bre 1921 7 avril 1922 non remplie',\n",
       " '2_9': 'Arrêté le cinq novembre 1919 Servais',\n",
       " '2_10': 'Arrêté le six novembre 1929 Servais',\n",
       " '2_11': '408 septembre Fontaine Florent Hulige 25 octobre 1924 Roosmans Armande 378 226 202 19 juin 1925 non francible',\n",
       " '2_12': '409 0 Allard Prosper Nivelles 16 avril 1919 Allard Clovis 4340 4340 19 7 15 juin 1920 15mouyens 54',\n",
       " '2_13': 'Arrêté le sept novembre 1919 Servais',\n",
       " '2_14': '410 Louis qba Deloutte Waterloo le mariéphe Isabelle Edouard 24457 369 12068 20 mars 1910 13 pluviôse 192',\n",
       " '3_0': \"N° d'ordre: [empty]  \\nDate du dépôt des déclarations: [empty]  \\nDÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES:  \\nNOMS: [empty]  \\nPRÉNOMS: [empty]  \\nDOMICILES: [empty]  \\nDATE DU DÉCÈS ou du JUGEMENT D'ENVOI en possession, en cas d'absence: [empty]  \\nNOMS, PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES: [empty]  \\nDROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE:  \\nACTIF: (2) [empty]  \\nPASSIF: (2) [empty]  \\nRESTANT NET: (2) [empty]  \\nDROIT DE MUTATION par décès:  \\nVALEUR des IMMEUBLES: (2) [empty]  \\nNUMÉROS des DÉCLARATIONS:  \\nPrimitives: [empty]  \\nSupplémentaires: [empty]  \\nDATE:  \\nde l'expiration du délai de rectification: [empty]  \\nde l'exigibilité des droits: [empty]  \\nNUMÉROS de la consignation des droits au sommier n° 28: [empty]  \\nRECETTE des DROITS ET AMENDES:  \\nDATE: [empty]  \\nN°: [empty]  \\nCAUTIONNEMENTS:  \\nNUMÉROS de la consignation au sommier n° 30: [empty]  \\nOBSERVATIONS:  \\n(Les déclarations qui figurent à l'état n° 413 doivent être émargées en conséquence, dans la présente colonne.): [empty]\",\n",
       " '3_1': '411 1er juillet 1919 Kutteler Henri Waterloo 28 août 1919 Lejeune Alix 3 347 847 20 8bre 1919 20 juillet 1920 non remplis',\n",
       " '3_2': \"112 2 Chabeau Alixie Mornel'Abbaye 6 8bre 1919 Capelle Antoine et autres 78692 48692 20 2 6 avril 1920 19 8bre 1920 203 204 207 209 229\",\n",
       " '3_3': '112 2° Reyners Louis Spa 4 avril 1916 Gellis André 4706 1726 298/1916 15 mars 1920 299',\n",
       " '3_4': 'Arrêté le huit novembre 1919 Servais',\n",
       " '3_5': 'Arrêté le neuf novembre 1929 Dumonceau Servais',\n",
       " '3_6': '413 du 9bre 1919 Mathieu Émérante Courquain Liège 11 mai 1919 16934 16934 22 9bre 1919',\n",
       " '3_7': '414 30 Laminiau Adeline Albert 2 juillet 1914 Delfosse Léon et autre 22991 22991 12 mai 1920 18 mars 1920 59 3 mai 1920 17 3 98 100',\n",
       " '3_8': '415 0 Dubois Amélie Athus 6 juin 1849 Adrien Jeanne et autre 500 85 144 22 6 avril 1870 non familials',\n",
       " '3_9': 'Arrêté le six novembre 1917 Servais',\n",
       " '3_10': \"416 mes d'obe Neuvens Emmanuel Nivelles et marié Delfine Louis 7861 566 6995 25 Août 1919 18 mars 1914\",\n",
       " '3_11': '117 3e Basigant Marie 14 3e Arquettes Eugénie 1746 1242 25 3e 5 mars 1928 62',\n",
       " '3_12': '117 bis Campinaire Elie Jemeppe-allez 27 mars 1904 Gellis Eugène 222285 23250 361 494',\n",
       " '3_13': 'Arrêté le onze novembre 1949 Servais',\n",
       " '4_0': \"N° d'ordre: 0  \\nDate du dépôt des déclarations:  \\nDÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES:  \\nNOMS:  \\nPRÉNOMS:  \\nDOMICILES:  \\nDATE DU DÉCÈS ou du JUGEMENT D'ENVOI en possession, en cas d'absence:  \\nNOMS, PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES:  \\nDROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE:  \\nACTIF. (2):  \\nPASSIF. (2):  \\nRESTANT NET. (2):  \\nDROIT DE MUTATION par décès:  \\nVALEUR des IMMEUBLES. (2):  \\nNUMÉROS des DÉCLARATIONS:  \\nPrimitives:  \\nSupplémentaires:  \\nDATE de l'expiration du délai de rectification:  \\nDATE de l'exigibilité des droits:  \\nNUMÉROS de la consignation des droits au sommier n° 28:  \\nRECETTE des DROITS ET AMENDES:  \\nDATE:  \\nN°:  \\nCAUTIONNEMENTS:  \\nNUMÉROS de la consignation au sommier n° 30:  \\nOBSERVATIONS:  \\n(Les déclarations qui figurent à l'état n° 413 doivent être chargées en conséquence, dans la présente colonne.)\",\n",
       " '4_1': 'Arrêté le douze novembre 1919 Servais',\n",
       " '4_2': 'H18 Louiz gre Cloquet Célestine Wauthier-Braine 28 mai 1919 Evrard Alix 1500 400 29 8bre 1919 15 mars 1920',\n",
       " '4_3': '419 3 Vincent Léonore Elvire 3 avril 1911 Grignote Emile à autin 26600 26600 29 3 juin 1911 3 mars 1912 46 3 300',\n",
       " '4_4': 'Arrêté le treize novembre 1919 Servais',\n",
       " '4_5': 'Arrêté le quatre novembre 1919 Servais',\n",
       " '4_6': '420 quinze Boisdenghien Clovis Quenast 14 mai 1919 Dr. Bois Elvatin à aulu 1738 1738 441 24 Mars 1920 30 1920 1 avril 1920 44',\n",
       " '4_7': '420 30 Lambotte Ernest Hastière 4 février 1918 Lambotte Emile 258 1918',\n",
       " '4_8': 'Arrêté le quinze novembre 1914 Servais',\n",
       " '4_9': 'Arrêté le seize novembre 1929 Dimanche Servais',\n",
       " '4_10': 'Arrêté le dix sept novembre 1919 Servais',\n",
       " '4_11': '420^3 recueil 5 Rousseau Charles Gm Nivelles 31 mars 1919 Rousseau Louis 24800 23800 110/1919',\n",
       " '4_12': '121 5 Lezancq Henri Athlée 20 avril 1916 Régleur Henri Bruxelles 3922 210 3712 30 juin 1926 9 avril 1940 364 308',\n",
       " '4_13': 'Arrêté le dix huit novembre 1919 Servais',\n",
       " '5_0': \"N° d'ordre DATE DU DÉPÔT des DÉCLARATIONS DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. NOMS. PRÉNOMS. DOMICILES. DATE DU DÉCÈS ou du JUGEMENT D'ENVOI en possession, en cas d'absence. NOMS, PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES. DROITS DE SUCCESSION EN LIGNE COLLATÉRALE et de MUTATION EN LIGNE DIRECTE. ACTIF. (2) PASSIF. (2) RESTANT NET. (2) DROIT DE MUTATION par décès. VALEUR des IMMEUBLES. (2) NUMÉROS des DÉCLARATIONS primitives supplémentaires. DATE de l'expiration du délai de rectification. DATE de l'exigibilité des droits. NUMÉROS de la consignation des droits au sommier n° 28. RECETTE des DROITS ET AMENDES. DATE N°03 CAUTIONNEMENTS. NUMÉROS de la consignation au sommier n° 30. OBSERVATIONS. (Les déclarations qui figurent à l'état n° 413 doivent être émargées en conséquence, dans la présente colonne.)\",\n",
       " '5_1': '1419',\n",
       " '5_2': '21e 1er neuf 9 novembre Vleemans Charles Steenokkerzeel 27 avril 1918 Paulus Victorine 5455 247 5468 39/1919 22 décembre 1919 332 10 janvier 1920 44',\n",
       " '5_3': '4213 2 Dewij Louis L Liège 4 Janvier 1918 Dewij Louis et autres 500 500 0 12 Septembre 1 Juillet 1920 413',\n",
       " '5_4': '4214 1er Pieckebons Pierre Joseph Aimé Waterloo 4 février 1918 Anne Geneviève autres Déclaration anticipée 21/1919',\n",
       " '5_5': '422 5 Pieterhons Jean Syn 26 mai 1849 266 223 121 31 mars 1850 non fumillé',\n",
       " '5_6': '423 1 Desaegher Marie Rosalie Rebecq 26 mai 1919 Blanchaire Vital 4875 2875 82 5 17 mars 1920',\n",
       " '5_7': 'Arrêté le dix neuf novembre 1929 Servais',\n",
       " '5_8': '424 vingt qbe Hautier Firmin Nivelles 23 juillet 1919 Desus Juliette autres 86181 86181 23 mai 1920 16 avril 1920 13',\n",
       " '5_9': \"425 5e Delaitre Élise Antoinette Jemeppe sur Sambre 26 mai 1911 Souffle Jean Acte d'auto 1500 1500 1 5e 12 mars 1912 non familier\",\n",
       " '5_10': 'Arrêté le vingt novembre 1919 Servais',\n",
       " '5_11': '425e vingt-un 2 Piercot Julien Waterloo 6 février 1919 Lempereur Louis Anatolie 213 1919',\n",
       " '5_12': '426 Tontignies 26 juin 1919 Bartholomé Edouard 2361 2661 1 26 avril 1920 10 avril 1926',\n",
       " '5_13': '417 3 Moens Joseph Louis 28 juillet 1919 Ixelles Elie Lauters 1545 476 1 3 28 mai 1920 non familier',\n",
       " '5_14': '418 5 Semal Henri Nivelles 16 juin 1921 Gurnet Alice Lauters 4000 4000 33/4 1920 2 10 avril 1920 12 avril 1920 99',\n",
       " '6_0': \"N° d'ordre: 1  \\nDate du dépôt des déclarations: 12 mars 1923  \\nDésignation des personnes décédées ou absentes:  \\nNom: Dupont  \\nPrénoms: Jean  \\nDomiciles: Bruxelles  \\nDate du décès ou du jugement d'envoi en possession, en cas d'absence: 5 février 1923  \\nNoms, Prénoms et demeures des parties déclarantes:  \\nMartin, Pierre, Liège  \\nDroits de succession en ligne collatérale et de mutation en ligne directe:  \\nActif: 5000  \\nPassif: 2000  \\nRestant NET: 3000  \\nDroit de mutation par décès:  \\nValeur des immeubles: 10000  \\nNuméros des déclarations:  \\nPrimitives: 45  \\nSupplémentaires: 12  \\nDate de l'expiration du délai de rectification: 12 juin 1923  \\nDate de l'exigibilité des droits: 12 juillet 1923  \\nNuméros de la consignation des droits au sommier n° 28: 34  \\nRecette des droits et amendes:  \\nDate: 15 août 1923  \\nN°: 78  \\nCautionnements:  \\nNuméros de la consignation au sommier n° 30: 56  \\nObservations: Aucune  \",\n",
       " '6_1': '101',\n",
       " '6_2': '150 vingt-quatre juin Lambert Valentin Nivelles 16 mars 1921 Gérés Civiels et autres 18610 1467 26743 16 mars 1921',\n",
       " '6_3': '151 2° Leveau Adolphine Etterbeek Ixelles Forest et autres 4540 4540 758091 139 16 29',\n",
       " '6_4': '152 5° Vanpée Félicie à 29 8bre 1925 à 47442 584 46858 non fixée',\n",
       " '6_5': '153 D Delabij Joachim Joseph Bruxelles 15 janvier 1920 Jeanmin Antoine Henri 2290 546 1744 non fixable',\n",
       " '6_6': 'Arrêté le vingt-quatre juin 1925 Servais',\n",
       " '6_7': '153½ unif. 1er juin Charlier Hoochense Nivelles 8 avril 1930 Hout Jules et Léon 821 108/120',\n",
       " '6_8': 'Arrêté le vingt-cinq juin 1921 Servais',\n",
       " '6_9': 'Arrêté le vingt-six juin 1921 Dimanche Servais',\n",
       " '6_10': '154 28 juillet Froment Georges Nivelles 28 8bre 1921 Van Damme Juliette 250475 1369 248246 361 9 janvier 1922',\n",
       " '6_11': '155 Devreux Jean Ste Bruxelles Schaerbeek 29 novembre 1920 Henriette Housin et autres 2469 2469 non taxable',\n",
       " '6_12': '156 Seolas Jean Joseph Waulthier Anvers 6 7bre 1921 Seolas Jules Joh. autres 2481 2481 id.',\n",
       " '6_13': 'Arrêté le vingt-sept juin 1921 Servais',\n",
       " '6_14': '15e vingt huit 8 Delalque Maria Louise Brine Octobreau 29 8bre 1920 Delalque Adélaïde 14864 1326 12919 19 Février 1923',\n",
       " '7_0': \"N° d'ordre Date du dépôt des déclarations Désignation des personnes décédées ou absentes.: Nom Désignation des personnes décédées ou absentes.: Prénoms Désignation des personnes décédées ou absentes.: Domiciles Date du décès ou du jugement d'envoi en possession, en cas d'absence. Noms, Prénoms et demeures des parties déclarantes. Droits de succession en ligne collatérale et de mutation en ligne directe.: Actif. (2) Droits de succession en ligne collatérale et de mutation en ligne directe.: Passif. (2) Droits de succession en ligne collatérale et de mutation en ligne directe.: Restant NET. (2) Droit de mutation par décès: Valeur des immeubles. (2) Numéros des déclarations: Primitives. Numéros des déclarations: Supplémentaires. Date de l'expiration du délai de rectification. Date de l'exigibilité des droits. Numéros de la consignation des droits au sommier n° 28 Recette des droits et amendes.: Date Recette des droits et amendes.: N° Cautionnements.: Numéros de la consignation au sommier n° 30 Observations (Les déclarations qui figurent à l'état n° 413 doivent être émargées en conséquence, dans la présente colonne.)\",\n",
       " '7_1': 'Arrêté le dix-sept juin 1925 Servais',\n",
       " '7_2': '145 16 septembre Luycx Charles Léopold 16 9 1920 Van Acker Julienne et autres 58246 1618 56432 128 28 9 21 124 16 10bre 531',\n",
       " '7_3': 'Arrêté le dix-sept juin 1921 Servais',\n",
       " '7_4': '146 dix huit juin Masson Jean Bt Baulers 19 8bre 20 Rose Elvire 12905 814 11020 23-11-1921 164',\n",
       " '7_5': 'Arrêté le dix-sept juin 1924 Servais',\n",
       " '7_6': 'Arrêté le dix-neuf juin 1910 Dimanche Servais',\n",
       " '7_7': 'Arrêté le vingt juin 1924 Servais',\n",
       " '7_8': '45 21 septembre Leblicq Jean Bte Ottomont 13 mars 1920 Gérard Henri Thérèse et autres 4960 326 16264 non francili',\n",
       " '7_9': 'Arrêté le vingt-un juin 1921 Servais',\n",
       " '7_10': 'Arrêté le vingt deux juin 1921 Servais',\n",
       " '7_11': 'Arrêté le vingt trois juin 1923 Servais',\n",
       " '7_12': '148 vingt quatre Basset Emmanuel Joseph Géronsart 1926 Pépin Emilie et autres 4945 1333 1612 160 5 1926 4 janvier 1926',\n",
       " '7_13': '140 7 Kiegelart Laurent Ph Anvers (Calv.) 29 mai 1926 Hazaert Elisabeth et autres 8386 288 3911 non possédé',\n",
       " '8_0': \"N° d'ordre Date du dépôt des déclarations Désignation des personnes décédées ou absentes.: Nom Désignation des personnes décédées ou absentes.: Prénoms Désignation des personnes décédées ou absentes.: Domiciles Date du décès ou du jugement d'envoi en possession, en cas d'absence. Noms, Prénoms et demeures des parties déclarantes. Droits de succession en ligne collatérale et de mutation en ligne directe.: Actif. (2) Droits de succession en ligne collatérale et de mutation en ligne directe.: Passif. (2) Droits de succession en ligne collatérale et de mutation en ligne directe.: Restant NET. (2) Droit de mutation par décès: Valeur des immeubles. (2) Numéros des déclarations: Primitives. Numéros des déclarations: Supplémentaires. Date de l'expiration du délai de rectification. Date de l'exigibilité des droits. Numéros de la consignation des droits au sommier n° 28 Recette des droits et amendes.: Date Recette des droits et amendes.: N° Cautionnements.: Numéros de la consignation au sommier n° 30 Observations (Les déclarations qui figurent à l'état n° 413 doivent être émargées en conséquence, dans la présente colonne.)\",\n",
       " '8_1': 'Arrêté le vingt-un novembre 1919 Servais',\n",
       " '8_2': '429 vingt deux novembre Beth Attre 26 mai 1919 Hebert Louis 47666 47666 3 janvier 1920 26 mars 1919 15 juillet 1920 560 369',\n",
       " '8_3': '430 5 Huart Ida 19 août 1918 Huart Joseph et autres 42307 1461 42346 3 8 19 avril 1919 Laveleye 1 juin 1920 302 3%',\n",
       " '8_4': '431 1° Romain Félicie 10 février 1919 Wautier Léonie et autres 10 518 10 458 3 0 10 juillet 1920 19 décembre 1919 36',\n",
       " '8_5': '122 Poliart Sim 28 8bre 1918 Vleminckx Claverie et autres 913 411 432 19 8bre 1919 22 avril 1921',\n",
       " '8_6': '433 5 Poliax Arthur 19 5 a 465 261 474 1345 5 1924 a 51',\n",
       " '8_7': '434 3 Houtmeyers Louis Waterlo 28 mai 1919 Balgan Dirigent 2034 417 1274 3 3 27 mars 1919 1 avril 1920 75',\n",
       " '8_8': '435 Thibaux Marie-Louise Menet 5/8/1919 Loyard Alexis et autres 46290 11290 448/22 9/8/22 non familier',\n",
       " '8_9': '136 Gaussin Eva Bruxelles 22 Août 1918 Gaussin Camille 1020 722 298 3 Août 1919 non fixée',\n",
       " '8_10': '437 30 Delannoiz Clémentine à 28 mars 1918 Desreux Adrien 6157 664 518 5 5 23 janvier 1919 14-11-21 148',\n",
       " '8_11': '138 5 Deloutte Jules Verviers 29 Sept 18 Deloutte Alfred 3988 2083 1905 1 5 29 août 1929 17 mai 1930 103 12 avril 1931 354',\n",
       " '8_12': 'Arrêté le vingt-deux novembre 1919 Servais',\n",
       " '8_13': 'Arrêté le vingt-trois novembre 1919 dimanche Servais',\n",
       " '9_0': \"N° d'ordre: 1  \\nDate du dépôt des déclarations: 15 mars 1923  \\nDésignation des personnes décédées ou absentes:  \\nNom: Dupont  \\nPrénoms: Jean  \\nDomiciles: Bruxelles  \\nDate du décès ou du jugement d'envoi en possession, en cas d'absence: 10 février 1923  \\nNoms, Prénoms et demeures des parties déclarantes: Marie Dupont, Bruxelles  \\nDroits de succession en ligne collatérale et de mutation en ligne directe:  \\nActif: 50000  \\nPassif: 20000  \\nRestant NET: 30000  \\nDroit de mutation par décès:  \\nValeur des immeubles: 15000  \\nNuméros des déclarations:  \\nPrimitives: 123  \\nSupplémentaires: 456  \\nDate de l'expiration du délai de rectification: 15 juin 1923  \\nDate de l'exigibilité des droits: 15 juillet 1923  \\nNuméros de la consignation des droits au sommier n° 28: 789  \\nRecette des droits et amendes:  \\nDate: 20 juillet 1923  \\nN°: 321  \\nCautionnements:  \\nNuméros de la consignation au sommier n° 30: 654  \\nObservations: Aucune  \",\n",
       " '9_1': 'Arrêté le vingt-quatre novembre mil neuf cent quarante-sept',\n",
       " '9_2': '439 vingt-cinq juillet Gossiaux Adélaïde Joséph. Florecourt 20 4bre 1919 Bastin Sylvain 1 autres 2225 5618 6 janvier 1920 20 juillet 1920 5 mai 1930 95',\n",
       " '9_3': 'Arrêté le vingt cinq novembre 1921',\n",
       " '9_4': 'Arrêté le vingt-trois novembre 1929 Servais',\n",
       " '9_5': 'Arrêté le vingt-sept novembre 1924 Servais',\n",
       " '9_6': 'Arrêté le vingt huit novembre 1849 Servais',\n",
       " '9_7': 'Arrêté le vingt-neuf novembre 19 Servais',\n",
       " '9_8': 'Arrêté le trente novembre 1929 dimanche Servais',\n",
       " '9_9': '439 1/2 Painblanc Joseph Bruine-le-Château 1 février 1919 Painblanc Georges & autres 5696 3696 206 1914',\n",
       " '9_10': '139^3 Painblanc Couronné 2650 2650 267 1911',\n",
       " '9_11': 'Arrêté le premier décembre 1929 Servais',\n",
       " '9_12': \"139 4 deux Dt Charlier Jean Att Thines 28/5/1918 Charlier Juliette Elise Justine d'autres 3000 3000 25/1919\",\n",
       " '9_13': 'Arrêté le deux décembre 1919, Servais',\n",
       " '10_0': \"N° d'ordre: 1  \\nDate du dépôt des déclarations: 15 mars 1923  \\nDésignation des personnes décédées ou absentes:  \\nNom: Dupont  \\nPrénoms: Jean  \\nDomiciles: Bruxelles  \\nDate du décès ou du jugement d'envoi en possession, en cas d'absence: 10 mars 1923  \\nNoms, Prénoms et demeures des parties déclarantes:  \\nMarie Dupont, Bruxelles  \\nDroits de succession en ligne collatérale et de mutation en ligne directe:  \\nActif: 50000  \\nPassif: 10000  \\nRestant NET: 40000  \\nDroit de mutation par décès:  \\nValeur des immeubles: 30000  \\nNuméros des déclarations:  \\nPrimitives: 123  \\nSupplémentaires: 456  \\nDate de l'expiration du délai de rectification: 15 juin 1923  \\nDate de l'exigibilité des droits: 15 juillet 1923  \\nNuméros de la consignation des droits au sommier n° 28: 789  \\nRecette des droits et amendes:  \\nDate: 20 juillet 1923  \\nN°: 321  \\nCautionnements:  \\nNuméros de la consignation au sommier n° 30: 654  \\nObservations: Aucune\",\n",
       " '10_1': 'Arrêté le trois décembre 1849 Servais',\n",
       " '10_2': '4395 quatre.obl. Knops Valentine Nivelles 4 7bre 1918 Devaux Léonard notaire Décla. rectificative 18 1919 15 8bre 30 13 avril 1920 661',\n",
       " '10_3': 'Arrêté le quatre décembre 1919 Servais',\n",
       " '10_4': '440 vingt obs Desfalque Eugène Bruxelles 6 juin 1919 Winderickx Régine 4100 4100 16 janvier 1920 5 mai 1920 96',\n",
       " '10_5': 'Arrêté le cinq décembre 1919 Servais',\n",
       " '10_6': '441 15 octobre Jaequin Cécile 27 juillet 449 Jossart François 56661 56661 102 14 30 21 mai 1920 le 1er août 1920 116',\n",
       " '10_7': '141e 3 Vossure Elie Louvain 18 février 1841 Gillis André 45 45 20. 211',\n",
       " '10_8': 'Arrêté le 6 décembre 1919 Servais',\n",
       " '10_9': 'Arrêté le sept décembre 1919 Dimanche Servais',\n",
       " '10_10': '141 3e huit décembre de Salieux Émile Mireille 4 7bre 1918 Simonis Maria 629 629 133 1919',\n",
       " '10_11': 'Arrêté le huit décembre 1919 Arreil',\n",
       " '10_12': '1414 neuf dble Neuwels Alphonsine Nivelles 6 février 1919 Neuwels Louis Acte rectificatif 237 1919',\n",
       " '10_13': '14215 x Goisse Adolphe x 6 janvier 1919 Hainaut Clara 416 410 204/1914',\n",
       " '11_0': \"N° d'ordre Date du dépôt des déclarations Désignation des personnes décédées ou absentes.: Nom Désignation des personnes décédées ou absentes.: Prénoms Désignation des personnes décédées ou absentes.: Domiciles Date du décès ou du jugement d'envoi en possession, en cas d'absence. Noms, Prénoms et demeures des parties déclarantes. Droits de succession en ligne collatérale et de mutation en ligne directe.: Actif. (2) Droits de succession en ligne collatérale et de mutation en ligne directe.: Passif. (2) Droits de succession en ligne collatérale et de mutation en ligne directe.: Restant NET. (2) Droit de mutation par décès: Valeur des immeubles. (2) Numéros des déclarations: Primitives. Numéros des déclarations: Supplémentaires. Date de l'expiration du délai de rectification. Date de l'exigibilité des droits. Numéros de la consignation des droits au sommier n° 28 Recette des droits et amendes.: Date Recette des droits et amendes.: N° Cautionnements.: Numéros de la consignation au sommier n° 30 Observations (Les déclarations qui figurent à l'état n° 413 doivent être émargées en conséquence, dans la présente colonne.)\",\n",
       " '11_1': 'Arrêté le neuf décembre 1949 Servais',\n",
       " '11_2': 'Arrêté le dix décembre 1921, servais',\n",
       " '11_3': '441e onze Obs Dewez Zénon Waterloo 9 août 1918 Dewez Fernand 921 921 102 1949',\n",
       " '11_4': 'Arrêté le onze décembre 1849 Servais',\n",
       " '11_5': '441 F Forges St Pelise Vital Quenast 1er 9bre 1913 Coppens Aimé 2543 2543 186 1914',\n",
       " '11_6': 'Arrêté le douze décembre 1917 Servais',\n",
       " '11_7': 'Arrêté le treize décembre 1919 Servais',\n",
       " '11_8': 'Arrêté le quatorze décembre 1919 dimanche Servais',\n",
       " '11_9': 'Arrêté le quinze décembre 1919 Servais',\n",
       " '11_10': 'Arrêté le seize décembre 1924 Servais',\n",
       " '11_11': '441 8 1er Sept Boisdeghien Louis Quaregnon 1er mai 1849 Brébis Gustave et autres 46396 45361 420 1849',\n",
       " '11_12': 'Arrêté le dix sept décembre 1919 Servais',\n",
       " '11_13': 'Arrêté le dix huit Décembre 1919 Servais',\n",
       " '12_0': \"N° d'ordre Date du dépôt des déclarations Désignation des personnes décédées ou absentes.: Nom Désignation des personnes décédées ou absentes.: Prénoms Désignation des personnes décédées ou absentes.: Domiciles Date du décès ou du jugement d'envoi en possession, en cas d'absence Noms, Prénoms et demeures des parties déclarantes Droits de succession en ligne collatérale et de mutation en ligne directe.: Actif. (2) Droits de succession en ligne collatérale et de mutation en ligne directe.: Passif. (2) Droits de succession en ligne collatérale et de mutation en ligne directe.: Restant NET. (2) Droit de mutation par décès: Valeur des immeubles. (2) Numéros des déclarations: Primitives Numéros des déclarations: Supplémentaires Date de l'expiration du délai de rectification Date de l'exigibilité des droits Numéros de la consignation des droits au sommier n° 28 Recette des droits et amendes.: Date Recette des droits et amendes.: N° Cautionnements.: Numéros de la consignation au sommier n° 30 Observations (Les déclarations qui figurent à l'état n° 413 doivent être émargées en conséquence, dans la présente colonne.)\",\n",
       " '12_1': \"9 février 1919 Devillers Josephine Bruxelles l'abbaye 9 février 1919 Devillers Félix et Adeline 243 1919\",\n",
       " '12_2': '141 bis 5 Clabecq Jeanne Nivelles Isacville Delbaux Louis 291 1919 4',\n",
       " '12_3': 'Arrêté le dix neuf décembre 1919 Servais',\n",
       " '12_4': 'Arrêté le vingt décembre 1919 Servais',\n",
       " '12_5': 'Arrêté le vingt-un février 1929 Dimanche Servais',\n",
       " '12_6': '442 vingt deux Gilbert Clémentine 10/12/1919 Loxoyderie Marie-Louise et Armand Gh 74215 74215 1 février 1920 7 juillet 1920',\n",
       " '12_7': \"142 3/4 D Paesmans Alexis Braine l'Alleud 13 mars 1915 Paesmans Henri 1551 440 4 février 31 28 5bre 1920 47\",\n",
       " '12_8': '4423 5 Minne Maria Anvers 4/12 Simon Jules 1646 1646 280 1917 9 janvier 1920 8',\n",
       " '12_9': '144 2 Mathieu Etienne 11 mai 1929 Boussu-lez-Walcourt 143766 149281 413/849',\n",
       " '12_10': 'Arrêté le vingt-deux décembre 1919 Servais',\n",
       " '12_11': 'Arrêté le vingt-trois décembre 1929 Servais',\n",
       " '12_12': '442^5 vingt-quatre Cauwenberg Victor Joseph Baulers 16.8.1918 Goorisau Adélie veuve 242 242 308 1919',\n",
       " '12_13': '343 x Anthoine Alphonse Stembery 28 Août 19 Rotthier Marie Claire Louise 1828 1826 4 février 1920 2',\n",
       " '13_0': \"N° d'ordre: 1  \\nDate du dépôt des déclarations: 12 mars 1923  \\nDésignation des personnes décédées ou absentes:  \\nNom: Dupont  \\nPrénoms: Jean  \\nDomiciles: Bruxelles  \\nDate du décès ou du jugement d'envoi en possession, en cas d'absence: 5 février 1923  \\nNoms, Prénoms et demeures des parties déclarantes:  \\nMarie Dupont, Bruxelles  \\nDroits de succession en ligne collatérale et de mutation en ligne directe:  \\nActif: 50000  \\nPassif: 20000  \\nRestant NET: 30000  \\nDroit de mutation par décès:  \\nValeur des immeubles: 15000  \\nNuméros des déclarations:  \\nPrimitives: 123  \\nSupplémentaires: 456  \\nDate de l'expiration du délai de rectification: 12 juin 1923  \\nDate de l'exigibilité des droits: 12 juillet 1923  \\nNuméros de la consignation des droits au sommier n° 28: 789  \\nRecette des droits et amendes:  \\nDate: 15 août 1923  \\nN°: 321  \\nCautionnements:  \\nNuméros de la consignation au sommier n° 30: 654  \\nObservations: Aucune\",\n",
       " '13_1': 'Arrêté le vingt-quatre décembre 1919 Servais',\n",
       " '13_2': 'Arrêté le vingt cinq décembre 1919 Noël Servais',\n",
       " '13_3': '1452 enregistré Arlon Thibaux Marie Louise Arlon 5 7bre 19 Loyens Alexis et autres 2250 1250 1000',\n",
       " '13_4': 'Arrêté le vingt-six décembre 1919 Servais',\n",
       " '13_5': '144 uniflopl 9 Wautbiez Lucie Baulers 18 juin 1914 Moxhe Abel 16629 16629 19 février 1920 19 avril 1920 91',\n",
       " '13_6': '145 30 Jacquet Emouleur ég d° Jacquet Émile 1854 2393 56202 4 d° 19 avril 1905',\n",
       " '13_7': 'Arrêté le vingt-sept décembre 1919 Servais',\n",
       " '13_8': 'Arrêté le vingt-huit décembre 1909 Dimanche Servais',\n",
       " '13_9': '146 vingt neuf Vanglaire Guillaume Anvers le Château 4 7bre 1919 Devogeleer-Liesse et autres 400 100 9 30 juillet 1920 non fixée',\n",
       " '13_10': 'Arrêté le vingt neuf décembre 1919 servais bonifié 1917 fractions neuf 1916 99 1918 258 1919 188 191 220 288 318 408 408 413 432 433 436 437',\n",
       " '13_11': \"Arrêté le trente Décembre 1919 Servais Numéro d'enregistrement de 1919 68 335 1918 68 294 HG 576\",\n",
       " '13_12': '446^2 9 février Plasman Louise Bruxelles 10 mars 1914 Veny Pierre et autres 148 745 24/1914 1918 87 114 116 127 138 177 273 341 360 366 400 410 412 429',\n",
       " '13_13': 'Arrêté le trente décembre 1929 Servais Le vérificateur Signature',\n",
       " '14_0': \"N° d'ordre:  \\nDate du dépôt des déclarations:  \\nDÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES.  \\nNOMS:  \\nPRÉNOMS:  \\nDOMICILES:  \\nDATE DU DÉCÈS ou du jugement d'envoi en possession, en cas d'absence:  \\nNOMS, PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES:  \\nDROITS DE SUCCESSION EN LIGNE COLLATÉRALE et de MUTATION EN LIGNE DIRECTE.  \\nACTIF. (2):  \\nPASSIF. (2):  \\nRESTANT NET. (2):  \\nDROIT DE MUTATION par décès: VALEUR des IMMEUBLES. (2):  \\nNUMÉROS des DÉCLARATIONS: Primitives:  \\nSupplémentaires:  \\nDATE de l'expiration du délai de rectification:  \\nDATE de l'exigibilité des droits:  \\nNUMÉROS de la consignation des droits au sommier n° 28:  \\nRECETTE des DROITS ET AMENDES.  \\nDATE:  \\nN°:  \\nCAUTIONNEMENTS.  \\nNUMÉROS de la consignation au sommier n° 30:  \\nOBSERVATIONS:  \\n(Les déclarations qui figurent à l'état n° 41 doivent être énoncées en conséquence, dans la présente colonne.)\",\n",
       " '14_1': 'Arrêté le premier janvier 1900 Circonscription Servais',\n",
       " '14_2': '1er janvier 1920 Séverin Jules Anorée L. 6 juillet 1919 Delestrée Adolphine et autres 34842 34842 3,16 1920 18 février 1920 6',\n",
       " '14_3': '2 1er Dumont Louise Nivelles 3 do Hanry Juliette et autre 369 2030 15 No 3 24 janvier 1920',\n",
       " '14_4': 'Arrêté le deux janvier 1910 Servais',\n",
       " '14_5': 'Arrêté le trois janvier 1930 Servais',\n",
       " '14_6': 'Arrêté le quatorze janvier dix-neuf cent servais',\n",
       " '14_7': '3 cinq janvier Houlin Edouard Lobbes 5 juillet 1924 Ernest Meverée Laules 781752 7387452 188 16 février 1920 22 juillet 1920 4 février 1920 726',\n",
       " '14_8': '3e Dr Séverin Jules Bruxelles Gendarm 294 Séverin dom 36442 1 1920',\n",
       " '14_9': 'Wanderpepen Marie Nivelles 29 Août 1918 Remacle Léonie 2665 1619 1042 1919 14 Juillet 1920',\n",
       " '14_10': 'Arrêté le cinq janvier 1924 Servais',\n",
       " '14_11': '4 janvier Scolas Victor Joseph Bruxelles 22 avril 1919 Koekelberg Joseph Callaud autres 9039 9039 14 février 1920 23 juillet 1920 juillet 1920 126',\n",
       " '14_12': 'Arrêté le dix Janvier mil neuf cent servais',\n",
       " '14_13': 'Arreté le Sept Janvier 1924 servais',\n",
       " '15_0': \"N° d'ordre: Date du dépôt des déclarations: Désignation des personnes décédées ou absentes: Noms: Prénoms: Domiciles: Date du décès ou du jugement d'envoi en possession, en cas d'absence: Noms, Prénoms et demeures des parties déclarantes: Droits de succession en ligne collatérale et de mutation en ligne directe: Actif. (2): Passif. (2): Restant NET. (2): Droit de mutation par décès: Valeur des immeubles. (2): Numéros des déclarations: Primitives: Supplémentaires: Date de l'expiration du délai de rectification: Date de l'exigibilité des droits: Numéros de la consignation des droits au sommier n° 28: Recette des droits et amendes: Date: N° 03: Cautionnements: Numéros de la consignation au sommier n° 30: Observations: (Les déclarations qui figurent à l'état n° 43 doivent être envisagées en conséquence, dans la présente colonne.)\",\n",
       " '15_1': '47 huit Janvier 1910 Lefebvre Laurent Cubizje 30 9bre 1915 Nicolas Euphrasine 4450 4450 1422 1919 23 8bre 211 24 8bre 219',\n",
       " '15_2': 'Arrêté le neuf janvier 1920 Servais',\n",
       " '15_3': 'Arrêté le neuf janvier 1920 Servais',\n",
       " '15_4': 'Arrêté le dix janvier 1920 Servais',\n",
       " '15_5': 'Arrêté le onze janvier 1920 Dimanche Servais',\n",
       " '15_6': '5 douze janvier Drieux Henri Bonival 2 mai 1919 Deguelle Jules court 4200 1200 280 29 février 1920 non fixée',\n",
       " '15_7': 'Arrêté le douze janvier 1920 Servais',\n",
       " '15_8': '6 treize janvier Lacroix Marie Catherine Wijneghem 15 juillet 1849 3641 2691 26 30 1er mai 1850 non remplie',\n",
       " '15_9': 'Arrêté le treize janvier 1920 Servais',\n",
       " '15_10': 'Arrêté le quatorze janvier 1920 Servais',\n",
       " '15_11': 'Arrêté le quinze janvier 1920 Servais',\n",
       " '15_12': 'Arrêté le seize janvier 1930 Servais',\n",
       " '15_13': '7 21 septembre Miebiels Victorine Verviers 29 juillet 1929 Bodonghien Alfred et autres 14428 44428 29 février 1930 29 mai 1930 1 août 1930 290',\n",
       " '16_0': \"N° d'ordre: [empty]  \\nDate du dépôt des déclarations: [empty]  \\nDÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES:  \\nNom: [empty]  \\nPrénoms: [empty]  \\nDomiciles: [empty]  \\nDate du décès ou du jugement d'envoi en possession, en cas d'absence: [empty]  \\nNOMS, PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES: [empty]  \\nDROITS DE SUCCESSION EN LIGNE COLLATERALE ET DE MUTATION EN LIGNE DIRECTE:  \\nActif: [empty]  \\nPassif: [empty]  \\nRestant NET: [empty]  \\nDROIT DE MUTATION PAR DÉCÈS:  \\nValeur des immeubles: [empty]  \\nNUMÉROS DES DÉCLARATIONS:  \\nPrimitives: [empty]  \\nSupplémentaires: [empty]  \\nDate de l'expiration du délai de rectification: [empty]  \\nDate de l'exigibilité des droits: [empty]  \\nNUMÉROS DE LA CONSIGNATION DES DROITS AU SOMMIER N° 28: [empty]  \\nRECETTE DES DROITS ET AMENDES:  \\nDate: [empty]  \\nN°: [empty]  \\nCAUTIONNEMENTS:  \\nNuméros de la consignation au sommier n° 30: [empty]  \\nOBSERVATIONS: [empty]  \",\n",
       " '16_1': '8 31 décembre 1920 Leclercq Florine de Charleroi 6 février 1919 Leclercq Victor et autres 8468 3466 1928 28 février 1920 6 juillet 1920 non fournies',\n",
       " '16_2': \"1 5e Gerroir Célesphore Anvers 20 janvier 1918 Bastiaens Alverius Possession d'usufruit 2 avril 1920\",\n",
       " '16_3': '9e 5 Arez Alphonse Gx a reg 28/10 Gérères Marie Gx ce 334 1919 2 février 30',\n",
       " '16_4': 'Arrêté le 26 Septembre 1920 Servais',\n",
       " '16_5': 'Arrêté le dix-huit janvier 1920 Dimanche Servais',\n",
       " '16_6': 'Arrêté le dix neuf janvier 1920 Servais',\n",
       " '16_7': 'Arrêté le vingt janvier 1940 Servais',\n",
       " '16_8': '9^3 vingt et un Janvier Becquet Marcel Bruxelles 8 mai 1916 Becquet René Dix neuf cent dix-neuf 285 1919',\n",
       " '16_9': 'Arrêté le vingt-un janvier 1920 Servais',\n",
       " '16_10': 'Arrêté le vingt-deux novembre 1940 Servais',\n",
       " '16_11': 'Arrêté le vingt trois janvier 1920 Servais',\n",
       " '16_12': '10 vingt-quatre Duvieux Henri Nivelles 25 juillet 1919 Duvieux Louis autres 444 52 585 108 940 1432 1920 7 mars 1920 1 avril 1920 13 13 F 1920',\n",
       " '16_13': 'Arrêté le vingt quatre janvier 1923 à Servais',\n",
       " '17_0': \"N° d'ordre:  \\nDate du dépôt des déclarations:  \\nDésignation des personnes décédées ou absentes:  \\nNom:  \\nPrénoms:  \\nDomiciles:  \\nDate du décès ou du jugement d'envoi en possession, en cas d'absence:  \\nNoms, Prénoms et demeures des parties déclarantes:  \\nDroits de succession en ligne collatérale et de mutation en ligne directe:  \\nActif:  \\nPassif:  \\nRestant NET:  \\nDroit de mutation par décès:  \\nValeur des immeubles:  \\nNuméros des déclarations:  \\nPrimitives:  \\nSupplémentaires:  \\nDate de l'expiration du délai de rectification:  \\nDate de l'exigibilité des droits:  \\nNuméros de la consignation des droits au sommier n° 28:  \\nRecette des droits et amendes:  \\nDate:  \\nN°:  \\nCautionnements:  \\nNuméros de la consignation au sommier n° 30:  \\nObservations:  \",\n",
       " '17_1': 'Arrêté le vingt cinq janvier 1920 Dimanche Servais',\n",
       " '17_2': '10e enregistré janvier Desflandre Gustave Désiré Cuesmes 22 Août 1913 Leclercq Marie Philippine 494 510 189 1914',\n",
       " '17_3': '10 30 Ypersiel Julien Ghislain 18 Août 1918 Eleonore Oestier 220 490 8 6 1919',\n",
       " '17_4': 'Arrêté le vingt-six janvier 1920 Servais',\n",
       " '17_5': \"10e 21 septembre bordereau Louis Braine l'Alleud 25 février 1919 Casteur Antoine 300 300 131/131 u 21 janvier 1920\",\n",
       " '17_6': 'Arrêté le vingt-sept janvier 1910 Servais',\n",
       " '17_7': '10^5 vingt-huit Janvier Decock Léonie 22 février 1917 Alleur Seraing 544 544 238 1918',\n",
       " '17_8': '106 3 Decock Adèle 10 Août 1918 140 1918',\n",
       " '17_9': '11 2e Bolendries Anastasie Nivelles 18 8bre 1919 Bolendries Virginie 950 360 590 11 mars 1920 18 avril 1920 1 avril 1920 149',\n",
       " '17_10': 'Arrêté le vingt-huit Janvier 1920 Servais',\n",
       " '17_11': 'Arrêté le vingt neuf janvier 1920 Servais',\n",
       " '17_12': '11e 6 septembre Rousseau Charles Bruxelles 31 mars 1919 Rousseau Laura 1500 1500 1500 1919',\n",
       " '17_13': '11 3° Bedonckx Vital Culege 14 8bre 18 Bonemans Elie Thérèse 1449 1560 95.40 1381/19 19',\n",
       " '18_0': \"N' d'ordre: [empty]  \\nDate du dépôt des déclarations: [empty]  \\n\\nDésignation des personnes décédées ou absentes.:  \\nNoms: [empty]  \\nPrénoms: [empty]  \\nDomiciles: [empty]  \\nDate du décès ou du jugement d'envoi en possession, en cas d'absence.: [empty]  \\n\\nNoms, Prénoms et demeures des parties déclarantes.: [empty]  \\n\\nDroits de succession en ligne collatérale et de mutation en ligne directe.:  \\nActif. (2): [empty]  \\nPassif. (2): [empty]  \\nRestant NET. (2): [empty]  \\n\\nDroit de mutation par décès:  \\nValeur des immeubles. (2): [empty]  \\n\\nNuméros des déclarations:  \\nPrimitives.: [empty]  \\nSupplémentaires.: [empty]  \\n\\nDate de l'expiration du délai de rectification.: [empty]  \\nDate de l'exigibilité des droits.: [empty]  \\n\\nNuméros de la consignation des droits au sommier n' 28: [empty]  \\n\\nRecette des droits et amendes.:  \\nDate: [empty]  \\nN^03: [empty]  \\n\\nCautionnements.:  \\nNuméros de la consignation au sommier n'30: [empty]  \\n\\nObservations: [Les déclarations qui figurent à l'état n° 41 doivent être chargées en conséquence, dans la présente colonne.]\",\n",
       " '18_1': 'Arrêté le trente janvier 1920 Servais',\n",
       " '18_2': 'Arrêté le trente-un janvier 1920 Servais',\n",
       " '18_3': 'Arrêté le premier février 1920 Dimanche servais',\n",
       " '18_4': '12 2ème février Carlier Victor Quenast 4 février 1910 Carlier Vital et Marie 6345 509 6069 11e 1925 15 mars 1910 6 février 1910 36',\n",
       " '18_5': 'Arrêté le deux février 1920 Servais',\n",
       " '18_6': 'Arrêté le 21 février 1920 Servais',\n",
       " '18_7': \"13 9 Juin 1919 Longe Arsine l'abbé 20 juillet 1919 Delay Henri d'autres 16234 2624 18 7 Mai 1920 non taxables\",\n",
       " '18_8': '14 15 Legain Escula Anna-Marie Rommel 8 Août 1918 Evergée Belge autres 9412 3246 6421 1904 1920 1er 2e Août 1919 9 Août 1921 27 janvier 1922',\n",
       " '18_9': 'Arrêté le quatre février 1920 servais',\n",
       " '18_10': '15 cinq février Kaivez Alvare Cathérine Louisa Calais 5 avril 1919 Blanckaert Alphonse Auden 1590 1590 18 8 juin 1920 non payables',\n",
       " '18_11': '15² 5 Denys Elewijt Vilvoorde Opperstraat 499 Enser Emile Acte unifratif 20 1919 5 février 1920',\n",
       " '18_12': '15³ Van Hoobrouck Georges Chas. de Gueux 23 mars 1914 Capmans Émile 5545 2668 321 1914',\n",
       " '18_13': '154 Painblanc Joseph Jemeppe chateau 1 Février 1899 Rosy Halseux autres 2290 2290 205 1291',\n",
       " '19_0': \"N° d'ordre  \\nDate du dépôt des déclarations  \\nDésignation des personnes décédées ou absentes:  \\nNoms  \\nPrénoms  \\nDomiciles  \\nDate du décès ou du jugement d'envoi en possession, en cas d'absence  \\nNoms, Prénoms et demeures des parties déclarantes  \\nDroits de succession en ligne collatérale et de mutation en ligne directe:  \\nActif  \\nPassif  \\nRestant NET  \\nDroit de mutation par décès:  \\nValeur des immeubles  \\nNuméros des déclarations:  \\nPrimitives  \\nSupplémentaires  \\nDate de l'expiration du délai de rectification  \\nDate de l'exigibilité des droits  \\nNuméros de la consignation des droits au sommier n° 28  \\nRecette des droits et amendes:  \\nDate  \\nN°  \\nCautionnements:  \\nNuméros de la consignation au sommier n° 30  \\nObservations  \",\n",
       " '19_1': 'Arrêté le cinq février 1920 servais',\n",
       " '19_2': 'Arrêté le 15 février 1920 Servais',\n",
       " '19_3': 'Arrêté le sept février 1920',\n",
       " '19_4': 'Arrêté le huit Février 1920 Dimanche Servais',\n",
       " '19_5': 'Arrêté le neuf février 1920, Servais',\n",
       " '19_6': '16 13 février Soupart Emelie Bruxelles 11 mai 1899 Piriaux Henry et Oscar 39101 39101 26e 183 24 mars 1900 11 8bre 1900 173 192',\n",
       " '19_7': '16e 3 Février Alfred Gh Colbize 2 Août 95 Févie Albine et autres 1200 2200 1000 496 29 mars 1920 69',\n",
       " '19_8': '16 3/5 5 Sivaux Augustin Rebecq 19 mars 1912 Capmans Émile 2045 2025 149/1911',\n",
       " '19_9': 'Arrêté le dix février 1920 Servais',\n",
       " '19_10': 'Arrêté le onze février 1920 à Liège',\n",
       " '19_11': \"17 6 août Vancutsem Adeline Avenue de l'Alliance 13 août 1899 Bruxelles Charles & autres 13.628 13.628 16 1/2 27 mars 1900 20 juillet 1900\",\n",
       " '19_12': 'Arrêté le douze février 1920 Servais',\n",
       " '19_13': '18 croix ferrée Hrumjadis Julie Vienne Autriche 16 février Comte de Wicral Henri 1919 9501 25 3 février 1920',\n",
       " '20_0': \"N° d'ordre: [empty]  \\nDate du dépôt des déclarations: [empty]  \\nDÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES:  \\nNOMS: [empty]  \\nPRÉNOMS: [empty]  \\nDOMICILES: [empty]  \\nDATE DU DÉCÈS ou du jugement d'envoi en possession, en cas d'absence: [empty]  \\nNOMS, PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES: [empty]  \\nDROITS DE SUCCESSION en ligne collatérale et de mutation en ligne directe:  \\nACTIF: [empty]  \\nPASSIF: [empty]  \\nRESTANT NET: [empty]  \\nDROIT DE MUTATION par décès:  \\nVALEUR des IMMEUBLES: [empty]  \\nNUMÉROS des DÉCLARATIONS:  \\nPrimitives: [empty]  \\nSupplémentaires: [empty]  \\nDATE de l'expiration du délai de rectification: [empty]  \\nDATE de l'exigibilité des droits: [empty]  \\nNUMÉROS de la consignation des droits au sommier n° 28: [empty]  \\nRECETTE des DROITS et AMENDES:  \\nDATE: [empty]  \\nN°: [empty]  \\nCAUTIONNEMENTS:  \\nNUMÉROS de la consignation au sommier n° 30: [empty]  \\nOBSERVATIONS: [empty]  \",\n",
       " '20_1': 'Arrêté le treize février 1920 Servais',\n",
       " '20_2': 'Arrêté le quatorze février servais',\n",
       " '20_3': 'Arrêté le quinze février dix-neuf cent vingt',\n",
       " '20_4': 'Arrêté le seize février 1920, Servais',\n",
       " '20_5': '18 1/2 du 26 février Cabureau Louis Ecaussinnes Dielbaux Marcel instituteur 298 919',\n",
       " '20_6': '18 3e 0 Deches Jules 14.8.1918 Deches Gustave Lanter 03 03 356 1919',\n",
       " '20_7': 'Arrêté le dix sept février 1920 Servais',\n",
       " '20_8': 'Arrêté le dix-huit février 1920 Servais',\n",
       " '20_9': '19 tré neufbre Pékiaux Cornélie Nivelles 12 avril 1919 Pékiaux Constantin 6350 31 mars 1920 10 juillet 1920',\n",
       " '20_10': '19 2 Dubois Alexandre Quenast 26 9bre 1919 Dubois Jean dit et autres 350 320 360 1919',\n",
       " '20_11': 'Arrêté le dix-neuf février 1920 Servais',\n",
       " '20_12': 'Arrêté le vingt février 1920 Servais',\n",
       " '20_13': '193 vingt un Janv Remience Jean Bte Nivelles 4 février 400 400 100 1949 Remience Jeanne'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_refine_complex_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1f689f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "unable_ids = [id for id, content in gpt_refine_complex_output.items() if \"unable\" in content or \"I apologize\" in content or \"The image\" in content or \"sorry\" in content]\n",
    "print(unable_ids, len(unable_ids), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51068bb4",
   "metadata": {},
   "source": [
    "### To run with the saved json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81581278",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_refine_complex_output_df = pd.DataFrame(gpt_refine_complex_output.items(), columns=['id', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2d9533c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_0</td>\n",
       "      <td>N° d'ordre:   Date du dépôt des déclarations: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_1</td>\n",
       "      <td>Arrêté le vingt-huit octobre 1919 Servais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_2</td>\n",
       "      <td>Arrêté le vingt neuf octobre 1919 Servais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_3</td>\n",
       "      <td>398 trente octobre Herrenx Alphonse Opheim 19 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_4</td>\n",
       "      <td>398½ 2 Lefèvre Jules Bruxelles 8 janvier 1919 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_9</td>\n",
       "      <td>19 tré neufbre Pékiaux Cornélie Nivelles 12 av...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>19 2 Dubois Alexandre Quenast 26 9bre 1919 Dub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>Arrêté le dix-neuf février 1920 Servais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>Arrêté le vingt février 1920 Servais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>193 vingt un Janv Remience Jean Bte Nivelles 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0      1_0  N° d'ordre:   Date du dépôt des déclarations: ...\n",
       "1      1_1          Arrêté le vingt-huit octobre 1919 Servais\n",
       "2      1_2          Arrêté le vingt neuf octobre 1919 Servais\n",
       "3      1_3  398 trente octobre Herrenx Alphonse Opheim 19 ...\n",
       "4      1_4  398½ 2 Lefèvre Jules Bruxelles 8 janvier 1919 ...\n",
       "..     ...                                                ...\n",
       "278   20_9  19 tré neufbre Pékiaux Cornélie Nivelles 12 av...\n",
       "279  20_10  19 2 Dubois Alexandre Quenast 26 9bre 1919 Dub...\n",
       "280  20_11            Arrêté le dix-neuf février 1920 Servais\n",
       "281  20_12               Arrêté le vingt février 1920 Servais\n",
       "282  20_13  193 vingt un Janv Remience Jean Bte Nivelles 4...\n",
       "\n",
       "[283 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_refine_complex_output_df['text'] = gpt_refine_complex_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "gpt_refine_complex_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d265a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_refine_complex_output_df.to_csv(path+'/results/postprocessed/gpt_refine_complex_output_perline_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736b773",
   "metadata": {},
   "source": [
    "# CER/BLEU calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2f6551",
   "metadata": {},
   "source": [
    "## ground truth df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a4c03dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "text_path = path+'/data/transcriptions'\n",
    "file_list = glob(os.path.join(text_path, 'transcription_ex*.txt'))\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in file_list:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    lines = content.split('\\n')\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'line': range(0, len(lines)),  # Line numbers starting from 0\n",
    "        'text': lines\n",
    "    })\n",
    "    \n",
    "    name = os.path.basename(file)\n",
    "    name = name.split('.')[0]\n",
    "    df['file'] = name.split('ex')[1]\n",
    "    df['file'] = df['file'].astype(int)\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "90b2da7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N' d'ordre Date du dépot des déclarations Dési...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Nom. Prénoms Domiciles Actif. (2) Passif. (2) ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arrêté le vingt huit octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>arrêté le vingt neuf octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>398 trente octobre Herrent Alphones gh Ophain ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>10</td>\n",
       "      <td>19 dix neuf d Pétriaux Coralie Nivelles 22 av...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>11</td>\n",
       "      <td>19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>12</td>\n",
       "      <td>Arrêté le dix neuf février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>13</td>\n",
       "      <td>Arrêté le vingt février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>14</td>\n",
       "      <td>19^3 vingt un février Remience Jean Bte Nivell...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     line                                               text  file\n",
       "0       0  N' d'ordre Date du dépot des déclarations Dési...     1\n",
       "1       1  Nom. Prénoms Domiciles Actif. (2) Passif. (2) ...     1\n",
       "2       2   arrêté le vingt huit octobre 1919 servais    ...     1\n",
       "3       3   arrêté le vingt neuf octobre 1919 servais    ...     1\n",
       "4       4  398 trente octobre Herrent Alphones gh Ophain ...     1\n",
       "..    ...                                                ...   ...\n",
       "298    10   19 dix neuf d Pétriaux Coralie Nivelles 22 av...    20\n",
       "299    11  19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...    20\n",
       "300    12          Arrêté le dix neuf février 1920 servais      20\n",
       "301    13             Arrêté le vingt février 1920 servais      20\n",
       "302    14  19^3 vingt un février Remience Jean Bte Nivell...    20\n",
       "\n",
       "[303 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "df = df.sort_values(by=['file', 'line']).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a98c96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the text values of line number 0 and 1 (the two lines of the header)\n",
    "for file in df['file'].unique():\n",
    "    header_lines = df[(df['file'] == file) & (df['line'].isin([0, 1]))]\n",
    "    df.loc[header_lines.index[0], 'text'] = header_lines.iloc[0]['text'] + \" \" + header_lines.iloc[1]['text']\n",
    "df = df[df['line'] != 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d6d3fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['line'] != 0, 'line'] -= 1  # Adjust line numbers after removing the second line of the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dae62cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for file 6, two lines are used for some column.. we need to merge them\n",
    "# doubled_line = df[(df['file'] == 6) & (df['line'].isin([3, 4]))]\n",
    "# df.loc[doubled_line.index[0], 'text'] = doubled_line.iloc[0]['text'] + \" \" + doubled_line.iloc[1]['text']\n",
    "# df.drop(doubled_line.index[1], inplace=True)\n",
    "# df.loc[(df['file'] == 6) & (df['line'] > 4), 'line'] -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d8abb06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N' d'ordre Date du dépot des déclarations Dési...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>arrêté le vingt huit octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arrêté le vingt neuf octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>398 trente octobre Herrent Alphones gh Ophain ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>arrêté le trente octobre 1919 servais        ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>arrêté le trente un octobre 1919 servais     ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>arrêté le premier novembre 1919 Toussaint ser...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>arrêté le deux novembre 1919 Dimanche servais...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>399 trois 9bre Desmedt Jeanne Nivelles 13 mai ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>400 d Monseur Raoul Oscar Clabecq 1 8b 1918 Mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>401 d Bouty Henri Braine l'Alleud 26 février 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>arrêté le trois novembre 1919 servais        ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>402 quatre 9bre Godart Renelde Braine l'Alleud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    line                                               text  file\n",
       "0      0  N' d'ordre Date du dépot des déclarations Dési...     1\n",
       "1      1   arrêté le vingt huit octobre 1919 servais    ...     1\n",
       "2      2   arrêté le vingt neuf octobre 1919 servais    ...     1\n",
       "3      3  398 trente octobre Herrent Alphones gh Ophain ...     1\n",
       "4      4  398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...     1\n",
       "5      5   arrêté le trente octobre 1919 servais        ...     1\n",
       "6      6   arrêté le trente un octobre 1919 servais     ...     1\n",
       "7      7   arrêté le premier novembre 1919 Toussaint ser...     1\n",
       "8      8   arrêté le deux novembre 1919 Dimanche servais...     1\n",
       "9      9  399 trois 9bre Desmedt Jeanne Nivelles 13 mai ...     1\n",
       "10    10  400 d Monseur Raoul Oscar Clabecq 1 8b 1918 Mo...     1\n",
       "11    11  401 d Bouty Henri Braine l'Alleud 26 février 1...     1\n",
       "12    12   arrêté le trois novembre 1919 servais        ...     1\n",
       "13    13  402 quatre 9bre Godart Renelde Braine l'Alleud...     1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['file']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "68922e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N' d'ordre Date du dépot des déclarations Dési...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>arrêté le vingt huit octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arrêté le vingt neuf octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>398 trente octobre Herrent Alphones gh Ophain ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>9</td>\n",
       "      <td>19 dix neuf d Pétriaux Coralie Nivelles 22 av...</td>\n",
       "      <td>20</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>10</td>\n",
       "      <td>19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...</td>\n",
       "      <td>20</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>11</td>\n",
       "      <td>Arrêté le dix neuf février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>12</td>\n",
       "      <td>Arrêté le vingt février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>13</td>\n",
       "      <td>19^3 vingt un février Remience Jean Bte Nivell...</td>\n",
       "      <td>20</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     line                                               text  file     id\n",
       "0       0  N' d'ordre Date du dépot des déclarations Dési...     1    1_0\n",
       "1       1   arrêté le vingt huit octobre 1919 servais    ...     1    1_1\n",
       "2       2   arrêté le vingt neuf octobre 1919 servais    ...     1    1_2\n",
       "3       3  398 trente octobre Herrent Alphones gh Ophain ...     1    1_3\n",
       "4       4  398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...     1    1_4\n",
       "..    ...                                                ...   ...    ...\n",
       "278     9   19 dix neuf d Pétriaux Coralie Nivelles 22 av...    20   20_9\n",
       "279    10  19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...    20  20_10\n",
       "280    11          Arrêté le dix neuf février 1920 servais      20  20_11\n",
       "281    12             Arrêté le vingt février 1920 servais      20  20_12\n",
       "282    13  19^3 vingt un février Remience Jean Bte Nivell...    20  20_13\n",
       "\n",
       "[283 rows x 4 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'] = df['file'].astype(str) + '_' + df['line'].astype(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7fc07b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 1, Last Line: 13\n",
      "File: 2, Last Line: 14\n",
      "File: 3, Last Line: 13\n",
      "File: 4, Last Line: 13\n",
      "File: 5, Last Line: 14\n",
      "File: 6, Last Line: 14\n",
      "File: 7, Last Line: 13\n",
      "File: 8, Last Line: 13\n",
      "File: 9, Last Line: 13\n",
      "File: 10, Last Line: 13\n",
      "File: 11, Last Line: 13\n",
      "File: 12, Last Line: 13\n",
      "File: 13, Last Line: 13\n",
      "File: 14, Last Line: 13\n",
      "File: 15, Last Line: 13\n",
      "File: 16, Last Line: 13\n",
      "File: 17, Last Line: 13\n",
      "File: 18, Last Line: 13\n",
      "File: 19, Last Line: 13\n",
      "File: 20, Last Line: 13\n"
     ]
    }
   ],
   "source": [
    "for file in df['file'].unique():\n",
    "    last_line = df[df['file'] == file]['line'].max()\n",
    "    print(f\"File: {file}, Last Line: {last_line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8837aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path+'/data/transcription_perline_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fb89e02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283 283\n"
     ]
    }
   ],
   "source": [
    "print(df['id'].nunique(), claude_output_df['id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c1c9e",
   "metadata": {},
   "source": [
    "## Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "897e931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'/data/transcription_perline_text_whitespace-trimmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0be671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "cer_metric =load(\"cer\")\n",
    "bleu_metric = load(\"bleu\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c05a9600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob(os.path.join(path+'/results/postprocessed/per-line_experiments', '*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84956ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bleu_gpt = {}\n",
    "cer_gpt = {}\n",
    "\n",
    "for id in df_filtered['id'].unique():\n",
    "    # Extract the text as a single string, not as an array\n",
    "    pred_text = pred[pred['id'] == id]['text'].values[0]\n",
    "    ref_text = df_filtered[df_filtered['id'] == id]['text'].values[0]\n",
    "\n",
    "    # Ensure the predictions and references are passed as a list of strings\n",
    "    if pred_text and ref_text:  # Check if both texts are not empty (which happens for some OCR outputs)\n",
    "        bleu_gpt[id] = bleu_metric.compute(predictions=[pred_text], references=[ref_text])\n",
    "    else:\n",
    "        bleu_gpt[id] = {'bleu': 0.0}  # Assign a default value if texts are empty\n",
    "    cer_gpt[id] = cer_metric.compute(predictions=[pred_text], references=[ref_text])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8584298f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_one_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_two_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/pytesseractOCR_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_two_text_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_complex_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_one_text_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_refine_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_refine_complex_output_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_refine_complex_output_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/kerasOCR_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/trOCR_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_refine_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_one_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_two_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_two_text_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_complex_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/easyOCR_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_one_text_example_perline_output.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "637acb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gpt_one_example...\n",
      "Processing claude_two_example...\n",
      "Processing pytesseractOCR...\n",
      "Processing claude_two_text_example...\n",
      "Processing claude_complex...\n",
      "Processing gpt_one_text_example...\n",
      "Processing claude_refine...\n",
      "Processing gpt_refine_complex_output...\n",
      "Processing claude_refine_complex_output...\n",
      "Processing gpt...\n",
      "Processing kerasOCR...\n",
      "Processing trOCR...\n",
      "Processing claude...\n",
      "Processing gpt_refine...\n",
      "Processing claude_one_example...\n",
      "Processing gpt_two_example...\n",
      "Processing gpt_two_text_example...\n",
      "Processing gpt_complex...\n",
      "Processing easyOCR...\n",
      "Processing claude_one_text_example...\n"
     ]
    }
   ],
   "source": [
    "bleu_perline = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    pred = pd.read_csv(file)\n",
    "    df_filtered = df[df['id'].isin(pred['id'])]\n",
    "\n",
    "    name = os.path.basename(file)\n",
    "    name = name.split('_perline')[0]\n",
    "\n",
    "    print(f\"Processing {name}...\")\n",
    "\n",
    "    bleu_scores = []  # List to accumulate BLEU scores for this model\n",
    "\n",
    "    for id in df_filtered['id'].unique():\n",
    "        # Extract the text as a single string, not as an array\n",
    "        pred_text = pred[pred['id'] == id]['text'].values\n",
    "        ref_text = df_filtered[df_filtered['id'] == id]['text'].values\n",
    "\n",
    "        # Ensure the predictions and references are passed as a list of strings\n",
    "        if len(pred_text) > 0 and len(ref_text) > 0:  # Check if both texts are not empty\n",
    "            pred_text = pred_text[0]\n",
    "            ref_text = ref_text[0]\n",
    "\n",
    "            # Check for NaN values and strip whitespace\n",
    "            if pd.notna(pred_text) and pd.notna(ref_text):\n",
    "                pred_text = pred_text.strip()\n",
    "                ref_text = ref_text.strip()\n",
    "\n",
    "                # Ensure texts are not empty after stripping\n",
    "                if pred_text and ref_text:\n",
    "                    bleu_metrics = bleu_metric.compute(predictions=[pred_text], references=[ref_text], max_order=2)\n",
    "                else:\n",
    "                    bleu_metrics = {'bleu': 0.0}  # Assign a default value if texts are empty\n",
    "            else:\n",
    "                bleu_metrics = {'bleu': 0.0}  # Assign a default value if texts are NaN\n",
    "        else:\n",
    "            bleu_metrics = {'bleu': 0.0}  # Assign a default value if texts are empty\n",
    "\n",
    "        bleu_scores.append({\n",
    "                'model': name,\n",
    "                'id': id,\n",
    "                **bleu_metrics\n",
    "            })\n",
    "\n",
    "    bleu_perline = pd.concat([bleu_perline, pd.DataFrame(bleu_scores)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc16b3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>bleu</th>\n",
       "      <th>precisions</th>\n",
       "      <th>brevity_penalty</th>\n",
       "      <th>length_ratio</th>\n",
       "      <th>translation_length</th>\n",
       "      <th>reference_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt_one_example</td>\n",
       "      <td>1_0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>1.009021e-09</td>\n",
       "      <td>0.046053</td>\n",
       "      <td>7.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt_one_example</td>\n",
       "      <td>1_2</td>\n",
       "      <td>0.597614</td>\n",
       "      <td>[0.7142857142857143, 0.5]</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt_one_example</td>\n",
       "      <td>1_3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.2857142857142857, 0.0]</td>\n",
       "      <td>5.743262e-02</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt_one_example</td>\n",
       "      <td>1_4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.14285714285714285, 0.0]</td>\n",
       "      <td>2.077482e-01</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt_one_example</td>\n",
       "      <td>1_5</td>\n",
       "      <td>0.436436</td>\n",
       "      <td>[0.5714285714285714, 0.3333333333333333]</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5643</th>\n",
       "      <td>claude_one_text_example</td>\n",
       "      <td>20_9</td>\n",
       "      <td>0.377229</td>\n",
       "      <td>[0.5454545454545454, 0.2857142857142857]</td>\n",
       "      <td>9.555630e-01</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>claude_one_text_example</td>\n",
       "      <td>20_10</td>\n",
       "      <td>0.211604</td>\n",
       "      <td>[0.3684210526315789, 0.16666666666666666]</td>\n",
       "      <td>8.539397e-01</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5645</th>\n",
       "      <td>claude_one_text_example</td>\n",
       "      <td>20_11</td>\n",
       "      <td>0.845154</td>\n",
       "      <td>[0.8571428571428571, 0.8333333333333334]</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5646</th>\n",
       "      <td>claude_one_text_example</td>\n",
       "      <td>20_12</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>[0.42857142857142855, 0.16666666666666666]</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5647</th>\n",
       "      <td>claude_one_text_example</td>\n",
       "      <td>20_13</td>\n",
       "      <td>0.266186</td>\n",
       "      <td>[0.5625, 0.26666666666666666]</td>\n",
       "      <td>6.872893e-01</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5648 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model     id      bleu  \\\n",
       "0             gpt_one_example    1_0  0.000000   \n",
       "1             gpt_one_example    1_2  0.597614   \n",
       "2             gpt_one_example    1_3  0.000000   \n",
       "3             gpt_one_example    1_4  0.000000   \n",
       "4             gpt_one_example    1_5  0.436436   \n",
       "...                       ...    ...       ...   \n",
       "5643  claude_one_text_example   20_9  0.377229   \n",
       "5644  claude_one_text_example  20_10  0.211604   \n",
       "5645  claude_one_text_example  20_11  0.845154   \n",
       "5646  claude_one_text_example  20_12  0.267261   \n",
       "5647  claude_one_text_example  20_13  0.266186   \n",
       "\n",
       "                                      precisions  brevity_penalty  \\\n",
       "0                                     [0.0, 0.0]     1.009021e-09   \n",
       "1                      [0.7142857142857143, 0.5]     1.000000e+00   \n",
       "2                      [0.2857142857142857, 0.0]     5.743262e-02   \n",
       "3                     [0.14285714285714285, 0.0]     2.077482e-01   \n",
       "4       [0.5714285714285714, 0.3333333333333333]     1.000000e+00   \n",
       "...                                          ...              ...   \n",
       "5643    [0.5454545454545454, 0.2857142857142857]     9.555630e-01   \n",
       "5644   [0.3684210526315789, 0.16666666666666666]     8.539397e-01   \n",
       "5645    [0.8571428571428571, 0.8333333333333334]     1.000000e+00   \n",
       "5646  [0.42857142857142855, 0.16666666666666666]     1.000000e+00   \n",
       "5647               [0.5625, 0.26666666666666666]     6.872893e-01   \n",
       "\n",
       "      length_ratio  translation_length  reference_length  \n",
       "0         0.046053                 7.0             152.0  \n",
       "1         1.000000                 7.0               7.0  \n",
       "2         0.259259                 7.0              27.0  \n",
       "3         0.388889                 7.0              18.0  \n",
       "4         1.166667                 7.0               6.0  \n",
       "...            ...                 ...               ...  \n",
       "5643      0.956522                22.0              23.0  \n",
       "5644      0.863636                19.0              22.0  \n",
       "5645      1.000000                 7.0               7.0  \n",
       "5646      1.166667                 7.0               6.0  \n",
       "5647      0.727273                16.0              22.0  \n",
       "\n",
       "[5648 rows x 8 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_perline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d77448a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gpt_one_example', 'claude_two_example', 'Pytesseract',\n",
       "       'claude_two_text_example', 'claude_complex',\n",
       "       'gpt_one_text_example', 'claude_refine', 'gpt_refine_complex',\n",
       "       'claude_refine_complex', 'gpt_simple', 'KerasOCR', 'TrOCR',\n",
       "       'claude_simple', 'gpt_refine', 'claude_one_example',\n",
       "       'gpt_two_example', 'gpt_two_text_example', 'gpt_complex',\n",
       "       'EasyOCR', 'claude_one_text_example'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_perline.replace({'model': {'gpt': 'gpt_simple', 'claude': 'claude_simple',\n",
    "                               'trOCR': 'TrOCR', 'pytesseractOCR': 'Pytesseract',\n",
    "                               'kerasOCR': 'KerasOCR', 'easyOCR': 'EasyOCR',\n",
    "                               'gpt_refine_complex_output': 'gpt_refine_complex', 'claude_refine_complex_output': 'claude_refine_complex'}}, inplace=True)\n",
    "bleu_perline['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e3d731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_perline.to_csv(path+'/results/scores_comparisons/bleu_perline_all_n2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8774a8e",
   "metadata": {},
   "source": [
    "### BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e5be7601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.8091067115702212,\n",
       " 'precisions': [0.8571428571428571, 0.8333333333333334, 0.8, 0.75],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.0,\n",
       " 'translation_length': 7,\n",
       " 'reference_length': 7}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric.compute(predictions=['Arrêté le vingt cinq novembre 1919 Servais'], references=['Arrêté le vingt cinq novembre 1919 servais'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "968b6c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_gpt = pd.DataFrame(bleu_gpt).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc301e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>precisions</th>\n",
       "      <th>brevity_penalty</th>\n",
       "      <th>length_ratio</th>\n",
       "      <th>translation_length</th>\n",
       "      <th>reference_length</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.025, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.06081</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>40</td>\n",
       "      <td>152</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_3</th>\n",
       "      <td>0.137596</td>\n",
       "      <td>[0.38461538461538464, 0.2, 0.125, 0.0434782608...</td>\n",
       "      <td>0.962269</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.449329</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_9</th>\n",
       "      <td>0.259849</td>\n",
       "      <td>[0.5454545454545454, 0.38095238095238093, 0.25...</td>\n",
       "      <td>0.955563</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_10</th>\n",
       "      <td>0.150923</td>\n",
       "      <td>[0.45, 0.2631578947368421, 0.1111111111111111,...</td>\n",
       "      <td>0.904837</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_13</th>\n",
       "      <td>0.163304</td>\n",
       "      <td>[0.5, 0.3076923076923077, 0.25, 0.181818181818...</td>\n",
       "      <td>0.564718</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           bleu                                         precisions  \\\n",
       "1_0         0.0                             [0.025, 0.0, 0.0, 0.0]   \n",
       "1_1         1.0                               [1.0, 1.0, 1.0, 1.0]   \n",
       "1_2         1.0                               [1.0, 1.0, 1.0, 1.0]   \n",
       "1_3    0.137596  [0.38461538461538464, 0.2, 0.125, 0.0434782608...   \n",
       "1_4         0.0                               [0.1, 0.0, 0.0, 0.0]   \n",
       "...         ...                                                ...   \n",
       "20_9   0.259849  [0.5454545454545454, 0.38095238095238093, 0.25...   \n",
       "20_10  0.150923  [0.45, 0.2631578947368421, 0.1111111111111111,...   \n",
       "20_11       1.0                               [1.0, 1.0, 1.0, 1.0]   \n",
       "20_12       1.0                               [1.0, 1.0, 1.0, 1.0]   \n",
       "20_13  0.163304  [0.5, 0.3076923076923077, 0.25, 0.181818181818...   \n",
       "\n",
       "      brevity_penalty length_ratio translation_length reference_length     id  \n",
       "1_0           0.06081     0.263158                 40              152    1_0  \n",
       "1_1               1.0          1.0                  7                7    1_1  \n",
       "1_2               1.0          1.0                  7                7    1_2  \n",
       "1_3          0.962269     0.962963                 26               27    1_3  \n",
       "1_4          0.449329     0.555556                 10               18    1_4  \n",
       "...               ...          ...                ...              ...    ...  \n",
       "20_9         0.955563     0.956522                 22               23   20_9  \n",
       "20_10        0.904837     0.909091                 20               22  20_10  \n",
       "20_11             1.0          1.0                  7                7  20_11  \n",
       "20_12             1.0          1.0                  6                6  20_12  \n",
       "20_13        0.564718     0.636364                 14               22  20_13  \n",
       "\n",
       "[283 rows x 7 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_gpt['id'] = bleu_gpt.index\n",
    "bleu_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42415cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_gpt.to_csv(path+'/results/scores_comparisons/eval_perline/bleu_claude_two_example_perline.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd8ab74",
   "metadata": {},
   "source": [
    "### CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9933242",
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_gpt = pd.DataFrame(cer_gpt.items(), columns=['id', 'cer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84bd52c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5713106915175424 2.935498085710415\n"
     ]
    }
   ],
   "source": [
    "print(cer_gpt['cer'].mean(), cer_gpt['cer'].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fba7876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_gpt.to_csv(path+'/results/scores_comparisons/eval_perline/cer_claude_two_example_perline.csv', float_format=\"%.6f\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783bfe80",
   "metadata": {},
   "source": [
    "# OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd1af15-25ff-4636-800b-599ef2d986f1",
   "metadata": {},
   "source": [
    "## EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bdaf499-ac45-438e-bb41-04d45d53f78c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[43mtest_path\u001b[49m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(test_image)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_path' is not defined"
     ]
    }
   ],
   "source": [
    "test_image = cv2.imread(test_path)\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e1baa4c9-2e16-47bf-aed6-47a4c0de1807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def easyOCR(image_path):\n",
    "    reader = easyocr.Reader(['fr'])\n",
    "    img = cv2.imread(image_path)\n",
    "    results = reader.readtext(img)\n",
    "    output = []\n",
    "    for res in results:\n",
    "        det, conf = res[1], res[2]\n",
    "        output.append((det, round(conf, 2))) \n",
    "    text = ' '.join([i[0] for i in output])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "474cc34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "easyOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = easyOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        easyOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b45d798e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>line_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_00</td>\n",
       "      <td>DÉSIGNATION DES PERSONNES DÉCÉDÉES OU AlSENTES...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_01</td>\n",
       "      <td>~Bcrta` 8 oetolz 1919 d4earuey vicytAul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_02</td>\n",
       "      <td>Jbsucala &amp; veyhmeuf ouoba  tg19 [eevœy</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_03</td>\n",
       "      <td>891 ta HBevcenk ~Bepkonssjk oj hain Hgoucoal Y...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_04</td>\n",
       "      <td>TulL Bouuù Q \"Janer ~aobà Bhuile RRXR 26 aplul...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_09</td>\n",
       "      <td>J9 ùcà nuf&gt; Sebiaw bo2nbi YÉvepQu X anel Bebel...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>4 49 0 : @ubovs ssexanbz Yuemaut ubuùd *ean [l...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>Jvuté &amp; oi = neuf fasles19:0 Huclai</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>Jarsalé -   vms] Hinsenq %0 djeceia |</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>3 [9' vrqkun )a4| Semience Run Gl Yusvellen Le...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text  file_name  \\\n",
       "0     1_00  DÉSIGNATION DES PERSONNES DÉCÉDÉES OU AlSENTES...          1   \n",
       "1     1_01            ~Bcrta` 8 oetolz 1919 d4earuey vicytAul          1   \n",
       "2     1_02             Jbsucala & veyhmeuf ouoba  tg19 [eevœy          1   \n",
       "3     1_03  891 ta HBevcenk ~Bepkonssjk oj hain Hgoucoal Y...          1   \n",
       "4     1_04  TulL Bouuù Q \"Janer ~aobà Bhuile RRXR 26 aplul...          1   \n",
       "..     ...                                                ...        ...   \n",
       "278  20_09  J9 ùcà nuf> Sebiaw bo2nbi YÉvepQu X anel Bebel...         20   \n",
       "279  20_10  4 49 0 : @ubovs ssexanbz Yuemaut ubuùd *ean [l...         20   \n",
       "280  20_11                Jvuté & oi = neuf fasles19:0 Huclai         20   \n",
       "281  20_12              Jarsalé -   vms] Hinsenq %0 djeceia |         20   \n",
       "282  20_13  3 [9' vrqkun )a4| Semience Run Gl Yusvellen Le...         20   \n",
       "\n",
       "     line_name     id  \n",
       "0            0    1_0  \n",
       "1            1    1_1  \n",
       "2            2    1_2  \n",
       "3            3    1_3  \n",
       "4            4    1_4  \n",
       "..         ...    ...  \n",
       "278          9   20_9  \n",
       "279         10  20_10  \n",
       "280         11  20_11  \n",
       "281         12  20_12  \n",
       "282         13  20_13  \n",
       "\n",
       "[283 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# easyOCR_output_df = pd.read_csv(path+'/results/postprocessed/easyOCR_perline_output.csv')\n",
    "easyOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6f85318b-55be-419d-b80a-0e8c5b861779",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_00</td>\n",
       "      <td>DATE I IÉcis DROITS DF SUCCESSION DROIT NUMÉRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_01</td>\n",
       "      <td>soceti &amp; tù déeemebza. 919 Yuepiy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_02</td>\n",
       "      <td>5 1439 DaLenlize Yiceppu #9lugu | Benuue YLama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10_03</td>\n",
       "      <td>Jaxat' € deeemlaac919 Fuupùa quebu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10_04</td>\n",
       "      <td>[4ho ceæy _ (ekalque Pnag;nl  Yjuuy Wv&amp;ezlbz (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>9_09</td>\n",
       "      <td>69*2.4 Scinllane Pots+a Gxz9&amp; SasBBoe Gpmzeyen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>9_10</td>\n",
       "      <td>kag' 0: Sainllane Bwun' à 26r' 1sr \"9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>9_11</td>\n",
       "      <td>Joaak + fnmauu dceehu 1919 Yeoeok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>9_12</td>\n",
       "      <td>[4Jg %eu 3- CBaslice fe At Z8ma 2e+eygu | Jwti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>9_13</td>\n",
       "      <td>~outi &amp; Jeun 1919 fuwsuik Lg déclerations recl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text\n",
       "0    10_00  DATE I IÉcis DROITS DF SUCCESSION DROIT NUMÉRO...\n",
       "1    10_01                  soceti & tù déeemebza. 919 Yuepiy\n",
       "2    10_02  5 1439 DaLenlize Yiceppu #9lugu | Benuue YLama...\n",
       "3    10_03                 Jaxat' € deeemlaac919 Fuupùa quebu\n",
       "4    10_04  [4ho ceæy _ (ekalque Pnag;nl  Yjuuy Wv&ezlbz (...\n",
       "..     ...                                                ...\n",
       "278   9_09  69*2.4 Scinllane Pots+a Gxz9& SasBBoe Gpmzeyen...\n",
       "279   9_10              kag' 0: Sainllane Bwun' à 26r' 1sr \"9\n",
       "280   9_11                  Joaak + fnmauu dceehu 1919 Yeoeok\n",
       "281   9_12  [4Jg %eu 3- CBaslice fe At Z8ma 2e+eygu | Jwti...\n",
       "282   9_13  ~outi & Jeun 1919 fuwsuik Lg déclerations recl...\n",
       "\n",
       "[283 rows x 2 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easyOCR_output_df = pd.DataFrame(easyOCR_output.items(), columns=['file', 'text'])\n",
    "easyOCR_output_df[['file_name', 'line_name']] = easyOCR_output_df['file'].str.split('_', expand=True)\n",
    "easyOCR_output_df[['file_name', 'line_name']] = easyOCR_output_df[['file_name', 'line_name']].astype(int)\n",
    "easyOCR_output_df = easyOCR_output_df.sort_values(by=['file_name', 'line_name']).reset_index(drop=True)\n",
    "easyOCR_output_df['text'] = easyOCR_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "easyOCR_output_df['id'] = easyOCR_output_df['file_name'].astype(str) + '_' + easyOCR_output_df['line_name'].astype(str)\n",
    "easyOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "512ffd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "easyOCR_output_df.to_csv(path+'/results/postprocessed/easyOCR_perline_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09134009-83a9-4ed0-b724-d9a4096ebe7d",
   "metadata": {},
   "source": [
    "## Pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e86c0ee3-034b-446d-aa51-3e5e6e348fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pytesseractOCR(image_path):\n",
    "    try:\n",
    "        image = PILImage.open(image_path)\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text\n",
    "    except:\n",
    "        print(\"[ERROR] pytesseractOCR failed! (should be installed)\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f596a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseractOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = pytesseractOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        pytesseractOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8149b7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>line_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_00</td>\n",
       "      <td>|  = | DATE DU DEPOT  des  DECLARATIONS.  DESI...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_01</td>\n",
       "      <td>ft alt alta</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_02</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_03</td>\n",
       "      <td>a cnte |Abevcenk a dette  Son &lt;a  1040’  i ee ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_04</td>\n",
       "      <td>L  3  be oi  7  Nf »- p</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_09</td>\n",
       "      <td>149 28 auf  Si elaiawx  Ve  |  | Wvebly eu ty ...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>; a : oe ssa  song  o  Sannin nomena  ie 3 (0....</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>|  aul</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>Caen torah Winéorg ty dieser’  es  oe  aaa. pa...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>+ i 4 | pane um ‘ uy R | £5 dée! t ctfleati ec...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text  file_name  \\\n",
       "0     1_00  |  = | DATE DU DEPOT  des  DECLARATIONS.  DESI...          1   \n",
       "1     1_01                                       ft alt alta           1   \n",
       "2     1_02                                                             1   \n",
       "3     1_03  a cnte |Abevcenk a dette  Son <a  1040’  i ee ...          1   \n",
       "4     1_04                          L  3  be oi  7  Nf »- p            1   \n",
       "..     ...                                                ...        ...   \n",
       "278  20_09  149 28 auf  Si elaiawx  Ve  |  | Wvebly eu ty ...         20   \n",
       "279  20_10  ; a : oe ssa  song  o  Sannin nomena  ie 3 (0....         20   \n",
       "280  20_11                                            |  aul          20   \n",
       "281  20_12  Caen torah Winéorg ty dieser’  es  oe  aaa. pa...         20   \n",
       "282  20_13  + i 4 | pane um ‘ uy R | £5 dée! t ctfleati ec...         20   \n",
       "\n",
       "     line_name     id  \n",
       "0            0    1_0  \n",
       "1            1    1_1  \n",
       "2            2    1_2  \n",
       "3            3    1_3  \n",
       "4            4    1_4  \n",
       "..         ...    ...  \n",
       "278          9   20_9  \n",
       "279         10  20_10  \n",
       "280         11  20_11  \n",
       "281         12  20_12  \n",
       "282         13  20_13  \n",
       "\n",
       "[283 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytesseractOCR_output_df = pd.DataFrame(pytesseractOCR_output.items(), columns=['file', 'text'])\n",
    "pytesseractOCR_output_df[['file_name', 'line_name']] = pytesseractOCR_output_df['file'].str.split('_', expand=True)\n",
    "pytesseractOCR_output_df[['file_name', 'line_name']] = pytesseractOCR_output_df[['file_name', 'line_name']].astype(int)\n",
    "pytesseractOCR_output_df = pytesseractOCR_output_df.sort_values(by=['file_name', 'line_name']).reset_index(drop=True)\n",
    "pytesseractOCR_output_df['text'] = pytesseractOCR_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "pytesseractOCR_output_df['id'] = pytesseractOCR_output_df['file_name'].astype(str) + '_' + pytesseractOCR_output_df['line_name'].astype(str)\n",
    "pytesseractOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f26931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseractOCR_output_df.to_csv(path+'/results/postprocessed/pytesseractOCR_perline_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061630dd-6446-4a62-9b39-bd87c86a99f4",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "Not good for non-english?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e561f951-54a9-4d73-b778-41f9dbcdbe0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kerasOCR(image_path):\n",
    "    pipeline = keras_ocr.pipeline.Pipeline()\n",
    "    image = keras_ocr.tools.read(image_path)\n",
    "    prediction_groups = pipeline.recognize([image])\n",
    "    words = []\n",
    "    for line in prediction_groups[0]:\n",
    "        for word in line:\n",
    "            try:\n",
    "                if isinstance(word[0], str):\n",
    "                    words.append(word[0])\n",
    "            except IndexError:\n",
    "                continue\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e1e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = kerasOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        kerasOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "82c872cd-131c-4bc4-96cf-2dd2e62e0f59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for /Users/serenekim/.keras-ocr/craft_mlt_25k.h5\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: resize_bilinear (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.image.resize(...method=ResizeMethod.BILINEAR...)` instead.\n",
      "Looking for /Users/serenekim/.keras-ocr/crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 806ms/step\n",
      "1/1 [==============================] - 1s 751ms/step\n",
      "d r p o a g\n"
     ]
    }
   ],
   "source": [
    "test_keras = kerasOCR(image_path=test_path)\n",
    "print(test_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf6c0a",
   "metadata": {},
   "source": [
    "## TrOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cde01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor\n",
    "from transformers import VisionEncoderDecoderModel\n",
    "import torch\n",
    "\n",
    "def trOCR(image_path):\n",
    "    processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "\n",
    "    image = PILImage.open(image_path)\n",
    "\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "    \n",
    "    # Set device (GPU or CPU)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)  # Move model to the device\n",
    "    pixel_values = pixel_values.to(device)  # Move image tensor to the same device\n",
    "    \n",
    "    try:\n",
    "        generated_ids = model.generate(pixel_values, max_length=400)  # Limit max length\n",
    "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return generated_text\n",
    "    except IndexError as e:\n",
    "        print(f\"IndexError: {e}\")\n",
    "        return \"Error: Index out of range during generation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27ab20c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/serenekim/.pyenv/versions/3.12.0/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = trOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        trOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caa3c0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>line_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_00</td>\n",
       "      <td>treat of the first time of the French Parliame...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_01</td>\n",
       "      <td># almost be weighted rather any standard for t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_02</td>\n",
       "      <td># almost the original module you formerly ... ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_03</td>\n",
       "      <td>THE GREAT BRONDSOME \" AIRMARK GABIT PARADE HAN...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_04</td>\n",
       "      <td>After Congress plan himself tough back down to...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_09</td>\n",
       "      <td>Manager Atkinson had made many awareness of th...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>After the Democratic gubernatorial judge took ...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>the best time of fourteen songs with the first...</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>\" To absorb confidence being a total of 1 000 ...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>After the Renaissance season would change thei...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text  file_name  \\\n",
       "0     1_00  treat of the first time of the French Parliame...          1   \n",
       "1     1_01  # almost be weighted rather any standard for t...          1   \n",
       "2     1_02  # almost the original module you formerly ... ...          1   \n",
       "3     1_03  THE GREAT BRONDSOME \" AIRMARK GABIT PARADE HAN...          1   \n",
       "4     1_04  After Congress plan himself tough back down to...          1   \n",
       "..     ...                                                ...        ...   \n",
       "278  20_09  Manager Atkinson had made many awareness of th...         20   \n",
       "279  20_10  After the Democratic gubernatorial judge took ...         20   \n",
       "280  20_11  the best time of fourteen songs with the first...         20   \n",
       "281  20_12  \" To absorb confidence being a total of 1 000 ...         20   \n",
       "282  20_13  After the Renaissance season would change thei...         20   \n",
       "\n",
       "     line_name     id  \n",
       "0            0    1_0  \n",
       "1            1    1_1  \n",
       "2            2    1_2  \n",
       "3            3    1_3  \n",
       "4            4    1_4  \n",
       "..         ...    ...  \n",
       "278          9   20_9  \n",
       "279         10  20_10  \n",
       "280         11  20_11  \n",
       "281         12  20_12  \n",
       "282         13  20_13  \n",
       "\n",
       "[283 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trOCR_output_df = pd.DataFrame(trOCR_output.items(), columns=['file', 'text'])\n",
    "trOCR_output_df[['file_name', 'line_name']] = trOCR_output_df['file'].str.split('_', expand=True)\n",
    "trOCR_output_df[['file_name', 'line_name']] = trOCR_output_df[['file_name', 'line_name']].astype(int)\n",
    "trOCR_output_df = trOCR_output_df.sort_values(by=['file_name', 'line_name']).reset_index(drop=True)\n",
    "trOCR_output_df['text'] = trOCR_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "trOCR_output_df['id'] = trOCR_output_df['file_name'].astype(str) + '_' + trOCR_output_df['line_name'].astype(str)\n",
    "trOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd3cec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "trOCR_output_df.to_csv(path+'/results/postprocessed/trOCR_perline_output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
