{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c798e7-9579-4c02-88ca-0c57e52c2966",
   "metadata": {},
   "source": [
    "# per-line transcription with LLM & OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069d0fa8-6403-402b-954a-cbc05503eb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import base64\n",
    "import subprocess\n",
    "from IPython.display import display, Image\n",
    "from PIL import Image as PILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f521cad-9da9-4cdf-a63d-f5dd4ca3e4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "import pytesseract\n",
    "import keras_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "857d11aa-8fb9-4f32-a20c-5e418f5154e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = os.path.dirname(os.getcwd()) # Parent directory\n",
    "image_folder = path+'/data/lines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffd293ec-7b82-4145-820e-9e910c7d099d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OpenAI\n",
    "load_dotenv() #get the environment \n",
    "openai_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_client = OpenAI(api_key=openai_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9cc501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "anthropic_client = Anthropic(api_key=anthropic_API_KEY)\n",
    "MODEL_NAME = \"claude-3-5-sonnet-20240620\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4c585-70a5-466a-ac27-f730debebfba",
   "metadata": {},
   "source": [
    "## Read and encode the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e6f97e1-5798-4253-a324-58a38bae7f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b48666f-fd04-4f79-ba1a-8a254e9d81c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        images.append(image)\n",
    "\n",
    "rows = []\n",
    "for image in images:\n",
    "    name = image.split('.')[0]\n",
    "    name_split = name.split('_')[0]\n",
    "    file_name = name_split.split('example')[1]\n",
    "    line_name = name.split('_')[1]\n",
    "    encoded_value = encode_image(image_folder+'/'+image)\n",
    "    rows.append({'file': file_name, 'line': line_name, 'encoded': encoded_value})\n",
    "\n",
    "images_encoded = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c988074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>line</th>\n",
       "      <th>encoded</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/9j/4QZBRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>/9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>/9j/4QYvRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>/9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>/9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>/9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>/9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>/9j/4QWRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>/9j/4QZyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>/9j/4QZRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>/9j/4QZ1RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>/9j/4QVrRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>/9j/4QaFRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QcyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>/9j/4QVORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>/9j/4QX+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>/9j/4QY6RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>/9j/4QaQRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>/9j/4QVWRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>/9j/4QZ3RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>/9j/4QXbRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>/9j/4QaORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>/9j/4QWIRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>/9j/4QWARXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>/9j/4QZwRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>/9j/4QZlRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>/9j/4QV+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>/9j/4QbYRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QbPRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>3_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file  line                                            encoded    id\n",
       "0      1     0  /9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_0\n",
       "1      1     1  /9j/4QZBRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_1\n",
       "2      1     2  /9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_2\n",
       "3      1     3  /9j/4QYvRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_3\n",
       "4      1     4  /9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_4\n",
       "5      1     5  /9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_5\n",
       "6      1     6  /9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_6\n",
       "7      1     7  /9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_7\n",
       "8      1     8  /9j/4QWRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_8\n",
       "9      1     9  /9j/4QZyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_9\n",
       "10     1    10  /9j/4QZRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_10\n",
       "11     1    11  /9j/4QZ1RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_11\n",
       "12     1    12  /9j/4QVrRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_12\n",
       "13     1    13  /9j/4QaFRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_13\n",
       "14     2     0  /9j/4QcyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_0\n",
       "15     2     1  /9j/4QVORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_1\n",
       "16     2     2  /9j/4QX+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_2\n",
       "17     2     3  /9j/4QY6RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_3\n",
       "18     2     4  /9j/4QaQRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_4\n",
       "19     2     5  /9j/4QVWRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_5\n",
       "20     2     6  /9j/4QZ3RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_6\n",
       "21     2     7  /9j/4QXbRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_7\n",
       "22     2     8  /9j/4QaORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_8\n",
       "23     2     9  /9j/4QWIRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_9\n",
       "24     2    10  /9j/4QWARXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_10\n",
       "25     2    11  /9j/4QZwRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_11\n",
       "26     2    12  /9j/4QZlRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_12\n",
       "27     2    13  /9j/4QV+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_13\n",
       "28     2    14  /9j/4QbYRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_14\n",
       "29     3     0  /9j/4QbPRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...   3_0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_encoded['file'] = images_encoded['file'].astype('int')\n",
    "images_encoded['line'] = images_encoded['line'].astype('int')\n",
    "images_encoded = images_encoded.sort_values(by=['file', 'line']).reset_index(drop=True)\n",
    "images_encoded['id'] = images_encoded['file'].astype(str) + '_' + images_encoded['line'].astype(str)\n",
    "images_encoded.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa240d54",
   "metadata": {},
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd51de42-7ecf-4171-88fd-cc78fb803632",
   "metadata": {},
   "source": [
    "## General API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73f51be1-2815-4280-ab50-4a909baf7016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def callOpenAI(prompt, max_tokens=800, base64_image=None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_API_KEY}\"\n",
    "    } \n",
    "    model_vision = \"gpt-4o\"\n",
    "    payload = {\n",
    "        \"model\": model_vision, \n",
    "        \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "            \n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                }\n",
    "            }\n",
    "            ]\n",
    "        }\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    try:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except:\n",
    "        print(response.json()[\"error\"][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6be70b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callAnthropic(prompt, max_tokens=5000, base64_image=None):\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=max_tokens,\n",
    "        system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\", \n",
    "                            \"media_type\": \"image/jpeg\", \n",
    "                            \"data\": base64_image}},\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt,\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.to_dict()[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a94328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callPostProcessing(max_tokens=800, prompt_parameter = None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_API_KEY}\"\n",
    "    } \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"\"\"This is an output from you. Clean it such that we have no separators and no comment from you: {prompt_parameter}\n",
    "                \"\"\"\n",
    "            }\n",
    "            ]\n",
    "        }\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    try:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except:\n",
    "        print(response.json()[\"error\"][\"message\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b44a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this when OpenAI credits are exhausted\n",
    "def callPostProcessing_anthropic(max_tokens=5000, prompt_parameter = None):\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=max_tokens,\n",
    "        system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"\"\"This is an output from you. Clean it such that we have no separators and no comment from you: {prompt_parameter}\n",
    "                \"\"\"\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.to_dict()[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65f775",
   "metadata": {},
   "source": [
    "### Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56c01d37-e85d-45ee-b6c8-9e92b5078e87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/xy/r3gq5vtd7bx6qb966l0fhh9h0000gn/T/ipykernel_69851/818506988.py:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  prompt_complex = \"\"\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "    Recognize the text from the image:\n",
    "    ```plaintext\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_complex = \"\"\"\n",
    "    Context:\n",
    "        It's an old Belgian document. And you're getting one row of a table from it. It's written in French language and the names of the people are domiciles are Belgian.\n",
    "\n",
    "    Structure:\n",
    "        The table is structured with the two-level headers as follows:\n",
    "        [(\"N' d'ordre\", \" \"),\n",
    "                (\"Date du dépot des déclarations\", \" \"),\n",
    "                (\"Désignation des personnes décédées ou absentes.:\", \"Nom.\"),\n",
    "                (\"Désignation des personnes décédées ou absentes.:\", \"Prénoms\"),\n",
    "                (\"Désignation des personnes décédées ou absentes.:\", \"Domiciles\"), \n",
    "                (\"Date du décès ou du judgement d'envoi en possession, en cas d'absence.\", \" \"),\n",
    "                (\"Noms, Prénoms et demeures des parties déclarantes.\", \" \"),\n",
    "                (\"Droits de succession en ligne collatérale et de mutation en ligne directe.\", \"Actif. (2)\"),\n",
    "                (\"Droits de succession en ligne collatérale et de mutation en ligne directe.\", \"Passif. (2)\"),\n",
    "                (\"Droits de succession en ligne collatérale et de mutation en ligne directe.\", \"Restant NET. (2)\"),\n",
    "                (\"Droit de mutation par déces\", \"Valeur des immeubles. (2)\"), \n",
    "                (\"Numéros des déclarations\", \"Primitives.\"),\n",
    "                (\"Numéros des déclarations\", \"Supplémentaires.\"), \n",
    "                (\"Date\", \"de l'expiration du délai de rectification.\"),\n",
    "                (\"Date\", \"de l'exigibilité des droits.\"),\n",
    "                (\"Numéros de la consignation des droits au sommier n' 28\", \" \"),\n",
    "                (\"Recette des droits et amendes.\", \"Date\"),\n",
    "                (\"Recette des droits et amendes.\", \"N^03\"),\n",
    "                (\"Cautionnements. \", \"Numéros de la consignation au sommier n'30\"),\n",
    "                (\"Observations (les déclarations qui figurent à l'état n'413 doivent être émargées en conséquence, dans la présnete colonne.)\", \" \")] \n",
    "\n",
    "        Some image (hence, some rows) may start with \"Arrêté le \\d{2} \\w+ \\d{4}( \\w+)? servais\" or contain notes.\n",
    "\n",
    "    Task:\n",
    "        Recognize the text from the image. Pay attention to reading each word and number correctly. Return the text as you read it and you must read the text from the image since the image contains texts.\n",
    "    ```plaintext \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2e72bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_ids = ['1_0', '2_0', '3_0', '4_0', '5_0', '6_0', '7_0', '8_0', '9_0', '10_0',\n",
    "              '11_0', '12_0', '13_0', '14_0', '15_0', '16_0', '17_0', '18_0', '19_0', '20_0']\n",
    "typo_ids = ['4_1', '4_7', '8_2', '8_5', '8_10', '13_9', '16_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7fedafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Start processing file 1_0 -------\n",
      "------- Finished processing file 1_0 in 15.672473192214966 seconds -------\n",
      "------- Start processing file 2_0 -------\n",
      "------- Finished processing file 2_0 in 13.086804866790771 seconds -------\n",
      "------- Start processing file 3_0 -------\n",
      "------- Finished processing file 3_0 in 15.490267992019653 seconds -------\n",
      "------- Start processing file 4_0 -------\n",
      "------- Finished processing file 4_0 in 5.324773073196411 seconds -------\n",
      "------- Start processing file 5_0 -------\n",
      "------- Finished processing file 5_0 in 17.278480768203735 seconds -------\n",
      "------- Start processing file 6_0 -------\n",
      "------- Finished processing file 6_0 in 7.705688714981079 seconds -------\n",
      "------- Start processing file 7_0 -------\n",
      "------- Finished processing file 7_0 in 5.692546129226685 seconds -------\n",
      "------- Start processing file 8_0 -------\n",
      "------- Finished processing file 8_0 in 12.433310985565186 seconds -------\n",
      "------- Start processing file 9_0 -------\n",
      "------- Finished processing file 9_0 in 7.879240274429321 seconds -------\n",
      "------- Start processing file 10_0 -------\n",
      "------- Finished processing file 10_0 in 7.068518161773682 seconds -------\n",
      "------- Start processing file 11_0 -------\n",
      "------- Finished processing file 11_0 in 13.515678882598877 seconds -------\n",
      "------- Start processing file 12_0 -------\n",
      "------- Finished processing file 12_0 in 5.530261039733887 seconds -------\n",
      "------- Start processing file 13_0 -------\n",
      "------- Finished processing file 13_0 in 15.97423791885376 seconds -------\n",
      "------- Start processing file 14_0 -------\n",
      "------- Finished processing file 14_0 in 11.80348801612854 seconds -------\n",
      "------- Start processing file 15_0 -------\n",
      "------- Finished processing file 15_0 in 6.611741065979004 seconds -------\n",
      "------- Start processing file 16_0 -------\n",
      "------- Finished processing file 16_0 in 5.299962759017944 seconds -------\n",
      "------- Start processing file 17_0 -------\n",
      "------- Finished processing file 17_0 in 13.901386976242065 seconds -------\n",
      "------- Start processing file 18_0 -------\n",
      "------- Finished processing file 18_0 in 6.925004720687866 seconds -------\n",
      "------- Start processing file 19_0 -------\n",
      "------- Finished processing file 19_0 in 7.026426076889038 seconds -------\n",
      "------- Start processing file 20_0 -------\n",
      "------- Finished processing file 20_0 in 14.682123899459839 seconds -------\n",
      "------- Start processing file 4_1 -------\n",
      "------- Finished processing file 4_1 in 2.505981922149658 seconds -------\n",
      "------- Start processing file 4_7 -------\n",
      "------- Finished processing file 4_7 in 4.536821603775024 seconds -------\n",
      "------- Start processing file 8_2 -------\n",
      "------- Finished processing file 8_2 in 4.117516040802002 seconds -------\n",
      "------- Start processing file 8_5 -------\n",
      "------- Finished processing file 8_5 in 4.609242677688599 seconds -------\n",
      "------- Start processing file 8_10 -------\n",
      "------- Finished processing file 8_10 in 5.323090076446533 seconds -------\n",
      "------- Start processing file 13_9 -------\n",
      "------- Finished processing file 13_9 in 4.495441198348999 seconds -------\n",
      "------- Start processing file 16_2 -------\n",
      "------- Finished processing file 16_2 in 4.208082914352417 seconds -------\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Load previous progress if available\n",
    "try:\n",
    "    with open(path+'/notebooks/json/claude_complex_output_progress.json', 'r') as file:\n",
    "        claude_complex_output = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    claude_complex_output = {}\n",
    "\n",
    "# Loop through each unique id\n",
    "# for id in images_encoded['id'].unique():\n",
    "for id in header_ids+typo_ids:\n",
    "    # Check if this ID is already processed (Skip this step if you want to re-process for unable_ids) ----------------\n",
    "    # if id in claude_complex_output:\n",
    "    #     print(f\"Skipping {id}, already processed.\")\n",
    "    #     continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        print(f'------- Start processing file {id} -------')\n",
    "        \n",
    "        # Call OpenAI/Anthropic and post-processing functions\n",
    "        prompt_complex += \"Even if it is hard to read the texts from the image, return as much as you can. You must read something. Do not return an apologetic message.\"\n",
    "        # output = callOpenAI(prompt=prompt_complex, max_tokens=800, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0])\n",
    "        output = callAnthropic(prompt=prompt_complex, max_tokens=800, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0])\n",
    "        output_cleaned = callPostProcessing(prompt_parameter=output)\n",
    "        \n",
    "        # Save the output\n",
    "        claude_complex_output[id] = output_cleaned\n",
    "        \n",
    "        # Save progress after each file\n",
    "        with open('claude_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_complex_output, file)\n",
    "        \n",
    "        print(f'------- Finished processing file {id} in {time.time() - start_time} seconds -------')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {id}: {str(e)}\")\n",
    "        # Save the progress and exit the loop in case of an error\n",
    "        with open('claude_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_complex_output, file)\n",
    "        break  # Exit the loop on error\n",
    "\n",
    "# Once all IDs are processed, save the final result\n",
    "with open('claude_complex_output_final.json', 'w') as file:\n",
    "    json.dump(claude_complex_output, file)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc31c4e8",
   "metadata": {},
   "source": [
    "### Few-shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24130132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'/data/transcriptions_perline_cleaned.csv', encoding='utf-8')\n",
    "df.replace({u'\\xa0': ' '}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95afd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = images_encoded[images_encoded['id'] == '1_1'].encoded.values[0]\n",
    "example2 = images_encoded[images_encoded['id'] == '1_3'].encoded.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c14ff3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_encoded_oneshot = images_encoded[~images_encoded['id'].isin(['1_1'])]\n",
    "images_encoded_twoshot = images_encoded[~images_encoded['id'].isin(['1_1', '1_3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbaa3fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "example1_text = df[df['id'] == '1_1'].text.values[0]\n",
    "example2_text = df[df['id'] == '1_3'].text.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "998fc479",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_texts =  [example1_text,example2_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a7b9774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arrêté le vingt huit octobre 1919 servais',\n",
       " '398 trente octobre Herrent Alphones gh Ophain 16 9b 1918 Herrent Maris & autres 2280 1045 1235 11 Db 1919 15 7bre 1919  7 avril 1920 303']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b683c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_encoded_extexts = images_encoded[~images_encoded['id'].isin(['1_1', '1_3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d04a03ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_example =  \"\"\"\n",
    "#     Recognize the texts from the image like the examples.\n",
    "#     ```plaintext\n",
    "#     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0bdb0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example1_text or exmple_texts\n",
    "prompt_example_text = f\"\"\"\n",
    "                        The ```plaintext block is the example transcription of the example image you saw:\n",
    "\n",
    "                        Transcription:\n",
    "                        ```plaintext\n",
    "                        {example_texts}\n",
    "                        ```\n",
    "                        Compare what you read initially and the solution key in ```plaintext block. Recreate the content of the table in this image. Only that, no other information from you.\n",
    "\n",
    "                        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "721c10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callOpenAI_example(prompt, NExample=1, base64_image=None, max_tokens=5000):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_API_KEY}\"\n",
    "    } \n",
    "    model_vision = \"gpt-4o\"\n",
    "\n",
    "    if NExample == 1:\n",
    "        payload = {\n",
    "            \"model\": model_vision, \n",
    "            \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "                \n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{example1}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": example1_text\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "                ]\n",
    "            }\n",
    "            ],\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    if NExample == 2:\n",
    "               payload = {\n",
    "            \"model\": model_vision, \n",
    "            \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "                \n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{example1}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": example1_text\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{example2}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": example2_text\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "                ]\n",
    "            }\n",
    "            ],\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    try:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except:\n",
    "        print(response.json()[\"error\"][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adc4a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callAnthropic_example(prompt, NExample=1, base64_image=None, max_tokens=5000):\n",
    "    if NExample == 1:\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=max_tokens,\n",
    "            system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": example1}},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example1_text,\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt,\n",
    "                        },\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": base64_image}}\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "        \n",
    "    if NExample == 2:\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=max_tokens,\n",
    "            system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": example1}},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example1_text,\n",
    "                        },\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": example2}},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example2_text,\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt,\n",
    "                        },\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": base64_image}}\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "    return response.to_dict()[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "663dc214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>line</th>\n",
       "      <th>encoded</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>/9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>/9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>/9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>/9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>/9j/4QY7RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>/9j/4QY3RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>/9j/4QWhRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>/9j/4QUtRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>/9j/4QX3RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     file  line                                            encoded     id\n",
       "0       1     0  /9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_0\n",
       "2       1     2  /9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_2\n",
       "4       1     4  /9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_4\n",
       "5       1     5  /9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_5\n",
       "6       1     6  /9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_6\n",
       "..    ...   ...                                                ...    ...\n",
       "278    20     9  /9j/4QY7RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...   20_9\n",
       "279    20    10  /9j/4QY3RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...  20_10\n",
       "280    20    11  /9j/4QWhRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...  20_11\n",
       "281    20    12  /9j/4QUtRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...  20_12\n",
       "282    20    13  /9j/4QX3RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...  20_13\n",
       "\n",
       "[281 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_encoded_twoshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "caa07d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 1_0, already processed.\n",
      "Skipping 1_2, already processed.\n",
      "Skipping 1_3, already processed.\n",
      "Skipping 1_4, already processed.\n",
      "Skipping 1_5, already processed.\n",
      "Skipping 1_6, already processed.\n",
      "Skipping 1_7, already processed.\n",
      "Skipping 1_8, already processed.\n",
      "Skipping 1_9, already processed.\n",
      "Skipping 1_10, already processed.\n",
      "Skipping 1_11, already processed.\n",
      "Skipping 1_12, already processed.\n",
      "Skipping 1_13, already processed.\n",
      "Skipping 2_0, already processed.\n",
      "Skipping 2_1, already processed.\n",
      "Skipping 2_2, already processed.\n",
      "Skipping 2_3, already processed.\n",
      "Skipping 2_4, already processed.\n",
      "Skipping 2_5, already processed.\n",
      "Skipping 2_6, already processed.\n",
      "Skipping 2_7, already processed.\n",
      "Skipping 2_8, already processed.\n",
      "Skipping 2_9, already processed.\n",
      "Skipping 2_10, already processed.\n",
      "Skipping 2_11, already processed.\n",
      "Skipping 2_12, already processed.\n",
      "Skipping 2_13, already processed.\n",
      "Skipping 2_14, already processed.\n",
      "Skipping 3_0, already processed.\n",
      "Skipping 3_1, already processed.\n",
      "Skipping 3_2, already processed.\n",
      "Skipping 3_3, already processed.\n",
      "Skipping 3_4, already processed.\n",
      "Skipping 3_5, already processed.\n",
      "Skipping 3_6, already processed.\n",
      "Skipping 3_7, already processed.\n",
      "Skipping 3_8, already processed.\n",
      "Skipping 3_9, already processed.\n",
      "Skipping 3_10, already processed.\n",
      "Skipping 3_11, already processed.\n",
      "Skipping 3_12, already processed.\n",
      "Skipping 3_13, already processed.\n",
      "Skipping 4_0, already processed.\n",
      "Skipping 4_1, already processed.\n",
      "Skipping 4_2, already processed.\n",
      "Skipping 4_3, already processed.\n",
      "Skipping 4_4, already processed.\n",
      "Skipping 4_5, already processed.\n",
      "Skipping 4_6, already processed.\n",
      "Skipping 4_7, already processed.\n",
      "Skipping 4_8, already processed.\n",
      "Skipping 4_9, already processed.\n",
      "Skipping 4_10, already processed.\n",
      "Skipping 4_11, already processed.\n",
      "Skipping 4_12, already processed.\n",
      "Skipping 4_13, already processed.\n",
      "Skipping 5_0, already processed.\n",
      "Skipping 5_1, already processed.\n",
      "Skipping 5_2, already processed.\n",
      "Skipping 5_3, already processed.\n",
      "Skipping 5_4, already processed.\n",
      "Skipping 5_5, already processed.\n",
      "Skipping 5_6, already processed.\n",
      "Skipping 5_7, already processed.\n",
      "Skipping 5_8, already processed.\n",
      "Skipping 5_9, already processed.\n",
      "Skipping 5_10, already processed.\n",
      "Skipping 5_11, already processed.\n",
      "Skipping 5_12, already processed.\n",
      "Skipping 5_13, already processed.\n",
      "Skipping 5_14, already processed.\n",
      "Skipping 6_0, already processed.\n",
      "Skipping 6_1, already processed.\n",
      "Skipping 6_2, already processed.\n",
      "Skipping 6_3, already processed.\n",
      "Skipping 6_4, already processed.\n",
      "Skipping 6_5, already processed.\n",
      "Skipping 6_6, already processed.\n",
      "Skipping 6_7, already processed.\n",
      "Skipping 6_8, already processed.\n",
      "Skipping 6_9, already processed.\n",
      "Skipping 6_10, already processed.\n",
      "Skipping 6_11, already processed.\n",
      "Skipping 6_12, already processed.\n",
      "Skipping 6_13, already processed.\n",
      "Skipping 6_14, already processed.\n",
      "Skipping 7_0, already processed.\n",
      "Skipping 7_1, already processed.\n",
      "Skipping 7_2, already processed.\n",
      "Skipping 7_3, already processed.\n",
      "Skipping 7_4, already processed.\n",
      "Skipping 7_5, already processed.\n",
      "Skipping 7_6, already processed.\n",
      "Skipping 7_7, already processed.\n",
      "Skipping 7_8, already processed.\n",
      "Skipping 7_9, already processed.\n",
      "Skipping 7_10, already processed.\n",
      "Skipping 7_11, already processed.\n",
      "Skipping 7_12, already processed.\n",
      "Skipping 7_13, already processed.\n",
      "Skipping 8_0, already processed.\n",
      "Skipping 8_1, already processed.\n",
      "Skipping 8_2, already processed.\n",
      "Skipping 8_3, already processed.\n",
      "Skipping 8_4, already processed.\n",
      "Skipping 8_5, already processed.\n",
      "Skipping 8_6, already processed.\n",
      "Skipping 8_7, already processed.\n",
      "Skipping 8_8, already processed.\n",
      "Skipping 8_9, already processed.\n",
      "Skipping 8_10, already processed.\n",
      "Skipping 8_11, already processed.\n",
      "Skipping 8_12, already processed.\n",
      "Skipping 8_13, already processed.\n",
      "Skipping 9_0, already processed.\n",
      "Skipping 9_1, already processed.\n",
      "Skipping 9_2, already processed.\n",
      "Skipping 9_3, already processed.\n",
      "Skipping 9_4, already processed.\n",
      "Skipping 9_5, already processed.\n",
      "Skipping 9_6, already processed.\n",
      "Skipping 9_7, already processed.\n",
      "Skipping 9_8, already processed.\n",
      "Skipping 9_9, already processed.\n",
      "Skipping 9_10, already processed.\n",
      "Skipping 9_11, already processed.\n",
      "Skipping 9_12, already processed.\n",
      "Skipping 9_13, already processed.\n",
      "Skipping 10_0, already processed.\n",
      "Skipping 10_1, already processed.\n",
      "Skipping 10_2, already processed.\n",
      "Skipping 10_3, already processed.\n",
      "Skipping 10_4, already processed.\n",
      "Skipping 10_5, already processed.\n",
      "Skipping 10_6, already processed.\n",
      "Skipping 10_7, already processed.\n",
      "Skipping 10_8, already processed.\n",
      "Skipping 10_9, already processed.\n",
      "Skipping 10_10, already processed.\n",
      "Skipping 10_11, already processed.\n",
      "Skipping 10_12, already processed.\n",
      "Skipping 10_13, already processed.\n",
      "Skipping 11_0, already processed.\n",
      "Skipping 11_1, already processed.\n",
      "Skipping 11_2, already processed.\n",
      "Skipping 11_3, already processed.\n",
      "Skipping 11_4, already processed.\n",
      "Skipping 11_5, already processed.\n",
      "Skipping 11_6, already processed.\n",
      "Skipping 11_7, already processed.\n",
      "Skipping 11_8, already processed.\n",
      "Skipping 11_9, already processed.\n",
      "Skipping 11_10, already processed.\n",
      "Skipping 11_11, already processed.\n",
      "Skipping 11_12, already processed.\n",
      "Skipping 11_13, already processed.\n",
      "Skipping 12_0, already processed.\n",
      "Skipping 12_1, already processed.\n",
      "Skipping 12_2, already processed.\n",
      "Skipping 12_3, already processed.\n",
      "Skipping 12_4, already processed.\n",
      "Skipping 12_5, already processed.\n",
      "Skipping 12_6, already processed.\n",
      "Skipping 12_7, already processed.\n",
      "Skipping 12_8, already processed.\n",
      "Skipping 12_9, already processed.\n",
      "Skipping 12_10, already processed.\n",
      "Skipping 12_11, already processed.\n",
      "Skipping 12_12, already processed.\n",
      "Skipping 12_13, already processed.\n",
      "Skipping 13_0, already processed.\n",
      "Skipping 13_1, already processed.\n",
      "Skipping 13_2, already processed.\n",
      "Skipping 13_3, already processed.\n",
      "Skipping 13_4, already processed.\n",
      "Skipping 13_5, already processed.\n",
      "Skipping 13_6, already processed.\n",
      "Skipping 13_7, already processed.\n",
      "Skipping 13_8, already processed.\n",
      "Skipping 13_9, already processed.\n",
      "Skipping 13_10, already processed.\n",
      "Skipping 13_11, already processed.\n",
      "Skipping 13_12, already processed.\n",
      "Skipping 13_13, already processed.\n",
      "Skipping 14_0, already processed.\n",
      "Skipping 14_1, already processed.\n",
      "Skipping 14_2, already processed.\n",
      "Skipping 14_3, already processed.\n",
      "Skipping 14_4, already processed.\n",
      "Skipping 14_5, already processed.\n",
      "Skipping 14_6, already processed.\n",
      "Skipping 14_7, already processed.\n",
      "Skipping 14_8, already processed.\n",
      "Skipping 14_9, already processed.\n",
      "Skipping 14_10, already processed.\n",
      "Skipping 14_11, already processed.\n",
      "Skipping 14_12, already processed.\n",
      "Skipping 14_13, already processed.\n",
      "Skipping 15_0, already processed.\n",
      "Skipping 15_1, already processed.\n",
      "Skipping 15_2, already processed.\n",
      "Skipping 15_3, already processed.\n",
      "Skipping 15_4, already processed.\n",
      "Skipping 15_5, already processed.\n",
      "Skipping 15_6, already processed.\n",
      "Skipping 15_7, already processed.\n",
      "Skipping 15_8, already processed.\n",
      "Skipping 15_9, already processed.\n",
      "Skipping 15_10, already processed.\n",
      "------- Start processing file 15_11 -------\n",
      "------- Finished processing file 15_11 in 6.87476372718811 seconds -------\n",
      "------- Start processing file 15_12 -------\n",
      "------- Finished processing file 15_12 in 3.8250539302825928 seconds -------\n",
      "------- Start processing file 15_13 -------\n",
      "------- Finished processing file 15_13 in 8.418600082397461 seconds -------\n",
      "------- Start processing file 16_0 -------\n",
      "------- Finished processing file 16_0 in 10.500346183776855 seconds -------\n",
      "------- Start processing file 16_1 -------\n",
      "------- Finished processing file 16_1 in 7.335936069488525 seconds -------\n",
      "------- Start processing file 16_2 -------\n",
      "------- Finished processing file 16_2 in 7.335402011871338 seconds -------\n",
      "------- Start processing file 16_3 -------\n",
      "------- Finished processing file 16_3 in 5.97693395614624 seconds -------\n",
      "------- Start processing file 16_4 -------\n",
      "------- Finished processing file 16_4 in 6.250653982162476 seconds -------\n",
      "------- Start processing file 16_5 -------\n",
      "------- Finished processing file 16_5 in 5.6174540519714355 seconds -------\n",
      "------- Start processing file 16_6 -------\n",
      "------- Finished processing file 16_6 in 4.92791223526001 seconds -------\n",
      "------- Start processing file 16_7 -------\n",
      "------- Finished processing file 16_7 in 6.014104127883911 seconds -------\n",
      "------- Start processing file 16_8 -------\n",
      "------- Finished processing file 16_8 in 3.9198389053344727 seconds -------\n",
      "------- Start processing file 16_9 -------\n",
      "------- Finished processing file 16_9 in 4.536156892776489 seconds -------\n",
      "------- Start processing file 16_10 -------\n",
      "------- Finished processing file 16_10 in 5.497853994369507 seconds -------\n",
      "------- Start processing file 16_11 -------\n",
      "------- Finished processing file 16_11 in 4.297598361968994 seconds -------\n",
      "------- Start processing file 16_12 -------\n",
      "------- Finished processing file 16_12 in 8.198738813400269 seconds -------\n",
      "------- Start processing file 16_13 -------\n",
      "------- Finished processing file 16_13 in 7.191823720932007 seconds -------\n",
      "------- Start processing file 17_0 -------\n",
      "------- Finished processing file 17_0 in 12.285139083862305 seconds -------\n",
      "------- Start processing file 17_1 -------\n",
      "------- Finished processing file 17_1 in 3.737494945526123 seconds -------\n",
      "------- Start processing file 17_2 -------\n",
      "------- Finished processing file 17_2 in 7.413358926773071 seconds -------\n",
      "------- Start processing file 17_3 -------\n",
      "------- Finished processing file 17_3 in 6.539854288101196 seconds -------\n",
      "------- Start processing file 17_4 -------\n",
      "------- Finished processing file 17_4 in 4.192394018173218 seconds -------\n",
      "------- Start processing file 17_5 -------\n",
      "------- Finished processing file 17_5 in 7.071882009506226 seconds -------\n",
      "------- Start processing file 17_6 -------\n",
      "------- Finished processing file 17_6 in 6.348166227340698 seconds -------\n",
      "------- Start processing file 17_7 -------\n",
      "------- Finished processing file 17_7 in 6.656067848205566 seconds -------\n",
      "------- Start processing file 17_8 -------\n",
      "------- Finished processing file 17_8 in 7.4842870235443115 seconds -------\n",
      "------- Start processing file 17_9 -------\n",
      "------- Finished processing file 17_9 in 11.466259002685547 seconds -------\n",
      "------- Start processing file 17_10 -------\n",
      "------- Finished processing file 17_10 in 5.499670028686523 seconds -------\n",
      "------- Start processing file 17_11 -------\n",
      "------- Finished processing file 17_11 in 4.938958168029785 seconds -------\n",
      "------- Start processing file 17_12 -------\n",
      "------- Finished processing file 17_12 in 6.245589017868042 seconds -------\n",
      "------- Start processing file 17_13 -------\n",
      "------- Finished processing file 17_13 in 6.1424360275268555 seconds -------\n",
      "------- Start processing file 18_0 -------\n",
      "------- Finished processing file 18_0 in 9.728538036346436 seconds -------\n",
      "------- Start processing file 18_1 -------\n",
      "------- Finished processing file 18_1 in 5.528614282608032 seconds -------\n",
      "------- Start processing file 18_2 -------\n",
      "------- Finished processing file 18_2 in 4.404000997543335 seconds -------\n",
      "------- Start processing file 18_3 -------\n",
      "------- Finished processing file 18_3 in 5.7486138343811035 seconds -------\n",
      "------- Start processing file 18_4 -------\n",
      "------- Finished processing file 18_4 in 6.947872161865234 seconds -------\n",
      "------- Start processing file 18_5 -------\n",
      "------- Finished processing file 18_5 in 8.19316816329956 seconds -------\n",
      "------- Start processing file 18_6 -------\n",
      "------- Finished processing file 18_6 in 3.7883808612823486 seconds -------\n",
      "------- Start processing file 18_7 -------\n",
      "------- Finished processing file 18_7 in 9.728127002716064 seconds -------\n",
      "------- Start processing file 18_8 -------\n",
      "------- Finished processing file 18_8 in 6.552689790725708 seconds -------\n",
      "------- Start processing file 18_9 -------\n",
      "------- Finished processing file 18_9 in 4.096157073974609 seconds -------\n",
      "------- Start processing file 18_10 -------\n",
      "------- Finished processing file 18_10 in 10.137078046798706 seconds -------\n",
      "------- Start processing file 18_11 -------\n",
      "------- Finished processing file 18_11 in 6.962701082229614 seconds -------\n",
      "------- Start processing file 18_12 -------\n",
      "------- Finished processing file 18_12 in 7.376532793045044 seconds -------\n",
      "------- Start processing file 18_13 -------\n",
      "------- Finished processing file 18_13 in 11.161044120788574 seconds -------\n",
      "------- Start processing file 19_0 -------\n",
      "------- Finished processing file 19_0 in 18.758485078811646 seconds -------\n",
      "------- Start processing file 19_1 -------\n",
      "------- Finished processing file 19_1 in 6.0196990966796875 seconds -------\n",
      "------- Start processing file 19_2 -------\n",
      "------- Finished processing file 19_2 in 5.0195231437683105 seconds -------\n",
      "------- Start processing file 19_3 -------\n",
      "------- Finished processing file 19_3 in 5.337875843048096 seconds -------\n",
      "------- Start processing file 19_4 -------\n",
      "------- Finished processing file 19_4 in 4.182577848434448 seconds -------\n",
      "------- Start processing file 19_5 -------\n",
      "------- Finished processing file 19_5 in 4.606994390487671 seconds -------\n",
      "------- Start processing file 19_6 -------\n",
      "------- Finished processing file 19_6 in 7.884893178939819 seconds -------\n",
      "------- Start processing file 19_7 -------\n",
      "------- Finished processing file 19_7 in 6.523704767227173 seconds -------\n",
      "------- Start processing file 19_8 -------\n",
      "------- Finished processing file 19_8 in 7.198280334472656 seconds -------\n",
      "------- Start processing file 19_9 -------\n",
      "------- Finished processing file 19_9 in 5.1199049949646 seconds -------\n",
      "------- Start processing file 19_10 -------\n",
      "------- Finished processing file 19_10 in 5.222336053848267 seconds -------\n",
      "------- Start processing file 19_11 -------\n",
      "------- Finished processing file 19_11 in 10.445899963378906 seconds -------\n",
      "------- Start processing file 19_12 -------\n",
      "------- Finished processing file 19_12 in 4.347573757171631 seconds -------\n",
      "------- Start processing file 19_13 -------\n",
      "------- Finished processing file 19_13 in 6.197279930114746 seconds -------\n",
      "------- Start processing file 20_0 -------\n",
      "------- Finished processing file 20_0 in 31.130364894866943 seconds -------\n",
      "------- Start processing file 20_1 -------\n",
      "------- Finished processing file 20_1 in 5.939423322677612 seconds -------\n",
      "------- Start processing file 20_2 -------\n",
      "------- Finished processing file 20_2 in 5.993369102478027 seconds -------\n",
      "------- Start processing file 20_3 -------\n",
      "------- Finished processing file 20_3 in 6.089133024215698 seconds -------\n",
      "------- Start processing file 20_4 -------\n",
      "------- Finished processing file 20_4 in 3.892444133758545 seconds -------\n",
      "------- Start processing file 20_5 -------\n",
      "------- Finished processing file 20_5 in 4.710644960403442 seconds -------\n",
      "------- Start processing file 20_6 -------\n",
      "------- Finished processing file 20_6 in 9.009104013442993 seconds -------\n",
      "------- Start processing file 20_7 -------\n",
      "------- Finished processing file 20_7 in 3.788818836212158 seconds -------\n",
      "------- Start processing file 20_8 -------\n",
      "------- Finished processing file 20_8 in 4.095562934875488 seconds -------\n",
      "------- Start processing file 20_9 -------\n",
      "------- Finished processing file 20_9 in 26.214518070220947 seconds -------\n",
      "------- Start processing file 20_10 -------\n",
      "------- Finished processing file 20_10 in 8.089354991912842 seconds -------\n",
      "------- Start processing file 20_11 -------\n",
      "------- Finished processing file 20_11 in 3.7892398834228516 seconds -------\n",
      "------- Start processing file 20_12 -------\n",
      "------- Finished processing file 20_12 in 3.3770999908447266 seconds -------\n",
      "------- Start processing file 20_13 -------\n",
      "------- Finished processing file 20_13 in 14.031964302062988 seconds -------\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "# Load previous progress if available\n",
    "try:\n",
    "    with open('claude_one_example_output_progress.json', 'r') as file:\n",
    "        claude_one_example_output = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    claude_one_example_output = {}\n",
    "\n",
    "# Loop through each unique id\n",
    "for id in images_encoded_oneshot['id'].unique():\n",
    "# for id in unable_ids:\n",
    "    # Check if this ID is already processed (Skip this step if you want to re-process for unable_ids) ----------------\n",
    "    if id in claude_one_example_output:\n",
    "        print(f\"Skipping {id}, already processed.\")\n",
    "        continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        print(f'------- Start processing file {id} -------')\n",
    "        \n",
    "        # Call OpenAI/Anthropic and post-processing functions\n",
    "        prompt_example_text += \"Even if it is hard to read the texts from the image, return as much as you can. You must read something. Do not return an apologetic message.\"\n",
    "        # output = callOpenAI_example(prompt=prompt_example_text, NExample=1, base64_image=images_encoded_oneshot[(images_encoded_oneshot['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        output = callAnthropic_example(prompt=prompt_example_text, NExample=1, base64_image=images_encoded_oneshot[(images_encoded_oneshot['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        output_cleaned = callPostProcessing(prompt_parameter=output)\n",
    "        \n",
    "        # Save the output\n",
    "        claude_one_example_output[id] = output_cleaned\n",
    "        \n",
    "        # Save progress after each file\n",
    "        with open('claude_one_example_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_one_example_output, file)\n",
    "        \n",
    "        print(f'------- Finished processing file {id} in {time.time() - start_time} seconds -------')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {id}: {str(e)}\")\n",
    "        # Save the progress and exit the loop in case of an error\n",
    "        with open('claude_one_example_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_one_example_output, file)\n",
    "        break  # Exit the loop on error\n",
    "\n",
    "# Once all IDs are processed, save the final result\n",
    "with open('claude_one_example_output_final.json', 'w') as file:\n",
    "    json.dump(claude_one_example_output, file)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a122d9",
   "metadata": {},
   "source": [
    "### Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ab11e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt_simple = pd.read_csv(path+'/results/postprocessed/gpt_perline_output.csv')\n",
    "# claude_simple =  pd.read_csv(path+'/results/postprocessed/claude_perline_output.csv')\n",
    "gpt_complex = pd.read_csv(path+'/results/postprocessed/gpt_complex_perline_output2.csv')\n",
    "claude_complex =  pd.read_csv(path+'/results/postprocessed/claude_complex_perline_output2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "851ef214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 1_0, already processed.\n",
      "Skipping 1_1, already processed.\n",
      "Skipping 1_2, already processed.\n",
      "Skipping 1_3, already processed.\n",
      "Skipping 1_4, already processed.\n",
      "Skipping 1_5, already processed.\n",
      "Skipping 1_6, already processed.\n",
      "Skipping 1_7, already processed.\n",
      "Skipping 1_8, already processed.\n",
      "Skipping 1_9, already processed.\n",
      "Skipping 1_10, already processed.\n",
      "Skipping 1_11, already processed.\n",
      "Skipping 1_12, already processed.\n",
      "Skipping 1_13, already processed.\n",
      "Skipping 2_0, already processed.\n",
      "Skipping 2_1, already processed.\n",
      "Skipping 2_2, already processed.\n",
      "Skipping 2_3, already processed.\n",
      "Skipping 2_4, already processed.\n",
      "Skipping 2_5, already processed.\n",
      "Skipping 2_6, already processed.\n",
      "Skipping 2_7, already processed.\n",
      "Skipping 2_8, already processed.\n",
      "Skipping 2_9, already processed.\n",
      "Skipping 2_10, already processed.\n",
      "Skipping 2_11, already processed.\n",
      "Skipping 2_12, already processed.\n",
      "Skipping 2_13, already processed.\n",
      "Skipping 2_14, already processed.\n",
      "Skipping 3_0, already processed.\n",
      "Skipping 3_1, already processed.\n",
      "Skipping 3_2, already processed.\n",
      "Skipping 3_3, already processed.\n",
      "Skipping 3_4, already processed.\n",
      "Skipping 3_5, already processed.\n",
      "Skipping 3_6, already processed.\n",
      "Skipping 3_7, already processed.\n",
      "Skipping 3_8, already processed.\n",
      "Skipping 3_9, already processed.\n",
      "Skipping 3_10, already processed.\n",
      "Skipping 3_11, already processed.\n",
      "Skipping 3_12, already processed.\n",
      "Skipping 3_13, already processed.\n",
      "Skipping 4_0, already processed.\n",
      "Skipping 4_1, already processed.\n",
      "Skipping 4_2, already processed.\n",
      "Skipping 4_3, already processed.\n",
      "Skipping 4_4, already processed.\n",
      "Skipping 4_5, already processed.\n",
      "Skipping 4_6, already processed.\n",
      "Skipping 4_7, already processed.\n",
      "Skipping 4_8, already processed.\n",
      "Skipping 4_9, already processed.\n",
      "Skipping 4_10, already processed.\n",
      "Skipping 4_11, already processed.\n",
      "Skipping 4_12, already processed.\n",
      "Skipping 4_13, already processed.\n",
      "Skipping 5_0, already processed.\n",
      "Skipping 5_1, already processed.\n",
      "Skipping 5_2, already processed.\n",
      "Skipping 5_3, already processed.\n",
      "Skipping 5_4, already processed.\n",
      "Skipping 5_5, already processed.\n",
      "Skipping 5_6, already processed.\n",
      "Skipping 5_7, already processed.\n",
      "Skipping 5_8, already processed.\n",
      "Skipping 5_9, already processed.\n",
      "Skipping 5_10, already processed.\n",
      "Skipping 5_11, already processed.\n",
      "Skipping 5_12, already processed.\n",
      "Skipping 5_13, already processed.\n",
      "Skipping 5_14, already processed.\n",
      "Skipping 6_0, already processed.\n",
      "Skipping 6_1, already processed.\n",
      "Skipping 6_2, already processed.\n",
      "Skipping 6_3, already processed.\n",
      "Skipping 6_4, already processed.\n",
      "Skipping 6_5, already processed.\n",
      "Skipping 6_6, already processed.\n",
      "Skipping 6_7, already processed.\n",
      "Skipping 6_8, already processed.\n",
      "Skipping 6_9, already processed.\n",
      "Skipping 6_10, already processed.\n",
      "Skipping 6_11, already processed.\n",
      "Skipping 6_12, already processed.\n",
      "Skipping 6_13, already processed.\n",
      "Skipping 6_14, already processed.\n",
      "Skipping 7_0, already processed.\n",
      "Skipping 7_1, already processed.\n",
      "Skipping 7_2, already processed.\n",
      "Skipping 7_3, already processed.\n",
      "Skipping 7_4, already processed.\n",
      "Skipping 7_5, already processed.\n",
      "Skipping 7_6, already processed.\n",
      "Skipping 7_7, already processed.\n",
      "Skipping 7_8, already processed.\n",
      "Skipping 7_9, already processed.\n",
      "Skipping 7_10, already processed.\n",
      "Skipping 7_11, already processed.\n",
      "Skipping 7_12, already processed.\n",
      "Skipping 7_13, already processed.\n",
      "Skipping 8_0, already processed.\n",
      "Skipping 8_1, already processed.\n",
      "Skipping 8_2, already processed.\n",
      "Skipping 8_3, already processed.\n",
      "Skipping 8_4, already processed.\n",
      "Skipping 8_5, already processed.\n",
      "Skipping 8_6, already processed.\n",
      "Skipping 8_7, already processed.\n",
      "Skipping 8_8, already processed.\n",
      "Skipping 8_9, already processed.\n",
      "Skipping 8_10, already processed.\n",
      "Skipping 8_11, already processed.\n",
      "Skipping 8_12, already processed.\n",
      "Skipping 8_13, already processed.\n",
      "Skipping 9_0, already processed.\n",
      "Skipping 9_1, already processed.\n",
      "Skipping 9_2, already processed.\n",
      "Skipping 9_3, already processed.\n",
      "Skipping 9_4, already processed.\n",
      "Skipping 9_5, already processed.\n",
      "Skipping 9_6, already processed.\n",
      "Skipping 9_7, already processed.\n",
      "Skipping 9_8, already processed.\n",
      "Skipping 9_9, already processed.\n",
      "Skipping 9_10, already processed.\n",
      "Skipping 9_11, already processed.\n",
      "Skipping 9_12, already processed.\n",
      "------- Start processing file 9_13 -------\n",
      "------- Finished processing file 9_13 in 4.5187788009643555 seconds -------\n",
      "Skipping 10_0, already processed.\n",
      "------- Start processing file 10_1 -------\n",
      "------- Finished processing file 10_1 in 3.4782819747924805 seconds -------\n",
      "------- Start processing file 10_2 -------\n",
      "------- Finished processing file 10_2 in 4.187901735305786 seconds -------\n",
      "------- Start processing file 10_3 -------\n",
      "------- Finished processing file 10_3 in 6.054029941558838 seconds -------\n",
      "------- Start processing file 10_4 -------\n",
      "------- Finished processing file 10_4 in 5.224471092224121 seconds -------\n",
      "------- Start processing file 10_5 -------\n",
      "------- Finished processing file 10_5 in 3.420477867126465 seconds -------\n",
      "------- Start processing file 10_6 -------\n",
      "------- Finished processing file 10_6 in 4.212242126464844 seconds -------\n",
      "------- Start processing file 10_7 -------\n",
      "------- Finished processing file 10_7 in 4.384124755859375 seconds -------\n",
      "------- Start processing file 10_8 -------\n",
      "------- Finished processing file 10_8 in 3.804175853729248 seconds -------\n",
      "------- Start processing file 10_9 -------\n",
      "------- Finished processing file 10_9 in 3.853947162628174 seconds -------\n",
      "------- Start processing file 10_10 -------\n",
      "------- Finished processing file 10_10 in 4.284922122955322 seconds -------\n",
      "------- Start processing file 10_11 -------\n",
      "------- Finished processing file 10_11 in 4.323278188705444 seconds -------\n",
      "------- Start processing file 10_12 -------\n",
      "------- Finished processing file 10_12 in 4.51911997795105 seconds -------\n",
      "------- Start processing file 10_13 -------\n",
      "------- Finished processing file 10_13 in 3.8604512214660645 seconds -------\n",
      "Skipping 11_0, already processed.\n",
      "------- Start processing file 11_1 -------\n",
      "------- Finished processing file 11_1 in 4.088183879852295 seconds -------\n",
      "------- Start processing file 11_2 -------\n",
      "------- Finished processing file 11_2 in 4.19830584526062 seconds -------\n",
      "------- Start processing file 11_3 -------\n",
      "------- Finished processing file 11_3 in 4.198432207107544 seconds -------\n",
      "------- Start processing file 11_4 -------\n",
      "------- Finished processing file 11_4 in 3.278395891189575 seconds -------\n",
      "------- Start processing file 11_5 -------\n",
      "------- Finished processing file 11_5 in 3.9985132217407227 seconds -------\n",
      "------- Start processing file 11_6 -------\n",
      "------- Finished processing file 11_6 in 3.9869489669799805 seconds -------\n",
      "------- Start processing file 11_7 -------\n",
      "------- Finished processing file 11_7 in 3.685598134994507 seconds -------\n",
      "------- Start processing file 11_8 -------\n",
      "------- Finished processing file 11_8 in 3.3508150577545166 seconds -------\n",
      "------- Start processing file 11_9 -------\n",
      "------- Finished processing file 11_9 in 4.879892826080322 seconds -------\n",
      "------- Start processing file 11_10 -------\n",
      "------- Finished processing file 11_10 in 3.990602970123291 seconds -------\n",
      "------- Start processing file 11_11 -------\n",
      "------- Finished processing file 11_11 in 3.957642078399658 seconds -------\n",
      "------- Start processing file 11_12 -------\n",
      "------- Finished processing file 11_12 in 5.119674205780029 seconds -------\n",
      "------- Start processing file 11_13 -------\n",
      "------- Finished processing file 11_13 in 4.096029996871948 seconds -------\n",
      "Skipping 12_0, already processed.\n",
      "------- Start processing file 12_1 -------\n",
      "------- Finished processing file 12_1 in 4.402475833892822 seconds -------\n",
      "------- Start processing file 12_2 -------\n",
      "------- Finished processing file 12_2 in 4.609771966934204 seconds -------\n",
      "------- Start processing file 12_3 -------\n",
      "------- Finished processing file 12_3 in 3.891646146774292 seconds -------\n",
      "------- Start processing file 12_4 -------\n",
      "------- Finished processing file 12_4 in 18.46848487854004 seconds -------\n",
      "------- Start processing file 12_5 -------\n",
      "------- Finished processing file 12_5 in 3.943117141723633 seconds -------\n",
      "------- Start processing file 12_6 -------\n",
      "------- Finished processing file 12_6 in 5.168059825897217 seconds -------\n",
      "------- Start processing file 12_7 -------\n",
      "------- Finished processing file 12_7 in 4.876936912536621 seconds -------\n",
      "------- Start processing file 12_8 -------\n",
      "------- Finished processing file 12_8 in 5.221391916275024 seconds -------\n",
      "------- Start processing file 12_9 -------\n",
      "------- Finished processing file 12_9 in 4.9164769649505615 seconds -------\n",
      "------- Start processing file 12_10 -------\n",
      "------- Finished processing file 12_10 in 4.131852865219116 seconds -------\n",
      "------- Start processing file 12_11 -------\n",
      "------- Finished processing file 12_11 in 5.11723518371582 seconds -------\n",
      "------- Start processing file 12_12 -------\n",
      "------- Finished processing file 12_12 in 4.471143960952759 seconds -------\n",
      "------- Start processing file 12_13 -------\n",
      "------- Finished processing file 12_13 in 5.017827987670898 seconds -------\n",
      "Skipping 13_0, already processed.\n",
      "------- Start processing file 13_1 -------\n",
      "------- Finished processing file 13_1 in 4.812385082244873 seconds -------\n",
      "------- Start processing file 13_2 -------\n",
      "------- Finished processing file 13_2 in 4.9164369106292725 seconds -------\n",
      "------- Start processing file 13_3 -------\n",
      "------- Finished processing file 13_3 in 4.373955249786377 seconds -------\n",
      "------- Start processing file 13_4 -------\n",
      "------- Finished processing file 13_4 in 3.6131551265716553 seconds -------\n",
      "------- Start processing file 13_5 -------\n",
      "------- Finished processing file 13_5 in 5.426492929458618 seconds -------\n",
      "------- Start processing file 13_6 -------\n",
      "------- Finished processing file 13_6 in 4.298884153366089 seconds -------\n",
      "------- Start processing file 13_7 -------\n",
      "------- Finished processing file 13_7 in 3.994813919067383 seconds -------\n",
      "------- Start processing file 13_8 -------\n",
      "------- Finished processing file 13_8 in 4.371685743331909 seconds -------\n",
      "Skipping 13_9, already processed.\n",
      "------- Start processing file 13_10 -------\n",
      "------- Finished processing file 13_10 in 6.788352012634277 seconds -------\n",
      "------- Start processing file 13_11 -------\n",
      "------- Finished processing file 13_11 in 4.6079630851745605 seconds -------\n",
      "------- Start processing file 13_12 -------\n",
      "------- Finished processing file 13_12 in 5.328459978103638 seconds -------\n",
      "------- Start processing file 13_13 -------\n",
      "------- Finished processing file 13_13 in 5.234277248382568 seconds -------\n",
      "Skipping 14_0, already processed.\n",
      "------- Start processing file 14_1 -------\n",
      "------- Finished processing file 14_1 in 3.668360948562622 seconds -------\n",
      "------- Start processing file 14_2 -------\n",
      "------- Finished processing file 14_2 in 5.249000072479248 seconds -------\n",
      "------- Start processing file 14_3 -------\n",
      "------- Finished processing file 14_3 in 4.277847051620483 seconds -------\n",
      "------- Start processing file 14_4 -------\n",
      "------- Finished processing file 14_4 in 4.159616708755493 seconds -------\n",
      "------- Start processing file 14_5 -------\n",
      "------- Finished processing file 14_5 in 4.235310792922974 seconds -------\n",
      "------- Start processing file 14_6 -------\n",
      "------- Finished processing file 14_6 in 4.503371953964233 seconds -------\n",
      "------- Start processing file 14_7 -------\n",
      "------- Finished processing file 14_7 in 5.020073890686035 seconds -------\n",
      "------- Start processing file 14_8 -------\n",
      "------- Finished processing file 14_8 in 4.579561948776245 seconds -------\n",
      "------- Start processing file 14_9 -------\n",
      "------- Finished processing file 14_9 in 4.73679780960083 seconds -------\n",
      "------- Start processing file 14_10 -------\n",
      "------- Finished processing file 14_10 in 3.689643144607544 seconds -------\n",
      "------- Start processing file 14_11 -------\n",
      "------- Finished processing file 14_11 in 6.857661008834839 seconds -------\n",
      "------- Start processing file 14_12 -------\n",
      "------- Finished processing file 14_12 in 3.8901748657226562 seconds -------\n",
      "------- Start processing file 14_13 -------\n",
      "------- Finished processing file 14_13 in 6.7566609382629395 seconds -------\n",
      "Skipping 15_0, already processed.\n",
      "------- Start processing file 15_1 -------\n",
      "------- Finished processing file 15_1 in 5.2317633628845215 seconds -------\n",
      "------- Start processing file 15_2 -------\n",
      "------- Finished processing file 15_2 in 4.5568459033966064 seconds -------\n",
      "------- Start processing file 15_3 -------\n",
      "------- Finished processing file 15_3 in 4.345600843429565 seconds -------\n",
      "------- Start processing file 15_4 -------\n",
      "------- Finished processing file 15_4 in 3.9988598823547363 seconds -------\n",
      "------- Start processing file 15_5 -------\n",
      "------- Finished processing file 15_5 in 4.047779083251953 seconds -------\n",
      "------- Start processing file 15_6 -------\n",
      "------- Finished processing file 15_6 in 4.086607933044434 seconds -------\n",
      "------- Start processing file 15_7 -------\n",
      "------- Finished processing file 15_7 in 3.982541084289551 seconds -------\n",
      "------- Start processing file 15_8 -------\n",
      "------- Finished processing file 15_8 in 4.568011999130249 seconds -------\n",
      "------- Start processing file 15_9 -------\n",
      "------- Finished processing file 15_9 in 4.295407056808472 seconds -------\n",
      "------- Start processing file 15_10 -------\n",
      "------- Finished processing file 15_10 in 3.191497325897217 seconds -------\n",
      "------- Start processing file 15_11 -------\n",
      "------- Finished processing file 15_11 in 2.9559600353240967 seconds -------\n",
      "------- Start processing file 15_12 -------\n",
      "------- Finished processing file 15_12 in 3.993644952774048 seconds -------\n",
      "------- Start processing file 15_13 -------\n",
      "------- Finished processing file 15_13 in 4.300524950027466 seconds -------\n",
      "Skipping 16_0, already processed.\n",
      "------- Start processing file 16_1 -------\n",
      "------- Finished processing file 16_1 in 4.096444845199585 seconds -------\n",
      "Skipping 16_2, already processed.\n",
      "------- Start processing file 16_3 -------\n",
      "------- Finished processing file 16_3 in 4.664058208465576 seconds -------\n",
      "------- Start processing file 16_4 -------\n",
      "------- Finished processing file 16_4 in 3.7609620094299316 seconds -------\n",
      "------- Start processing file 16_5 -------\n",
      "------- Finished processing file 16_5 in 3.749936103820801 seconds -------\n",
      "------- Start processing file 16_6 -------\n",
      "------- Finished processing file 16_6 in 4.072468996047974 seconds -------\n",
      "------- Start processing file 16_7 -------\n",
      "------- Finished processing file 16_7 in 3.309048652648926 seconds -------\n",
      "------- Start processing file 16_8 -------\n",
      "------- Finished processing file 16_8 in 5.734472036361694 seconds -------\n",
      "------- Start processing file 16_9 -------\n",
      "------- Finished processing file 16_9 in 4.7066709995269775 seconds -------\n",
      "------- Start processing file 16_10 -------\n",
      "------- Finished processing file 16_10 in 3.9973392486572266 seconds -------\n",
      "------- Start processing file 16_11 -------\n",
      "------- Finished processing file 16_11 in 4.403064012527466 seconds -------\n",
      "------- Start processing file 16_12 -------\n",
      "------- Finished processing file 16_12 in 5.882168769836426 seconds -------\n",
      "------- Start processing file 16_13 -------\n",
      "------- Finished processing file 16_13 in 4.460268020629883 seconds -------\n",
      "Skipping 17_0, already processed.\n",
      "------- Start processing file 17_1 -------\n",
      "------- Finished processing file 17_1 in 3.788515090942383 seconds -------\n",
      "------- Start processing file 17_2 -------\n",
      "------- Finished processing file 17_2 in 5.016230821609497 seconds -------\n",
      "------- Start processing file 17_3 -------\n",
      "------- Finished processing file 17_3 in 4.501795053482056 seconds -------\n",
      "------- Start processing file 17_4 -------\n",
      "------- Finished processing file 17_4 in 4.879002809524536 seconds -------\n",
      "------- Start processing file 17_5 -------\n",
      "------- Finished processing file 17_5 in 4.507422924041748 seconds -------\n",
      "------- Start processing file 17_6 -------\n",
      "------- Finished processing file 17_6 in 3.7890050411224365 seconds -------\n",
      "------- Start processing file 17_7 -------\n",
      "------- Finished processing file 17_7 in 4.812199115753174 seconds -------\n",
      "------- Start processing file 17_8 -------\n",
      "------- Finished processing file 17_8 in 6.040272951126099 seconds -------\n",
      "------- Start processing file 17_9 -------\n",
      "------- Finished processing file 17_9 in 4.709277153015137 seconds -------\n",
      "------- Start processing file 17_10 -------\n",
      "------- Finished processing file 17_10 in 4.711926221847534 seconds -------\n",
      "------- Start processing file 17_11 -------\n",
      "------- Finished processing file 17_11 in 3.572464942932129 seconds -------\n",
      "------- Start processing file 17_12 -------\n",
      "------- Finished processing file 17_12 in 4.51676607131958 seconds -------\n",
      "------- Start processing file 17_13 -------\n",
      "------- Finished processing file 17_13 in 3.887263059616089 seconds -------\n",
      "Skipping 18_0, already processed.\n",
      "------- Start processing file 18_1 -------\n",
      "------- Finished processing file 18_1 in 4.200323820114136 seconds -------\n",
      "------- Start processing file 18_2 -------\n",
      "------- Finished processing file 18_2 in 4.19882607460022 seconds -------\n",
      "------- Start processing file 18_3 -------\n",
      "------- Finished processing file 18_3 in 3.582446813583374 seconds -------\n",
      "------- Start processing file 18_4 -------\n",
      "------- Finished processing file 18_4 in 5.434032201766968 seconds -------\n",
      "------- Start processing file 18_5 -------\n",
      "------- Finished processing file 18_5 in 4.088507890701294 seconds -------\n",
      "------- Start processing file 18_6 -------\n",
      "------- Finished processing file 18_6 in 6.554315090179443 seconds -------\n",
      "------- Start processing file 18_7 -------\n",
      "------- Finished processing file 18_7 in 4.909409999847412 seconds -------\n",
      "------- Start processing file 18_8 -------\n",
      "------- Finished processing file 18_8 in 4.921012878417969 seconds -------\n",
      "------- Start processing file 18_9 -------\n",
      "------- Finished processing file 18_9 in 3.66916823387146 seconds -------\n",
      "------- Start processing file 18_10 -------\n",
      "------- Finished processing file 18_10 in 6.374696969985962 seconds -------\n",
      "------- Start processing file 18_11 -------\n",
      "------- Finished processing file 18_11 in 5.325391054153442 seconds -------\n",
      "------- Start processing file 18_12 -------\n",
      "------- Finished processing file 18_12 in 6.554369688034058 seconds -------\n",
      "------- Start processing file 18_13 -------\n",
      "------- Finished processing file 18_13 in 4.603408098220825 seconds -------\n",
      "Skipping 19_0, already processed.\n",
      "------- Start processing file 19_1 -------\n",
      "------- Finished processing file 19_1 in 4.633074998855591 seconds -------\n",
      "------- Start processing file 19_2 -------\n",
      "------- Finished processing file 19_2 in 3.1455390453338623 seconds -------\n",
      "------- Start processing file 19_3 -------\n",
      "------- Finished processing file 19_3 in 5.219139099121094 seconds -------\n",
      "------- Start processing file 19_4 -------\n",
      "------- Finished processing file 19_4 in 3.70662784576416 seconds -------\n",
      "------- Start processing file 19_5 -------\n",
      "------- Finished processing file 19_5 in 4.691181182861328 seconds -------\n",
      "------- Start processing file 19_6 -------\n",
      "------- Finished processing file 19_6 in 4.814079999923706 seconds -------\n",
      "------- Start processing file 19_7 -------\n",
      "------- Finished processing file 19_7 in 4.082614898681641 seconds -------\n",
      "------- Start processing file 19_8 -------\n",
      "------- Finished processing file 19_8 in 3.800102949142456 seconds -------\n",
      "------- Start processing file 19_9 -------\n",
      "------- Finished processing file 19_9 in 3.298182249069214 seconds -------\n",
      "------- Start processing file 19_10 -------\n",
      "------- Finished processing file 19_10 in 3.9988508224487305 seconds -------\n",
      "------- Start processing file 19_11 -------\n",
      "------- Finished processing file 19_11 in 4.682307243347168 seconds -------\n",
      "------- Start processing file 19_12 -------\n",
      "------- Finished processing file 19_12 in 6.988734006881714 seconds -------\n",
      "------- Start processing file 19_13 -------\n",
      "------- Finished processing file 19_13 in 5.811883211135864 seconds -------\n",
      "Skipping 20_0, already processed.\n",
      "------- Start processing file 20_1 -------\n",
      "------- Finished processing file 20_1 in 4.505818128585815 seconds -------\n",
      "------- Start processing file 20_2 -------\n",
      "------- Finished processing file 20_2 in 3.7904858589172363 seconds -------\n",
      "------- Start processing file 20_3 -------\n",
      "------- Finished processing file 20_3 in 4.50445294380188 seconds -------\n",
      "------- Start processing file 20_4 -------\n",
      "------- Finished processing file 20_4 in 4.909791946411133 seconds -------\n",
      "------- Start processing file 20_5 -------\n",
      "------- Finished processing file 20_5 in 4.304340839385986 seconds -------\n",
      "------- Start processing file 20_6 -------\n",
      "------- Finished processing file 20_6 in 4.937065124511719 seconds -------\n",
      "------- Start processing file 20_7 -------\n",
      "------- Finished processing file 20_7 in 3.884999990463257 seconds -------\n",
      "------- Start processing file 20_8 -------\n",
      "------- Finished processing file 20_8 in 3.7735650539398193 seconds -------\n",
      "------- Start processing file 20_9 -------\n",
      "------- Finished processing file 20_9 in 5.033324956893921 seconds -------\n",
      "------- Start processing file 20_10 -------\n",
      "------- Finished processing file 20_10 in 4.377002954483032 seconds -------\n",
      "------- Start processing file 20_11 -------\n",
      "------- Finished processing file 20_11 in 4.514448165893555 seconds -------\n",
      "------- Start processing file 20_12 -------\n",
      "------- Finished processing file 20_12 in 4.916759014129639 seconds -------\n",
      "------- Start processing file 20_13 -------\n",
      "------- Finished processing file 20_13 in 5.5274670124053955 seconds -------\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Load previous progress if available\n",
    "try:\n",
    "    with open('claude_refine_complex_output_progress.json', 'r') as file:\n",
    "        claude_refine_complex_output = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    claude_refine_complex_output = {}\n",
    "\n",
    "# Loop through each unique id\n",
    "for id in images_encoded['id'].unique():\n",
    "# for id in header_ids+typo_ids:\n",
    "# for id in unable_ids:\n",
    "    # Check if this ID is already processed (Skip this step if you want to re-process for unable_ids) ----------------\n",
    "    if id in claude_refine_complex_output:\n",
    "        print(f\"Skipping {id}, already processed.\")\n",
    "        continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        print(f'------- Start processing file {id} -------')\n",
    "        \n",
    "        # Call OpenAI/Anthropic and post-processing functions\n",
    "        response_text = claude_complex[claude_complex['id'] == id].text.values[0]\n",
    "        prompt_refine = f\"\"\"\n",
    "        \n",
    "        Your first draft:\n",
    "        ```plaintext\n",
    "        {response_text}\n",
    "        ```\n",
    "\n",
    "        Errors: \n",
    "        Your first transcription you made in ```plaintext block contains some errors.\n",
    "        \n",
    "        Task:\n",
    "        Refine your first trasncription in ```plaintext block. \n",
    "        Make sure to read the names of the people and the location as well as the dates and the numbers correctly.\n",
    "        Transcribe as you see in the image.\n",
    "        ```plaintext\n",
    "        \"\"\"\n",
    "\n",
    "        prompt_refine += \"Even if it is hard to read the texts from the image, return as much as you can. You must read something. Do not return an apologetic message.\"\n",
    "        # output = callOpenAI(prompt=prompt_refine, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        output = callAnthropic(prompt=prompt_refine, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        output_cleaned = callPostProcessing(prompt_parameter=output)\n",
    "        \n",
    "        # Save the output\n",
    "        claude_refine_complex_output[id] = output_cleaned\n",
    "        \n",
    "        # Save progress after each file\n",
    "        with open('claude_refine_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_refine_complex_output, file)\n",
    "        \n",
    "        print(f'------- Finished processing file {id} in {time.time() - start_time} seconds -------')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {id}: {str(e)}\")\n",
    "        # Save the progress and exit the loop in case of an error\n",
    "        with open('claude_refine_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_refine_complex_output, file)\n",
    "        break  # Exit the loop on error\n",
    "\n",
    "# Once all IDs are processed, save the final result\n",
    "with open('claude_refine_complex_output_final.json', 'w') as file:\n",
    "    json.dump(claude_refine_complex_output, file)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b34c7",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "683579cb-2bae-4a69-8271-ce4e67519e52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1_0': \"N° DATE DU DÉPÔT des déclarations DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES.: NOMS PRÉNOMS DOMICILES DATE DU DÉCÈS ou du jugement d'envoi en possession, en cas d'absence NOMS, PRÉNOMS et demeures des parties déclarantes DROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE: ACTIF PASSIF RESTANT NET DROIT DE MUTATION par décès: VALEUR des immeubles NUMÉROS des DÉCLARATIONS: Primitives Supplémentaires RECETTE des droits et amendes.: DATE N° CAUTIONNEMENTS: Numéros de la consignation au sommier n°30 OBSERVATIONS\",\n",
       " '2_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE NUMÉROS RECETTE CAUTION- OBSERVATIONS. d'ordre des NOMS. PRÉNOMS. DOMICILES ou du ET ou de DE MUTATION des de la des NEMENTS déclarations. jugement d'envoi DEMEURES DES PARTIES DÉCLARANTES. MUTATION EN LIGNE DIRECTE par décès DÉCLARATIONS consignation DROITS ET AMENDES. Numéros en possession, VALEUR des de la en cas d'absence. ACTIF. PASSIF. RESTANT des Primitives. Supplémen- de de droits au DATE N°s consignation (2) (2) NET. immeubles. taires. l'expiration l'exigibilité sommier au sommier (2) (2) du délai des droits n° 28 n°30 de rectification\",\n",
       " '3_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS DROITS DE SUCCESSION DROIT NUMÉROS RECETTE CAUTION d'ordre des déclarations NOMS PRÉNOMS DOMICILES jugement d'envoi en possession en cas d'absence NOMS PRÉNOMS et demeures des parties déclarantes MUTATION EN LIGNE DIRECTE VALEUR des Primitives Supplémentaires déclarations DATE NUMÉROS de la consignation au sommier n°30 OBSERVATIONS\",\n",
       " '4_0': \"DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS RECETTE CAUTION-NEMENT N° DATE DU DÉPÔT ou jugement d'envoi en possession. ET EN LIGNE COLLATÉRALE OU DE MUTATION EN LIGNE DIRECTE. DE MUTATION sur décès. DATE de la NOMS, PRÉNOMS, DOMICILES DEMEURES DES PARTIES DÉCLARANTES ACTIF. PASSIF. RESTANT NET. DROITS VALEUR des IMMEUBLES.\",\n",
       " '5_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS NOMS PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS RECETTE CAUTION OBSERVATIONS d'ordre des ou du ET en ligne collatérale et de DE MUTATION des DATE NEMENTS déclarations NOM PRÉNOMS DOMICILES jugement d'envoi DEMEURES DES PARTIES DÉCLARANTES MUTATION EN LIGNE DIRECTE par décès DÉCLARATIONS REMISES en cas d'absence ACTIF PASSIF RESTANT VALEUR des de de la (1) (2) NET des l'expiration l'exigibilité consignation (3) immeubles du délai des droits des droits de au au rectification sommier sommier n° 28 n° 30\",\n",
       " '6_0': 'N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE NUMÉROS RECETTE CAUTIONS des DÉCLARATIONS. NOMS. PRÉNOMS. DOMICILES. ou du jugement ET DEMEURES DES PARTIES DÉCLARANTES. EN LIGNE COLLATÉRALE DE MUTATION des DÉCLARATIONS de la feuille des DÉPOSÉES ACTIF. PASSIF. RESTANT par décès registre DROITS ET AMENDES OBSERVATIONS.',\n",
       " '7_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. DATE DU DÉCÈS DROITS DE SUCCESSION DROIT NUMÉROS RECETTE CAUTIONS d'ordre des NOMS, PRÉNOMS ou du NOMS, PRÉNOMS DE MUTATION des DATE DROITS des DÉCLARATIONS. NOMS. PRÉNOMS. DOMICILES jugement d'absence ET ACTIF. PASSIF. RESTANT sur décès. DÉCLARATIONS de PERÇUS, ou de l'envoi DEMEURES DES PARTIES DÉCLARANTES. NET. l'enregistrement DROITS ET AMENDES, en possession. TOTAUX.\",\n",
       " '8_0': \"N° d'ordre DATE DU DÉPÔT des déclarations DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES: NOMS PRÉNOMS DOMICILES DATE DU DÉCÈS ou du jugement d'envoi en possession, en cas d'absence. NOMS, PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES DROITS DE SUCCESSION en ligne collatérale et de mutation en ligne directe: ACTIF PASSIF RESTANT NET DROIT DE MUTATION par décès: VALEUR des IMMEUBLES NUMÉROS DES DÉCLARATIONS: PRIMITIVES SUPPLÉMENTAIRES DATE: de l'expiration du délai de rectification de l'exigibilité des droits RECETTE des droits et amendes: DATE N° CAUTIONNEMENTS: Numéros de la consignation au sommier n° 30 OBSERVATIONS\",\n",
       " '9_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS DROITS DE SUCCESSION DROIT NUMÉROS DATE RECETTE OBSERVATIONS des NOMS, PRÉNOMS, DOMICILES ou de NOMS, PRÉNOMS DE MUTATION des DÉCLARATIONS l'absence ET par décès DÉCLARATIONS présumée DEMEURES DES PARTIES DÉCLARANTES ACTIF, PASSIF, RESTANT VALEUR NET IMMEUBLES\",\n",
       " '10_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS DROITS DE SUCCESSION DROIT NUMÉROS RECETTE CAUTION des ou du NEMENTS DÉCLARATIONS NOMS PRÉNOMS DOMICILES DÉPART D'APRÈS NOMS PRÉNOMS EN LIGNE COLLATÉRALE DE MUTATION DATE PROVISOIRES LES ACTES ET et de par décès VALEUR DATE N° OBSERVATIONS OU PRÉSUMÉE DEMEURES DES PARTIES DÉCLARANTES MUTATION EN LIGNE DIRECTE ACTIF PASSIF RESTANT NET\",\n",
       " '11_0': \"N° d'ordre DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS DROITS DE SUCCESSION DROIT NUMÉROS RECETTE CAUTION des DÉCLARATIONS NOMS. PRÉNOMS. DOMICILES. ou du jugement EN LIGNE COLLATÉRALE DE des DÉCLARATIONS NEMENTS Cotes DÉCLARATIONS NOMS. PRÉNOMS. DOMICILES. d'envoi ET DE MUTATION EN LIGNE DIRECTE PAR DÉCÈS OBSERVATIONS. en possession NOMS, PRÉNOMS VALEUR en cas ET des d'absence. DEMEURES DES PARTIES IMMEUBLES DÉCLARANTES\",\n",
       " '12_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. DATE DU DÉCÈS DROITS DE SUCCESSION DROIT NUMÉROS RECETTE OBSERVATIONS des DÉCLARATIONS. NOMS. PRÉNOMS. DOMICILES. ou du JUGEMENT NOMS, PRÉNOMS DE MUTATION des DATE D'ABSENCE. DEMEURES DES PARTIES DÉCLARANTES PAR DÉCÈS DÉCLARATIONS ACTIF. PASSIF. RESTANT NET.\",\n",
       " '13_0': \"N° DATE DU DÉPÔT des DÉCLARATIONS DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES.: NOMS. DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES.: PRÉNOMS. DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES.: DOMICILES. DATE DU DÉCÈS ou du jugement d'envoi en possession, en cas d'absence. NOMS, PRÉNOMS et demeures des PARTIES DÉCLARANTES DROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE.: ACTIF DROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE.: PASSIF DROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE.: RESTANT NET DROIT DE MUTATION par décès: VALEUR des IMMEUBLES NUMÉROS des DÉCLARATIONS: PRIMITIVES NUMÉROS des DÉCLARATIONS: SUPPLÉMENTAIRES RECETTE DATE: de l'expiration du délai de rectification RECETTE DATE: de l'exigibilité des droits NUMÉROS de la consignation des droits au sommier n° 28 RECETTE des droits et amendes.: DATE RECETTE des droits et amendes.: N°s CAUTIONNEMENTS.: Numéros de la consignation au sommier n°30 OBSERVATIONS. (Les déclarations qui figurent à l'état n°413 doivent être émargées en conséquence, dans la présente colonne)\",\n",
       " '14_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS DROITS DE SUCCESSION DROIT NUMÉROS DATE RECETTE CAUTIONNEMENTS OBSERVATIONS des ou du EN LIGNE COLLATÉRALE DE MUTATION des de de la de la déclarations NOMS PRÉNOMS DOMICILES jugement d'envoi NOMS PRÉNOMS et de par décès DÉCLARATIONS l'expiration consignation consignation en possession et demeures des parties déclarantes MUTATION EN LIGNE DIRECTE du délai des droits au sommier en cas d'absence de rectification au sommier n° 28 n° 30 ACTIF PASSIF RESTANT VALEUR NET (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17)\",\n",
       " '15_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE NUMÉROS RECETTE CAUTION- des ou du ET EN LIGNE COLLATÉRALE DE MUTATION des des des NEMENT DÉCLARATIONS. NOMS. PRÉNOMS. DOMICILES. JUGEMENT D'ENVOI DEMEURES DES PARTIES DÉCLARANTES. et de par décès DÉCLARATIONS ARTICLES DROITS ET AMENDES. OBSERVATIONS. en possession. MUTATION EN LIGNE DIRECTE VALEUR registre ACTIF. PASSIF. RESTANT IMMEUBLES. de perception N° 70\",\n",
       " '16_0': 'N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE RECETTE CAUTION- OBSERVATIONS des DÉCLARATIONS. NOMS. PRÉNOMS. DOMICILES. JUGEMENT DEMEURES DES PARTIES DÉCLARANTES ET DE MUTATION EN LIGNE DIRECTE par décès DROITS ET AMENDES ACTIF. PASSIF. RESTANT NET',\n",
       " '17_0': \"N° d'ordre DATE DU DÉPÔT des DÉCLARATIONS DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES: NOMS, PRÉNOMS, DOMICILES DATE DU DÉCÈS ou du jugement d'envoi en possession, en cas d'absence. NOMS, PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES DROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE: ACTIF, PASSIF, RESTANT NET DROIT DE MUTATION par décès: VALEUR des immeubles NUMÉROS des DÉCLARATIONS DATE NUMÉROS de la consignation des droits au sommier n° 28 RECETTE des DROITS ET AMENDES CAUTIONNEMENTS OBSERVATIONS Les déclarations qui ne donnent lieu à aucun droit doivent être inscrites au sommier n° 28\",\n",
       " '18_0': \"N° | DATE DU DÉPÔT | DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES | DATE DU DÉCÈS | NOMS, PRÉNOMS | DROITS DE SUCCESSION | DROIT | NUMÉROS | DATE | RECETTE | CAUTION- | OBSERVATIONS | des | DÉCLARATIONS | NOMS, | PRÉNOMS, | DOMICILES. | l'ouverture | ET | DEMEURES DES | OU LIGNE COLLATÉRALE | DE | des | DÉCLARATIONS | | DROITS | | de | l'expédition | ET | l'absence. | DÉCLARANTES | ACTIF. | PASSIF. | RESTANT | VALEUR | | | du droit | AMENDES | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | |\",\n",
       " '19_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE RECETTE OBSERVATIONS des DÉCLARATIONS NOMS, PRÉNOMS, DOMICILES ou de l'absence et DEMEURES DES PARTIES DÉCLARANTES EN LIGNE COLLATÉRALE DE MUTA- des DÉCLARA- des DROITS RANTES MUTATION EN LIGNE DIRECTE TION TIONS ACTIF PASSIF RESTANT NET\",\n",
       " '20_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES: DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE RECETTE CAUTION- OBSERVATIONS d'ordre des NOMS, PRÉNOMS, DOMICILES ou du ET DE LIGNE COLLATÉRALE DE MUTATION des de des NEMENTS déclarations. JUGEMENT D'ENVOI DEMEURES DES PARTIES DÉCLARANTES. ET DE MUTATION EN LIGNE DIRECTE PAR DÉCÈS DÉCLARATIONS l'expiration DROITS ET AMENDES. en possession ACTIF. PASSIF. RESTANT VALEUR Primitives. Supplémen- du délai DATE N° Numéros de la en cas d'absence. (2) (2) NET. des taires. de consignation IMMEUBLES. rectification. au sommier n° 30\",\n",
       " '4_1': 'Arrêté le deux novembre 1919 clercx',\n",
       " '4_7': '420² Lambotte Ernest Waterloo 7 février 1911 Lambotte Emile 258 1914',\n",
       " '8_2': '429 vingt deux novembre Beth Louis Otto 28 mai 1919 Héritier Louis 9000 9000 5 janvier 1920 26 mars 1919 15 8/20 300 15 8/20 300',\n",
       " '8_5': '1532 5 Poliart Léon \" 3/8/1918 Veuve Clément Laurette 915 111 632 1532 5 15 août 1919 3 avril 1919 73',\n",
       " '8_10': '437 30 Delanney Clémentine 2 28 mars 1918 Bossut adrien 6154 644 513 1 30 28 février 1919 14-11-21 148',\n",
       " '13_9': \"446 second part Vanglaire Guillaume Prosper 5 7 1944 Bruxelles Boul d'anvers 100 700 9 30 17 juillet 1920 non fournie\",\n",
       " '16_2': '9 Gervis Esterphard Gustave Séraphin Castiau Marie Anderlues 3 juillet 1918 1 août 1918 384',\n",
       " '1_1': 'Arrêté le vingt huit octobre 1919 Servais',\n",
       " '1_2': 'Arrêté le vingt neuf octobre 1919 Servais',\n",
       " '1_3': '398 trente Herrent Alphonse Joseph ochain 30 8bre 1913 Herrent Désiré & autres 2280 1085 1195 11 30/315 15 9bre 1914 feuillet 365 octobre',\n",
       " '1_4': '398² Lefebvre Jules Bruxelles Ixelles Chaussée 244 xxxx xxxx 241 799',\n",
       " '1_5': 'Arrêté le trente octobre 1919 Servais',\n",
       " '1_6': 'Arrêté le trente un octobre 1919 Servais',\n",
       " '1_7': 'Arrêté le premier novembre 1919 Toussaint Servais',\n",
       " '1_8': 'Arrêté le deux novembre 1919 Dimanche Servais',\n",
       " '1_9': '399 6 mai 9 fev Desmedt Jeanne Nivelles 13 mai 2024 Desmedt Celine rentière 9110 520 89.10 15 8bre 13 mars 10 fevrier 35',\n",
       " '1_10': '400 Monseur Pascal Henri Philippe 4 8bre 1918 Nouveau Délais 69060 34478 34582 15 32 4 avril 1919',\n",
       " '1_11': \"401 8 Bouly Henri Ouvrier l' 20 février Bouly-Marie Père 2374 2374 15 8 20 Août non passible célibat. 1879 1879\",\n",
       " '1_12': 'Arrêté le trois novembre 1919 dix-neuf',\n",
       " '1_13': \"402 Godart Rombals Marie 11 mai Plesson Gustave Les déclarations rectificatives et supplémentaires portent le numéro de la déclaration qui les précède, suivi d'un exposant (bis a 1374, 8 b, etc.) 17237 17737 55 76 31 22 mai 1919 21 novembre 1920\",\n",
       " '2_1': '1419',\n",
       " '2_2': \"403 quatre 92° Bayot Antoinette Marie d'Aubly 11 mai 919 Payot Henri d'aubert 16971 5233 11700 suff 16.919.919 16 mai 919 1921\",\n",
       " '2_3': '405e De Paulus Adolphe Nivelles 25 février Paulus Leopold 2971 2971 481 10 Août 1920\\n                        1919                                1919',\n",
       " '2_4': '404 5° Vandermeers Louis Oscar Elbert 4 avril Bruxelles Boitsfort 500 500 16 30 7 janvier non passible 1918 1919',\n",
       " '2_5': 'Arrêté le quatre novembre 1919 Servais',\n",
       " '2_6': '405 cinq 764 Lemoine Joseph Ath 24 Août Domien julesse & autres 1885 1885 18 Août 26 août 1889 non fournie',\n",
       " '2_7': \"406 30 Monnaye Julie Dampremy le 9/8/1911 Monnaye Cécile à Jumet Cessation d'usufruit 11 février 97\",\n",
       " '2_8': '105 de Godeau Clément Dottignies 7 8bre 47 Godeau Hortense veuve 500 500 18 8bre 7 avril non passible Saintblanc 1911',\n",
       " '2_9': 'Arrêté le cinq novembre 1919 (Servais)',\n",
       " '2_10': 'Arrêté le dix novembre 1949 Servais',\n",
       " '2_11': '408 sept 9bre Fontaine Florent Cutsys 15 octobre 1928 Rousseaux Armande 848 225 202 18 9bre 25 avril non passible',\n",
       " '2_12': '409 5° Allard Prosper Nivelles 16 avril Bellens Marie 9420 9420 17 5° 16 juin 25 message 54 1919 1920',\n",
       " '2_13': 'Arrêté le sept novembre 1919 Servais',\n",
       " '2_14': '410 Paul plus Delontte gustave 22/12/1909 16 mai 1919 delville Edouard Zulte 11451 369 11087 20 30 16 mars 1920 29 février 1920',\n",
       " '3_1': '411 Paul 26/3/39 Houtelet Henri Waterloo 25/3/39 Epouse Huwe 3978 3978 20/3/39 20 juillet non fournie 1920',\n",
       " '3_2': '412 30 Chabreau Henri Emile 6 8/1919 Capelle Antoinette et autres 78692 78692 20 30 6 octobre 19 8/1919 201 202 203 204 205',\n",
       " '3_3': '412 3 Reynens Louis officier 4 avril 1916 Gilles ordre 1296 1296 280 31 mars 1920 549',\n",
       " '3_4': 'Arrêté le huit novembre 1919 Servais',\n",
       " '3_5': 'Arrêté le neuf novembre 1919 Dimanche Servais',\n",
       " '3_6': '413 dec 9/1919 Mathieu Emerance Désiré 11 mai 1919 Beauvechain Leopold 14934 14934 22 dec 1919 11 mai 1920',\n",
       " '3_7': \"414 32 Caminiau Adeline Marie 27 juillet 1919 Dépêche Secr. d'Etat 25391 25391 41.52 32 2 mai 1920 13 mars 1920 59 100 5 mai 1920 12 32 100\",\n",
       " '3_8': '415 5° Dubru Amandine Albert 6 juin 1949 décédée femme x autre 500 355 144 26 5° 6 avril 949 non payable',\n",
       " '3_9': 'Arrêté le dix novembre 1919 dressé',\n",
       " '3_10': '416 aug. 9/82 Heuvels Emmanuel Nivelle 22 mai 1917 Saffon Louis 7561 586 6975 25 Déc. renoncé 15 mai 1917 ♂',\n",
       " '3_11': '417 2 Basigant Marie 47 2 Bruyenne Eugénie 1264 4264 23 2 15 2 5 mars 1920 52',\n",
       " '3_12': '4112 5° Campinaire 221 (Renard taillé) 29/3/1915 Gillis Eugène 22295 23750 361 414',\n",
       " '3_13': 'Arrêté le 4 mars novembre 1919 déclaré',\n",
       " '4_2': '418 Enreg 952 Cloquet Célestine Wauthier 28 mai 1919 Décédé aliéné 5500 5500 29 3/4 44 28 mars 5 mars 1920',\n",
       " '4_3': '419 3° Vincent Edouard Denis 3 avril 1911 Bréfort Emile et autre 22600 22600 3° 3° 3 juin 1911 3 mars 1914 945 10 5° 300',\n",
       " '4_4': 'Arrêté le treize novembre 1919 dressé',\n",
       " '4_5': 'Arrêté le quinze novembre 1919 Servais',\n",
       " '4_6': '420 quinge Boisdenghien Rosalie quesnoit 17 mai 1919 décès Renaix veuve 1938 1938 607 24 36 1/2 15 mars 1940 1 août 38',\n",
       " '4_8': 'Arrêté le quinze novembre 1919 Servais',\n",
       " '4_9': 'Arrêté le deux novembre 1919 Dimanche [illegible]',\n",
       " '4_10': 'Arrêté le 2nd sept novembre 1919 Servais',\n",
       " '4_11': '420 3 décembre Rousseau Charles Gh Nivelles 21 mars 1919 Rousseau Louis 24.800 24.800 780 1949',\n",
       " '4_12': '421 3° Lehamg Henri Euthie 2 aout 1915 Neufchateau Bras Arlon 1922 210 3912 28 Aout 49 2 juin 1915 3 aout 1920 24 49 5 385',\n",
       " '4_13': 'Arrêté le dix huit novembre 1919 quinze',\n",
       " '5_1': '1919',\n",
       " '5_2': '425 neuf Sleemans Charles Otto 27 avril 1917 Boussu Hainaut 5888 214 5675 39 10254/14 322 17 19 janvier 1918 24',\n",
       " '5_3': '435 3. Burÿ Léontine Maria Catharina 4 janvier 1912 Bury Marie Leontine 500 500 10 août 241 9 janv. 1913',\n",
       " '5_4': '4234 3° Pieterbons Remi J. Henri Wilhelm 17 février 1913 Deux garçons rentiers Duffel 21/2/1913 249 4917',\n",
       " '5_5': '422 5 Pietersons Jean Gn. 26 mars 1898 - - 366 245 121 31 Aug 25 mars 1920 non fournie',\n",
       " '5_6': '423 5 Desaeger Henri Bertha Arthur 20 mai 1919 Ghislenghien Attel 2895 2895 30 25 5 17 mars 60 1940',\n",
       " '5_7': 'Arrêté le dix neuf novembre 1913 Servais',\n",
       " '5_8': '424 vingt 9bre Hantier Firmin Nivelles épicier décès juillet avant 86101 86101 7bre 2 janvier 1923 1922 1923 16 juillet 83',\n",
       " '5_9': '485 5e Delaitre Céline Catherine Rosine 26 mars 1924 Louppé Jean Bte et autre 500 500 1 5e 26 mars 924 non fournie',\n",
       " '5_10': 'Arrêté le vingt novembre 1919 Servais',\n",
       " '5_11': '425² Longchamps Pierrot Julien 22/12/1940 à Gérin Beauraing constable Déclaration rectificative 223 1944',\n",
       " '5_12': '426 3° Fontignies Ath Athan St-jean 1914 Bartholomé Edouard veuve 2261 2261 1 3° 20 avril 1920 10 juillet 20',\n",
       " '5_13': '429 8 Moens Joseph Calais expulsé Liège déc. d autres 1595 3095 1 3- 28 mai 1929 non payable',\n",
       " '5_14': '428 x Semal Henri Nivelles 15 juin 1924 Guyot alice et autres 4000 4000 334/1 3x 16 août 1924 16 août 1924 79',\n",
       " '6_1': '1911 Bureau de Bruxelles 3e division Déclaration No 773 Succession de Mme Jeanne Marie Josephe Ghislaine Orts décédée à Bruxelles le 14 février 1911 épouse de M. Auguste Beernaert Déposée le 14 août 1911 par M. [illegible name] domicilié à [illegible address]',\n",
       " '6_2': '150 vingt quatre juin Lambert Valentin Rebecq 16 mars 1921 Gérard Camille et autres 12880 1609 11271 16 mars 1922 19',\n",
       " '6_3': '151 Lerseau Adolphine Charleroy 3 mars 97 Vanspré Rosalie & autres 6768 6860 7869/4 157 16 - 97',\n",
       " '6_4': '152 5° Vanpée Frédéric \" 29/8/920 9 4100 594 6504 non passible',\n",
       " '6_5': '153 Dr Delabij Joachim Joseph exupère léopold Joachim Antoine Henri 1890 fév 1891',\n",
       " '6_6': 'Arrêté Le vingt quatre juin 1920 Servais',\n",
       " '6_7': '153² Charlier Hosdain Nestor 8 avril 1920 Henri Jules à Bon 341 1920',\n",
       " '6_8': 'Arrêté le vingt-cinq juin mil neuf cent',\n",
       " '6_9': 'Arrêté le vingt-six juin 1921 Dimanche Servais',\n",
       " '6_10': '154 Froment Roger Nivelles 28 février Van Dormael Juliette 90705 3369 87336 3075 janvier 239\\n                                                                              1926',\n",
       " '6_11': '155 8 Devreux Jean Ste Léonard épicier Rèves Hainaut canton 26/6 248 non passible Charleroi 1928',\n",
       " '6_12': '156 Seolas Jean Joseph Wautier 6 Août décédé juge de paix autres 2691 2691 id',\n",
       " '6_13': 'Arrêté le vingt sept février 1921 (illisible)',\n",
       " '6_14': '157 vingt huit 8 Declercque Marie-Emma Rosalie 29 8bre 1910 Declercque Adelaide 14.066 3326 10.740 9.649.20.28',\n",
       " '7_1': 'Arrêté le dix-sept juin 1920 dressé',\n",
       " '7_2': '145 cinquième Luyer Charles Louis Original 15 8/1920 Van assche julienne x enfants 50188 1418 51606 28 8/1921 28 2/1921 30',\n",
       " '7_3': 'Arrêté le dix sept juin 1921 Servais',\n",
       " '7_4': '146 des Paulfinis Masson Jean Bte Baulers 19 Abgra Porte Eloise 12905 598 12020 31-11-41 114',\n",
       " '7_5': 'Arrêté le 30 Avril juin 1921 (illisible)',\n",
       " '7_6': 'Arrêté le trente juin 1901 Dimanche soir',\n",
       " '7_7': 'Arrêté le vingt juin 1921 Servais',\n",
       " '7_8': '115 vingt un juin Leblicq Jason Ste Ghislain 13 mars 1920 Veuve Marie Dhaese et autres 4950 336 4614 non passible',\n",
       " '7_9': 'Arrêté le vingt-un juin 1921 dressé',\n",
       " '7_10': 'Arrêté le vingt deux juin 1923 dressé',\n",
       " '7_11': 'Arrêté le vingt trois juin 1920 clôturé',\n",
       " '7_12': '148 vingt quatre Dasset Emmanuel Gérard Bruxelles Gérin Emile & autres 4/8/1 1833 1612 100 6 janvier 1912 1834',\n",
       " '7_13': '149 de Liegelaert Laurent Th. Regina 18 mai 1926 Huygens-Elisabeth & autres 6378 2568 3810 non fournie',\n",
       " '8_1': 'Arrêté le vingt-un novembre 1919 sceau',\n",
       " '8_3': '430 8° Huart Paul ° 19 8bre 1913 Huart Joseph et autres 44207 1861 42346 3 8° 19 avril 1914 4 avril 1914 362 1 juin 1914 942',\n",
       " '8_4': \"431 3° Romain Félicie 9 1897 8/19 Wanlin Livret d'ouvrier 1915 10 38 5 0 10 juillet 1938 15/3°1939 130\",\n",
       " '8_6': '133 Poliart Arthur 19 5 a 945 441 674 135 5 50 19 5 5 71',\n",
       " '8_7': '434 Houtmeyers Henri célibataire 38 ans 1/2 Belgique Duffel 1834 78 1878 3° 21 mars 1 avril 1923 78',\n",
       " '8_8': '455 dr Thibaut Beau Louis Germant 5 9bre 1919 époux Denis & autres 11290 11290 455 dr 5 7bre 1920 non passible',\n",
       " '8_9': '436 5 Gaussin Eva Bruxelles 22/6/1915 Gaussin Daniel 1020 722 298 5 50 20 avril 1919 non passible',\n",
       " '8_11': '438 Debutte Jules 20 octobre 29 fév 48 Debutte alfred 3988 1483 2505 75 29 avril 15 mai 1920 ou 1929 15 août 1920 565',\n",
       " '8_12': 'Arrêté le vingt trois novembre 1919 clôturé',\n",
       " '8_13': \"Arrêté le vingt trois novembre 1919 (Dimanche) Servais\\n\\n(1) Les déclarations rectificatives et supplémentaires portent le numéro de la déclaration qui les précède, suivie d'un\",\n",
       " '9_1': 'Arrêté le vingt quatre novembre 1919 (signature)',\n",
       " '9_2': '439 vingt-cinq Gossiaux Adelain Jos Plancenoit 20 7 1911 Gostiaux Sophie a autres 804 5015 6 janvier 20 juillet 1920 5 mai 1920 615',\n",
       " '9_3': 'Arrêté le vingt cinq novembre 1919 courant',\n",
       " '9_4': 'Arrêté le vingt trois novembre 1909 Servais',\n",
       " '9_5': 'Arrêté le vingt-sept novembre 1919 deurnis',\n",
       " '9_6': 'Arrêté le vingt huit novembre 1919 Servais',\n",
       " '9_7': 'Arrêté le vingt neuf novembre 1919 Servais',\n",
       " '9_8': 'Arrêté le trente novembre 1919 Dimanche Servais',\n",
       " '9_9': '439 1/2 Sainblane Joseph huissier Anvers 1 février 1914 Sainblane Georges & autres 5596 5596 206 1914',\n",
       " '9_10': '1293 5 Saintelette Bonavent 13 5 73 2830 2830 107 1911',\n",
       " '9_11': 'Arrêté le premier décembre 1919 Servais',\n",
       " '9_12': '439 4 deux 54 Charlier Jean Bte Alphonse 29/8/1915 Chevalier Juliette Veuve Fontier Lucien 5000 5000 91 199',\n",
       " '9_13': 'Jeudi 8 deux décembre 1919 Servais',\n",
       " '10_1': 'Arrêté le trois décembre 1919 Servais',\n",
       " '10_2': '4395 Knops Valentine Nicolle 7/4/1911 Bouwel Lierre x veuve Delft insuffisance 38 23.36 40.330 1914 17 avril 30 oct',\n",
       " '10_3': 'Arrêté le quatre décembre 1919 Servais',\n",
       " '10_4': '440 cinq octobre Defalque Eugene Namur le 5 juin 1911 Wanfercée Baulet 4102 4202 16 janvier-7avril 1920 3 mai 1920 96',\n",
       " '10_5': 'Arrêté le vingt décembre 1919 Servais',\n",
       " '10_6': '411 bis 584 Jacqmin Cécile Ophain 27 juillet 914 Joseph François 58611 58611 108758 38 27 mai 1920 16 février 1916',\n",
       " '10_7': '445 8 Voussure Léon Renaix 18 Juillet 1914 Gillis André 41 41 28',\n",
       " '10_8': 'Lundi le 2 décembre 1919 Servais',\n",
       " '10_9': 'Arrêté le 5 septembre 1919 Rimambly Servais',\n",
       " '10_10': '941 Vanbiesbroeck de Lahenne Emile Nivelles 7/6/1918 Servais Marie 628 628 133 19.7',\n",
       " '10_11': 'Arrêté le huit décembre 1919 dressé',\n",
       " '10_12': '4414 neuf sta Heuvels Alphonsine Nicelle 6 février 1919 Parents décés décl négative 585 197',\n",
       " '10_13': '445 x Goisse Adolphe \" 6 janvier 1919 Rouvenel Clara 910 910 204 1919',\n",
       " '11_1': 'Arrêté le vingt décembre 1919 Servais',\n",
       " '11_2': 'Arrêté le trente et un décembre 1919 Servais',\n",
       " '11_3': '445 bis Dewez Jean Waterloo 9 8/43 Dewez Germaine 921 921 4/6 1949',\n",
       " '11_4': 'Arrêté le vingt décembre 1919 Servais',\n",
       " '11_5': '445 aout 32 Belise Vital Quarant 1 8/43 Cappens Camille 2593 2593 10',\n",
       " '11_6': 'Arrêté le douze décembre 1919 Servais',\n",
       " '11_7': 'Arrêté le treize décembre 1919 Servais',\n",
       " '11_8': 'Arrêté le 31 octobre 1919 dimanche dernier',\n",
       " '11_9': 'Arrêté le quinze décembre 1919 Servais',\n",
       " '11_10': 'Arrêté le deux décembre 1939 (Servais)',\n",
       " '11_11': '8 Boisdenghien Henri generet 15 mai debois Docteur à Aiseau 4239 0 4239 0 619 1899',\n",
       " '11_12': 'Arrêté le six sept décembre 1919 Servais',\n",
       " '11_13': \"Arrêté le dix huit décembre 1919 Servais\\n\\n(1) Les déclarations rectificatives et supplémentaires portent le numéro de la déclaration qu'elles modifient.\",\n",
       " '12_1': '9 1848 22 août 1848 Devillers Joséphine Marie 9 février soillers julie à Fleurus 495 1919 4 4',\n",
       " '12_2': '41 10 35 Clabecq Fernand Mathieu François Delcuve Emile 16 291 1919',\n",
       " '12_3': 'Arrêté le dix neuf décembre 1919 feuille',\n",
       " '12_4': 'Arrêté le vingt-et-unième 1919 janvier',\n",
       " '12_5': 'Arrêté le vingt-un décembre 1919 Dimanche-Servais',\n",
       " '12_6': '442 vingt deux Gilbert Clémence veuve 19 2 1917 Soignies rue neuve 2 armand 72 7291 7291 1 février 20 février 1920 7 juillet 97',\n",
       " '12_7': '442² 8 Paesmans Henri Bruxelles 6 mars Paesmans Henri 1881 1180 945 4 Août 31 1917 1917',\n",
       " '12_8': '442³ 5° Minne Maria Ghysel 2 avril décédée jules 1646 . 1646 648 \" 7 janvier 8 1925 1926',\n",
       " '12_9': '4424 5° Malbieu Constance Elise 11 mars 1914 Bousquiaux (époux) 149741 149741 413/1919',\n",
       " '12_10': 'Arrêté le vingt-deux décembre 1919 Servais',\n",
       " '12_11': 'Arrêté le vingt-trois décembre 1929 Servais',\n",
       " '12_12': '1405 Cauwenberg Victor Joseph Charles 16.8.911 Gembloux célibataire rentier 262 262 305 1911',\n",
       " '12_13': '543 Anthoine Alphonse Aubry 20 Août 1919 Patteet Maurice Ghlin et suite 1826 1826 expirant 26 avril 1920 exigible',\n",
       " '13_1': 'Arrêté le vingt-quatre décembre 1919 Servais',\n",
       " '13_2': 'Arrêté le vingt-neuf décembre 1919 Noël Servais',\n",
       " '13_3': '14043 Thibault Alexis Louis épicier 5/4/43 Leysele décédé à autres 1940 415/1919',\n",
       " '13_4': 'Arrêté le vingt-six Décembre 1919 Servais',\n",
       " '13_5': '464 rentepligt Wautkier Cécile Pauline 20 juin 91 Bossuu Abel 11689 11689 17 février 28 avril 29 avril 1920 1920 1920',\n",
       " '13_6': '445 Jacquet Emmerence Roseline 29 a° Jacquet Emile 58298 2373 56202 7 a° 29 a° 18 avril 1920 38',\n",
       " '13_7': 'Arrêté le vingt-sept décembre 1919 Servais',\n",
       " '13_8': 'Arrêté le vingt-huit décembre 1919 Permanence donnée',\n",
       " '13_10': 'Arrêté le vingt neuf décembre 1919 Servais\\n\\nVersées 1919 perceptions pour\\n1916 - 39\\n1918 - 418\\n1919 - 388 . 191 220 268 . 368 . 402\\n      948 . 813 . 932 . 935 . 938',\n",
       " '13_11': \"Arrêté le trente décembre 1919 servais\\n\\nSuccession d'appartenant de\\n1919 68 395\\n1918 68 394 396 396\",\n",
       " '13_12': '446² écouteur Plasman Désiré Maurice 10 mars Veny Remy & autres 158. - 158 1918 81 114 116 142 122 177 de 1918 341 360 366 370 410',\n",
       " '13_13': 'Arrêté le trente-un décembre 1918 (Servais) Le Receveur, (Signature)',\n",
       " '14_1': 'Arrêté le premier janvier 1920 Déclaration Servais',\n",
       " '14_2': '1 deux janvier Severin Jules menuisier à puers delarivière Josephine et 36762 36762 5/6/2 15/3 février 6 mars épouse déc 4920 autres 1919 1920 1919',\n",
       " '14_3': '2 Jo Dumont Louise Rosalie 3 Jo Fleury-julette x auto 369 10 10 10 5 3 5 14 janvier 1920',\n",
       " '14_4': 'Arrêté le deux janvier 1920 signé',\n",
       " '14_5': 'Arrêté le trois janvier 1920 Servais',\n",
       " '14_6': 'Arrêté le quatre janvier 1910 Demeester Servais',\n",
       " '14_7': '3 aout janvier Houlin Edgard Aubry 7 juillet Somme décédé Aubry 111.72 111.72 108 16 janvier 4 mai 22 juillet 1939 1940 1940 526',\n",
       " '14_8': '3e Séverin Jules Ouvrier 6 juillet décédé 1917 34.745 1920 célibataire',\n",
       " '14_9': '33 de Wanderpepen Louis Nivelles 29/8/73 Rentier Seules 1615 . 1615 707 . . 27 janvier 1916 1920',\n",
       " '14_10': 'Arrêté le vingt janvier 1920 Servais',\n",
       " '14_11': '4 septembre Scolas Victoire Joseph Barras 22/8/1944 Rossignol Joseph & autres 9039 9039 15 fevrier 22 juillet spécial 120 1920 1920',\n",
       " '14_12': 'Arrêté le 31 janvier 1920 Servais',\n",
       " '14_13': \"Arrêté le 31 janvier 1920 Servais\\n\\n(1) Les déclarations rectificatives et supplémentaires portent le numéro de la déclaration qu'elles modifient, affecté d'un exposant (1bis, 2bis, etc.)\",\n",
       " '15_1': '34 Paul François Lefebvre Laurent Cullige 30/8/1913 Héritiers Euphémie veuve 6510 6510 1447 23/8/1914 1914 24/8/1914',\n",
       " '15_2': 'Arrêté le huit janvier 1920 Servais',\n",
       " '15_3': 'Arrêté le neuf janvier 1920 Servais',\n",
       " '15_4': 'Arrêté le dix janvier 1920 Servais',\n",
       " '15_5': 'Arrêté le vingt janvier 1920 Duysenche servais',\n",
       " '15_6': '5 deux janv Denck Henri Bouvignal 2 mai Arquennes Julien cadet 1200 1200 20 24 février 6 mars 1920 1920 1920',\n",
       " '15_7': 'Arrêté le onze janvier 1920 Servais',\n",
       " '15_8': '6 Lacroix Louis Catherin négociant officier 21/7 Standberg usde autel 3641 3641 20 7° 15 mai 1863 non fournis',\n",
       " '15_9': 'Arrêté le trois janvier 1920 Servais',\n",
       " '15_10': 'Arrêté le quatre janvier 1920 Servais',\n",
       " '15_11': 'Arrêté le quinze janvier 1920 dressé',\n",
       " '15_12': 'Arrêté le deux janvier 1920 Servais',\n",
       " '15_13': '7 Schillebeeckx Nicolas Uccle Bruxelles 29 juillet Bodenghem Albert 2 août 14625 14625 28 février 29 mars 1 août 1920 270',\n",
       " '16_1': '822/9/922LeclercqFleuronMarieL.Anderlues6/10/919LeclercqVictor&autres84688468191622janvier-6juillet1923nonprescrit',\n",
       " '16_3': '9^e 2^e Oreye alphonse gén a 25 8^b 1911 Gembloux Namur Gand 384 4 janvier 50 1930',\n",
       " '16_4': 'Arrêté le dix sept janvier 1930 Servais',\n",
       " '16_5': 'Arrêté le dix huit janvier 1920 Dimanche Servais',\n",
       " '16_6': 'Arrêté le trois neuf janvier 1921 Servais',\n",
       " '16_7': 'Arrêté le vingt janvier 1920 dressé',\n",
       " '16_8': '93 vingt/deux Becquet Barral Rosalie 3 mariage Becquet Rose Son certificat 585 1919 janvier',\n",
       " '16_9': 'Arrêté le vingt un janvier 1920 sceau',\n",
       " '16_10': 'Arrêté le vingt deux janvier 1930 Servais',\n",
       " '16_11': 'Arrêté le vingt trois janvier 1920 dressé',\n",
       " '16_12': '10 vingt/quatre Durieux Henri Nestor 4 juillet 1949 Durieux Louis décédé 141 563 8185 149748 1950 1950 3 avril 1950 3 juillet 1950',\n",
       " '16_13': 'Arrêté le vingt quatre janvier 1920 dix neuf',\n",
       " '17_1': 'Arrêté le vingt cinq janvier 1920 Dimanche soir',\n",
       " '17_2': '102 vingt-deux janvier Deflandre Gustave Henri Emile 22/8/913 Auderghem Belgique 440 50 198/1914',\n",
       " '17_3': '10³ 5 Ypersiel Julien Ghislain Rombaux 18 Août 1918 Charleroi coiffeur 280 . 280 15/1919',\n",
       " '17_4': 'Arrêté le vingt-six janvier 1920 Servais',\n",
       " '17_5': '10 4 janvier Cordeau Louis Maxime 31 janvier Cordeau Adonis 300 300 191 - - 21 janvier 1918 1918 janvier',\n",
       " '17_6': 'Arrêté le vingt-huit janvier 1920 dix-neuf',\n",
       " '17_7': '10 vingt huit janvier Declerck Désiré Eugène 26 février 1917 Mesvin Ciply 544 544 533 1918',\n",
       " '17_8': '405 d. Decook Isabelle 10 8bre/15 2 1916',\n",
       " '17_9': '11 3° Bolendries Anastasie Nivelles 13/8/1847 Bolendries Virginie 590 398 198 11 mars 1920 13 avril 1920 2 avril 1920 760',\n",
       " '17_10': 'Arrêté le vingt huit Janvier 1920 [illegible]',\n",
       " '17_11': 'Arrêté le vingt neuf janvier mil neuf cent vingt',\n",
       " '17_12': '11e Rousseau Charles Gm Nivelles St maurice Rousseau Jeanne 1500 - 500 1000',\n",
       " '17_13': '115 Dedoncker Vital Eugène 24 août Gouvernement du Hainaut 4487 1568 9340 137 41',\n",
       " '18_1': 'Arrêté le trente janvier 1920 signé',\n",
       " '18_2': 'Arrêté le trente un janvier 1920 Servais',\n",
       " '18_3': 'Arrêté le premier février 1920 Dimanche Servais',\n",
       " '18_4': \"12 deux fevrier Carlier Victor quarant 15 fevrier 1912 Rentier veuf d'Ameil 6795 309 6486 1/2 7 novembre 15 Aout 16 fevrier 1913\",\n",
       " '18_5': 'Arrêté le deux février 1920 Servais',\n",
       " '18_6': 'Arrêté le Trois février 1920 (Servais)',\n",
       " '18_7': \"13 quatre mars 1920 Longe Célestin Bassin S' 29 juillet Selay Henri et autre 1 1634 1634 15 3° 25 juin 1920 non passible 1919\",\n",
       " '18_8': '14 Legain Emile Oscar Flormont 5 9/1917 Longfils Nelly Castro 1978 3266 6691 19° 19° 3° 1 76419 9 3/1921 135',\n",
       " '18_9': 'Arrêté le quatre février 1920 dressé',\n",
       " '18_10': '15 vingt février Raincy Décès Catherine Pauline 5 avril Boussemart Alphonse Nestor 4390 4390 18 8e 5 juin 1926 non prescrite',\n",
       " '18_11': '15e 5 Denys Marie Virginie Ghislaine épouse Lemaire Emile 1925 décès supplémentaire 201 1925 5 février 32',\n",
       " '18_12': '15³ ³ Vanhoolebrouck Georges Charles Alphonse 29 mars 1949 Cuypers Emile 5575 5565 304',\n",
       " '18_13': '454 Sainblanc Joseph Auguste Chatelet 7 février 1949 Veuve Huebens et autres 2280 2280 2097,99',\n",
       " '19_1': 'Arrêté le cinq février 1920 suivant',\n",
       " '19_2': 'Arrêté le 22 février 1920 (Servais)',\n",
       " '19_3': 'Arrêté le sept février 1920 Servais',\n",
       " '19_4': 'Arrêté le huit février 1920 Dimanche Servais',\n",
       " '19_5': 'Arrêté le neuf février 1920 Servais',\n",
       " '19_6': '16 six février Soupart Corneille Nivelles 11 avril 1927 Receveur François à Ohain 39101 39101 26 et mars 11 juin 215 40 215 1928 1928 11 5 1928 178 11 5 1928 178',\n",
       " '19_7': '16a Favre Alphonse Jph Eulalie 2 Août 1915 Trois enfants et autres 1200 1200 90/1916 24 mars 1920 49',\n",
       " '19_8': '163 5 Siraux Augustin Delory Thomas Coupienne Emile 1025 1025 174 1911',\n",
       " '19_9': 'Arrêté le 31 Janvier 1920 donnais',\n",
       " '19_10': 'Arrêté le onze février 1920 Servais',\n",
       " '19_11': '17 août 30 Vaneutsem Adeline Bruxelles 13 août 1929 Vaneutsem Charles & autre 73.628 73.628 161 27 mars 1930 27 juillet 1930 20 juillet 1930 230',\n",
       " '19_12': 'Arrêté le douze février 1920 Servais',\n",
       " '19_13': \"18 Honnijadis Jules Vienne 22 Août Recton de Vienne Bernal 71.507 25 3 25 Août 1923 (1) Les déclarations rectificatives et supplémentaires portent le numéro de la déclaration qu'elles complètent, suivie d'un exposant, (ex: 1254²)\",\n",
       " '20_1': 'Arrêté le deux février 1920 (illisible)',\n",
       " '20_2': 'Arrêté le quinze Juin 1920 Servais',\n",
       " '20_3': 'Arrêté le quinze février 1920 Dimanche Servais',\n",
       " '20_4': 'Arrêté le dix-sept février 1920 dressé',\n",
       " '20_5': '18² du 24 juin Cabureau Louis tiller 5 maison Beauchamp louis 2 enfants declaration suppletoire 29/5 919',\n",
       " '20_6': '183 Beebes Jules 7 14/8/1918 Despl. f. Gustave xavier 103 563 356/1919',\n",
       " '20_7': 'Arrêté le dix sept Janvier 1920 Servais',\n",
       " '20_8': 'Arrêté le dix huit janvier 1910 Servais',\n",
       " '20_9': '10 décembre 30 Pétriaux Camile Morville 22 avril 1919 Robert Cordantier 6390 31 mars 1920 28 juin 1920 10 juillet 1920 118',\n",
       " '20_10': '10² 5 Dubois Alexandre épicier 5/8/1919 Dubois Jean Bte et autres 310 310 162/1919',\n",
       " '20_11': 'Arrêté le dix neuf février 1920 Servais',\n",
       " '20_12': 'Arrêté le vingt février 1920 Servais',\n",
       " '20_13': \"3 Remience Leon Sta Bruxelles 8 fevrier 1916 Remience Jeanne 400 400 100 9 4 19 vergeten som Les déclarations rectificatives et supplémentaires portent le numéro de la déclaration qui les précède, suivi d'un numéro d'ordre.\"}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claude_refine_complex_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f1f689f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "unable_ids = [id for id, content in claude_refine_complex_output.items() if \"unable\" in content or \"I apologize\" in content or \"The image\" in content or \"sorry\" in content]\n",
    "print(unable_ids, len(unable_ids), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51068bb4",
   "metadata": {},
   "source": [
    "### To run with the saved json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e2d9533c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_0</td>\n",
       "      <td>N° DATE DU DÉPÔT des déclarations DÉSIGNATION ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_0</td>\n",
       "      <td>N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_0</td>\n",
       "      <td>N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4_0</td>\n",
       "      <td>DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5_0</td>\n",
       "      <td>N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_9</td>\n",
       "      <td>10 décembre 30 Pétriaux Camile Morville 22 avr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>10² 5 Dubois Alexandre épicier 5/8/1919 Dubois...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>Arrêté le dix neuf février 1920 Servais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>Arrêté le vingt février 1920 Servais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>3 Remience Leon Sta Bruxelles 8 fevrier 1916 R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0      1_0  N° DATE DU DÉPÔT des déclarations DÉSIGNATION ...\n",
       "1      2_0  N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...\n",
       "2      3_0  N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...\n",
       "3      4_0  DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES...\n",
       "4      5_0  N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...\n",
       "..     ...                                                ...\n",
       "278   20_9  10 décembre 30 Pétriaux Camile Morville 22 avr...\n",
       "279  20_10  10² 5 Dubois Alexandre épicier 5/8/1919 Dubois...\n",
       "280  20_11            Arrêté le dix neuf février 1920 Servais\n",
       "281  20_12               Arrêté le vingt février 1920 Servais\n",
       "282  20_13  3 Remience Leon Sta Bruxelles 8 fevrier 1916 R...\n",
       "\n",
       "[283 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claude_refine_complex_output_df = pd.DataFrame(claude_refine_complex_output.items(), columns=['id', 'text'])\n",
    "claude_refine_complex_output_df['text'] = claude_refine_complex_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "claude_refine_complex_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2d265a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_refine_complex_output_df.to_csv(path+'/results/postprocessed/claude_refine_complex_perline_output2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736b773",
   "metadata": {},
   "source": [
    "# CER/BLEU calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2f6551",
   "metadata": {},
   "source": [
    "## ground truth df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a4c03dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "text_path = path+'/data/transcriptions'\n",
    "file_list = glob(os.path.join(text_path, 'transcription_ex*.txt'))\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in file_list:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    lines = content.split('\\n')\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'line': range(0, len(lines)),  # Line numbers starting from 0\n",
    "        'text': lines\n",
    "    })\n",
    "    \n",
    "    name = os.path.basename(file)\n",
    "    name = name.split('.')[0]\n",
    "    df['file'] = name.split('ex')[1]\n",
    "    df['file'] = df['file'].astype(int)\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "90b2da7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N' d'ordre Date du dépot des déclarations Dési...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Nom. Prénoms Domiciles Actif. (2) Passif. (2) ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arrêté le vingt huit octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>arrêté le vingt neuf octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>398 trente octobre Herrent Alphones gh Ophain ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>10</td>\n",
       "      <td>19 dix neuf d Pétriaux Coralie Nivelles 22 av...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>11</td>\n",
       "      <td>19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>12</td>\n",
       "      <td>Arrêté le dix neuf février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>13</td>\n",
       "      <td>Arrêté le vingt février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>14</td>\n",
       "      <td>19^3 vingt un février Remience Jean Bte Nivell...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     line                                               text  file\n",
       "0       0  N' d'ordre Date du dépot des déclarations Dési...     1\n",
       "1       1  Nom. Prénoms Domiciles Actif. (2) Passif. (2) ...     1\n",
       "2       2   arrêté le vingt huit octobre 1919 servais    ...     1\n",
       "3       3   arrêté le vingt neuf octobre 1919 servais    ...     1\n",
       "4       4  398 trente octobre Herrent Alphones gh Ophain ...     1\n",
       "..    ...                                                ...   ...\n",
       "298    10   19 dix neuf d Pétriaux Coralie Nivelles 22 av...    20\n",
       "299    11  19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...    20\n",
       "300    12          Arrêté le dix neuf février 1920 servais      20\n",
       "301    13             Arrêté le vingt février 1920 servais      20\n",
       "302    14  19^3 vingt un février Remience Jean Bte Nivell...    20\n",
       "\n",
       "[303 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "df = df.sort_values(by=['file', 'line']).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a98c96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the text values of line number 0 and 1 (the two lines of the header)\n",
    "for file in df['file'].unique():\n",
    "    header_lines = df[(df['file'] == file) & (df['line'].isin([0, 1]))]\n",
    "    df.loc[header_lines.index[0], 'text'] = header_lines.iloc[0]['text'] + \" \" + header_lines.iloc[1]['text']\n",
    "df = df[df['line'] != 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d6d3fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['line'] != 0, 'line'] -= 1  # Adjust line numbers after removing the second line of the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dae62cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for file 6, two lines are used for some column.. we need to merge them\n",
    "# doubled_line = df[(df['file'] == 6) & (df['line'].isin([3, 4]))]\n",
    "# df.loc[doubled_line.index[0], 'text'] = doubled_line.iloc[0]['text'] + \" \" + doubled_line.iloc[1]['text']\n",
    "# df.drop(doubled_line.index[1], inplace=True)\n",
    "# df.loc[(df['file'] == 6) & (df['line'] > 4), 'line'] -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d8abb06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N' d'ordre Date du dépot des déclarations Dési...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>arrêté le vingt huit octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arrêté le vingt neuf octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>398 trente octobre Herrent Alphones gh Ophain ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>arrêté le trente octobre 1919 servais        ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>arrêté le trente un octobre 1919 servais     ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>arrêté le premier novembre 1919 Toussaint ser...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>arrêté le deux novembre 1919 Dimanche servais...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>399 trois 9bre Desmedt Jeanne Nivelles 13 mai ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>400 d Monseur Raoul Oscar Clabecq 1 8b 1918 Mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>401 d Bouty Henri Braine l'Alleud 26 février 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>arrêté le trois novembre 1919 servais        ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>402 quatre 9bre Godart Renelde Braine l'Alleud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    line                                               text  file\n",
       "0      0  N' d'ordre Date du dépot des déclarations Dési...     1\n",
       "1      1   arrêté le vingt huit octobre 1919 servais    ...     1\n",
       "2      2   arrêté le vingt neuf octobre 1919 servais    ...     1\n",
       "3      3  398 trente octobre Herrent Alphones gh Ophain ...     1\n",
       "4      4  398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...     1\n",
       "5      5   arrêté le trente octobre 1919 servais        ...     1\n",
       "6      6   arrêté le trente un octobre 1919 servais     ...     1\n",
       "7      7   arrêté le premier novembre 1919 Toussaint ser...     1\n",
       "8      8   arrêté le deux novembre 1919 Dimanche servais...     1\n",
       "9      9  399 trois 9bre Desmedt Jeanne Nivelles 13 mai ...     1\n",
       "10    10  400 d Monseur Raoul Oscar Clabecq 1 8b 1918 Mo...     1\n",
       "11    11  401 d Bouty Henri Braine l'Alleud 26 février 1...     1\n",
       "12    12   arrêté le trois novembre 1919 servais        ...     1\n",
       "13    13  402 quatre 9bre Godart Renelde Braine l'Alleud...     1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['file']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "68922e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N' d'ordre Date du dépot des déclarations Dési...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>arrêté le vingt huit octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arrêté le vingt neuf octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>398 trente octobre Herrent Alphones gh Ophain ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>9</td>\n",
       "      <td>19 dix neuf d Pétriaux Coralie Nivelles 22 av...</td>\n",
       "      <td>20</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>10</td>\n",
       "      <td>19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...</td>\n",
       "      <td>20</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>11</td>\n",
       "      <td>Arrêté le dix neuf février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>12</td>\n",
       "      <td>Arrêté le vingt février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>13</td>\n",
       "      <td>19^3 vingt un février Remience Jean Bte Nivell...</td>\n",
       "      <td>20</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     line                                               text  file     id\n",
       "0       0  N' d'ordre Date du dépot des déclarations Dési...     1    1_0\n",
       "1       1   arrêté le vingt huit octobre 1919 servais    ...     1    1_1\n",
       "2       2   arrêté le vingt neuf octobre 1919 servais    ...     1    1_2\n",
       "3       3  398 trente octobre Herrent Alphones gh Ophain ...     1    1_3\n",
       "4       4  398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...     1    1_4\n",
       "..    ...                                                ...   ...    ...\n",
       "278     9   19 dix neuf d Pétriaux Coralie Nivelles 22 av...    20   20_9\n",
       "279    10  19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...    20  20_10\n",
       "280    11          Arrêté le dix neuf février 1920 servais      20  20_11\n",
       "281    12             Arrêté le vingt février 1920 servais      20  20_12\n",
       "282    13  19^3 vingt un février Remience Jean Bte Nivell...    20  20_13\n",
       "\n",
       "[283 rows x 4 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'] = df['file'].astype(str) + '_' + df['line'].astype(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7fc07b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 1, Last Line: 13\n",
      "File: 2, Last Line: 14\n",
      "File: 3, Last Line: 13\n",
      "File: 4, Last Line: 13\n",
      "File: 5, Last Line: 14\n",
      "File: 6, Last Line: 14\n",
      "File: 7, Last Line: 13\n",
      "File: 8, Last Line: 13\n",
      "File: 9, Last Line: 13\n",
      "File: 10, Last Line: 13\n",
      "File: 11, Last Line: 13\n",
      "File: 12, Last Line: 13\n",
      "File: 13, Last Line: 13\n",
      "File: 14, Last Line: 13\n",
      "File: 15, Last Line: 13\n",
      "File: 16, Last Line: 13\n",
      "File: 17, Last Line: 13\n",
      "File: 18, Last Line: 13\n",
      "File: 19, Last Line: 13\n",
      "File: 20, Last Line: 13\n"
     ]
    }
   ],
   "source": [
    "for file in df['file'].unique():\n",
    "    last_line = df[df['file'] == file]['line'].max()\n",
    "    print(f\"File: {file}, Last Line: {last_line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8837aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path+'/data/transcription_perline_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fb89e02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283 283\n"
     ]
    }
   ],
   "source": [
    "print(df['id'].nunique(), claude_output_df['id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c1c9e",
   "metadata": {},
   "source": [
    "## Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "897e931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'/data/transcription_perline_text_whitespace-trimmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0be671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "cer_metric =load(\"cer\")\n",
    "bleu_metric = load(\"bleu\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c05a9600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob(os.path.join(path+'/results/postprocessed/per-line_experiments', '*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84956ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bleu_gpt = {}\n",
    "cer_gpt = {}\n",
    "\n",
    "for id in df_filtered['id'].unique():\n",
    "    # Extract the text as a single string, not as an array\n",
    "    pred_text = pred[pred['id'] == id]['text'].values[0]\n",
    "    ref_text = df_filtered[df_filtered['id'] == id]['text'].values[0]\n",
    "\n",
    "    # Ensure the predictions and references are passed as a list of strings\n",
    "    if pred_text and ref_text:  # Check if both texts are not empty (which happens for some OCR outputs)\n",
    "        bleu_gpt[id] = bleu_metric.compute(predictions=[pred_text], references=[ref_text])\n",
    "    else:\n",
    "        bleu_gpt[id] = {'bleu': 0.0}  # Assign a default value if texts are empty\n",
    "    cer_gpt[id] = cer_metric.compute(predictions=[pred_text], references=[ref_text])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8584298f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_one_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_two_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/pytesseractOCR_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_two_text_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_complex_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_one_text_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_refine_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_refine_complex_output_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_refine_complex_output_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/kerasOCR_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/trOCR_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_refine_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_one_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_two_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_two_text_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_complex_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/easyOCR_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_one_text_example_perline_output.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "637acb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gpt_one_example...\n",
      "Processing claude_two_example...\n",
      "Processing pytesseractOCR...\n",
      "Processing claude_two_text_example...\n",
      "Processing claude_complex...\n",
      "Processing gpt_one_text_example...\n",
      "Processing claude_refine...\n",
      "Processing gpt_refine_complex_output...\n",
      "Processing claude_refine_complex_output...\n",
      "Processing gpt...\n",
      "Processing kerasOCR...\n",
      "Processing trOCR...\n",
      "Processing claude...\n",
      "Processing gpt_refine...\n",
      "Processing claude_one_example...\n",
      "Processing gpt_two_example...\n",
      "Processing gpt_two_text_example...\n",
      "Processing gpt_complex...\n",
      "Processing easyOCR...\n",
      "Processing claude_one_text_example...\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "\n",
    "bleu_perline = pd.DataFrame()\n",
    "cer_perline = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    pred = pd.read_csv(file)\n",
    "    df_filtered = df[df['id'].isin(pred['id'])]\n",
    "\n",
    "    name = os.path.basename(file)\n",
    "    name = name.split('_perline')[0]\n",
    "\n",
    "    print(f\"Processing {name}...\")\n",
    "\n",
    "    bleu_scores = []  # List to accumulate BLEU scores for this model\n",
    "    cer_scores = []  # List to accumulate CER scores for this model\n",
    "\n",
    "    for id in df_filtered['id'].unique():\n",
    "        # Extract the text as a single string, not as an array\n",
    "        pred_text = pred[pred['id'] == id]['text'].values\n",
    "        ref_text = df_filtered[df_filtered['id'] == id]['text'].values\n",
    "\n",
    "        # Ensure the predictions and references are passed as a list of strings\n",
    "        if len(pred_text) > 0 and len(ref_text) > 0:  # Check if both texts are not empty\n",
    "            pred_text = pred_text[0]\n",
    "            ref_text = ref_text[0]\n",
    "\n",
    "            # Check for NaN values \n",
    "            if pd.notna(pred_text) and pd.notna(ref_text):\n",
    "                # Strip white spaces\n",
    "                pred_text = pred_text.strip()\n",
    "                ref_text = ref_text.strip()\n",
    "                # Normalize: uncapitalize and remove accents (Try 3 different normalizations)\n",
    "                # pred_text = pred_text.lower()\n",
    "                # ref_text = ref_text.lower()\n",
    "                # pred_text = unidecode.unidecode(pred_text)\n",
    "                # ref_text = unidecode.unidecode(ref_text)\n",
    "                # pred_text = unidecode.unidecode(pred_text).lower()\n",
    "                # ref_text = unidecode.unidecode(ref_text).lower()\n",
    "\n",
    "                # Ensure texts are not empty after stripping\n",
    "                if pred_text and ref_text:\n",
    "                    bleu_metrics = bleu_metric.compute(predictions=[pred_text], references=[ref_text], max_order=3)\n",
    "                    cer_metrics = cer_metric.compute(predictions=[pred_text], references=[ref_text])\n",
    "                else:\n",
    "                    bleu_metrics = {'bleu': 0.0}  # Assign a default value if texts are empty\n",
    "                    cer_metrics = 1.0\n",
    "            else:\n",
    "                bleu_metrics = {'bleu': 0.0}  # Assign a default value if texts are NaN\n",
    "                cer_metrics = 1.0\n",
    "        else:\n",
    "            bleu_metrics = {'bleu': 0.0}  # Assign a default value if texts are empty\n",
    "            cer_metrics = 1.0\n",
    "\n",
    "        bleu_scores.append({\n",
    "                'model': name,\n",
    "                'id': id,\n",
    "                **bleu_metrics\n",
    "            })\n",
    "        cer_scores.append({\n",
    "                'model': name,\n",
    "                'id': id,\n",
    "                'cer': cer_metrics\n",
    "            })\n",
    "\n",
    "    bleu_perline = pd.concat([bleu_perline, pd.DataFrame(bleu_scores)], ignore_index=True)\n",
    "    cer_perline = pd.concat([cer_perline, pd.DataFrame(cer_scores)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dc16b3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt_one_example</td>\n",
       "      <td>1_0</td>\n",
       "      <td>0.958180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt_one_example</td>\n",
       "      <td>1_2</td>\n",
       "      <td>0.121951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt_one_example</td>\n",
       "      <td>1_3</td>\n",
       "      <td>0.822222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt_one_example</td>\n",
       "      <td>1_4</td>\n",
       "      <td>0.804598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt_one_example</td>\n",
       "      <td>1_5</td>\n",
       "      <td>0.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5643</th>\n",
       "      <td>claude_one_text_example</td>\n",
       "      <td>20_9</td>\n",
       "      <td>0.341463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>claude_one_text_example</td>\n",
       "      <td>20_10</td>\n",
       "      <td>0.448276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5645</th>\n",
       "      <td>claude_one_text_example</td>\n",
       "      <td>20_11</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5646</th>\n",
       "      <td>claude_one_text_example</td>\n",
       "      <td>20_12</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5647</th>\n",
       "      <td>claude_one_text_example</td>\n",
       "      <td>20_13</td>\n",
       "      <td>0.280000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5648 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model     id       cer\n",
       "0             gpt_one_example    1_0  0.958180\n",
       "1             gpt_one_example    1_2  0.121951\n",
       "2             gpt_one_example    1_3  0.822222\n",
       "3             gpt_one_example    1_4  0.804598\n",
       "4             gpt_one_example    1_5  0.270270\n",
       "...                       ...    ...       ...\n",
       "5643  claude_one_text_example   20_9  0.341463\n",
       "5644  claude_one_text_example  20_10  0.448276\n",
       "5645  claude_one_text_example  20_11  0.025641\n",
       "5646  claude_one_text_example  20_12  0.388889\n",
       "5647  claude_one_text_example  20_13  0.280000\n",
       "\n",
       "[5648 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cer_perline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d77448a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_perline.replace({'model': {'gpt': 'gpt_simple', 'claude': 'claude_simple',\n",
    "                               'trOCR': 'TrOCR', 'pytesseractOCR': 'Pytesseract',\n",
    "                               'kerasOCR': 'KerasOCR', 'easyOCR': 'EasyOCR',\n",
    "                               'gpt_refine_complex_output': 'gpt_refine_complex', 'claude_refine_complex_output': 'claude_refine_complex'}}, inplace=True)\n",
    "cer_perline.replace({'model': {'gpt': 'gpt_simple', 'claude': 'claude_simple',\n",
    "                               'trOCR': 'TrOCR', 'pytesseractOCR': 'Pytesseract',\n",
    "                               'kerasOCR': 'KerasOCR', 'easyOCR': 'EasyOCR',\n",
    "                               'gpt_refine_complex_output': 'gpt_refine_complex', 'claude_refine_complex_output': 'claude_refine_complex'}}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7e3d731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_perline.to_csv(path+'/results/scores_comparisons/bleu_perline_all_n3.csv', index=False)\n",
    "cer_perline.to_csv(path+'/results/scores_comparisons/cer_perline_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8774a8e",
   "metadata": {},
   "source": [
    "### BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e5be7601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.8091067115702212,\n",
       " 'precisions': [0.8571428571428571, 0.8333333333333334, 0.8, 0.75],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.0,\n",
       " 'translation_length': 7,\n",
       " 'reference_length': 7}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric.compute(predictions=['Arrêté le vingt cinq novembre 1919 Servais'], references=['Arrêté le vingt cinq novembre 1919 servais'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "968b6c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_gpt = pd.DataFrame(bleu_gpt).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc301e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>precisions</th>\n",
       "      <th>brevity_penalty</th>\n",
       "      <th>length_ratio</th>\n",
       "      <th>translation_length</th>\n",
       "      <th>reference_length</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.025, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.06081</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>40</td>\n",
       "      <td>152</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_3</th>\n",
       "      <td>0.137596</td>\n",
       "      <td>[0.38461538461538464, 0.2, 0.125, 0.0434782608...</td>\n",
       "      <td>0.962269</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.449329</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_9</th>\n",
       "      <td>0.259849</td>\n",
       "      <td>[0.5454545454545454, 0.38095238095238093, 0.25...</td>\n",
       "      <td>0.955563</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_10</th>\n",
       "      <td>0.150923</td>\n",
       "      <td>[0.45, 0.2631578947368421, 0.1111111111111111,...</td>\n",
       "      <td>0.904837</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_13</th>\n",
       "      <td>0.163304</td>\n",
       "      <td>[0.5, 0.3076923076923077, 0.25, 0.181818181818...</td>\n",
       "      <td>0.564718</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           bleu                                         precisions  \\\n",
       "1_0         0.0                             [0.025, 0.0, 0.0, 0.0]   \n",
       "1_1         1.0                               [1.0, 1.0, 1.0, 1.0]   \n",
       "1_2         1.0                               [1.0, 1.0, 1.0, 1.0]   \n",
       "1_3    0.137596  [0.38461538461538464, 0.2, 0.125, 0.0434782608...   \n",
       "1_4         0.0                               [0.1, 0.0, 0.0, 0.0]   \n",
       "...         ...                                                ...   \n",
       "20_9   0.259849  [0.5454545454545454, 0.38095238095238093, 0.25...   \n",
       "20_10  0.150923  [0.45, 0.2631578947368421, 0.1111111111111111,...   \n",
       "20_11       1.0                               [1.0, 1.0, 1.0, 1.0]   \n",
       "20_12       1.0                               [1.0, 1.0, 1.0, 1.0]   \n",
       "20_13  0.163304  [0.5, 0.3076923076923077, 0.25, 0.181818181818...   \n",
       "\n",
       "      brevity_penalty length_ratio translation_length reference_length     id  \n",
       "1_0           0.06081     0.263158                 40              152    1_0  \n",
       "1_1               1.0          1.0                  7                7    1_1  \n",
       "1_2               1.0          1.0                  7                7    1_2  \n",
       "1_3          0.962269     0.962963                 26               27    1_3  \n",
       "1_4          0.449329     0.555556                 10               18    1_4  \n",
       "...               ...          ...                ...              ...    ...  \n",
       "20_9         0.955563     0.956522                 22               23   20_9  \n",
       "20_10        0.904837     0.909091                 20               22  20_10  \n",
       "20_11             1.0          1.0                  7                7  20_11  \n",
       "20_12             1.0          1.0                  6                6  20_12  \n",
       "20_13        0.564718     0.636364                 14               22  20_13  \n",
       "\n",
       "[283 rows x 7 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_gpt['id'] = bleu_gpt.index\n",
    "bleu_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42415cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_gpt.to_csv(path+'/results/scores_comparisons/eval_perline/bleu_claude_two_example_perline.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd8ab74",
   "metadata": {},
   "source": [
    "### CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9933242",
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_gpt = pd.DataFrame(cer_gpt.items(), columns=['id', 'cer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84bd52c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5713106915175424 2.935498085710415\n"
     ]
    }
   ],
   "source": [
    "print(cer_gpt['cer'].mean(), cer_gpt['cer'].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fba7876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_gpt.to_csv(path+'/results/scores_comparisons/eval_perline/cer_claude_two_example_perline.csv', float_format=\"%.6f\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783bfe80",
   "metadata": {},
   "source": [
    "# OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd1af15-25ff-4636-800b-599ef2d986f1",
   "metadata": {},
   "source": [
    "## EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bdaf499-ac45-438e-bb41-04d45d53f78c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[43mtest_path\u001b[49m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(test_image)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_path' is not defined"
     ]
    }
   ],
   "source": [
    "test_image = cv2.imread(test_path)\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e1baa4c9-2e16-47bf-aed6-47a4c0de1807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def easyOCR(image_path):\n",
    "    reader = easyocr.Reader(['fr'])\n",
    "    img = cv2.imread(image_path)\n",
    "    results = reader.readtext(img)\n",
    "    output = []\n",
    "    for res in results:\n",
    "        det, conf = res[1], res[2]\n",
    "        output.append((det, round(conf, 2))) \n",
    "    text = ' '.join([i[0] for i in output])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "474cc34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "easyOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = easyOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        easyOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b45d798e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>line_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_00</td>\n",
       "      <td>DÉSIGNATION DES PERSONNES DÉCÉDÉES OU AlSENTES...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_01</td>\n",
       "      <td>~Bcrta` 8 oetolz 1919 d4earuey vicytAul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_02</td>\n",
       "      <td>Jbsucala &amp; veyhmeuf ouoba  tg19 [eevœy</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_03</td>\n",
       "      <td>891 ta HBevcenk ~Bepkonssjk oj hain Hgoucoal Y...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_04</td>\n",
       "      <td>TulL Bouuù Q \"Janer ~aobà Bhuile RRXR 26 aplul...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_09</td>\n",
       "      <td>J9 ùcà nuf&gt; Sebiaw bo2nbi YÉvepQu X anel Bebel...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>4 49 0 : @ubovs ssexanbz Yuemaut ubuùd *ean [l...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>Jvuté &amp; oi = neuf fasles19:0 Huclai</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>Jarsalé -   vms] Hinsenq %0 djeceia |</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>3 [9' vrqkun )a4| Semience Run Gl Yusvellen Le...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text  file_name  \\\n",
       "0     1_00  DÉSIGNATION DES PERSONNES DÉCÉDÉES OU AlSENTES...          1   \n",
       "1     1_01            ~Bcrta` 8 oetolz 1919 d4earuey vicytAul          1   \n",
       "2     1_02             Jbsucala & veyhmeuf ouoba  tg19 [eevœy          1   \n",
       "3     1_03  891 ta HBevcenk ~Bepkonssjk oj hain Hgoucoal Y...          1   \n",
       "4     1_04  TulL Bouuù Q \"Janer ~aobà Bhuile RRXR 26 aplul...          1   \n",
       "..     ...                                                ...        ...   \n",
       "278  20_09  J9 ùcà nuf> Sebiaw bo2nbi YÉvepQu X anel Bebel...         20   \n",
       "279  20_10  4 49 0 : @ubovs ssexanbz Yuemaut ubuùd *ean [l...         20   \n",
       "280  20_11                Jvuté & oi = neuf fasles19:0 Huclai         20   \n",
       "281  20_12              Jarsalé -   vms] Hinsenq %0 djeceia |         20   \n",
       "282  20_13  3 [9' vrqkun )a4| Semience Run Gl Yusvellen Le...         20   \n",
       "\n",
       "     line_name     id  \n",
       "0            0    1_0  \n",
       "1            1    1_1  \n",
       "2            2    1_2  \n",
       "3            3    1_3  \n",
       "4            4    1_4  \n",
       "..         ...    ...  \n",
       "278          9   20_9  \n",
       "279         10  20_10  \n",
       "280         11  20_11  \n",
       "281         12  20_12  \n",
       "282         13  20_13  \n",
       "\n",
       "[283 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# easyOCR_output_df = pd.read_csv(path+'/results/postprocessed/easyOCR_perline_output.csv')\n",
    "easyOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6f85318b-55be-419d-b80a-0e8c5b861779",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_00</td>\n",
       "      <td>DATE I IÉcis DROITS DF SUCCESSION DROIT NUMÉRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_01</td>\n",
       "      <td>soceti &amp; tù déeemebza. 919 Yuepiy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_02</td>\n",
       "      <td>5 1439 DaLenlize Yiceppu #9lugu | Benuue YLama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10_03</td>\n",
       "      <td>Jaxat' € deeemlaac919 Fuupùa quebu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10_04</td>\n",
       "      <td>[4ho ceæy _ (ekalque Pnag;nl  Yjuuy Wv&amp;ezlbz (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>9_09</td>\n",
       "      <td>69*2.4 Scinllane Pots+a Gxz9&amp; SasBBoe Gpmzeyen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>9_10</td>\n",
       "      <td>kag' 0: Sainllane Bwun' à 26r' 1sr \"9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>9_11</td>\n",
       "      <td>Joaak + fnmauu dceehu 1919 Yeoeok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>9_12</td>\n",
       "      <td>[4Jg %eu 3- CBaslice fe At Z8ma 2e+eygu | Jwti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>9_13</td>\n",
       "      <td>~outi &amp; Jeun 1919 fuwsuik Lg déclerations recl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text\n",
       "0    10_00  DATE I IÉcis DROITS DF SUCCESSION DROIT NUMÉRO...\n",
       "1    10_01                  soceti & tù déeemebza. 919 Yuepiy\n",
       "2    10_02  5 1439 DaLenlize Yiceppu #9lugu | Benuue YLama...\n",
       "3    10_03                 Jaxat' € deeemlaac919 Fuupùa quebu\n",
       "4    10_04  [4ho ceæy _ (ekalque Pnag;nl  Yjuuy Wv&ezlbz (...\n",
       "..     ...                                                ...\n",
       "278   9_09  69*2.4 Scinllane Pots+a Gxz9& SasBBoe Gpmzeyen...\n",
       "279   9_10              kag' 0: Sainllane Bwun' à 26r' 1sr \"9\n",
       "280   9_11                  Joaak + fnmauu dceehu 1919 Yeoeok\n",
       "281   9_12  [4Jg %eu 3- CBaslice fe At Z8ma 2e+eygu | Jwti...\n",
       "282   9_13  ~outi & Jeun 1919 fuwsuik Lg déclerations recl...\n",
       "\n",
       "[283 rows x 2 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easyOCR_output_df = pd.DataFrame(easyOCR_output.items(), columns=['file', 'text'])\n",
    "easyOCR_output_df[['file_name', 'line_name']] = easyOCR_output_df['file'].str.split('_', expand=True)\n",
    "easyOCR_output_df[['file_name', 'line_name']] = easyOCR_output_df[['file_name', 'line_name']].astype(int)\n",
    "easyOCR_output_df = easyOCR_output_df.sort_values(by=['file_name', 'line_name']).reset_index(drop=True)\n",
    "easyOCR_output_df['text'] = easyOCR_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "easyOCR_output_df['id'] = easyOCR_output_df['file_name'].astype(str) + '_' + easyOCR_output_df['line_name'].astype(str)\n",
    "easyOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "512ffd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "easyOCR_output_df.to_csv(path+'/results/postprocessed/easyOCR_perline_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09134009-83a9-4ed0-b724-d9a4096ebe7d",
   "metadata": {},
   "source": [
    "## Pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e86c0ee3-034b-446d-aa51-3e5e6e348fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pytesseractOCR(image_path):\n",
    "    try:\n",
    "        image = PILImage.open(image_path)\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text\n",
    "    except:\n",
    "        print(\"[ERROR] pytesseractOCR failed! (should be installed)\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f596a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseractOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = pytesseractOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        pytesseractOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8149b7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>line_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_00</td>\n",
       "      <td>|  = | DATE DU DEPOT  des  DECLARATIONS.  DESI...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_01</td>\n",
       "      <td>ft alt alta</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_02</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_03</td>\n",
       "      <td>a cnte |Abevcenk a dette  Son &lt;a  1040’  i ee ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_04</td>\n",
       "      <td>L  3  be oi  7  Nf »- p</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_09</td>\n",
       "      <td>149 28 auf  Si elaiawx  Ve  |  | Wvebly eu ty ...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>; a : oe ssa  song  o  Sannin nomena  ie 3 (0....</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>|  aul</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>Caen torah Winéorg ty dieser’  es  oe  aaa. pa...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>+ i 4 | pane um ‘ uy R | £5 dée! t ctfleati ec...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text  file_name  \\\n",
       "0     1_00  |  = | DATE DU DEPOT  des  DECLARATIONS.  DESI...          1   \n",
       "1     1_01                                       ft alt alta           1   \n",
       "2     1_02                                                             1   \n",
       "3     1_03  a cnte |Abevcenk a dette  Son <a  1040’  i ee ...          1   \n",
       "4     1_04                          L  3  be oi  7  Nf »- p            1   \n",
       "..     ...                                                ...        ...   \n",
       "278  20_09  149 28 auf  Si elaiawx  Ve  |  | Wvebly eu ty ...         20   \n",
       "279  20_10  ; a : oe ssa  song  o  Sannin nomena  ie 3 (0....         20   \n",
       "280  20_11                                            |  aul          20   \n",
       "281  20_12  Caen torah Winéorg ty dieser’  es  oe  aaa. pa...         20   \n",
       "282  20_13  + i 4 | pane um ‘ uy R | £5 dée! t ctfleati ec...         20   \n",
       "\n",
       "     line_name     id  \n",
       "0            0    1_0  \n",
       "1            1    1_1  \n",
       "2            2    1_2  \n",
       "3            3    1_3  \n",
       "4            4    1_4  \n",
       "..         ...    ...  \n",
       "278          9   20_9  \n",
       "279         10  20_10  \n",
       "280         11  20_11  \n",
       "281         12  20_12  \n",
       "282         13  20_13  \n",
       "\n",
       "[283 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytesseractOCR_output_df = pd.DataFrame(pytesseractOCR_output.items(), columns=['file', 'text'])\n",
    "pytesseractOCR_output_df[['file_name', 'line_name']] = pytesseractOCR_output_df['file'].str.split('_', expand=True)\n",
    "pytesseractOCR_output_df[['file_name', 'line_name']] = pytesseractOCR_output_df[['file_name', 'line_name']].astype(int)\n",
    "pytesseractOCR_output_df = pytesseractOCR_output_df.sort_values(by=['file_name', 'line_name']).reset_index(drop=True)\n",
    "pytesseractOCR_output_df['text'] = pytesseractOCR_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "pytesseractOCR_output_df['id'] = pytesseractOCR_output_df['file_name'].astype(str) + '_' + pytesseractOCR_output_df['line_name'].astype(str)\n",
    "pytesseractOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f26931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseractOCR_output_df.to_csv(path+'/results/postprocessed/pytesseractOCR_perline_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061630dd-6446-4a62-9b39-bd87c86a99f4",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "Not good for non-english?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e561f951-54a9-4d73-b778-41f9dbcdbe0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kerasOCR(image_path):\n",
    "    pipeline = keras_ocr.pipeline.Pipeline()\n",
    "    image = keras_ocr.tools.read(image_path)\n",
    "    prediction_groups = pipeline.recognize([image])\n",
    "    words = []\n",
    "    for line in prediction_groups[0]:\n",
    "        for word in line:\n",
    "            try:\n",
    "                if isinstance(word[0], str):\n",
    "                    words.append(word[0])\n",
    "            except IndexError:\n",
    "                continue\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e1e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = kerasOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        kerasOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "82c872cd-131c-4bc4-96cf-2dd2e62e0f59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for /Users/serenekim/.keras-ocr/craft_mlt_25k.h5\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: resize_bilinear (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.image.resize(...method=ResizeMethod.BILINEAR...)` instead.\n",
      "Looking for /Users/serenekim/.keras-ocr/crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 806ms/step\n",
      "1/1 [==============================] - 1s 751ms/step\n",
      "d r p o a g\n"
     ]
    }
   ],
   "source": [
    "test_keras = kerasOCR(image_path=test_path)\n",
    "print(test_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf6c0a",
   "metadata": {},
   "source": [
    "## TrOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cde01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor\n",
    "from transformers import VisionEncoderDecoderModel\n",
    "import torch\n",
    "\n",
    "def trOCR(image_path):\n",
    "    processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "\n",
    "    image = PILImage.open(image_path)\n",
    "\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "    \n",
    "    # Set device (GPU or CPU)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)  # Move model to the device\n",
    "    pixel_values = pixel_values.to(device)  # Move image tensor to the same device\n",
    "    \n",
    "    try:\n",
    "        generated_ids = model.generate(pixel_values, max_length=400)  # Limit max length\n",
    "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return generated_text\n",
    "    except IndexError as e:\n",
    "        print(f\"IndexError: {e}\")\n",
    "        return \"Error: Index out of range during generation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27ab20c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/serenekim/.pyenv/versions/3.12.0/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = trOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        trOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caa3c0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>line_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_00</td>\n",
       "      <td>treat of the first time of the French Parliame...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_01</td>\n",
       "      <td># almost be weighted rather any standard for t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_02</td>\n",
       "      <td># almost the original module you formerly ... ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_03</td>\n",
       "      <td>THE GREAT BRONDSOME \" AIRMARK GABIT PARADE HAN...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_04</td>\n",
       "      <td>After Congress plan himself tough back down to...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_09</td>\n",
       "      <td>Manager Atkinson had made many awareness of th...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>After the Democratic gubernatorial judge took ...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>the best time of fourteen songs with the first...</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>\" To absorb confidence being a total of 1 000 ...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>After the Renaissance season would change thei...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text  file_name  \\\n",
       "0     1_00  treat of the first time of the French Parliame...          1   \n",
       "1     1_01  # almost be weighted rather any standard for t...          1   \n",
       "2     1_02  # almost the original module you formerly ... ...          1   \n",
       "3     1_03  THE GREAT BRONDSOME \" AIRMARK GABIT PARADE HAN...          1   \n",
       "4     1_04  After Congress plan himself tough back down to...          1   \n",
       "..     ...                                                ...        ...   \n",
       "278  20_09  Manager Atkinson had made many awareness of th...         20   \n",
       "279  20_10  After the Democratic gubernatorial judge took ...         20   \n",
       "280  20_11  the best time of fourteen songs with the first...         20   \n",
       "281  20_12  \" To absorb confidence being a total of 1 000 ...         20   \n",
       "282  20_13  After the Renaissance season would change thei...         20   \n",
       "\n",
       "     line_name     id  \n",
       "0            0    1_0  \n",
       "1            1    1_1  \n",
       "2            2    1_2  \n",
       "3            3    1_3  \n",
       "4            4    1_4  \n",
       "..         ...    ...  \n",
       "278          9   20_9  \n",
       "279         10  20_10  \n",
       "280         11  20_11  \n",
       "281         12  20_12  \n",
       "282         13  20_13  \n",
       "\n",
       "[283 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trOCR_output_df = pd.DataFrame(trOCR_output.items(), columns=['file', 'text'])\n",
    "trOCR_output_df[['file_name', 'line_name']] = trOCR_output_df['file'].str.split('_', expand=True)\n",
    "trOCR_output_df[['file_name', 'line_name']] = trOCR_output_df[['file_name', 'line_name']].astype(int)\n",
    "trOCR_output_df = trOCR_output_df.sort_values(by=['file_name', 'line_name']).reset_index(drop=True)\n",
    "trOCR_output_df['text'] = trOCR_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "trOCR_output_df['id'] = trOCR_output_df['file_name'].astype(str) + '_' + trOCR_output_df['line_name'].astype(str)\n",
    "trOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd3cec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "trOCR_output_df.to_csv(path+'/results/postprocessed/trOCR_perline_output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
