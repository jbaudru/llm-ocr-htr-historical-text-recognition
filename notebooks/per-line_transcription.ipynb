{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c798e7-9579-4c02-88ca-0c57e52c2966",
   "metadata": {},
   "source": [
    "# per-line transcription with LLM & OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069d0fa8-6403-402b-954a-cbc05503eb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import base64\n",
    "import subprocess\n",
    "from IPython.display import display, Image\n",
    "from PIL import Image as PILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f521cad-9da9-4cdf-a63d-f5dd4ca3e4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "import pytesseract\n",
    "import keras_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "857d11aa-8fb9-4f32-a20c-5e418f5154e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = os.path.dirname(os.getcwd()) # Parent directory\n",
    "image_folder = path+'/data/lines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffd293ec-7b82-4145-820e-9e910c7d099d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OpenAI\n",
    "load_dotenv() #get the environment \n",
    "openai_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_client = OpenAI(api_key=openai_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9cc501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "anthropic_client = Anthropic(api_key=anthropic_API_KEY)\n",
    "MODEL_NAME = \"claude-3-5-sonnet-20240620\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4c585-70a5-466a-ac27-f730debebfba",
   "metadata": {},
   "source": [
    "## Read and encode the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e6f97e1-5798-4253-a324-58a38bae7f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b48666f-fd04-4f79-ba1a-8a254e9d81c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        images.append(image)\n",
    "\n",
    "rows = []\n",
    "for image in images:\n",
    "    name = image.split('.')[0]\n",
    "    name_split = name.split('_')[0]\n",
    "    file_name = name_split.split('example')[1]\n",
    "    line_name = name.split('_')[1]\n",
    "    encoded_value = encode_image(image_folder+'/'+image)\n",
    "    rows.append({'file': file_name, 'line': line_name, 'encoded': encoded_value})\n",
    "\n",
    "images_encoded = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c988074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>line</th>\n",
       "      <th>encoded</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/9j/4QZBRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>/9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>/9j/4QYvRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>/9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>/9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>/9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>/9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>/9j/4QWRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>/9j/4QZyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>/9j/4QZRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>/9j/4QZ1RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>/9j/4QVrRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>/9j/4QaFRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QcyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>/9j/4QVORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>/9j/4QX+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>/9j/4QY6RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>/9j/4QaQRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>/9j/4QVWRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>/9j/4QZ3RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>/9j/4QXbRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>/9j/4QaORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>/9j/4QWIRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>/9j/4QWARXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>/9j/4QZwRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>/9j/4QZlRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>/9j/4QV+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>/9j/4QbYRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QbPRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>3_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file  line                                            encoded    id\n",
       "0      1     0  /9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_0\n",
       "1      1     1  /9j/4QZBRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_1\n",
       "2      1     2  /9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_2\n",
       "3      1     3  /9j/4QYvRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_3\n",
       "4      1     4  /9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_4\n",
       "5      1     5  /9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_5\n",
       "6      1     6  /9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_6\n",
       "7      1     7  /9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_7\n",
       "8      1     8  /9j/4QWRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_8\n",
       "9      1     9  /9j/4QZyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_9\n",
       "10     1    10  /9j/4QZRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_10\n",
       "11     1    11  /9j/4QZ1RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_11\n",
       "12     1    12  /9j/4QVrRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_12\n",
       "13     1    13  /9j/4QaFRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_13\n",
       "14     2     0  /9j/4QcyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_0\n",
       "15     2     1  /9j/4QVORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_1\n",
       "16     2     2  /9j/4QX+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_2\n",
       "17     2     3  /9j/4QY6RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_3\n",
       "18     2     4  /9j/4QaQRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_4\n",
       "19     2     5  /9j/4QVWRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_5\n",
       "20     2     6  /9j/4QZ3RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_6\n",
       "21     2     7  /9j/4QXbRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_7\n",
       "22     2     8  /9j/4QaORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_8\n",
       "23     2     9  /9j/4QWIRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_9\n",
       "24     2    10  /9j/4QWARXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_10\n",
       "25     2    11  /9j/4QZwRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_11\n",
       "26     2    12  /9j/4QZlRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_12\n",
       "27     2    13  /9j/4QV+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_13\n",
       "28     2    14  /9j/4QbYRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_14\n",
       "29     3     0  /9j/4QbPRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...   3_0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_encoded['file'] = images_encoded['file'].astype('int')\n",
    "images_encoded['line'] = images_encoded['line'].astype('int')\n",
    "images_encoded = images_encoded.sort_values(by=['file', 'line']).reset_index(drop=True)\n",
    "images_encoded['id'] = images_encoded['file'].astype(str) + '_' + images_encoded['line'].astype(str)\n",
    "images_encoded.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa240d54",
   "metadata": {},
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd51de42-7ecf-4171-88fd-cc78fb803632",
   "metadata": {},
   "source": [
    "## General API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "73f51be1-2815-4280-ab50-4a909baf7016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def callOpenAI(prompt, max_tokens=800, base64_image=None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_API_KEY}\"\n",
    "    } \n",
    "    model_vision = \"gpt-4o\"\n",
    "    payload = {\n",
    "        \"model\": model_vision, \n",
    "        \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "            \n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                }\n",
    "            }\n",
    "            ]\n",
    "        }\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    try:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except:\n",
    "        print(response.json()[\"error\"][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6be70b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callAnthropic(prompt, max_tokens=5000, base64_image=None):\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=max_tokens,\n",
    "        system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\", \n",
    "                            \"media_type\": \"image/jpeg\", \n",
    "                            \"data\": base64_image}},\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt,\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.to_dict()[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7a94328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callPostProcessing(max_tokens=800, prompt_parameter = None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_API_KEY}\"\n",
    "    } \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"\"\"This is an output from you. Clean it such that we have no separators and no comment from you: {prompt_parameter}\n",
    "                \"\"\"\n",
    "            }\n",
    "            ]\n",
    "        }\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    try:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except:\n",
    "        print(response.json()[\"error\"][\"message\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1b44a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this when OpenAI credits are exhausted\n",
    "def callPostProcessing_anthropic(max_tokens=5000, prompt_parameter = None):\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=max_tokens,\n",
    "        system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"\"\"This is an output from you. Clean it such that we have no separators and no comment from you: {prompt_parameter}\n",
    "                \"\"\"\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.to_dict()[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65f775",
   "metadata": {},
   "source": [
    "### Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "56c01d37-e85d-45ee-b6c8-9e92b5078e87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/xy/r3gq5vtd7bx6qb966l0fhh9h0000gn/T/ipykernel_1814/795820489.py:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  prompt_complex = \"\"\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "    Recognize the text from the image:\n",
    "    ```plaintext\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_complex = \"\"\"\n",
    "    Context:\n",
    "        It's an old Belgian document. And you're getting one row of a table from it. It's written in French language and the names of the people are domiciles are Belgian.\n",
    "\n",
    "    Structure:\n",
    "        The table is structured with the two-level headers as follows:\n",
    "        [(\"N' d'ordre\", \" \"),\n",
    "                (\"Date du dépot des déclarations\", \" \"),\n",
    "                (\"Désignation des personnes décédées ou absentes.:\", \"Nom.\"),\n",
    "                (\"Désignation des personnes décédées ou absentes.:\", \"Prénoms\"),\n",
    "                (\"Désignation des personnes décédées ou absentes.:\", \"Domiciles\"), \n",
    "                (\"Date du décès ou du judgement d'envoi en possession, en cas d'absence.\", \" \"),\n",
    "                (\"Noms, Prénoms et demeures des parties déclarantes.\", \" \"),\n",
    "                (\"Droits de succession en ligne collatérale et de mutation en ligne directe.\", \"Actif. (2)\"),\n",
    "                (\"Droits de succession en ligne collatérale et de mutation en ligne directe.\", \"Passif. (2)\"),\n",
    "                (\"Droits de succession en ligne collatérale et de mutation en ligne directe.\", \"Restant NET. (2)\"),\n",
    "                (\"Droit de mutation par décès\", \"Valeur des immeubles. (2)\"), \n",
    "                (\"Numéros des déclarations\", \"Primitives.\"),\n",
    "                (\"Numéros des déclarations\", \"Supplémentaires.\"), \n",
    "                (\"Date\", \"de l'expiration du délai de rectification.\"),\n",
    "                (\"Date\", \"de l'exigibilité des droits.\"),\n",
    "                (\"Numéros de la consignation des droits au sommier n' 28\", \" \"),\n",
    "                (\"Recette des droits et amendes.\", \"Date\"),\n",
    "                (\"Recette des droits et amendes.\", \"N^03\"),\n",
    "                (\"Cautionnements. \", \"Numéros de la consignation au sommier n'30\"),\n",
    "                (\"Observations (les déclarations qui figurent à l'état n'413 doivent être émargées en conséquence, dans la présente colonne.)\", \" \")] \n",
    "\n",
    "        Some image (hence, some rows) may start with \"Arrêté le \\d{2} \\w+ \\d{4}( \\w+)? servais\" or contain notes.\n",
    "\n",
    "    Task:\n",
    "        Recognize the text from the image. Pay attention to reading each word and number correctly. Return the text as you read it and you must read the text from the image since the image contains texts.\n",
    "    ```plaintext \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2e72bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_ids = ['1_0', '2_0', '3_0', '4_0', '5_0', '6_0', '7_0', '8_0', '9_0', '10_0',\n",
    "              '11_0', '12_0', '13_0', '14_0', '15_0', '16_0', '17_0', '18_0', '19_0', '20_0']\n",
    "typo_ids = ['4_1', '4_7', '8_2', '8_5', '8_10', '13_9', '16_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a15e1a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18_0', '19_0']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unable_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f7fedafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Start processing file 18_0 -------\n",
      "------- Finished processing file 18_0 in 5.452270030975342 seconds -------\n",
      "------- Start processing file 19_0 -------\n",
      "------- Finished processing file 19_0 in 5.630033016204834 seconds -------\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Load previous progress if available\n",
    "try:\n",
    "    with open('claude_complex_output_progress.json', 'r') as file:\n",
    "        claude_complex_output = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    claude_complex_output = {}\n",
    "\n",
    "# Loop through each unique id\n",
    "# for id in images_encoded['id'].unique():\n",
    "# for id in header_ids+typo_ids:\n",
    "for id in unable_ids:\n",
    "    # Check if this ID is already processed (Skip this step if you want to re-process for unable_ids) ----------------\n",
    "    # if id in claude_complex_output:\n",
    "    #     print(f\"Skipping {id}, already processed.\")\n",
    "    #     continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        print(f'------- Start processing file {id} -------')\n",
    "        \n",
    "        # Call OpenAI/Anthropic and post-processing functions\n",
    "        prompt_complex += \"Even if it is hard to read the texts from the image, return as much as you can. You must read something. Do not return an apologetic message.\"\n",
    "        # output = callOpenAI(prompt=prompt_complex, max_tokens=800, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0])\n",
    "        output = callAnthropic(prompt=prompt_complex, max_tokens=800, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0])\n",
    "        output_cleaned = callPostProcessing(prompt_parameter=output)\n",
    "        \n",
    "        # Save the output\n",
    "        claude_complex_output[id] = output_cleaned\n",
    "        \n",
    "        # Save progress after each file\n",
    "        with open('claude_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_complex_output, file)\n",
    "        \n",
    "        print(f'------- Finished processing file {id} in {time.time() - start_time} seconds -------')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {id}: {str(e)}\")\n",
    "        # Save the progress and exit the loop in case of an error\n",
    "        with open('claude_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_complex_output, file)\n",
    "        break  # Exit the loop on error\n",
    "\n",
    "# Once all IDs are processed, save the final result\n",
    "with open('claude_complex_output_final.json', 'w') as file:\n",
    "    json.dump(claude_complex_output, file)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc31c4e8",
   "metadata": {},
   "source": [
    "### Few-shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "24130132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'/data/transcriptions_perline_cleaned.csv', encoding='utf-8')\n",
    "df.replace({u'\\xa0': ' '}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "95afd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = images_encoded[images_encoded['id'] == '1_1'].encoded.values[0]\n",
    "example2 = images_encoded[images_encoded['id'] == '1_3'].encoded.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c14ff3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_encoded_oneshot = images_encoded[~images_encoded['id'].isin(['1_1'])]\n",
    "images_encoded_twoshot = images_encoded[~images_encoded['id'].isin(['1_1', '1_3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bbaa3fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "example1_text = df[df['id'] == '1_1'].text.values[0]\n",
    "example2_text = df[df['id'] == '1_3'].text.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "998fc479",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_texts =  [example1_text,example2_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7a7b9774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arrêté le vingt huit octobre 1919 servais',\n",
       " '398 trente octobre Herrent Alphones gh Ophain 16 9b 1918 Herrent Maris & autres 2280 1045 1235 11 Db 1919 15 7bre 1919  7 avril 1920 303']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5b683c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_encoded_extexts = images_encoded[~images_encoded['id'].isin(['1_1', '1_3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d04a03ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_example =  \"\"\"\n",
    "#     Recognize the texts from the image like the examples.\n",
    "#     ```plaintext\n",
    "#     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f0bdb0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example1_text or exmple_texts\n",
    "prompt_example_text = f\"\"\"\n",
    "                        The ```plaintext block is the example transcription of the example image you saw:\n",
    "\n",
    "                        Transcription:\n",
    "                        ```plaintext\n",
    "                        {example_texts}\n",
    "                        ```\n",
    "                        Compare what you read initially and the solution key in ```plaintext block. Recreate the content of the table in this image. Only that, no other information from you.\n",
    "\n",
    "                        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "721c10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callOpenAI_example(prompt, NExample=1, base64_image=None, max_tokens=5000):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_API_KEY}\"\n",
    "    } \n",
    "    model_vision = \"gpt-4o\"\n",
    "\n",
    "    if NExample == 1:\n",
    "        payload = {\n",
    "            \"model\": model_vision, \n",
    "            \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "                \n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{example1}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": example1_text\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "                ]\n",
    "            }\n",
    "            ],\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    if NExample == 2:\n",
    "               payload = {\n",
    "            \"model\": model_vision, \n",
    "            \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "                \n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{example1}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": example1_text\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{example2}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": example2_text\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "                ]\n",
    "            }\n",
    "            ],\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    try:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except:\n",
    "        print(response.json()[\"error\"][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "adc4a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callAnthropic_example(prompt, NExample=1, base64_image=None, max_tokens=5000):\n",
    "    if NExample == 1:\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=max_tokens,\n",
    "            system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": example1}},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example1_text,\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt,\n",
    "                        },\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": base64_image}}\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "        \n",
    "    if NExample == 2:\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=max_tokens,\n",
    "            system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": example1}},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example1_text,\n",
    "                        },\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": example2}},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example2_text,\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt,\n",
    "                        },\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": base64_image}}\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "    return response.to_dict()[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "663dc214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>line</th>\n",
       "      <th>encoded</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>/9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>/9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>/9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>/9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>/9j/4QY7RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>/9j/4QY3RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>/9j/4QWhRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>/9j/4QUtRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>/9j/4QX3RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     file  line                                            encoded     id\n",
       "0       1     0  /9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_0\n",
       "2       1     2  /9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_2\n",
       "4       1     4  /9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_4\n",
       "5       1     5  /9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_5\n",
       "6       1     6  /9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_6\n",
       "..    ...   ...                                                ...    ...\n",
       "278    20     9  /9j/4QY7RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...   20_9\n",
       "279    20    10  /9j/4QY3RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...  20_10\n",
       "280    20    11  /9j/4QWhRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...  20_11\n",
       "281    20    12  /9j/4QUtRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...  20_12\n",
       "282    20    13  /9j/4QX3RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...  20_13\n",
       "\n",
       "[281 rows x 4 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_encoded_twoshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "76255ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>line</th>\n",
       "      <th>encoded</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>/9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>/9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>/9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>/9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>/9j/4QY7RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>/9j/4QY3RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>/9j/4QWhRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>/9j/4QUtRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>/9j/4QX3RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     file  line                                            encoded     id\n",
       "0       1     0  /9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_0\n",
       "2       1     2  /9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_2\n",
       "4       1     4  /9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_4\n",
       "5       1     5  /9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_5\n",
       "6       1     6  /9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_6\n",
       "..    ...   ...                                                ...    ...\n",
       "278    20     9  /9j/4QY7RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...   20_9\n",
       "279    20    10  /9j/4QY3RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...  20_10\n",
       "280    20    11  /9j/4QWhRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...  20_11\n",
       "281    20    12  /9j/4QUtRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...  20_12\n",
       "282    20    13  /9j/4QX3RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...  20_13\n",
       "\n",
       "[281 rows x 4 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_encoded_twoshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa07d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Start processing file 1_0 -------\n",
      "------- Finished processing file 1_0 in 12.108368158340454 seconds -------\n",
      "------- Start processing file 1_2 -------\n",
      "------- Finished processing file 1_2 in 3.0430891513824463 seconds -------\n",
      "------- Start processing file 1_4 -------\n",
      "------- Finished processing file 1_4 in 4.388018846511841 seconds -------\n",
      "------- Start processing file 1_5 -------\n",
      "------- Finished processing file 1_5 in 3.7039988040924072 seconds -------\n",
      "------- Start processing file 1_6 -------\n",
      "------- Finished processing file 1_6 in 4.339546203613281 seconds -------\n",
      "------- Start processing file 1_7 -------\n",
      "------- Finished processing file 1_7 in 6.516517162322998 seconds -------\n",
      "------- Start processing file 1_8 -------\n",
      "------- Finished processing file 1_8 in 3.1763272285461426 seconds -------\n",
      "------- Start processing file 1_9 -------\n",
      "------- Finished processing file 1_9 in 4.989033937454224 seconds -------\n",
      "------- Start processing file 1_10 -------\n",
      "------- Finished processing file 1_10 in 3.9149880409240723 seconds -------\n",
      "------- Start processing file 1_11 -------\n",
      "------- Finished processing file 1_11 in 4.095865964889526 seconds -------\n",
      "------- Start processing file 1_12 -------\n",
      "------- Finished processing file 1_12 in 2.973928213119507 seconds -------\n",
      "------- Start processing file 1_13 -------\n",
      "------- Finished processing file 1_13 in 5.121206998825073 seconds -------\n",
      "------- Start processing file 2_0 -------\n",
      "------- Finished processing file 2_0 in 11.36214303970337 seconds -------\n",
      "------- Start processing file 2_1 -------\n",
      "------- Finished processing file 2_1 in 2.874177932739258 seconds -------\n",
      "------- Start processing file 2_2 -------\n",
      "------- Finished processing file 2_2 in 4.600250959396362 seconds -------\n",
      "------- Start processing file 2_3 -------\n",
      "------- Finished processing file 2_3 in 4.610837936401367 seconds -------\n",
      "------- Start processing file 2_4 -------\n",
      "------- Finished processing file 2_4 in 6.6512839794158936 seconds -------\n",
      "------- Start processing file 2_5 -------\n",
      "------- Finished processing file 2_5 in 3.333621025085449 seconds -------\n",
      "------- Start processing file 2_6 -------\n",
      "------- Finished processing file 2_6 in 5.2672929763793945 seconds -------\n",
      "------- Start processing file 2_7 -------\n",
      "------- Finished processing file 2_7 in 4.621170282363892 seconds -------\n",
      "------- Start processing file 2_8 -------\n",
      "------- Finished processing file 2_8 in 4.947443962097168 seconds -------\n",
      "------- Start processing file 2_9 -------\n",
      "------- Finished processing file 2_9 in 3.9507031440734863 seconds -------\n",
      "------- Start processing file 2_10 -------\n",
      "------- Finished processing file 2_10 in 3.481940984725952 seconds -------\n",
      "------- Start processing file 2_11 -------\n",
      "------- Finished processing file 2_11 in 5.119842052459717 seconds -------\n",
      "------- Start processing file 2_12 -------\n",
      "------- Finished processing file 2_12 in 6.351062059402466 seconds -------\n",
      "------- Start processing file 2_13 -------\n",
      "------- Finished processing file 2_13 in 3.16648006439209 seconds -------\n",
      "------- Start processing file 2_14 -------\n"
     ]
    }
   ],
   "source": [
    "# Load previous progress if available\n",
    "try:\n",
    "    with open('gpt_two_example_output_progress.json', 'r') as file:\n",
    "        gpt_two_example_output = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    gpt_two_example_output = {}\n",
    "\n",
    "# Loop through each unique id\n",
    "for id in images_encoded_twoshot['id'].unique():\n",
    "# for id in unable_ids:\n",
    "    # Check if this ID is already processed (Skip this step if you want to re-process for unable_ids) ----------------\n",
    "    if id in gpt_two_example_output:\n",
    "        print(f\"Skipping {id}, already processed.\")\n",
    "        continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        print(f'------- Start processing file {id} -------')\n",
    "        \n",
    "        # Call OpenAI/Anthropic and post-processing functions\n",
    "        prompt_example_text += \"Even if it is hard to read the texts from the image, return as much as you can. You must read something. Do not return an apologetic message.\"\n",
    "        output = callOpenAI_example(prompt=prompt_example_text, NExample=2, base64_image=images_encoded_twoshot[(images_encoded_twoshot['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        # output = callAnthropic_example(prompt=prompt_example_text, NExample=1, base64_image=images_encoded_oneshot[(images_encoded_oneshot['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        output_cleaned = callPostProcessing(prompt_parameter=output)\n",
    "        \n",
    "        # Save the output\n",
    "        gpt_two_example_output[id] = output_cleaned\n",
    "        \n",
    "        # Save progress after each file\n",
    "        with open('gpt_two_example_output_progress.json', 'w') as file:\n",
    "            json.dump(gpt_two_example_output, file)\n",
    "        \n",
    "        print(f'------- Finished processing file {id} in {time.time() - start_time} seconds -------')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {id}: {str(e)}\")\n",
    "        # Save the progress and exit the loop in case of an error\n",
    "        with open('gpt_two_example_output_progress.json', 'w') as file:\n",
    "            json.dump(gpt_two_example_output, file)\n",
    "        break  # Exit the loop on error\n",
    "\n",
    "# Once all IDs are processed, save the final result\n",
    "with open('gpt_two_example_output_final.json', 'w') as file:\n",
    "    json.dump(gpt_two_example_output, file)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a122d9",
   "metadata": {},
   "source": [
    "### Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ab11e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt_simple = pd.read_csv(path+'/results/postprocessed/gpt_perline_output.csv')\n",
    "# claude_simple =  pd.read_csv(path+'/results/postprocessed/claude_perline_output.csv')\n",
    "gpt_complex = pd.read_csv(path+'/results/postprocessed/gpt_complex_perline_output2.csv')\n",
    "claude_complex =  pd.read_csv(path+'/results/postprocessed/claude_complex_perline_output2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "851ef214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 1_0, already processed.\n",
      "Skipping 1_1, already processed.\n",
      "Skipping 1_2, already processed.\n",
      "Skipping 1_3, already processed.\n",
      "Skipping 1_4, already processed.\n",
      "Skipping 1_5, already processed.\n",
      "Skipping 1_6, already processed.\n",
      "Skipping 1_7, already processed.\n",
      "Skipping 1_8, already processed.\n",
      "Skipping 1_9, already processed.\n",
      "Skipping 1_10, already processed.\n",
      "Skipping 1_11, already processed.\n",
      "Skipping 1_12, already processed.\n",
      "Skipping 1_13, already processed.\n",
      "Skipping 2_0, already processed.\n",
      "Skipping 2_1, already processed.\n",
      "Skipping 2_2, already processed.\n",
      "Skipping 2_3, already processed.\n",
      "Skipping 2_4, already processed.\n",
      "Skipping 2_5, already processed.\n",
      "Skipping 2_6, already processed.\n",
      "Skipping 2_7, already processed.\n",
      "Skipping 2_8, already processed.\n",
      "Skipping 2_9, already processed.\n",
      "Skipping 2_10, already processed.\n",
      "Skipping 2_11, already processed.\n",
      "Skipping 2_12, already processed.\n",
      "Skipping 2_13, already processed.\n",
      "Skipping 2_14, already processed.\n",
      "Skipping 3_0, already processed.\n",
      "Skipping 3_1, already processed.\n",
      "Skipping 3_2, already processed.\n",
      "Skipping 3_3, already processed.\n",
      "Skipping 3_4, already processed.\n",
      "Skipping 3_5, already processed.\n",
      "Skipping 3_6, already processed.\n",
      "Skipping 3_7, already processed.\n",
      "Skipping 3_8, already processed.\n",
      "Skipping 3_9, already processed.\n",
      "Skipping 3_10, already processed.\n",
      "Skipping 3_11, already processed.\n",
      "Skipping 3_12, already processed.\n",
      "Skipping 3_13, already processed.\n",
      "Skipping 4_0, already processed.\n",
      "Skipping 4_1, already processed.\n",
      "Skipping 4_2, already processed.\n",
      "Skipping 4_3, already processed.\n",
      "Skipping 4_4, already processed.\n",
      "Skipping 4_5, already processed.\n",
      "Skipping 4_6, already processed.\n",
      "Skipping 4_7, already processed.\n",
      "Skipping 4_8, already processed.\n",
      "Skipping 4_9, already processed.\n",
      "Skipping 4_10, already processed.\n",
      "Skipping 4_11, already processed.\n",
      "Skipping 4_12, already processed.\n",
      "Skipping 4_13, already processed.\n",
      "Skipping 5_0, already processed.\n",
      "Skipping 5_1, already processed.\n",
      "Skipping 5_2, already processed.\n",
      "Skipping 5_3, already processed.\n",
      "Skipping 5_4, already processed.\n",
      "Skipping 5_5, already processed.\n",
      "Skipping 5_6, already processed.\n",
      "Skipping 5_7, already processed.\n",
      "Skipping 5_8, already processed.\n",
      "Skipping 5_9, already processed.\n",
      "Skipping 5_10, already processed.\n",
      "Skipping 5_11, already processed.\n",
      "Skipping 5_12, already processed.\n",
      "Skipping 5_13, already processed.\n",
      "Skipping 5_14, already processed.\n",
      "Skipping 6_0, already processed.\n",
      "Skipping 6_1, already processed.\n",
      "Skipping 6_2, already processed.\n",
      "Skipping 6_3, already processed.\n",
      "Skipping 6_4, already processed.\n",
      "Skipping 6_5, already processed.\n",
      "Skipping 6_6, already processed.\n",
      "Skipping 6_7, already processed.\n",
      "Skipping 6_8, already processed.\n",
      "Skipping 6_9, already processed.\n",
      "Skipping 6_10, already processed.\n",
      "Skipping 6_11, already processed.\n",
      "Skipping 6_12, already processed.\n",
      "Skipping 6_13, already processed.\n",
      "Skipping 6_14, already processed.\n",
      "Skipping 7_0, already processed.\n",
      "Skipping 7_1, already processed.\n",
      "Skipping 7_2, already processed.\n",
      "Skipping 7_3, already processed.\n",
      "Skipping 7_4, already processed.\n",
      "Skipping 7_5, already processed.\n",
      "Skipping 7_6, already processed.\n",
      "Skipping 7_7, already processed.\n",
      "Skipping 7_8, already processed.\n",
      "Skipping 7_9, already processed.\n",
      "Skipping 7_10, already processed.\n",
      "Skipping 7_11, already processed.\n",
      "Skipping 7_12, already processed.\n",
      "Skipping 7_13, already processed.\n",
      "Skipping 8_0, already processed.\n",
      "Skipping 8_1, already processed.\n",
      "Skipping 8_2, already processed.\n",
      "Skipping 8_3, already processed.\n",
      "Skipping 8_4, already processed.\n",
      "Skipping 8_5, already processed.\n",
      "Skipping 8_6, already processed.\n",
      "Skipping 8_7, already processed.\n",
      "Skipping 8_8, already processed.\n",
      "Skipping 8_9, already processed.\n",
      "Skipping 8_10, already processed.\n",
      "Skipping 8_11, already processed.\n",
      "Skipping 8_12, already processed.\n",
      "Skipping 8_13, already processed.\n",
      "Skipping 9_0, already processed.\n",
      "Skipping 9_1, already processed.\n",
      "Skipping 9_2, already processed.\n",
      "Skipping 9_3, already processed.\n",
      "Skipping 9_4, already processed.\n",
      "Skipping 9_5, already processed.\n",
      "Skipping 9_6, already processed.\n",
      "Skipping 9_7, already processed.\n",
      "Skipping 9_8, already processed.\n",
      "Skipping 9_9, already processed.\n",
      "Skipping 9_10, already processed.\n",
      "Skipping 9_11, already processed.\n",
      "Skipping 9_12, already processed.\n",
      "------- Start processing file 9_13 -------\n",
      "------- Finished processing file 9_13 in 4.5187788009643555 seconds -------\n",
      "Skipping 10_0, already processed.\n",
      "------- Start processing file 10_1 -------\n",
      "------- Finished processing file 10_1 in 3.4782819747924805 seconds -------\n",
      "------- Start processing file 10_2 -------\n",
      "------- Finished processing file 10_2 in 4.187901735305786 seconds -------\n",
      "------- Start processing file 10_3 -------\n",
      "------- Finished processing file 10_3 in 6.054029941558838 seconds -------\n",
      "------- Start processing file 10_4 -------\n",
      "------- Finished processing file 10_4 in 5.224471092224121 seconds -------\n",
      "------- Start processing file 10_5 -------\n",
      "------- Finished processing file 10_5 in 3.420477867126465 seconds -------\n",
      "------- Start processing file 10_6 -------\n",
      "------- Finished processing file 10_6 in 4.212242126464844 seconds -------\n",
      "------- Start processing file 10_7 -------\n",
      "------- Finished processing file 10_7 in 4.384124755859375 seconds -------\n",
      "------- Start processing file 10_8 -------\n",
      "------- Finished processing file 10_8 in 3.804175853729248 seconds -------\n",
      "------- Start processing file 10_9 -------\n",
      "------- Finished processing file 10_9 in 3.853947162628174 seconds -------\n",
      "------- Start processing file 10_10 -------\n",
      "------- Finished processing file 10_10 in 4.284922122955322 seconds -------\n",
      "------- Start processing file 10_11 -------\n",
      "------- Finished processing file 10_11 in 4.323278188705444 seconds -------\n",
      "------- Start processing file 10_12 -------\n",
      "------- Finished processing file 10_12 in 4.51911997795105 seconds -------\n",
      "------- Start processing file 10_13 -------\n",
      "------- Finished processing file 10_13 in 3.8604512214660645 seconds -------\n",
      "Skipping 11_0, already processed.\n",
      "------- Start processing file 11_1 -------\n",
      "------- Finished processing file 11_1 in 4.088183879852295 seconds -------\n",
      "------- Start processing file 11_2 -------\n",
      "------- Finished processing file 11_2 in 4.19830584526062 seconds -------\n",
      "------- Start processing file 11_3 -------\n",
      "------- Finished processing file 11_3 in 4.198432207107544 seconds -------\n",
      "------- Start processing file 11_4 -------\n",
      "------- Finished processing file 11_4 in 3.278395891189575 seconds -------\n",
      "------- Start processing file 11_5 -------\n",
      "------- Finished processing file 11_5 in 3.9985132217407227 seconds -------\n",
      "------- Start processing file 11_6 -------\n",
      "------- Finished processing file 11_6 in 3.9869489669799805 seconds -------\n",
      "------- Start processing file 11_7 -------\n",
      "------- Finished processing file 11_7 in 3.685598134994507 seconds -------\n",
      "------- Start processing file 11_8 -------\n",
      "------- Finished processing file 11_8 in 3.3508150577545166 seconds -------\n",
      "------- Start processing file 11_9 -------\n",
      "------- Finished processing file 11_9 in 4.879892826080322 seconds -------\n",
      "------- Start processing file 11_10 -------\n",
      "------- Finished processing file 11_10 in 3.990602970123291 seconds -------\n",
      "------- Start processing file 11_11 -------\n",
      "------- Finished processing file 11_11 in 3.957642078399658 seconds -------\n",
      "------- Start processing file 11_12 -------\n",
      "------- Finished processing file 11_12 in 5.119674205780029 seconds -------\n",
      "------- Start processing file 11_13 -------\n",
      "------- Finished processing file 11_13 in 4.096029996871948 seconds -------\n",
      "Skipping 12_0, already processed.\n",
      "------- Start processing file 12_1 -------\n",
      "------- Finished processing file 12_1 in 4.402475833892822 seconds -------\n",
      "------- Start processing file 12_2 -------\n",
      "------- Finished processing file 12_2 in 4.609771966934204 seconds -------\n",
      "------- Start processing file 12_3 -------\n",
      "------- Finished processing file 12_3 in 3.891646146774292 seconds -------\n",
      "------- Start processing file 12_4 -------\n",
      "------- Finished processing file 12_4 in 18.46848487854004 seconds -------\n",
      "------- Start processing file 12_5 -------\n",
      "------- Finished processing file 12_5 in 3.943117141723633 seconds -------\n",
      "------- Start processing file 12_6 -------\n",
      "------- Finished processing file 12_6 in 5.168059825897217 seconds -------\n",
      "------- Start processing file 12_7 -------\n",
      "------- Finished processing file 12_7 in 4.876936912536621 seconds -------\n",
      "------- Start processing file 12_8 -------\n",
      "------- Finished processing file 12_8 in 5.221391916275024 seconds -------\n",
      "------- Start processing file 12_9 -------\n",
      "------- Finished processing file 12_9 in 4.9164769649505615 seconds -------\n",
      "------- Start processing file 12_10 -------\n",
      "------- Finished processing file 12_10 in 4.131852865219116 seconds -------\n",
      "------- Start processing file 12_11 -------\n",
      "------- Finished processing file 12_11 in 5.11723518371582 seconds -------\n",
      "------- Start processing file 12_12 -------\n",
      "------- Finished processing file 12_12 in 4.471143960952759 seconds -------\n",
      "------- Start processing file 12_13 -------\n",
      "------- Finished processing file 12_13 in 5.017827987670898 seconds -------\n",
      "Skipping 13_0, already processed.\n",
      "------- Start processing file 13_1 -------\n",
      "------- Finished processing file 13_1 in 4.812385082244873 seconds -------\n",
      "------- Start processing file 13_2 -------\n",
      "------- Finished processing file 13_2 in 4.9164369106292725 seconds -------\n",
      "------- Start processing file 13_3 -------\n",
      "------- Finished processing file 13_3 in 4.373955249786377 seconds -------\n",
      "------- Start processing file 13_4 -------\n",
      "------- Finished processing file 13_4 in 3.6131551265716553 seconds -------\n",
      "------- Start processing file 13_5 -------\n",
      "------- Finished processing file 13_5 in 5.426492929458618 seconds -------\n",
      "------- Start processing file 13_6 -------\n",
      "------- Finished processing file 13_6 in 4.298884153366089 seconds -------\n",
      "------- Start processing file 13_7 -------\n",
      "------- Finished processing file 13_7 in 3.994813919067383 seconds -------\n",
      "------- Start processing file 13_8 -------\n",
      "------- Finished processing file 13_8 in 4.371685743331909 seconds -------\n",
      "Skipping 13_9, already processed.\n",
      "------- Start processing file 13_10 -------\n",
      "------- Finished processing file 13_10 in 6.788352012634277 seconds -------\n",
      "------- Start processing file 13_11 -------\n",
      "------- Finished processing file 13_11 in 4.6079630851745605 seconds -------\n",
      "------- Start processing file 13_12 -------\n",
      "------- Finished processing file 13_12 in 5.328459978103638 seconds -------\n",
      "------- Start processing file 13_13 -------\n",
      "------- Finished processing file 13_13 in 5.234277248382568 seconds -------\n",
      "Skipping 14_0, already processed.\n",
      "------- Start processing file 14_1 -------\n",
      "------- Finished processing file 14_1 in 3.668360948562622 seconds -------\n",
      "------- Start processing file 14_2 -------\n",
      "------- Finished processing file 14_2 in 5.249000072479248 seconds -------\n",
      "------- Start processing file 14_3 -------\n",
      "------- Finished processing file 14_3 in 4.277847051620483 seconds -------\n",
      "------- Start processing file 14_4 -------\n",
      "------- Finished processing file 14_4 in 4.159616708755493 seconds -------\n",
      "------- Start processing file 14_5 -------\n",
      "------- Finished processing file 14_5 in 4.235310792922974 seconds -------\n",
      "------- Start processing file 14_6 -------\n",
      "------- Finished processing file 14_6 in 4.503371953964233 seconds -------\n",
      "------- Start processing file 14_7 -------\n",
      "------- Finished processing file 14_7 in 5.020073890686035 seconds -------\n",
      "------- Start processing file 14_8 -------\n",
      "------- Finished processing file 14_8 in 4.579561948776245 seconds -------\n",
      "------- Start processing file 14_9 -------\n",
      "------- Finished processing file 14_9 in 4.73679780960083 seconds -------\n",
      "------- Start processing file 14_10 -------\n",
      "------- Finished processing file 14_10 in 3.689643144607544 seconds -------\n",
      "------- Start processing file 14_11 -------\n",
      "------- Finished processing file 14_11 in 6.857661008834839 seconds -------\n",
      "------- Start processing file 14_12 -------\n",
      "------- Finished processing file 14_12 in 3.8901748657226562 seconds -------\n",
      "------- Start processing file 14_13 -------\n",
      "------- Finished processing file 14_13 in 6.7566609382629395 seconds -------\n",
      "Skipping 15_0, already processed.\n",
      "------- Start processing file 15_1 -------\n",
      "------- Finished processing file 15_1 in 5.2317633628845215 seconds -------\n",
      "------- Start processing file 15_2 -------\n",
      "------- Finished processing file 15_2 in 4.5568459033966064 seconds -------\n",
      "------- Start processing file 15_3 -------\n",
      "------- Finished processing file 15_3 in 4.345600843429565 seconds -------\n",
      "------- Start processing file 15_4 -------\n",
      "------- Finished processing file 15_4 in 3.9988598823547363 seconds -------\n",
      "------- Start processing file 15_5 -------\n",
      "------- Finished processing file 15_5 in 4.047779083251953 seconds -------\n",
      "------- Start processing file 15_6 -------\n",
      "------- Finished processing file 15_6 in 4.086607933044434 seconds -------\n",
      "------- Start processing file 15_7 -------\n",
      "------- Finished processing file 15_7 in 3.982541084289551 seconds -------\n",
      "------- Start processing file 15_8 -------\n",
      "------- Finished processing file 15_8 in 4.568011999130249 seconds -------\n",
      "------- Start processing file 15_9 -------\n",
      "------- Finished processing file 15_9 in 4.295407056808472 seconds -------\n",
      "------- Start processing file 15_10 -------\n",
      "------- Finished processing file 15_10 in 3.191497325897217 seconds -------\n",
      "------- Start processing file 15_11 -------\n",
      "------- Finished processing file 15_11 in 2.9559600353240967 seconds -------\n",
      "------- Start processing file 15_12 -------\n",
      "------- Finished processing file 15_12 in 3.993644952774048 seconds -------\n",
      "------- Start processing file 15_13 -------\n",
      "------- Finished processing file 15_13 in 4.300524950027466 seconds -------\n",
      "Skipping 16_0, already processed.\n",
      "------- Start processing file 16_1 -------\n",
      "------- Finished processing file 16_1 in 4.096444845199585 seconds -------\n",
      "Skipping 16_2, already processed.\n",
      "------- Start processing file 16_3 -------\n",
      "------- Finished processing file 16_3 in 4.664058208465576 seconds -------\n",
      "------- Start processing file 16_4 -------\n",
      "------- Finished processing file 16_4 in 3.7609620094299316 seconds -------\n",
      "------- Start processing file 16_5 -------\n",
      "------- Finished processing file 16_5 in 3.749936103820801 seconds -------\n",
      "------- Start processing file 16_6 -------\n",
      "------- Finished processing file 16_6 in 4.072468996047974 seconds -------\n",
      "------- Start processing file 16_7 -------\n",
      "------- Finished processing file 16_7 in 3.309048652648926 seconds -------\n",
      "------- Start processing file 16_8 -------\n",
      "------- Finished processing file 16_8 in 5.734472036361694 seconds -------\n",
      "------- Start processing file 16_9 -------\n",
      "------- Finished processing file 16_9 in 4.7066709995269775 seconds -------\n",
      "------- Start processing file 16_10 -------\n",
      "------- Finished processing file 16_10 in 3.9973392486572266 seconds -------\n",
      "------- Start processing file 16_11 -------\n",
      "------- Finished processing file 16_11 in 4.403064012527466 seconds -------\n",
      "------- Start processing file 16_12 -------\n",
      "------- Finished processing file 16_12 in 5.882168769836426 seconds -------\n",
      "------- Start processing file 16_13 -------\n",
      "------- Finished processing file 16_13 in 4.460268020629883 seconds -------\n",
      "Skipping 17_0, already processed.\n",
      "------- Start processing file 17_1 -------\n",
      "------- Finished processing file 17_1 in 3.788515090942383 seconds -------\n",
      "------- Start processing file 17_2 -------\n",
      "------- Finished processing file 17_2 in 5.016230821609497 seconds -------\n",
      "------- Start processing file 17_3 -------\n",
      "------- Finished processing file 17_3 in 4.501795053482056 seconds -------\n",
      "------- Start processing file 17_4 -------\n",
      "------- Finished processing file 17_4 in 4.879002809524536 seconds -------\n",
      "------- Start processing file 17_5 -------\n",
      "------- Finished processing file 17_5 in 4.507422924041748 seconds -------\n",
      "------- Start processing file 17_6 -------\n",
      "------- Finished processing file 17_6 in 3.7890050411224365 seconds -------\n",
      "------- Start processing file 17_7 -------\n",
      "------- Finished processing file 17_7 in 4.812199115753174 seconds -------\n",
      "------- Start processing file 17_8 -------\n",
      "------- Finished processing file 17_8 in 6.040272951126099 seconds -------\n",
      "------- Start processing file 17_9 -------\n",
      "------- Finished processing file 17_9 in 4.709277153015137 seconds -------\n",
      "------- Start processing file 17_10 -------\n",
      "------- Finished processing file 17_10 in 4.711926221847534 seconds -------\n",
      "------- Start processing file 17_11 -------\n",
      "------- Finished processing file 17_11 in 3.572464942932129 seconds -------\n",
      "------- Start processing file 17_12 -------\n",
      "------- Finished processing file 17_12 in 4.51676607131958 seconds -------\n",
      "------- Start processing file 17_13 -------\n",
      "------- Finished processing file 17_13 in 3.887263059616089 seconds -------\n",
      "Skipping 18_0, already processed.\n",
      "------- Start processing file 18_1 -------\n",
      "------- Finished processing file 18_1 in 4.200323820114136 seconds -------\n",
      "------- Start processing file 18_2 -------\n",
      "------- Finished processing file 18_2 in 4.19882607460022 seconds -------\n",
      "------- Start processing file 18_3 -------\n",
      "------- Finished processing file 18_3 in 3.582446813583374 seconds -------\n",
      "------- Start processing file 18_4 -------\n",
      "------- Finished processing file 18_4 in 5.434032201766968 seconds -------\n",
      "------- Start processing file 18_5 -------\n",
      "------- Finished processing file 18_5 in 4.088507890701294 seconds -------\n",
      "------- Start processing file 18_6 -------\n",
      "------- Finished processing file 18_6 in 6.554315090179443 seconds -------\n",
      "------- Start processing file 18_7 -------\n",
      "------- Finished processing file 18_7 in 4.909409999847412 seconds -------\n",
      "------- Start processing file 18_8 -------\n",
      "------- Finished processing file 18_8 in 4.921012878417969 seconds -------\n",
      "------- Start processing file 18_9 -------\n",
      "------- Finished processing file 18_9 in 3.66916823387146 seconds -------\n",
      "------- Start processing file 18_10 -------\n",
      "------- Finished processing file 18_10 in 6.374696969985962 seconds -------\n",
      "------- Start processing file 18_11 -------\n",
      "------- Finished processing file 18_11 in 5.325391054153442 seconds -------\n",
      "------- Start processing file 18_12 -------\n",
      "------- Finished processing file 18_12 in 6.554369688034058 seconds -------\n",
      "------- Start processing file 18_13 -------\n",
      "------- Finished processing file 18_13 in 4.603408098220825 seconds -------\n",
      "Skipping 19_0, already processed.\n",
      "------- Start processing file 19_1 -------\n",
      "------- Finished processing file 19_1 in 4.633074998855591 seconds -------\n",
      "------- Start processing file 19_2 -------\n",
      "------- Finished processing file 19_2 in 3.1455390453338623 seconds -------\n",
      "------- Start processing file 19_3 -------\n",
      "------- Finished processing file 19_3 in 5.219139099121094 seconds -------\n",
      "------- Start processing file 19_4 -------\n",
      "------- Finished processing file 19_4 in 3.70662784576416 seconds -------\n",
      "------- Start processing file 19_5 -------\n",
      "------- Finished processing file 19_5 in 4.691181182861328 seconds -------\n",
      "------- Start processing file 19_6 -------\n",
      "------- Finished processing file 19_6 in 4.814079999923706 seconds -------\n",
      "------- Start processing file 19_7 -------\n",
      "------- Finished processing file 19_7 in 4.082614898681641 seconds -------\n",
      "------- Start processing file 19_8 -------\n",
      "------- Finished processing file 19_8 in 3.800102949142456 seconds -------\n",
      "------- Start processing file 19_9 -------\n",
      "------- Finished processing file 19_9 in 3.298182249069214 seconds -------\n",
      "------- Start processing file 19_10 -------\n",
      "------- Finished processing file 19_10 in 3.9988508224487305 seconds -------\n",
      "------- Start processing file 19_11 -------\n",
      "------- Finished processing file 19_11 in 4.682307243347168 seconds -------\n",
      "------- Start processing file 19_12 -------\n",
      "------- Finished processing file 19_12 in 6.988734006881714 seconds -------\n",
      "------- Start processing file 19_13 -------\n",
      "------- Finished processing file 19_13 in 5.811883211135864 seconds -------\n",
      "Skipping 20_0, already processed.\n",
      "------- Start processing file 20_1 -------\n",
      "------- Finished processing file 20_1 in 4.505818128585815 seconds -------\n",
      "------- Start processing file 20_2 -------\n",
      "------- Finished processing file 20_2 in 3.7904858589172363 seconds -------\n",
      "------- Start processing file 20_3 -------\n",
      "------- Finished processing file 20_3 in 4.50445294380188 seconds -------\n",
      "------- Start processing file 20_4 -------\n",
      "------- Finished processing file 20_4 in 4.909791946411133 seconds -------\n",
      "------- Start processing file 20_5 -------\n",
      "------- Finished processing file 20_5 in 4.304340839385986 seconds -------\n",
      "------- Start processing file 20_6 -------\n",
      "------- Finished processing file 20_6 in 4.937065124511719 seconds -------\n",
      "------- Start processing file 20_7 -------\n",
      "------- Finished processing file 20_7 in 3.884999990463257 seconds -------\n",
      "------- Start processing file 20_8 -------\n",
      "------- Finished processing file 20_8 in 3.7735650539398193 seconds -------\n",
      "------- Start processing file 20_9 -------\n",
      "------- Finished processing file 20_9 in 5.033324956893921 seconds -------\n",
      "------- Start processing file 20_10 -------\n",
      "------- Finished processing file 20_10 in 4.377002954483032 seconds -------\n",
      "------- Start processing file 20_11 -------\n",
      "------- Finished processing file 20_11 in 4.514448165893555 seconds -------\n",
      "------- Start processing file 20_12 -------\n",
      "------- Finished processing file 20_12 in 4.916759014129639 seconds -------\n",
      "------- Start processing file 20_13 -------\n",
      "------- Finished processing file 20_13 in 5.5274670124053955 seconds -------\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Load previous progress if available\n",
    "try:\n",
    "    with open('claude_refine_complex_output_progress.json', 'r') as file:\n",
    "        claude_refine_complex_output = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    claude_refine_complex_output = {}\n",
    "\n",
    "# Loop through each unique id\n",
    "for id in images_encoded['id'].unique():\n",
    "# for id in header_ids+typo_ids:\n",
    "# for id in unable_ids:\n",
    "    # Check if this ID is already processed (Skip this step if you want to re-process for unable_ids) ----------------\n",
    "    if id in claude_refine_complex_output:\n",
    "        print(f\"Skipping {id}, already processed.\")\n",
    "        continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        print(f'------- Start processing file {id} -------')\n",
    "        \n",
    "        # Call OpenAI/Anthropic and post-processing functions\n",
    "        response_text = claude_complex[claude_complex['id'] == id].text.values[0]\n",
    "        prompt_refine = f\"\"\"\n",
    "        \n",
    "        Your first draft:\n",
    "        ```plaintext\n",
    "        {response_text}\n",
    "        ```\n",
    "\n",
    "        Errors: \n",
    "        Your first transcription you made in ```plaintext block contains some errors.\n",
    "        \n",
    "        Task:\n",
    "        Refine your first trasncription in ```plaintext block. \n",
    "        Make sure to read the names of the people and the location as well as the dates and the numbers correctly.\n",
    "        Transcribe as you see in the image.\n",
    "        ```plaintext\n",
    "        \"\"\"\n",
    "\n",
    "        prompt_refine += \"Even if it is hard to read the texts from the image, return as much as you can. You must read something. Do not return an apologetic message.\"\n",
    "        # output = callOpenAI(prompt=prompt_refine, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        output = callAnthropic(prompt=prompt_refine, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        output_cleaned = callPostProcessing(prompt_parameter=output)\n",
    "        \n",
    "        # Save the output\n",
    "        claude_refine_complex_output[id] = output_cleaned\n",
    "        \n",
    "        # Save progress after each file\n",
    "        with open('claude_refine_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_refine_complex_output, file)\n",
    "        \n",
    "        print(f'------- Finished processing file {id} in {time.time() - start_time} seconds -------')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {id}: {str(e)}\")\n",
    "        # Save the progress and exit the loop in case of an error\n",
    "        with open('claude_refine_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_refine_complex_output, file)\n",
    "        break  # Exit the loop on error\n",
    "\n",
    "# Once all IDs are processed, save the final result\n",
    "with open('claude_refine_complex_output_final.json', 'w') as file:\n",
    "    json.dump(claude_refine_complex_output, file)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b34c7",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "683579cb-2bae-4a69-8271-ce4e67519e52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1_0': 'N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES, OU ABSENTES. DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT DE MUTATION NUMÉROS DATE NUMÉROS OBSERVATIONS. d’ordre des NOMS. PRÉNOMS DOMICILES ou du et de des de la DÉCLARATIONS. JUGEMENT D’ENVOI DEMEURES DES PARTIES DÉCLARANTES. MUTATION EN LIGNE DIRECTE. par décès. DÉCLARATIONS en possession, ACTIF. PASSIF. RESTANT NET. VALEUR des IMMEUBLES. des de l’expiration de la consignation des DROITS ET AMENDES. CAUTIONNEMENTS. de la consignation en cas d’absence. (2) (2) (2) (2) DÉCLARATIONS de l’exigibilité des droits DATE N° au sommaire n° 25. au sommaire n° 30.',\n",
       " '1_3': '398 trente octobre Herrent Alphonse fils Oplinter 29 7bre 1919 Heverlee Louis et autres 2230 504 225 11 7bre 1919 Hasselt 363',\n",
       " '1_4': \"398 bis 2 Lesévre Jules Braîne-l'Alleud 5 janvier 1919 Brodis Thérèse 2222 2222 236 1919\",\n",
       " '1_5': 'Arrêté le trente octobre 1919 Servais',\n",
       " '1_6': 'Arrêté le trente un octobre 1919 Servais',\n",
       " '1_7': 'Arrêté le premier novembre 1919 Toussaint Servais',\n",
       " '1_8': 'Arrêté le deux novembre 1919 Dimanche servais',\n",
       " '1_9': '399 trente octobre Desmedt Jeanne Nivelles 13 mai 1919 Willebeke Elise autres 9180 530 8910 15 7bre 1919 13 7bre 1919 10 février 1920 5',\n",
       " '1_10': '400 5 novembre Monseu Raoul Oscar 1 8bre 1918 Monseur Arthur 6990 2147 4843 15 7bre 1919 7 avril 1919',\n",
       " '1_11': \"401 3 Bouly Henri Marie l'abbaye 26 février 1919 Bouly Marie & Félix 2240 2046 15 2bre 1919 non taxables\",\n",
       " '1_12': 'Arrêté le trois novembre 1919 servais',\n",
       " '1_13': '407 quatre qté Godart Renaulde Pauline veuve 12 mai 1919 Charon Gustave 14137 7437 33 2/11 1920 16 8bre 1919 24',\n",
       " '2_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT DE MUTATION NUMÉROS DATE OBSERVATIONS. d'ordre. des NOMS. PRÉNOMS. ou du et par décès. des de DÉCLARATIONS. DOMICILES. JUGEMENT D'ENVOI DEMEURES DES PARTIES DÉCLARANTES. en LIGNE COLLÉTÉRALE VALEUR DÉCLARATIONS l'expiration en possession, et de des du délai en cas d'absence. MUTATION EN LIGNE DIRECTE. DÉCLARATIONS de rectification ACTIF. PASSIF. RESTANT NET. des des droits DÉCLARATIONS au supplétives sommiers ou n° 28 explicatives\",\n",
       " '2_1': '1919',\n",
       " '2_2': '403 quatre 9bre Payot Andrinette Louis 4 mars 1919 Payot Henri & autres 16948 5233 11740 2350 16 8bre 1919 16 mars 1920',\n",
       " '2_3': '403 2e 30 Paulus Abelanie Nivelles 15 janvier 1919 Paulus François 2941 2921 1911919 4 10 Db 1919',\n",
       " '2_4': '404 5 Vandermens Abauit Anna Chaberg 4 avril 1918 Bresske Brouwer 500 500 16 8bre 1918 non passible',\n",
       " '2_5': 'Arrêté le quatre novembre 1919 Servais',\n",
       " '2_6': '405 cinq 9bre Lemoine Pierre Gh Ittre 24 8bre 1918 Lemoine Juliette & autres 2885 1885 16 9bre 1919 non payables',\n",
       " '2_7': '406 Monnaye Julie Alosteen 16 9bre 1911 Monnaye Aimé & autres',\n",
       " '2_8': '407 5 de Godeau née Painblanc Clément Origenweg 7 8b 1919 Godeau Hoorens & autres 800 800 7e Db 1919 7 avril 1920 non formelle',\n",
       " '2_9': 'Arrêté le cinq novembre 1919 Servais',\n",
       " '2_10': 'Arrêté le six novembre 1919 Servais',\n",
       " '2_11': '408 sept 9bre Fontaine Florent Hulpe 29 octobre 1924 Boonmans Armande 378 226 202 19 8bre 1919 non familite',\n",
       " '2_12': '409 trente octobre Allard Prosper Nivelles 14 avril 1919 Allard Elvire 4340 4240 19 7bre 1919 15 mars 1920 54',\n",
       " '2_13': 'Arrêté le sept novembre 1919 servais',\n",
       " '2_14': '410 huit 9bre Deloutte Julien Waterloo de mariage Debelle Edouard Jules 14457 369 12088 20 8bre 1920 13 fevrier 1921',\n",
       " '3_0': \"```\\n['N°', 'DATE DU DÉPÔT', 'DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES.', 'DATE DU DÉCÈS', 'NOMS, PRÉNOMS', 'DROITS DE SUCCESSION', 'DROIT', 'NUMÉROS', 'DATE', 'OBSERVATIONS.']\\n['', 'des', 'NOMS.', 'PRÉNOMS.', 'DOMICILES.', 'ou du', 'et', 'DE MUTATION', 'des', '']\\n['', 'DÉCLARATIONS.', '', '', '', 'JUGEMENT D’ENVOI', '', 'par décès.', 'DÉCLARATIONS', '']\\n['', '', '', '', '', 'en possession,', '', 'VALEUR', 'applicateur', '']\\n['', '', '', '', '', 'en cas d’absence.', '', 'des', 'du délai', '']\\n['', '', '', '', '', '', '', 'IMMEUBLES.', 'de rectification', '']\\n['', '', '', '', '', '', '', '', 'de l’exigibilité', '']\\n['', '', '', '', '', '', '', '', 'des droits.', '']\\n```\",\n",
       " '3_1': '411 huit 9bre 1919 Kutteler Henri Waterloo 28 8bre 1919 Lepine Elisa 3 9bre 1919 878 20 8bre 1919 20 juillet 1920 non pénible',\n",
       " '3_2': \"412 Chabreau Marie née L'Abus 6 8bre 1919 Capelle Antoinette & autres 4662 48692 20 6 avril 1918 19 8bre 1919 203 204 207 209 229\",\n",
       " '3_3': '412 1/2 Reyners Louis Ophain 4 avril 1918 Gills André 2406 1766 258 1918 15 mars 1920 299',\n",
       " '3_4': 'Arrêté le huit novembre 1919 Servais',\n",
       " '3_5': 'Arrêté le neuf novembre 1919 Dimanche Servais',\n",
       " '3_6': '413 dix 9bre 1919 Mathieu Emérance 11 mai 1919 Bourguignon Léopold 16934 16934 22 8bre 1919 21 mars 1920',\n",
       " '3_7': '414 30 Laminiau Adeline Bruin Albert 2 juillet 1919 Delfosse Laure & autres 2291 2291 18 mars 1920 9 3 mai 1920 12 5 1920 98 100',\n",
       " '3_8': '415 2 Dubois Amantine Alleur 6 juin 1919 Silvère Jeanne 1 autre 500 356 144 22 8 6 avril 1920 non familials',\n",
       " '3_9': 'Arrêté le dix novembre 1919 servais',\n",
       " '3_10': 'H16 mes 9bre Heuwels Emmanuel Nivelles 16 mai 1919 Delfosse Louis 7581 566 6995 25 8bre 1919 18 8bre 1919',\n",
       " '3_11': '117 2 Basigant Marie 14 2 Arquetta Eugénie 3746 1746 2242 28 2 5 mars 1918 62',\n",
       " '3_12': '417 2 Campinaire Elie Benoit-Callix Alphonse 27 mars 1919 Gellis Eugenie 22285 12350 361 494',\n",
       " '3_13': 'Arrêté le onze novembre 1919 servais',\n",
       " '4_0': '398 trente octobre Herrent Alphones gh Ophain 16 9b 1918 Herrent Maris & autres 2280 1045 1235 11 Db 1919 15 7bre 1919 7 avril 1920 303',\n",
       " '4_1': 'Arrêté le douze novembre 1919 servais',\n",
       " '4_2': '418 treize 9bre Cloquet Célestine veuve Luthier mère 28 mai 1919 Servais Alix 1500 400 29 8bre 1919 15 mai 1920 55',\n",
       " '4_3': '419 Vincent Vicaire Elvire 3 avril 1919 Brigeck Emile & autres 26600 26600 29 3 juin 1919 3 mars 1919 26 300',\n",
       " '4_4': 'Arrêté le treize novembre 1919 Servais',\n",
       " '4_5': 'Arrêté le quatre novembre 1919 Servais',\n",
       " '4_6': '420 quinze octobre Boisdenghien Louis Ghislenghien 17 mai 1919 De Bois Martin autres 1738 1238 441 24 9bre 1919 1 avril 1920 44',\n",
       " '4_7': '420 30 Lambotte Ernest Waterloo 4 février 1918 Lambotte Émile 258 1918',\n",
       " '4_8': 'Arrêté le quinze novembre 1919 Servais',\n",
       " '4_9': 'Arrêté le seize novembre 1919 Dimanche Servais',\n",
       " '4_10': 'Arrêté le dix sept novembre 1919 servais',\n",
       " '4_11': '420 3e avril Rousseau Charles Gh Nivelles 31 mars 1919 Rousseau Henri 24800 23800 110 1919',\n",
       " '4_12': '421 5 Lejeune Henri Alphonse 20 avril 1918 Lejeune Henri Arabe 3922 210 3712 30 8bre 1918 15 avril 1920 304',\n",
       " '4_13': 'Arrêté le dix huit novembre 1919 servais',\n",
       " '5_0': '398 trente octobre Herrent Alphones gh Ophain 16 9b 1918 Herrent Maris & autres 2280 1045 1235 11 Db 1919 15 7bre 1919 7 avril 1920 303',\n",
       " '5_1': '1919',\n",
       " '5_2': '451 trente neuf novembre Kleemans Charles 27 avril 1918 Peeters Célestine 5455 247 5486 39 1919 22 Db 1919 10 janvier 1920 332',\n",
       " '5_3': '4213 2 Duvig Dieudonné Louis & Jeanne 4 janvier 1918 Duvig Louis & autres 500 500 11 8bre 1919 1 avril 1920 341',\n",
       " '5_4': '421 1er Piekersons Pierre Gh Ami Waterloo 4 février 1918 Aves Geneviève & autres 21/1919',\n",
       " '5_5': '422 1er Pietershons Léon Syn 26 7bre 1919 266 223 121 31 8bre 26 mars 1920 non fumible',\n",
       " '5_6': 'Arrêté le vingt huit octobre 1919 servais 398 trente octobre Herrent Alphones gh Ophain 16 9b 1918 Herrent Maris & autres 2280 1045 1235 11 Db 1919 15 7bre 1919 7 avril 1920 303 423 1 Desaegher Marie Louise Rebecq 26 mai 1919 Blanstrieu Vital 4875 2815 26 2 17 mars 1920 60',\n",
       " '5_7': 'Arrêté le dix neuf novembre 1919 Servais',\n",
       " '5_8': '424 vingt qbe Hautier Firmin Nivelles 23 juillet 1919 Desus Juliette autres 86181 86181 7 7bre 1920 23 mars 1920 16 avril 1920 33',\n",
       " '5_9': '425 D Delaître Elize Marie 26 mai 1919 Souffle Jean Bte & autres 1500 750 750 1 D. 12 7bre 420 nm famille',\n",
       " '5_10': 'Arrêté le vingt novembre 1919 Servais',\n",
       " '5_11': '425 vingt un 9bre Piercot Julien Waterloo 6 février 1919 Fonykberdins Anatolie Declon zeil Justin 213 194',\n",
       " '5_12': '426 1er Tontignies Alz Feluy 26 juin 1919 Bartholomé Edouard autres 2361 2661 1er 2e 7 avril 1920 10 avril 1920 36',\n",
       " '5_13': '447 d Moens Joseph Colazi 28 juillet 1919 Evange Elvie autres 1548 476 1 d 25 mai 1920 rent famille',\n",
       " '5_14': '418 5 Semal Henri Nivelles 16 juin 1921 Gurnet Adéla autres 4000 4000 33 4 1920 12 avril 1920 29',\n",
       " '6_0': 'Arrêté le vingt huit octobre 1919 servais 398 trente octobre Herrent Alphones gh Ophain 16 9b 1918 Herrent Maris & autres 2280 1045 1235 11 Db 1919 15 7bre 1919 7 avril 1920 303',\n",
       " '6_1': '494',\n",
       " '6_2': \"150 vingt quatre juin Lambert Valentin Nivelles 16 mars 1921 Gpes d'Oisquies autres 7810 1267 26 x 19 16 mars 1921\",\n",
       " '6_3': '151 2 Leveau Adolphine Clabecq 3 mai 1919 Vanpéé Ernest & autres 6540 4840 7 8bre 1919 16-2 19',\n",
       " '6_4': '152 5 Vanpee Félicie 29 8bre 1918 4755 985 3770 non frustille',\n",
       " '6_5': '153 2 Delabij Joachim Joseph exécuteur Alphonse 1920 Jeanmin Antoine Henri 2290 986 1304 nm faisible',\n",
       " '6_6': 'Arrêté le vingt quatre juin 1921 Servais',\n",
       " '6_7': '153½ vingt cinq juin Charlier Hoetersse Nivelles 8 avril 1920 Haut Jules & Léon 821 180 1920',\n",
       " '6_8': 'Arrêté le vingt et un juin 1921 Servais',\n",
       " '6_9': 'Arrêté le vingt six juin 1921 Dimanche Servais',\n",
       " '6_10': '154 vingt sept Froment Georges Nivelles 28 8bre 1921 Van Damme Juliette 150475 1369 149106 31 3bre 1921 9 janvier 1922 289',\n",
       " '6_11': '155 5 Devreux Jean Ste Breveté de Chatean 29 janvier 1920 Devreux Henriette & autres 2469 2469 non prescrit',\n",
       " '6_12': '156 Seolas Jean Joseph Cloutier Assine 6 féb 1920 Seolas Jules Joh autres 2481 2481 id',\n",
       " '6_13': 'Arrêté le vingt sept juin 1921 Servais',\n",
       " '6_14': '158 vingt huit 8 Delalque Alacia Louise Brime Octobre 29 8bre 1920 Delalque Adélaïde 1484 326 1219 19 19 8bre 1920',\n",
       " '7_0': \"DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT DE MUTATION NUMÉROS DATE RECETTE OBSERVATIONS N° NOMS PRÉNOMS DOMICILES ou du JUGEMENT D'ENVOI ET EN LIGNE COLLATÉRALE en ligne directe des de des DROITS ET AMENDES d'ordre en possession DEMEURES DES PARTIES DÉCLARANTES et VALEUR DÉCLARATIONS l'exigibilité DATE des en cas d'absence MUTATION EN LIGNE DIRECTE des IMMEUBLES primitives des droits N° DÉCLARATIONS ACTIF PASSIF RESTANT NET supplémentaires (1) (2) (3) (2)\",\n",
       " '7_1': 'Arrêté le dix juin 1921 servais',\n",
       " '7_2': '145 trente juin Linex Charles Léopold 16 9b 1920 Van Acker Julienne autres 5245 1613 3632 18 9bre 1921 16 7bre 1921',\n",
       " '7_3': 'Arrêté le dix sept juin 1921 Servais',\n",
       " '7_4': '346 dix huit juin Masson Jean Bt Baulers 19 9bre 1920 Rose Eloise 12905 814 12020 27 11 1919 14',\n",
       " '7_5': 'Arrêté le dix neuf juin 1920 servais',\n",
       " '7_6': 'Arrêté le dix neuf juin 1920 Dimanche servais',\n",
       " '7_7': 'Arrêté le vingt juin servais',\n",
       " '7_8': 'Arrêté le vingt huit octobre 1919 servais 398 trente octobre Herrent Alphones gh Ophain 16 9b 1918 Herrent Maris & autres 2280 1045 1235 11 Db 1919 15 7bre 1919 7 avril 1920 303 445 vingt et un juin Leblicq Jeven Alx Ottomont 13 mars 1920 Leblicq Henri Thérèse & autres 1960 826 1634 non familier',\n",
       " '7_9': 'Arrêté le vingt un juin 1921 servais',\n",
       " '7_10': 'Arrêté le vingt deux juin 1921 Servais',\n",
       " '7_11': 'Arrêté le vingt trois juin 1923 servais',\n",
       " '7_12': '148 vingt quatre Basset Emmanuel Joseph 1920 Gérin Emilie & autres 4945 1333 1612 160 5 1920 4 janvier 1922 286',\n",
       " '7_13': '149 2e Kegelart Laurent gh Regine dcd le 25 mai 1918 Hagard Elisabeth & autres 8326 288 3911 non fusible',\n",
       " '8_0': 'N°  \\nDATE DU DÉPÔT  \\nDÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES.  \\nDATE DU DÉCÈS  \\nNOMS, PRÉNOMS  \\nDROITS DE SUCCESSION  \\nDROIT DE MUTATION  \\nNUMÉROS  \\nDATE  \\nOBSERVATIONS.  \\nd’ordre  \\ndes DÉCLARATIONS.  \\nNOMS.  \\nPRÉNOMS.  \\nDOMICILES.  \\nou du JUGEMENT D’ENVOI en possession, en cas d’absence.  \\nET DEMEURES DES PARTIES DÉCLARANTES.  \\nEN LIGNE COLLATÉRALE et de MUTATION EN LIGNE DIRECTE  \\nsur décès.  \\ndes DÉCLARATIONS  \\nde l’expiration du délai de rectification.  \\nACTIF.  \\nPASSIF.  \\nRESTANT NET  \\nVALEUR des IMMEUBLES.',\n",
       " '8_1': 'Arrêté le vingt un novembre 1919 servais',\n",
       " '8_2': '429 vingt deux novembre Beth Henri Athée 26 mai 1919 Hebert Louis 7666 7666 3 janvier 1920 15 9bre 1920 360 369',\n",
       " '8_3': '430 5 Huart Ida 19 8bre 1918 Huart Joseph & autres 4207 1461 2746 3 8bre 1919 7 avril 1920 302',\n",
       " '8_4': '431 Romain Félicie 10 4bre 1919 Wautier Léonie autres 4058 1048 3 8 10 7bre 1920 346',\n",
       " '8_5': '432 5 octobre Poliart Sim 4 28 8bre 1918 Herrent Claverie & autres 913 411 432 19 2bre 1919 8 8bre 1919 22 avril 1920 60',\n",
       " '8_6': '433 5 Poliax Arthur 19 5 965 266 674 13 8bre 1920 5 7bre 1920 7 avril 1921 41',\n",
       " '8_7': '434 3 Houtmeyers Henri Waterloo 28 mai 1919 Balgan Dirpret 2034 417 1617 8 8bre 1919 21 mars 1920 1 avril 1920 75',\n",
       " '8_8': '435 D Thibaux Marie Louise Menet 5 9bre 1919 Loyens Alexis & autres 16630 11290 448 12 D 5 9bre 1919 non familier',\n",
       " '8_9': '436 Gaussin Eva Bruxelles 22 8br 1918 Gaussin Daniel 1020 722 298 8 8bre 1919 non favorisé',\n",
       " '8_10': '437 30 Delannoy Clémentine a 28 mars 1918 Déseron Adrien 6157 644 513 8 Db 23 janvier 1919 14-11-21 148',\n",
       " '8_11': '138 5 Deloutte Jules Ittre 29 8bre 1918 Deloutte Alfred 3988 2083 1905 15 29 août 1919 17 mai 1920 103 12 avril 1921 354',\n",
       " '8_12': 'Arrêté le vingt deux novembre 1919 servais',\n",
       " '8_13': 'Arrêté le vingt trois novembre 1919 dimanche servais',\n",
       " '9_0': \"N° DATE DU DÉPÔT DESIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE OBSERVATIONS. d'autre des NOMS. PRÉNOMS. DOMICILES. DATE DU DÉCÈS et DE MUTATION des de NUMÉROS RECETTE CAUTION- DÉCLARATIONS. ou du DEMEURES DES PARTIES DÉCLARANTES. EN LIGNE COLLATERALE par décès. IMMEUBLES. des de des (1) JUGEMENT D'ENVOI et de DÉCLARATIONS DROITS ET AMENDES. NEMENTS. en possession, MUTATION EN LIGNE DIRECTE primaires supplémentaires en cas d'absence. ACTIF. PASSIF. RESTANT NET. VALEUR DATE (2) (2) (2)\",\n",
       " '9_1': 'Arrêté le vingt quatrième novembre servais',\n",
       " '9_2': '439 vingt cinq 9bre Gossiaux Adélaïde Jos. Florecourt 20 4bre 1919 Gossiaux Sylvie & autres 2225 5615 6 janvier 1920 20 juillet 1920 5 mai 1930 95',\n",
       " '9_3': 'Arrêté le vingt cinq novembre 1919 servais',\n",
       " '9_4': 'Arrêté le vingt trois novembre 1919 servais',\n",
       " '9_5': 'Arrêté le vingt sept novembre 1919 servais',\n",
       " '9_6': 'Arrêté le vingt huit novembre 1919 Servais',\n",
       " '9_7': 'Arrêté le vingt neuf novembre 1919 Servais',\n",
       " '9_8': 'Arrêté le trente novembre 1919 Dimanche Servais',\n",
       " '9_9': '439 1/2 trente premier 8bre Painblanc Joseph Iverines-le-Château 4 février 1919 Painblanc Georges & autres 1569 3646 206 1919',\n",
       " '9_10': '439 Painblanc Couronné 18 25 2590 2590 20 7 1919',\n",
       " '9_11': 'Arrêté le premier décembre 1919 servais',\n",
       " '9_12': '439 4 deux 8bre Charlier Jean Att Thines 28 9bre 1918 Charlier Juliette les jeunes autres 2000 3000 25 1919',\n",
       " '9_13': 'Arrêté le deux décembre 1919 servais',\n",
       " '10_0': 'N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE NUMÉROS RECETTE CAUTION- OBSERVATIONS. d’ordre. des NOMS. PRÉNOMS. DOMICILES. ou du et DE MUTATION des de de la des NEMENTS. (Les déclarations qui figurent à l’état DÉCLARATIONS. jugement d’envoi par décès. DÉCLARATIONS l’exigibilité consigna- DROITS ET AMENDES. NUMÉROS n° 45) doivent être écartées en conséquence, dans la présente colonne. en pension, VALEUR primitives du délai tion DATE de la en cas d’absence. des supplémentaires de des droits N° consigna- IMMEUBLES rectification au tion au sommiers sommiers n° 28. n° 30.',\n",
       " '10_1': 'Arrêté le trois décembre 1919 servais',\n",
       " '10_2': '439 quinto octobre Knops Valentine Nivelles 4 7bre 1918 Devaux Léonard autres 38 1919 15 8bre 1919 13 avril 1920 461',\n",
       " '10_3': 'Arrêté le quatre décembre 1919 Servais',\n",
       " '10_4': \"440 vingt 8bre Desfalque Eugène servais L'abbé 4 juin 44 Winderickx Régine 4100 4500 16 janvier 1920 7 avril 1920 5 mai 1920 96\",\n",
       " '10_5': 'Arrêté le cinq décembre 1919 servais',\n",
       " '10_6': '441 six 8bre Jaeqmin Cécile Ophain 27 juillet 1919 Jossart François 54661 54661 102 14 30 21 mai 1920 16',\n",
       " '10_7': '141 8 Voussure Elie Bovinne Lalleux 18 février 1914 Gillis André 45 45 28 1919',\n",
       " '10_8': 'Arrêté le six décembre 1919 servais',\n",
       " '10_9': 'Arrêté le sept décembre 1919 Dimanche Servais',\n",
       " '10_10': '441 3 huit 8bre de Lalieux Emile Nivelles 4 9bre 1918 Simonis Maria 649 649 133 1919',\n",
       " '10_11': 'Arrêté le huit décembre 1919 Servais',\n",
       " '10_12': '4414 neuf 9bre Heuwels Alphonse Nivelles 6 février 1919 Heuwels Louis Acte rectificatif 237 1919',\n",
       " '10_13': '415 x Goisse Adolphe 6 janvier 1919 Hanquet Clara 416 410 204/1919',\n",
       " '11_0': 'Arrêté le vingt huit octobre 1919 servais 398 trente octobre Herrent Alphones gh Ophain 16 9b 1918 Herrent Maris & autres 2280 1045 1235 11 Db 1919 15 7bre 1919 7 avril 1920 303',\n",
       " '11_1': 'Arrêté le neuf décembre 1919 Servais',\n",
       " '11_2': 'Arrêté le dix décembre 1919 servais',\n",
       " '11_3': '441 onze 8bre Dewez Zénon Waterloo 9 9bre 1918 Dewez Fernand 921 921 4 11 1919',\n",
       " '11_4': 'Arrêté le onze décembre 1919 servais',\n",
       " '11_5': '441 F douze 9bre Delise Vital Quenon 1 8bre 1913 Coppens Aimée 2543 2743 186 1911 4',\n",
       " '11_6': 'Arrêté le douze décembre 1919 Servais',\n",
       " '11_7': 'Arrêté le treize décembre 1919 Servais',\n",
       " '11_8': 'Arrêté le quatorze décembre 1919 dimanche servais',\n",
       " '11_9': 'Arrêté le quinze décembre 1919 Servais',\n",
       " '11_10': 'Arrêté le dix décembre 1919 Servais',\n",
       " '11_11': '441 8 7bre Boisdenghien Louis Quenast 1er mai 1919 Boisdenghien autres 46396 46361 430 631',\n",
       " '11_12': 'Arrêté le dix sept décembre 1919 servais',\n",
       " '11_13': 'Arrêté le dix huit décembre 1919 Servais',\n",
       " '12_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE RECETTE OBSERVATIONS. d'ordre des NOMS. PRÉNOMS. DATE DU DÉCÈS et ACTIF. PASSIF. RESTANT VALEUR de des de des (1) DÉCLARATIONS. DOMICILES. ou du JUGEMENT D'ENVOI en en cas d'absence. NET. des IMMUEBLES. MUTATION par décès. DÉCLARATIONS\",\n",
       " '12_1': \"411 trente octobre Devillers Josephine Marie l'alleud 9 février 1919 Devillers Felix & Adeline 243 1919\",\n",
       " '12_2': '441 5 Clabecq Fernand Nivelle 15 avril 1919 Delbroux Léonie 291 1919 4',\n",
       " '12_3': 'Arrêté le dix neuf décembre 1919 Servais',\n",
       " '12_4': 'Arrêté le vingt décembre 1919 Servais',\n",
       " '12_5': 'Arrêté le vingt un décembre 1919 Dimanche servais',\n",
       " '12_6': '442 vingt deux octobre Gilbert Clémentine célibre 10 7bre 1919 Longendries Marie Louis Armand gh 4215 4215 2 février 1920 77',\n",
       " '12_7': \"142 5 D Paesmans Henri Braine l'Alleud 12 mars 1917 Paesmans Marie 1551 440 1918 4 février 1920 31 29 5bre 1920 47\",\n",
       " '12_8': '423 5 Hinne Alexis 6 avril 1918 Henne Jules 1646 1646 280 1919 9 janvier 1920 8',\n",
       " '12_9': '444 5 Mathieu Etienne 11 mars 1919 Boussu-lez-Walcourt 1487.60 1489.31 413 1919',\n",
       " '12_10': 'Arrêté le vingt deux décembre 1919 servais',\n",
       " '12_11': 'Arrêté le vingt trois décembre 1919 servais',\n",
       " '12_12': '442 vingt quatre 5bre Cauwenberg Victor Joseph Baulers 16 8 1918 Goossiau Adeline autres 242 242 308 1919',\n",
       " '12_13': '343 x Anthoine Alphonse Perwez 28 8bre 1919 Anthoine Marie Claire & autres 1828 1826 2 février 1920 4 avril 1920 2',\n",
       " '13_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT DE MUTATION NUMÉROS DATE OBSERVATIONS. d'ordre des NOMS. PRÉNOMS. DOMICILES. ou du et ACTIF. PASSIF RESTANT VALEUR des de de de RECETTE CAUTIONNEMENTS. (1) DÉCLARATIONS. JUGEMENT D'ENVOI possession, NET. des DÉCLARATIONS l'expiration l'exigibilité la des NUMÉROS en cas d'absence. IMMEUBLES. du délai des droits. consignation DROITS ET AMENDES. de la (2) (2) (2) publications de rectification. des droits DATE compilation expéditions au sommaire n° 25. au sommaire n° 50.\",\n",
       " '13_1': 'Arrêté le vingt quatre décembre 1919 servais',\n",
       " '13_2': 'Arrêté le vingt cinq décembre 1919 Noël Servais',\n",
       " '13_3': '4452 vingt six 8bre Thibaux Marie Louise Quenast 5 9bre 1919 Loyal Maris autres 2250 1250 1919',\n",
       " '13_4': 'Arrêté le vingt six décembre 1919 Servais',\n",
       " '13_5': '444 vingt sept Wantbrier Louis Baulers 28 juin 1919 Moorsel Abel 16629 14439 17 février 1920 8 avril 1920 9 avril 1920 91',\n",
       " '13_6': '145 30 Jacquet Emmerence Hortense epse Jacquet Emile 6557 2383 5610 7 9bre 1919 7 avril 1920 85',\n",
       " '13_7': 'Arrêté le vingt sept décembre 1919 Servais',\n",
       " '13_8': 'Arrêté le vingt huit décembre 1919 Dimanche Servais',\n",
       " '13_9': 'Arrêté le vingt huit octobre 1919 servais 398 trente octobre Herrent Alphones gh Ophain 16 9b 1918 Herrent Maris & autres 2280 1045 1235 11 Db 1919 15 7bre 1919 7 avril 1920 303 146 vingt neuf Vanglaire Guillaume Bruine Lechateau 4 7bre 1919 Devogeleer Elise & autres 400 100 9 30 11 juillet 1920 non juvible',\n",
       " '13_10': 'Arrêté le vingt neuf décembre 1919 Servais bonifié 1917 francophones neuf 1916 99 1918 258 1919 188 191 220 288 318 408 113 132 133 136 137',\n",
       " '13_11': 'Arrêté le trente décembre 1919 servais 1917 68 355 1918 48 294 HG 576',\n",
       " '13_12': '446 1/2 trentian 8bre Plasman Louise Calluy 10 mars 1914 Veny Pierre & autres 1918 1918 87 273 412 429 114 116 127 138 177 341 360 366 400 410',\n",
       " '13_13': 'Arrêté le trente un décembre 1919 Servais',\n",
       " '14_0': \"['N°', 'DATE DU DÉPÔT', 'DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES.', 'DATE DU DÉCÈS', 'NOMS, PRÉNOMS', 'DROITS DE SUCCESSION', 'DROIT', 'NUMÉROS', 'DATE', 'OBSERVATIONS.'] ['d’ordre', 'des', 'NOMS.', 'PRÉNOMS.', 'DOMICILES.', 'en du', 'et', 'DE MUTATION', 'des', 'de'] ['DÉCLARATIONS.', '', '', '', '', 'jugement d’envoi', 'demeures des parties déclarantes.', 'par décès.', 'DÉCLARATIONS', 'l’expiration'] ['', '', '', '', '', 'en possession,', '', 'VALEUR', 'primitifs', 'des délais'] ['', '', '', '', '', 'en cas d’absence.', '', 'des', 'supplémentaires', 'de rectification'] ['', '', '', '', '', '', '', 'IMMEUBLES.', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '', '', '', '', '', '', '', '', ''] ['', '',\",\n",
       " '14_1': 'Arrêté le premier janvier 1920 Ciccacioni servais',\n",
       " '14_2': '1 1er janvier 1920 Séverin Jules Annie L. 4 juillet 1919 Sébastien Delphine & autres 34842 34842 3,16 1920 18 février 1920',\n",
       " '14_3': '2 Dumont Louise Nivelles 3 Harcy Juliette autres 369 2030 15 8bre 1919 24 janvier 1920 460',\n",
       " '14_4': 'Arrêté le deux janvier 1920 servais',\n",
       " '14_5': 'Arrêté le trois janvier 1920 Servais',\n",
       " '14_6': 'Arrêté le quatre janvier 1923 Armand Servais',\n",
       " '14_7': '3 cinq janvier Houlin Edouard Aubry 7 juillet 1919 Houlin Maris & autres 787 752 1237 452 16 février 1920 22 juillet 1920 4 8bre 1920 726',\n",
       " '14_8': '3e Séverin Jules Bruine et autres 6 juillet 1914 Séverin Léon 36442 1 1920',\n",
       " '14_9': '3 3/4 Wanderpepen Marie Nivelles 29 7bre 1918 Remacle Léonie 2665 1619 1042 1919 14 janvier 1920',\n",
       " '14_10': 'Arrêté le cinq janvier 1920 Servais',\n",
       " '14_11': '4 six janvier Scolas Victor Joseph Louis Callaud 22 8bre 1919 Koeselberg Joseph & autres 2039 2039 14 février 1920 23 juillet 1920 126',\n",
       " '14_12': 'Arrêté le dix janvier 1920 servais',\n",
       " '14_13': 'Arrêté le sept janvier 1920 servais',\n",
       " '15_0': 'N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS NOMS PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE OBSERVATIONS des NOMS PRÉNOMS ou du ET EN LIGNE COLLATERALE DE MUTATION des RECETTE DÉCLARATIONS DOMICILES JUGEMENT D’ENVOI DEMEURES DES PARTIES DÉCLARANTES et de par décès DÉCLARATIONS des des en MUTATION EN LIGNE DIRECTE publicité droits DROITS ET AMENDES possession ACTIF PASSIF RESTANT NET VALEUR et en cas d’absence des transcriptions IMMEUBLES hypothécaires et autres droits',\n",
       " '15_1': 'Arrêté le vingt huit janvier 1920 Lefebvre Prudence Celibée 30 9bre 1918 Nicolas Euphémie autres 4750 4750 1822 1919 28 8bre 211 24 8bre 219',\n",
       " '15_2': 'Arrêté le huit janvier 1920 servais',\n",
       " '15_3': 'Arrêté le neuf janvier 1920 Servais',\n",
       " '15_4': 'Arrêté le dix janvier 1920 Servais',\n",
       " '15_5': 'Arrêté le onze janvier 1920 dimanche Servais',\n",
       " '15_6': '5 douze janvier Druet Henri Bonival 2 mai 1919 Deguelle Jules & autres 4200 1200 210 20 février 1920 non fourni',\n",
       " '15_7': 'Arrêté le douze janvier 1920 servais',\n",
       " '15_8': '6 treize janvier Lacroix Marie Catherine Wijeral 15 juillet 1919 Flawinne Wale autres 3691 2691 26 8bre 1919 1er mai 1920 non payables',\n",
       " '15_9': 'Arrêté le treize janvier 1920 Servais',\n",
       " '15_10': 'Arrêté le quatorze janvier 1920 Servais',\n",
       " '15_11': 'Arrêté le quinze janvier 1920 servais',\n",
       " '15_12': 'Arrêté le seize janvier 1920 Servais',\n",
       " '15_13': '7 1er septembre Miebiels Victorine épouse 29 juillet 1919 Bodonghien Alfred & autres 14428 44428 29 février 1920 29 mai 1920 1 août 1920 390',\n",
       " '16_0': 'Arrêté le vingt huit octobre 1919 servais 398 trente octobre Herrent Alphones gh Ophain 16 9b 1918 Herrent Maris & autres 2280 1045 1235 11 Db 1919 15 7bre 1919 7 avril 1920 303',\n",
       " '16_1': '8 dix sept janvier 1920 Leclercq Florine La Hulpe 6 9bre 1919 Leclercq Victor & autres 8468 3446 1920 28 février 1920 6 juillet 1920 non fourni',\n",
       " '16_2': \"9 1er Gerroir Célestin Marie Benjamin 26 janvier 1918 Bastinaux Alexis Possession d'usufruit 2 avril 1920\",\n",
       " '16_3': '9 5 Areq Alphonse Gh 16 9b 1918 Gérard Marie Gh 334 1919 2 février 1920 30',\n",
       " '16_4': 'Arrêté le dix sept janvier 1920 servais',\n",
       " '16_5': 'Arrêté le dix huit janvier 1920 Dimanche Servais',\n",
       " '16_6': 'Arrêté le dix neuf janvier 1920 servais',\n",
       " '16_7': 'Arrêté le vingt janvier 1920 Servais',\n",
       " '16_8': 'Arrêté le vingt huit octobre 1919 servais 398 trente octobre Herrent Alphones gh Ophain 16 9b 1918 Herrent Maris & autres 2280 1045 1235 11 Db 1919 15 7bre 1919 7 avril 1920 303 9 3 vingt un janvier Becquet Alvensle Bruxelles 8 mai 1916 Becquet René Demunifiante 285 1919',\n",
       " '16_9': 'Arrêté le vingt un janvier 1920 Servais',\n",
       " '16_10': 'Arrêté le vingt deux novembre 1920 servais',\n",
       " '16_11': 'Arrêté le vingt trois janvier 1920 servais',\n",
       " '16_12': '10 vingt quatre octobre Divieux Henri Nivelles 15 juillet 1919 Divieux Louis & autres 444 585 105 940 14 2bre 1919 7 mars 1920 3 avril 1920 13 13 2 8bre 1920 63',\n",
       " '16_13': 'Arrêté le vingt quatre janvier 1920 servais',\n",
       " '17_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT DE MUTATION NUMÉROS DATE NUMÉROS OBSERVATIONS. d'ordre des NOMS. PRÉNOMS. DOMICILES. ou du et en ligne collatérale par décès des de de la Les déclarations qui figurent à l'état DÉCLARATIONS. JUGEMENT D'ENVOI DEMEURES DES PARTIES DÉCLARANTES. et de VALEUR DÉCLARATIONS l'expiration consignation n° 413 doivent être indiquées en consé- en possession, MUTATION EN LIGNE DIRECTE. des du délai des droits quence, dans la présente colonne) en cas d'absence. ACTIF. PASSIF. RESTANT NET. IMMUEBLES. de rectification. au au sommier sommiers n° 28. n° 30.\",\n",
       " '17_1': 'Arrêté le vingt cinq janvier 1920 Dimanche Servais',\n",
       " '17_2': '10 2e vingt six janvier Desflandre Gustave Désiré Cubize 22 Août 1918 Lendersmavers Philippine 494 500 189 1919',\n",
       " '17_3': '10 30 Ypersiel Julien Ghislain 18 8bre 1918 Eleonore Creteur 290 490 8bre 1919',\n",
       " '17_4': 'Arrêté le vingt huit janvier 1920 Servais',\n",
       " '17_5': \"10 4 vingt sept janvier bordenx Louis Bruine d'Alleud 21 février 1919 Casteur Antonis 300 300 131/131 21 janvier 1920\",\n",
       " '17_6': 'Arrêté le vingt sept janvier 1920 Servais',\n",
       " '17_7': '10 5 vingt huit janvier Decock Léonie 21 février 1917 Meurs seul 544 544 258 1918',\n",
       " '17_8': '106 5 Decock Adèle 10 12 1918 170 1918',\n",
       " '17_9': '11 x Bolendries Anastasie Nivelles 18 8br 1919 Bolendries Virginie 950 360 590 11 mars 1920 18 avril 1920 149',\n",
       " '17_10': 'Arrêté le vingt huit janvier 1920 Servais',\n",
       " '17_11': 'Arrêté le vingt neuf janvier 1920 Servais',\n",
       " '17_12': '11e entre janvier Roussea Charles Oph Nivelles 31 mars 1919 Roussea Laura 1500 1500 1919',\n",
       " '17_13': '11 3 Bedonckx Vital Tubize 14 8bre 1918 Bonemans Elisabeth 1440 1560 980 1381 1919',\n",
       " '18_0': 'N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE OBSERVATIONS. d’ordre des NOMS. PRÉNOMS. DOMICILES. ou du et DE des de DÉCLARATIONS. JUGEMENT D’ENVOI DE MUTATION DÉCLARATIONS l’expiration en MUTATION EN LIGNE DIRECTE. par décès. répétition du délai possession, ACTIF. PASSIF RESTANT VALEUR des des de en cas d’absence. NET. des droits rectification',\n",
       " '18_1': 'Arrêté le trente janvier 1920 servais',\n",
       " '18_2': 'Arrêté le trente un janvier 1920 servais',\n",
       " '18_3': 'Arrêté le premier février 1920 Dimanche servais',\n",
       " '18_4': '12 deux février Casliers Victor Quenast 4 février 48 Caslier Vital & Louis 6745 509 609 11 7bre 1919 15 mars 1920 16 février 1920 36',\n",
       " '18_5': 'Arrêté le deux février 1920 servais',\n",
       " '18_6': 'Arrêté le dix-huit février 1920 servais',\n",
       " '18_7': '13 quatre février 1920 Longe Adrienne Louise 20 juillet 1919 Deloy Henri autres 1624 2 2624 2 18 7bre 1919 20 mai 1920 non taxible',\n",
       " '18_8': '14 Segain Evariste Anne Marie Romarin 8 9bre 1918 Evariste Belges autres 9412 3246 6421 1904 1920 18 2bre 1919 9 8bre 1921 27 6 janvier 1922',\n",
       " '18_9': 'Arrêté le quatre février 1920 servais',\n",
       " '18_10': '15 cinq fevrier Kaivez Marie Catherine Louise Adrienne Lallieux 5 avril 1919 Blanckart Alphonse autres 1590 1590 18 8bre 1920 non favorables',\n",
       " '18_11': '15 2 5 Denys Henri Virginie veuve Lepomme Emile 1918 Acte unifratric 1919 5 février 1920 323',\n",
       " '18_12': '15 3bre Van Hoobrouck Georges chevalier de 23 mars 1919 Capmans Emile 25545 26665 321 1919',\n",
       " '18_13': '15 4 Painblanc Joseph Joseph chateau 1 février 1919 Rosy Halonne autres 2290 2290 201 1919',\n",
       " '19_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE OBSERVATIONS. d'Ordre. des NOMS. PRÉNOMS. DOMICILES. ou du et de DE MUTATION des de DÉCLARATIONS. JUGEMENT D'ENVOI MUTATION EN LIGNE DIRECTE. par décès. DÉCLARATIONS l'exigibilité (Les déclarations qui figurent à l'état en possession, en cas d'absence. supplémentaires des droits. n° 415 doivent être extraites, en conséquence, dans la présente colonne.) ACTIF. PASSIF. RESTANT NET. VALEUR des IMMUEBLES.\",\n",
       " '19_1': 'Arrêté le cinq février 1920 servais',\n",
       " '19_2': 'Arrêté le six février 1920 Servais',\n",
       " '19_3': 'Arrêté le sept février 1920 servais',\n",
       " '19_4': 'Arrêté le huit février 1920 Dimanche servais',\n",
       " '19_5': 'Arrêté le neuf février 1920 servais',\n",
       " '19_6': '16 février Soupart Emelie Bruxelles 11 avril 1919 Pétrieux Henry Oscar 39101 39101 26 7bre 1920 24 mars 1920 11 8bre 1920 173 192',\n",
       " '19_7': '16 3 Tâché Alfred gh Calbize 2 8bre 1919 Tâché Almir & autres 1200 1200 11 4/0 1919 27 mars 1920 69',\n",
       " '19_8': '16 3/5 5 Sivaux Augustin Rebecq 18 mars 1912 Capmans Émile 2045 2025 14/9 1919',\n",
       " '19_9': 'Arrêté le dix février 1920 servais',\n",
       " '19_10': 'Arrêté le onze février 1920 servais',\n",
       " '19_11': '17 douze 9 Vancutsem Adeline veuve de aelux 13 août 1919 Bouthier Charles & autres 13628 13628 16 4 1920 27 mars 1920 20 juillet 1920',\n",
       " '19_12': 'Arrêté le douze février 1920 servais',\n",
       " '19_13': '18 treize février Hrumjadis Yulei Vienne Autriche 14 février 1919 carton de Michel Henri 11504 25 3 février 1920',\n",
       " '20_0': 'Arrêté le vingt huit octobre 1919 servais 398 trente octobre Herrent Alphones gh Ophain 16 9b 1918 Herrent Maris & autres 2280 1045 1235 11 Db 1919 15 7bre 1919 7 avril 1920 303',\n",
       " '20_1': 'Arrêté le treize février 1920 servais',\n",
       " '20_2': 'Arrêté le quatorze février 1920 servais',\n",
       " '20_3': 'Arrêté le quinze février 1920 Dimanche servais',\n",
       " '20_4': 'Arrêté le seize février 1920 servais',\n",
       " '20_5': '18 1/2 dix sept fevrier Cabreau Louis lettre Seneffe 5 mai 1919 Cabreau Louis & autres 198 1919',\n",
       " '20_6': '18 3bre Deches Jules 14 8bre 1918 Deches Gustave & autres 503 503 356 1919',\n",
       " '20_7': 'Arrêté le dix sept février 1920 Servais',\n",
       " '20_8': 'Arrêté le dix huit février 1920 Servais',\n",
       " '20_9': '19 trente neuf Pékiaux Cornélie Nivelles 12 avril 1919 Servais Constantin 6350 31 mars 1920 1er juin 1920 1er juillet 1920',\n",
       " '20_10': '19 5 Dubois Alexandre 4 6 1919 Dubois Jeanette autres 350 320 860 1919',\n",
       " '20_11': 'Arrêté le dix neuf février 1920 servais',\n",
       " '20_12': 'Arrêté le vingt février 1920 servais',\n",
       " '20_13': '193 vingt un juin Remience Fern Bte Nivelles Février 1916 Remience Jeanne 400 400 10c 1919',\n",
       " '1_2': 'Arrêté le vingt neuf octobre 1919 servais'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('gpt_two_example_output_progress.json', 'r') as file:\n",
    "        gpt_two_example_output = json.load(file)\n",
    "# claude_complex_output\n",
    "gpt_two_example_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f1f689f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['18_0', '19_0']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "unable_ids = [id for id, content in claude_complex_output.items() if \"unable\" in content or \"I apologize\" in content or \"The image\" in content or \"sorry\" in content]\n",
    "print(unable_ids, len(unable_ids), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51068bb4",
   "metadata": {},
   "source": [
    "### To run with the saved json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e2d9533c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_0</td>\n",
       "      <td>N° DATE DU DÉPÔT des déclarations DÉSIGNATION ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_0</td>\n",
       "      <td>N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_0</td>\n",
       "      <td>N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4_0</td>\n",
       "      <td>DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5_0</td>\n",
       "      <td>N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_9</td>\n",
       "      <td>10 décembre 30 Pétriaux Camile Morville 22 avr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>10² 5 Dubois Alexandre épicier 5/8/1919 Dubois...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>Arrêté le dix neuf février 1920 Servais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>Arrêté le vingt février 1920 Servais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>3 Remience Leon Sta Bruxelles 8 fevrier 1916 R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0      1_0  N° DATE DU DÉPÔT des déclarations DÉSIGNATION ...\n",
       "1      2_0  N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...\n",
       "2      3_0  N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...\n",
       "3      4_0  DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES...\n",
       "4      5_0  N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...\n",
       "..     ...                                                ...\n",
       "278   20_9  10 décembre 30 Pétriaux Camile Morville 22 avr...\n",
       "279  20_10  10² 5 Dubois Alexandre épicier 5/8/1919 Dubois...\n",
       "280  20_11            Arrêté le dix neuf février 1920 Servais\n",
       "281  20_12               Arrêté le vingt février 1920 Servais\n",
       "282  20_13  3 Remience Leon Sta Bruxelles 8 fevrier 1916 R...\n",
       "\n",
       "[283 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claude_refine_complex_output_df = pd.DataFrame(claude_refine_complex_output.items(), columns=['id', 'text'])\n",
    "claude_refine_complex_output_df['text'] = claude_refine_complex_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "claude_refine_complex_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2d265a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_refine_complex_output_df.to_csv(path+'/results/postprocessed/claude_refine_complex_perline_output2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736b773",
   "metadata": {},
   "source": [
    "# CER/BLEU calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2f6551",
   "metadata": {},
   "source": [
    "## ground truth df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a4c03dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "text_path = path+'/data/transcriptions'\n",
    "file_list = glob(os.path.join(text_path, 'transcription_ex*.txt'))\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in file_list:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    lines = content.split('\\n')\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'line': range(0, len(lines)),  # Line numbers starting from 0\n",
    "        'text': lines\n",
    "    })\n",
    "    \n",
    "    name = os.path.basename(file)\n",
    "    name = name.split('.')[0]\n",
    "    df['file'] = name.split('ex')[1]\n",
    "    df['file'] = df['file'].astype(int)\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "90b2da7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N' d'ordre Date du dépot des déclarations Dési...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Nom. Prénoms Domiciles Actif. (2) Passif. (2) ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arrêté le vingt huit octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>arrêté le vingt neuf octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>398 trente octobre Herrent Alphones gh Ophain ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>10</td>\n",
       "      <td>19 dix neuf d Pétriaux Coralie Nivelles 22 av...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>11</td>\n",
       "      <td>19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>12</td>\n",
       "      <td>Arrêté le dix neuf février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>13</td>\n",
       "      <td>Arrêté le vingt février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>14</td>\n",
       "      <td>19^3 vingt un février Remience Jean Bte Nivell...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     line                                               text  file\n",
       "0       0  N' d'ordre Date du dépot des déclarations Dési...     1\n",
       "1       1  Nom. Prénoms Domiciles Actif. (2) Passif. (2) ...     1\n",
       "2       2   arrêté le vingt huit octobre 1919 servais    ...     1\n",
       "3       3   arrêté le vingt neuf octobre 1919 servais    ...     1\n",
       "4       4  398 trente octobre Herrent Alphones gh Ophain ...     1\n",
       "..    ...                                                ...   ...\n",
       "298    10   19 dix neuf d Pétriaux Coralie Nivelles 22 av...    20\n",
       "299    11  19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...    20\n",
       "300    12          Arrêté le dix neuf février 1920 servais      20\n",
       "301    13             Arrêté le vingt février 1920 servais      20\n",
       "302    14  19^3 vingt un février Remience Jean Bte Nivell...    20\n",
       "\n",
       "[303 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "df = df.sort_values(by=['file', 'line']).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a98c96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the text values of line number 0 and 1 (the two lines of the header)\n",
    "for file in df['file'].unique():\n",
    "    header_lines = df[(df['file'] == file) & (df['line'].isin([0, 1]))]\n",
    "    df.loc[header_lines.index[0], 'text'] = header_lines.iloc[0]['text'] + \" \" + header_lines.iloc[1]['text']\n",
    "df = df[df['line'] != 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d6d3fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['line'] != 0, 'line'] -= 1  # Adjust line numbers after removing the second line of the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dae62cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for file 6, two lines are used for some column.. we need to merge them\n",
    "# doubled_line = df[(df['file'] == 6) & (df['line'].isin([3, 4]))]\n",
    "# df.loc[doubled_line.index[0], 'text'] = doubled_line.iloc[0]['text'] + \" \" + doubled_line.iloc[1]['text']\n",
    "# df.drop(doubled_line.index[1], inplace=True)\n",
    "# df.loc[(df['file'] == 6) & (df['line'] > 4), 'line'] -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d8abb06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N' d'ordre Date du dépot des déclarations Dési...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>arrêté le vingt huit octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arrêté le vingt neuf octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>398 trente octobre Herrent Alphones gh Ophain ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>arrêté le trente octobre 1919 servais        ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>arrêté le trente un octobre 1919 servais     ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>arrêté le premier novembre 1919 Toussaint ser...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>arrêté le deux novembre 1919 Dimanche servais...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>399 trois 9bre Desmedt Jeanne Nivelles 13 mai ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>400 d Monseur Raoul Oscar Clabecq 1 8b 1918 Mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>401 d Bouty Henri Braine l'Alleud 26 février 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>arrêté le trois novembre 1919 servais        ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>402 quatre 9bre Godart Renelde Braine l'Alleud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    line                                               text  file\n",
       "0      0  N' d'ordre Date du dépot des déclarations Dési...     1\n",
       "1      1   arrêté le vingt huit octobre 1919 servais    ...     1\n",
       "2      2   arrêté le vingt neuf octobre 1919 servais    ...     1\n",
       "3      3  398 trente octobre Herrent Alphones gh Ophain ...     1\n",
       "4      4  398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...     1\n",
       "5      5   arrêté le trente octobre 1919 servais        ...     1\n",
       "6      6   arrêté le trente un octobre 1919 servais     ...     1\n",
       "7      7   arrêté le premier novembre 1919 Toussaint ser...     1\n",
       "8      8   arrêté le deux novembre 1919 Dimanche servais...     1\n",
       "9      9  399 trois 9bre Desmedt Jeanne Nivelles 13 mai ...     1\n",
       "10    10  400 d Monseur Raoul Oscar Clabecq 1 8b 1918 Mo...     1\n",
       "11    11  401 d Bouty Henri Braine l'Alleud 26 février 1...     1\n",
       "12    12   arrêté le trois novembre 1919 servais        ...     1\n",
       "13    13  402 quatre 9bre Godart Renelde Braine l'Alleud...     1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['file']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "68922e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N' d'ordre Date du dépot des déclarations Dési...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>arrêté le vingt huit octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arrêté le vingt neuf octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>398 trente octobre Herrent Alphones gh Ophain ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>9</td>\n",
       "      <td>19 dix neuf d Pétriaux Coralie Nivelles 22 av...</td>\n",
       "      <td>20</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>10</td>\n",
       "      <td>19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...</td>\n",
       "      <td>20</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>11</td>\n",
       "      <td>Arrêté le dix neuf février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>12</td>\n",
       "      <td>Arrêté le vingt février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>13</td>\n",
       "      <td>19^3 vingt un février Remience Jean Bte Nivell...</td>\n",
       "      <td>20</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     line                                               text  file     id\n",
       "0       0  N' d'ordre Date du dépot des déclarations Dési...     1    1_0\n",
       "1       1   arrêté le vingt huit octobre 1919 servais    ...     1    1_1\n",
       "2       2   arrêté le vingt neuf octobre 1919 servais    ...     1    1_2\n",
       "3       3  398 trente octobre Herrent Alphones gh Ophain ...     1    1_3\n",
       "4       4  398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...     1    1_4\n",
       "..    ...                                                ...   ...    ...\n",
       "278     9   19 dix neuf d Pétriaux Coralie Nivelles 22 av...    20   20_9\n",
       "279    10  19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...    20  20_10\n",
       "280    11          Arrêté le dix neuf février 1920 servais      20  20_11\n",
       "281    12             Arrêté le vingt février 1920 servais      20  20_12\n",
       "282    13  19^3 vingt un février Remience Jean Bte Nivell...    20  20_13\n",
       "\n",
       "[283 rows x 4 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'] = df['file'].astype(str) + '_' + df['line'].astype(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7fc07b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 1, Last Line: 13\n",
      "File: 2, Last Line: 14\n",
      "File: 3, Last Line: 13\n",
      "File: 4, Last Line: 13\n",
      "File: 5, Last Line: 14\n",
      "File: 6, Last Line: 14\n",
      "File: 7, Last Line: 13\n",
      "File: 8, Last Line: 13\n",
      "File: 9, Last Line: 13\n",
      "File: 10, Last Line: 13\n",
      "File: 11, Last Line: 13\n",
      "File: 12, Last Line: 13\n",
      "File: 13, Last Line: 13\n",
      "File: 14, Last Line: 13\n",
      "File: 15, Last Line: 13\n",
      "File: 16, Last Line: 13\n",
      "File: 17, Last Line: 13\n",
      "File: 18, Last Line: 13\n",
      "File: 19, Last Line: 13\n",
      "File: 20, Last Line: 13\n"
     ]
    }
   ],
   "source": [
    "for file in df['file'].unique():\n",
    "    last_line = df[df['file'] == file]['line'].max()\n",
    "    print(f\"File: {file}, Last Line: {last_line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8837aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path+'/data/transcription_perline_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fb89e02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283 283\n"
     ]
    }
   ],
   "source": [
    "print(df['id'].nunique(), claude_output_df['id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c1c9e",
   "metadata": {},
   "source": [
    "## Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "897e931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'/data/transcription_perline_text_whitespace-trimmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0be671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "cer_metric =load(\"cer\")\n",
    "bleu_metric = load(\"bleu\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c05a9600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob(os.path.join(path+'/results/postprocessed/per-line_experiments', '*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84956ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bleu_gpt = {}\n",
    "cer_gpt = {}\n",
    "\n",
    "for id in df_filtered['id'].unique():\n",
    "    # Extract the text as a single string, not as an array\n",
    "    pred_text = pred[pred['id'] == id]['text'].values[0]\n",
    "    ref_text = df_filtered[df_filtered['id'] == id]['text'].values[0]\n",
    "\n",
    "    # Ensure the predictions and references are passed as a list of strings\n",
    "    if pred_text and ref_text:  # Check if both texts are not empty (which happens for some OCR outputs)\n",
    "        bleu_gpt[id] = bleu_metric.compute(predictions=[pred_text], references=[ref_text])\n",
    "    else:\n",
    "        bleu_gpt[id] = {'bleu': 0.0}  # Assign a default value if texts are empty\n",
    "    cer_gpt[id] = cer_metric.compute(predictions=[pred_text], references=[ref_text])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8584298f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_one_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_two_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/pytesseractOCR_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_two_text_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_complex_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_one_text_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_refine_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_refine_complex_output_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_refine_complex_output_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/kerasOCR_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/trOCR_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_refine_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_one_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_two_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_two_text_example_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/gpt_complex_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/easyOCR_perline_output.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/per-line_experiments/claude_one_text_example_perline_output.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "637acb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gpt_one_example...\n",
      "Processing claude_two_example...\n",
      "Processing pytesseractOCR...\n",
      "Processing claude_two_text_example...\n",
      "Processing claude_complex...\n",
      "Processing gpt_one_text_example...\n",
      "Processing claude_refine...\n",
      "Processing gpt_refine_complex_output...\n",
      "Processing claude_refine_complex_output...\n",
      "Processing gpt...\n",
      "Processing kerasOCR...\n",
      "Processing trOCR...\n",
      "Processing claude...\n",
      "Processing gpt_refine...\n",
      "Processing claude_one_example...\n",
      "Processing gpt_two_example...\n",
      "Processing gpt_two_text_example...\n",
      "Processing gpt_complex...\n",
      "Processing easyOCR...\n",
      "Processing claude_one_text_example...\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "\n",
    "bleu_perline = pd.DataFrame()\n",
    "cer_perline = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    pred = pd.read_csv(file)\n",
    "    df_filtered = df[df['id'].isin(pred['id'])]\n",
    "\n",
    "    name = os.path.basename(file)\n",
    "    name = name.split('_perline')[0]\n",
    "\n",
    "    print(f\"Processing {name}...\")\n",
    "\n",
    "    bleu_scores = []  # List to accumulate BLEU scores for this model\n",
    "    cer_scores = []  # List to accumulate CER scores for this model\n",
    "\n",
    "    for id in df_filtered['id'].unique():\n",
    "        # Extract the text as a single string, not as an array\n",
    "        pred_text = pred[pred['id'] == id]['text'].values\n",
    "        ref_text = df_filtered[df_filtered['id'] == id]['text'].values\n",
    "\n",
    "        # Ensure the predictions and references are passed as a list of strings\n",
    "        if len(pred_text) > 0 and len(ref_text) > 0:  # Check if both texts are not empty\n",
    "            pred_text = pred_text[0]\n",
    "            ref_text = ref_text[0]\n",
    "\n",
    "            # Check for NaN values \n",
    "            if pd.notna(pred_text) and pd.notna(ref_text):\n",
    "                # Strip white spaces\n",
    "                pred_text = pred_text.strip()\n",
    "                ref_text = ref_text.strip()\n",
    "                # Normalize: uncapitalize and remove accents (Try 3 different normalizations)\n",
    "                # pred_text = pred_text.lower()\n",
    "                # ref_text = ref_text.lower()\n",
    "                # pred_text = unidecode.unidecode(pred_text)\n",
    "                # ref_text = unidecode.unidecode(ref_text)\n",
    "                # pred_text = unidecode.unidecode(pred_text).lower()\n",
    "                # ref_text = unidecode.unidecode(ref_text).lower()\n",
    "\n",
    "                # Ensure texts are not empty after stripping\n",
    "                if pred_text and ref_text:\n",
    "                    bleu_metrics = bleu_metric.compute(predictions=[pred_text], references=[ref_text], max_order=3)\n",
    "                    cer_metrics = cer_metric.compute(predictions=[pred_text], references=[ref_text])\n",
    "                else:\n",
    "                    bleu_metrics = {'bleu': 0.0}  # Assign a default value if texts are empty\n",
    "                    cer_metrics = 1.0\n",
    "            else:\n",
    "                bleu_metrics = {'bleu': 0.0}  # Assign a default value if texts are NaN\n",
    "                cer_metrics = 1.0\n",
    "        else:\n",
    "            bleu_metrics = {'bleu': 0.0}  # Assign a default value if texts are empty\n",
    "            cer_metrics = 1.0\n",
    "\n",
    "        bleu_scores.append({\n",
    "                'model': name,\n",
    "                'id': id,\n",
    "                **bleu_metrics\n",
    "            })\n",
    "        cer_scores.append({\n",
    "                'model': name,\n",
    "                'id': id,\n",
    "                'cer': cer_metrics\n",
    "            })\n",
    "\n",
    "    bleu_perline = pd.concat([bleu_perline, pd.DataFrame(bleu_scores)], ignore_index=True)\n",
    "    cer_perline = pd.concat([cer_perline, pd.DataFrame(cer_scores)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dc16b3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt_one_example</td>\n",
       "      <td>1_0</td>\n",
       "      <td>0.958180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt_one_example</td>\n",
       "      <td>1_2</td>\n",
       "      <td>0.121951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt_one_example</td>\n",
       "      <td>1_3</td>\n",
       "      <td>0.822222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt_one_example</td>\n",
       "      <td>1_4</td>\n",
       "      <td>0.804598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt_one_example</td>\n",
       "      <td>1_5</td>\n",
       "      <td>0.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5643</th>\n",
       "      <td>claude_one_text_example</td>\n",
       "      <td>20_9</td>\n",
       "      <td>0.341463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>claude_one_text_example</td>\n",
       "      <td>20_10</td>\n",
       "      <td>0.448276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5645</th>\n",
       "      <td>claude_one_text_example</td>\n",
       "      <td>20_11</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5646</th>\n",
       "      <td>claude_one_text_example</td>\n",
       "      <td>20_12</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5647</th>\n",
       "      <td>claude_one_text_example</td>\n",
       "      <td>20_13</td>\n",
       "      <td>0.280000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5648 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model     id       cer\n",
       "0             gpt_one_example    1_0  0.958180\n",
       "1             gpt_one_example    1_2  0.121951\n",
       "2             gpt_one_example    1_3  0.822222\n",
       "3             gpt_one_example    1_4  0.804598\n",
       "4             gpt_one_example    1_5  0.270270\n",
       "...                       ...    ...       ...\n",
       "5643  claude_one_text_example   20_9  0.341463\n",
       "5644  claude_one_text_example  20_10  0.448276\n",
       "5645  claude_one_text_example  20_11  0.025641\n",
       "5646  claude_one_text_example  20_12  0.388889\n",
       "5647  claude_one_text_example  20_13  0.280000\n",
       "\n",
       "[5648 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cer_perline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d77448a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_perline.replace({'model': {'gpt': 'gpt_simple', 'claude': 'claude_simple',\n",
    "                               'trOCR': 'TrOCR', 'pytesseractOCR': 'Pytesseract',\n",
    "                               'kerasOCR': 'KerasOCR', 'easyOCR': 'EasyOCR',\n",
    "                               'gpt_refine_complex_output': 'gpt_refine_complex', 'claude_refine_complex_output': 'claude_refine_complex'}}, inplace=True)\n",
    "cer_perline.replace({'model': {'gpt': 'gpt_simple', 'claude': 'claude_simple',\n",
    "                               'trOCR': 'TrOCR', 'pytesseractOCR': 'Pytesseract',\n",
    "                               'kerasOCR': 'KerasOCR', 'easyOCR': 'EasyOCR',\n",
    "                               'gpt_refine_complex_output': 'gpt_refine_complex', 'claude_refine_complex_output': 'claude_refine_complex'}}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7e3d731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_perline.to_csv(path+'/results/scores_comparisons/bleu_perline_all_n3.csv', index=False)\n",
    "cer_perline.to_csv(path+'/results/scores_comparisons/cer_perline_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8774a8e",
   "metadata": {},
   "source": [
    "### BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e5be7601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.8091067115702212,\n",
       " 'precisions': [0.8571428571428571, 0.8333333333333334, 0.8, 0.75],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.0,\n",
       " 'translation_length': 7,\n",
       " 'reference_length': 7}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric.compute(predictions=['Arrêté le vingt cinq novembre 1919 Servais'], references=['Arrêté le vingt cinq novembre 1919 servais'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "968b6c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_gpt = pd.DataFrame(bleu_gpt).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc301e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>precisions</th>\n",
       "      <th>brevity_penalty</th>\n",
       "      <th>length_ratio</th>\n",
       "      <th>translation_length</th>\n",
       "      <th>reference_length</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.025, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.06081</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>40</td>\n",
       "      <td>152</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_3</th>\n",
       "      <td>0.137596</td>\n",
       "      <td>[0.38461538461538464, 0.2, 0.125, 0.0434782608...</td>\n",
       "      <td>0.962269</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.449329</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_9</th>\n",
       "      <td>0.259849</td>\n",
       "      <td>[0.5454545454545454, 0.38095238095238093, 0.25...</td>\n",
       "      <td>0.955563</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_10</th>\n",
       "      <td>0.150923</td>\n",
       "      <td>[0.45, 0.2631578947368421, 0.1111111111111111,...</td>\n",
       "      <td>0.904837</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_13</th>\n",
       "      <td>0.163304</td>\n",
       "      <td>[0.5, 0.3076923076923077, 0.25, 0.181818181818...</td>\n",
       "      <td>0.564718</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           bleu                                         precisions  \\\n",
       "1_0         0.0                             [0.025, 0.0, 0.0, 0.0]   \n",
       "1_1         1.0                               [1.0, 1.0, 1.0, 1.0]   \n",
       "1_2         1.0                               [1.0, 1.0, 1.0, 1.0]   \n",
       "1_3    0.137596  [0.38461538461538464, 0.2, 0.125, 0.0434782608...   \n",
       "1_4         0.0                               [0.1, 0.0, 0.0, 0.0]   \n",
       "...         ...                                                ...   \n",
       "20_9   0.259849  [0.5454545454545454, 0.38095238095238093, 0.25...   \n",
       "20_10  0.150923  [0.45, 0.2631578947368421, 0.1111111111111111,...   \n",
       "20_11       1.0                               [1.0, 1.0, 1.0, 1.0]   \n",
       "20_12       1.0                               [1.0, 1.0, 1.0, 1.0]   \n",
       "20_13  0.163304  [0.5, 0.3076923076923077, 0.25, 0.181818181818...   \n",
       "\n",
       "      brevity_penalty length_ratio translation_length reference_length     id  \n",
       "1_0           0.06081     0.263158                 40              152    1_0  \n",
       "1_1               1.0          1.0                  7                7    1_1  \n",
       "1_2               1.0          1.0                  7                7    1_2  \n",
       "1_3          0.962269     0.962963                 26               27    1_3  \n",
       "1_4          0.449329     0.555556                 10               18    1_4  \n",
       "...               ...          ...                ...              ...    ...  \n",
       "20_9         0.955563     0.956522                 22               23   20_9  \n",
       "20_10        0.904837     0.909091                 20               22  20_10  \n",
       "20_11             1.0          1.0                  7                7  20_11  \n",
       "20_12             1.0          1.0                  6                6  20_12  \n",
       "20_13        0.564718     0.636364                 14               22  20_13  \n",
       "\n",
       "[283 rows x 7 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_gpt['id'] = bleu_gpt.index\n",
    "bleu_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42415cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_gpt.to_csv(path+'/results/scores_comparisons/eval_perline/bleu_claude_two_example_perline.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd8ab74",
   "metadata": {},
   "source": [
    "### CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9933242",
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_gpt = pd.DataFrame(cer_gpt.items(), columns=['id', 'cer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84bd52c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5713106915175424 2.935498085710415\n"
     ]
    }
   ],
   "source": [
    "print(cer_gpt['cer'].mean(), cer_gpt['cer'].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fba7876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_gpt.to_csv(path+'/results/scores_comparisons/eval_perline/cer_claude_two_example_perline.csv', float_format=\"%.6f\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783bfe80",
   "metadata": {},
   "source": [
    "# OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd1af15-25ff-4636-800b-599ef2d986f1",
   "metadata": {},
   "source": [
    "## EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bdaf499-ac45-438e-bb41-04d45d53f78c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[43mtest_path\u001b[49m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(test_image)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_path' is not defined"
     ]
    }
   ],
   "source": [
    "test_image = cv2.imread(test_path)\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e1baa4c9-2e16-47bf-aed6-47a4c0de1807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def easyOCR(image_path):\n",
    "    reader = easyocr.Reader(['fr'])\n",
    "    img = cv2.imread(image_path)\n",
    "    results = reader.readtext(img)\n",
    "    output = []\n",
    "    for res in results:\n",
    "        det, conf = res[1], res[2]\n",
    "        output.append((det, round(conf, 2))) \n",
    "    text = ' '.join([i[0] for i in output])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "474cc34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "easyOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = easyOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        easyOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b45d798e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>line_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_00</td>\n",
       "      <td>DÉSIGNATION DES PERSONNES DÉCÉDÉES OU AlSENTES...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_01</td>\n",
       "      <td>~Bcrta` 8 oetolz 1919 d4earuey vicytAul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_02</td>\n",
       "      <td>Jbsucala &amp; veyhmeuf ouoba  tg19 [eevœy</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_03</td>\n",
       "      <td>891 ta HBevcenk ~Bepkonssjk oj hain Hgoucoal Y...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_04</td>\n",
       "      <td>TulL Bouuù Q \"Janer ~aobà Bhuile RRXR 26 aplul...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_09</td>\n",
       "      <td>J9 ùcà nuf&gt; Sebiaw bo2nbi YÉvepQu X anel Bebel...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>4 49 0 : @ubovs ssexanbz Yuemaut ubuùd *ean [l...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>Jvuté &amp; oi = neuf fasles19:0 Huclai</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>Jarsalé -   vms] Hinsenq %0 djeceia |</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>3 [9' vrqkun )a4| Semience Run Gl Yusvellen Le...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text  file_name  \\\n",
       "0     1_00  DÉSIGNATION DES PERSONNES DÉCÉDÉES OU AlSENTES...          1   \n",
       "1     1_01            ~Bcrta` 8 oetolz 1919 d4earuey vicytAul          1   \n",
       "2     1_02             Jbsucala & veyhmeuf ouoba  tg19 [eevœy          1   \n",
       "3     1_03  891 ta HBevcenk ~Bepkonssjk oj hain Hgoucoal Y...          1   \n",
       "4     1_04  TulL Bouuù Q \"Janer ~aobà Bhuile RRXR 26 aplul...          1   \n",
       "..     ...                                                ...        ...   \n",
       "278  20_09  J9 ùcà nuf> Sebiaw bo2nbi YÉvepQu X anel Bebel...         20   \n",
       "279  20_10  4 49 0 : @ubovs ssexanbz Yuemaut ubuùd *ean [l...         20   \n",
       "280  20_11                Jvuté & oi = neuf fasles19:0 Huclai         20   \n",
       "281  20_12              Jarsalé -   vms] Hinsenq %0 djeceia |         20   \n",
       "282  20_13  3 [9' vrqkun )a4| Semience Run Gl Yusvellen Le...         20   \n",
       "\n",
       "     line_name     id  \n",
       "0            0    1_0  \n",
       "1            1    1_1  \n",
       "2            2    1_2  \n",
       "3            3    1_3  \n",
       "4            4    1_4  \n",
       "..         ...    ...  \n",
       "278          9   20_9  \n",
       "279         10  20_10  \n",
       "280         11  20_11  \n",
       "281         12  20_12  \n",
       "282         13  20_13  \n",
       "\n",
       "[283 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# easyOCR_output_df = pd.read_csv(path+'/results/postprocessed/easyOCR_perline_output.csv')\n",
    "easyOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6f85318b-55be-419d-b80a-0e8c5b861779",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_00</td>\n",
       "      <td>DATE I IÉcis DROITS DF SUCCESSION DROIT NUMÉRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_01</td>\n",
       "      <td>soceti &amp; tù déeemebza. 919 Yuepiy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_02</td>\n",
       "      <td>5 1439 DaLenlize Yiceppu #9lugu | Benuue YLama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10_03</td>\n",
       "      <td>Jaxat' € deeemlaac919 Fuupùa quebu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10_04</td>\n",
       "      <td>[4ho ceæy _ (ekalque Pnag;nl  Yjuuy Wv&amp;ezlbz (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>9_09</td>\n",
       "      <td>69*2.4 Scinllane Pots+a Gxz9&amp; SasBBoe Gpmzeyen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>9_10</td>\n",
       "      <td>kag' 0: Sainllane Bwun' à 26r' 1sr \"9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>9_11</td>\n",
       "      <td>Joaak + fnmauu dceehu 1919 Yeoeok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>9_12</td>\n",
       "      <td>[4Jg %eu 3- CBaslice fe At Z8ma 2e+eygu | Jwti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>9_13</td>\n",
       "      <td>~outi &amp; Jeun 1919 fuwsuik Lg déclerations recl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text\n",
       "0    10_00  DATE I IÉcis DROITS DF SUCCESSION DROIT NUMÉRO...\n",
       "1    10_01                  soceti & tù déeemebza. 919 Yuepiy\n",
       "2    10_02  5 1439 DaLenlize Yiceppu #9lugu | Benuue YLama...\n",
       "3    10_03                 Jaxat' € deeemlaac919 Fuupùa quebu\n",
       "4    10_04  [4ho ceæy _ (ekalque Pnag;nl  Yjuuy Wv&ezlbz (...\n",
       "..     ...                                                ...\n",
       "278   9_09  69*2.4 Scinllane Pots+a Gxz9& SasBBoe Gpmzeyen...\n",
       "279   9_10              kag' 0: Sainllane Bwun' à 26r' 1sr \"9\n",
       "280   9_11                  Joaak + fnmauu dceehu 1919 Yeoeok\n",
       "281   9_12  [4Jg %eu 3- CBaslice fe At Z8ma 2e+eygu | Jwti...\n",
       "282   9_13  ~outi & Jeun 1919 fuwsuik Lg déclerations recl...\n",
       "\n",
       "[283 rows x 2 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easyOCR_output_df = pd.DataFrame(easyOCR_output.items(), columns=['file', 'text'])\n",
    "easyOCR_output_df[['file_name', 'line_name']] = easyOCR_output_df['file'].str.split('_', expand=True)\n",
    "easyOCR_output_df[['file_name', 'line_name']] = easyOCR_output_df[['file_name', 'line_name']].astype(int)\n",
    "easyOCR_output_df = easyOCR_output_df.sort_values(by=['file_name', 'line_name']).reset_index(drop=True)\n",
    "easyOCR_output_df['text'] = easyOCR_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "easyOCR_output_df['id'] = easyOCR_output_df['file_name'].astype(str) + '_' + easyOCR_output_df['line_name'].astype(str)\n",
    "easyOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "512ffd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "easyOCR_output_df.to_csv(path+'/results/postprocessed/easyOCR_perline_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09134009-83a9-4ed0-b724-d9a4096ebe7d",
   "metadata": {},
   "source": [
    "## Pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e86c0ee3-034b-446d-aa51-3e5e6e348fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pytesseractOCR(image_path):\n",
    "    try:\n",
    "        image = PILImage.open(image_path)\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text\n",
    "    except:\n",
    "        print(\"[ERROR] pytesseractOCR failed! (should be installed)\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f596a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseractOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = pytesseractOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        pytesseractOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8149b7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>line_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_00</td>\n",
       "      <td>|  = | DATE DU DEPOT  des  DECLARATIONS.  DESI...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_01</td>\n",
       "      <td>ft alt alta</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_02</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_03</td>\n",
       "      <td>a cnte |Abevcenk a dette  Son &lt;a  1040’  i ee ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_04</td>\n",
       "      <td>L  3  be oi  7  Nf »- p</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_09</td>\n",
       "      <td>149 28 auf  Si elaiawx  Ve  |  | Wvebly eu ty ...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>; a : oe ssa  song  o  Sannin nomena  ie 3 (0....</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>|  aul</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>Caen torah Winéorg ty dieser’  es  oe  aaa. pa...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>+ i 4 | pane um ‘ uy R | £5 dée! t ctfleati ec...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text  file_name  \\\n",
       "0     1_00  |  = | DATE DU DEPOT  des  DECLARATIONS.  DESI...          1   \n",
       "1     1_01                                       ft alt alta           1   \n",
       "2     1_02                                                             1   \n",
       "3     1_03  a cnte |Abevcenk a dette  Son <a  1040’  i ee ...          1   \n",
       "4     1_04                          L  3  be oi  7  Nf »- p            1   \n",
       "..     ...                                                ...        ...   \n",
       "278  20_09  149 28 auf  Si elaiawx  Ve  |  | Wvebly eu ty ...         20   \n",
       "279  20_10  ; a : oe ssa  song  o  Sannin nomena  ie 3 (0....         20   \n",
       "280  20_11                                            |  aul          20   \n",
       "281  20_12  Caen torah Winéorg ty dieser’  es  oe  aaa. pa...         20   \n",
       "282  20_13  + i 4 | pane um ‘ uy R | £5 dée! t ctfleati ec...         20   \n",
       "\n",
       "     line_name     id  \n",
       "0            0    1_0  \n",
       "1            1    1_1  \n",
       "2            2    1_2  \n",
       "3            3    1_3  \n",
       "4            4    1_4  \n",
       "..         ...    ...  \n",
       "278          9   20_9  \n",
       "279         10  20_10  \n",
       "280         11  20_11  \n",
       "281         12  20_12  \n",
       "282         13  20_13  \n",
       "\n",
       "[283 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytesseractOCR_output_df = pd.DataFrame(pytesseractOCR_output.items(), columns=['file', 'text'])\n",
    "pytesseractOCR_output_df[['file_name', 'line_name']] = pytesseractOCR_output_df['file'].str.split('_', expand=True)\n",
    "pytesseractOCR_output_df[['file_name', 'line_name']] = pytesseractOCR_output_df[['file_name', 'line_name']].astype(int)\n",
    "pytesseractOCR_output_df = pytesseractOCR_output_df.sort_values(by=['file_name', 'line_name']).reset_index(drop=True)\n",
    "pytesseractOCR_output_df['text'] = pytesseractOCR_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "pytesseractOCR_output_df['id'] = pytesseractOCR_output_df['file_name'].astype(str) + '_' + pytesseractOCR_output_df['line_name'].astype(str)\n",
    "pytesseractOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f26931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseractOCR_output_df.to_csv(path+'/results/postprocessed/pytesseractOCR_perline_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061630dd-6446-4a62-9b39-bd87c86a99f4",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "Not good for non-english?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e561f951-54a9-4d73-b778-41f9dbcdbe0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kerasOCR(image_path):\n",
    "    pipeline = keras_ocr.pipeline.Pipeline()\n",
    "    image = keras_ocr.tools.read(image_path)\n",
    "    prediction_groups = pipeline.recognize([image])\n",
    "    words = []\n",
    "    for line in prediction_groups[0]:\n",
    "        for word in line:\n",
    "            try:\n",
    "                if isinstance(word[0], str):\n",
    "                    words.append(word[0])\n",
    "            except IndexError:\n",
    "                continue\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e1e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = kerasOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        kerasOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "82c872cd-131c-4bc4-96cf-2dd2e62e0f59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for /Users/serenekim/.keras-ocr/craft_mlt_25k.h5\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: resize_bilinear (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.image.resize(...method=ResizeMethod.BILINEAR...)` instead.\n",
      "Looking for /Users/serenekim/.keras-ocr/crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 806ms/step\n",
      "1/1 [==============================] - 1s 751ms/step\n",
      "d r p o a g\n"
     ]
    }
   ],
   "source": [
    "test_keras = kerasOCR(image_path=test_path)\n",
    "print(test_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf6c0a",
   "metadata": {},
   "source": [
    "## TrOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cde01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor\n",
    "from transformers import VisionEncoderDecoderModel\n",
    "import torch\n",
    "\n",
    "def trOCR(image_path):\n",
    "    processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "\n",
    "    image = PILImage.open(image_path)\n",
    "\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "    \n",
    "    # Set device (GPU or CPU)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)  # Move model to the device\n",
    "    pixel_values = pixel_values.to(device)  # Move image tensor to the same device\n",
    "    \n",
    "    try:\n",
    "        generated_ids = model.generate(pixel_values, max_length=400)  # Limit max length\n",
    "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return generated_text\n",
    "    except IndexError as e:\n",
    "        print(f\"IndexError: {e}\")\n",
    "        return \"Error: Index out of range during generation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27ab20c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/serenekim/.pyenv/versions/3.12.0/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = trOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        trOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caa3c0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>line_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_00</td>\n",
       "      <td>treat of the first time of the French Parliame...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_01</td>\n",
       "      <td># almost be weighted rather any standard for t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_02</td>\n",
       "      <td># almost the original module you formerly ... ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_03</td>\n",
       "      <td>THE GREAT BRONDSOME \" AIRMARK GABIT PARADE HAN...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_04</td>\n",
       "      <td>After Congress plan himself tough back down to...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_09</td>\n",
       "      <td>Manager Atkinson had made many awareness of th...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>After the Democratic gubernatorial judge took ...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>the best time of fourteen songs with the first...</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>\" To absorb confidence being a total of 1 000 ...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>After the Renaissance season would change thei...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text  file_name  \\\n",
       "0     1_00  treat of the first time of the French Parliame...          1   \n",
       "1     1_01  # almost be weighted rather any standard for t...          1   \n",
       "2     1_02  # almost the original module you formerly ... ...          1   \n",
       "3     1_03  THE GREAT BRONDSOME \" AIRMARK GABIT PARADE HAN...          1   \n",
       "4     1_04  After Congress plan himself tough back down to...          1   \n",
       "..     ...                                                ...        ...   \n",
       "278  20_09  Manager Atkinson had made many awareness of th...         20   \n",
       "279  20_10  After the Democratic gubernatorial judge took ...         20   \n",
       "280  20_11  the best time of fourteen songs with the first...         20   \n",
       "281  20_12  \" To absorb confidence being a total of 1 000 ...         20   \n",
       "282  20_13  After the Renaissance season would change thei...         20   \n",
       "\n",
       "     line_name     id  \n",
       "0            0    1_0  \n",
       "1            1    1_1  \n",
       "2            2    1_2  \n",
       "3            3    1_3  \n",
       "4            4    1_4  \n",
       "..         ...    ...  \n",
       "278          9   20_9  \n",
       "279         10  20_10  \n",
       "280         11  20_11  \n",
       "281         12  20_12  \n",
       "282         13  20_13  \n",
       "\n",
       "[283 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trOCR_output_df = pd.DataFrame(trOCR_output.items(), columns=['file', 'text'])\n",
    "trOCR_output_df[['file_name', 'line_name']] = trOCR_output_df['file'].str.split('_', expand=True)\n",
    "trOCR_output_df[['file_name', 'line_name']] = trOCR_output_df[['file_name', 'line_name']].astype(int)\n",
    "trOCR_output_df = trOCR_output_df.sort_values(by=['file_name', 'line_name']).reset_index(drop=True)\n",
    "trOCR_output_df['text'] = trOCR_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "trOCR_output_df['id'] = trOCR_output_df['file_name'].astype(str) + '_' + trOCR_output_df['line_name'].astype(str)\n",
    "trOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd3cec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "trOCR_output_df.to_csv(path+'/results/postprocessed/trOCR_perline_output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
