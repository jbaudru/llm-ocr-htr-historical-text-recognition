{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c798e7-9579-4c02-88ca-0c57e52c2966",
   "metadata": {},
   "source": [
    "# per-line transcription with LLM & OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069d0fa8-6403-402b-954a-cbc05503eb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import base64\n",
    "import subprocess\n",
    "from IPython.display import display, Image\n",
    "from PIL import Image as PILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f521cad-9da9-4cdf-a63d-f5dd4ca3e4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "import pytesseract\n",
    "import keras_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "857d11aa-8fb9-4f32-a20c-5e418f5154e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = os.path.dirname(os.getcwd()) # Parent directory\n",
    "image_folder = path+'/data/lines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16012f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffd293ec-7b82-4145-820e-9e910c7d099d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OpenAI\n",
    "load_dotenv() #get the environment \n",
    "openai_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_client = OpenAI(api_key=openai_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9cc501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "anthropic_client = Anthropic(api_key=anthropic_API_KEY)\n",
    "MODEL_NAME = \"claude-3-5-sonnet-20240620\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4c585-70a5-466a-ac27-f730debebfba",
   "metadata": {},
   "source": [
    "## Read and encode the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e6f97e1-5798-4253-a324-58a38bae7f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b48666f-fd04-4f79-ba1a-8a254e9d81c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        images.append(image)\n",
    "\n",
    "rows = []\n",
    "for image in images:\n",
    "    name = image.split('.')[0]\n",
    "    name_split = name.split('_')[0]\n",
    "    file_name = name_split.split('example')[1]\n",
    "    line_name = name.split('_')[1]\n",
    "    encoded_value = encode_image(image_folder+'/'+image)\n",
    "    rows.append({'file': file_name, 'line': line_name, 'encoded': encoded_value})\n",
    "\n",
    "images_encoded = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c988074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>line</th>\n",
       "      <th>encoded</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/9j/4QZBRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>/9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>/9j/4QYvRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>/9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>/9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>/9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>/9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>/9j/4QWRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>/9j/4QZyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>/9j/4QZRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>/9j/4QZ1RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>/9j/4QVrRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>/9j/4QaFRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QcyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>/9j/4QVORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>/9j/4QX+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>/9j/4QY6RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>/9j/4QaQRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>/9j/4QVWRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>/9j/4QZ3RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>/9j/4QXbRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>/9j/4QaORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>/9j/4QWIRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>/9j/4QWARXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>/9j/4QZwRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>/9j/4QZlRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>/9j/4QV+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>/9j/4QbYRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QbPRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>3_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file  line                                            encoded    id\n",
       "0      1     0  /9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_0\n",
       "1      1     1  /9j/4QZBRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_1\n",
       "2      1     2  /9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_2\n",
       "3      1     3  /9j/4QYvRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_3\n",
       "4      1     4  /9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_4\n",
       "5      1     5  /9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_5\n",
       "6      1     6  /9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_6\n",
       "7      1     7  /9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_7\n",
       "8      1     8  /9j/4QWRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_8\n",
       "9      1     9  /9j/4QZyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_9\n",
       "10     1    10  /9j/4QZRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_10\n",
       "11     1    11  /9j/4QZ1RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_11\n",
       "12     1    12  /9j/4QVrRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_12\n",
       "13     1    13  /9j/4QaFRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_13\n",
       "14     2     0  /9j/4QcyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_0\n",
       "15     2     1  /9j/4QVORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_1\n",
       "16     2     2  /9j/4QX+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_2\n",
       "17     2     3  /9j/4QY6RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_3\n",
       "18     2     4  /9j/4QaQRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_4\n",
       "19     2     5  /9j/4QVWRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_5\n",
       "20     2     6  /9j/4QZ3RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_6\n",
       "21     2     7  /9j/4QXbRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_7\n",
       "22     2     8  /9j/4QaORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_8\n",
       "23     2     9  /9j/4QWIRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_9\n",
       "24     2    10  /9j/4QWARXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_10\n",
       "25     2    11  /9j/4QZwRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_11\n",
       "26     2    12  /9j/4QZlRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_12\n",
       "27     2    13  /9j/4QV+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_13\n",
       "28     2    14  /9j/4QbYRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_14\n",
       "29     3     0  /9j/4QbPRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...   3_0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_encoded['file'] = images_encoded['file'].astype('int')\n",
    "images_encoded['line'] = images_encoded['line'].astype('int')\n",
    "images_encoded = images_encoded.sort_values(by=['file', 'line']).reset_index(drop=True)\n",
    "images_encoded['id'] = images_encoded['file'].astype(str) + '_' + images_encoded['line'].astype(str)\n",
    "images_encoded.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa240d54",
   "metadata": {},
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd51de42-7ecf-4171-88fd-cc78fb803632",
   "metadata": {},
   "source": [
    "## General API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73f51be1-2815-4280-ab50-4a909baf7016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def callOpenAI(prompt, max_tokens=800, base64_image=None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_API_KEY}\"\n",
    "    } \n",
    "    model_vision = \"gpt-4o\"\n",
    "    payload = {\n",
    "        \"model\": model_vision, \n",
    "        \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "            \n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                }\n",
    "            }\n",
    "            ]\n",
    "        }\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    try:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except:\n",
    "        print(response.json()[\"error\"][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6be70b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callAnthropic(prompt, max_tokens=5000, base64_image=None):\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=max_tokens,\n",
    "        system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\", \n",
    "                            \"media_type\": \"image/jpeg\", \n",
    "                            \"data\": base64_image}},\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt,\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.to_dict()[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a94328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callPostProcessing(max_tokens=800, prompt_parameter = None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_API_KEY}\"\n",
    "    } \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"\"\"This is an output from you. Clean it such that we have no separators and no comment from you: {prompt_parameter}\n",
    "                \"\"\"\n",
    "            }\n",
    "            ]\n",
    "        }\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    try:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except:\n",
    "        print(response.json()[\"error\"][\"message\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b44a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this when OpenAI credits are exhausted\n",
    "def callPostProcessing_anthropic(max_tokens=5000, prompt_parameter = None):\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=max_tokens,\n",
    "        system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"\"\"This is an output from you. Clean it such that we have no separators and no comment from you: {prompt_parameter}\n",
    "                \"\"\"\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.to_dict()[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65f775",
   "metadata": {},
   "source": [
    "### Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56c01d37-e85d-45ee-b6c8-9e92b5078e87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/xy/r3gq5vtd7bx6qb966l0fhh9h0000gn/T/ipykernel_45019/795820489.py:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  prompt_complex = \"\"\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "    Recognize the text from the image:\n",
    "    ```plaintext\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_complex = \"\"\"\n",
    "    Context:\n",
    "        It's an old Belgian document. And you're getting one row of a table from it. It's written in French language and the names of the people are domiciles are Belgian.\n",
    "\n",
    "    Structure:\n",
    "        The table is structured with the two-level headers as follows:\n",
    "        [(\"N' d'ordre\", \" \"),\n",
    "                (\"Date du dépot des déclarations\", \" \"),\n",
    "                (\"Désignation des personnes décédées ou absentes.:\", \"Nom.\"),\n",
    "                (\"Désignation des personnes décédées ou absentes.:\", \"Prénoms\"),\n",
    "                (\"Désignation des personnes décédées ou absentes.:\", \"Domiciles\"), \n",
    "                (\"Date du décès ou du judgement d'envoi en possession, en cas d'absence.\", \" \"),\n",
    "                (\"Noms, Prénoms et demeures des parties déclarantes.\", \" \"),\n",
    "                (\"Droits de succession en ligne collatérale et de mutation en ligne directe.\", \"Actif. (2)\"),\n",
    "                (\"Droits de succession en ligne collatérale et de mutation en ligne directe.\", \"Passif. (2)\"),\n",
    "                (\"Droits de succession en ligne collatérale et de mutation en ligne directe.\", \"Restant NET. (2)\"),\n",
    "                (\"Droit de mutation par décès\", \"Valeur des immeubles. (2)\"), \n",
    "                (\"Numéros des déclarations\", \"Primitives.\"),\n",
    "                (\"Numéros des déclarations\", \"Supplémentaires.\"), \n",
    "                (\"Date\", \"de l'expiration du délai de rectification.\"),\n",
    "                (\"Date\", \"de l'exigibilité des droits.\"),\n",
    "                (\"Numéros de la consignation des droits au sommier n' 28\", \" \"),\n",
    "                (\"Recette des droits et amendes.\", \"Date\"),\n",
    "                (\"Recette des droits et amendes.\", \"N^03\"),\n",
    "                (\"Cautionnements. \", \"Numéros de la consignation au sommier n'30\"),\n",
    "                (\"Observations (les déclarations qui figurent à l'état n'413 doivent être émargées en conséquence, dans la présente colonne.)\", \" \")] \n",
    "\n",
    "        Some image (hence, some rows) may start with \"Arrêté le \\d{2} \\w+ \\d{4}( \\w+)? servais\" or contain notes.\n",
    "\n",
    "    Task:\n",
    "        Recognize the text from the image. Pay attention to reading each word and number correctly. Return the text as you read it and you must read the text from the image since the image contains texts.\n",
    "    ```plaintext \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2e72bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_ids = ['1_0', '2_0', '3_0', '4_0', '5_0', '6_0', '7_0', '8_0', '9_0', '10_0',\n",
    "              '11_0', '12_0', '13_0', '14_0', '15_0', '16_0', '17_0', '18_0', '19_0', '20_0']\n",
    "typo_ids = ['4_1', '4_7', '8_2', '8_5', '8_10', '13_9', '16_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a15e1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "unable_ids = ['18_0', '19_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7fedafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Start processing file 18_0 -------\n",
      "------- Finished processing file 18_0 in 9.064611911773682 seconds -------\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Load previous progress if available\n",
    "try:\n",
    "    with open('claude_complex_output_progress.json', 'r') as file:\n",
    "        claude_complex_output = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    claude_complex_output = {}\n",
    "\n",
    "# Loop through each unique id\n",
    "# for id in images_encoded['id'].unique():\n",
    "# for id in header_ids+typo_ids:\n",
    "for id in unable_ids:\n",
    "    # Check if this ID is already processed (Skip this step if you want to re-process for unable_ids) ----------------\n",
    "    # if id in claude_complex_output:\n",
    "    #     print(f\"Skipping {id}, already processed.\")\n",
    "    #     continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        print(f'------- Start processing file {id} -------')\n",
    "        \n",
    "        # Call OpenAI/Anthropic and post-processing functions\n",
    "        prompt_complex += \"Even if it is hard to read the texts from the image, return as much as you can. You must read something. Do not return an apologetic message.\"\n",
    "        # output = callOpenAI(prompt=prompt_complex, max_tokens=800, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0])\n",
    "        output = callAnthropic(prompt=prompt_complex, max_tokens=800, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0])\n",
    "        output_cleaned = callPostProcessing(prompt_parameter=output)\n",
    "        \n",
    "        # Save the output\n",
    "        claude_complex_output[id] = output_cleaned\n",
    "        \n",
    "        # Save progress after each file\n",
    "        with open('claude_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_complex_output, file)\n",
    "        \n",
    "        print(f'------- Finished processing file {id} in {time.time() - start_time} seconds -------')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {id}: {str(e)}\")\n",
    "        # Save the progress and exit the loop in case of an error\n",
    "        with open('claude_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_complex_output, file)\n",
    "        break  # Exit the loop on error\n",
    "\n",
    "# Once all IDs are processed, save the final result\n",
    "with open('claude_complex_output_final.json', 'w') as file:\n",
    "    json.dump(claude_complex_output, file)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc31c4e8",
   "metadata": {},
   "source": [
    "### Few-shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24130132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'/data/transcriptions_perline_cleaned.csv', encoding='utf-8')\n",
    "df.replace({u'\\xa0': ' '}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95afd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = images_encoded[images_encoded['id'] == '1_1'].encoded.values[0]\n",
    "example2 = images_encoded[images_encoded['id'] == '1_3'].encoded.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c14ff3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_encoded_oneshot = images_encoded[~images_encoded['id'].isin(['1_1'])]\n",
    "images_encoded_twoshot = images_encoded[~images_encoded['id'].isin(['1_1', '1_3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbaa3fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "example1_text = df[df['id'] == '1_1'].text.values[0]\n",
    "example2_text = df[df['id'] == '1_3'].text.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "998fc479",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_texts =  [example1_text,example2_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a7b9774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arrêté le vingt huit octobre 1919 servais',\n",
       " '398 trente octobre Herrent Alphones gh Ophain 16 9b 1918 Herrent Maris & autres 2280 1045 1235 11 Db 1919 15 7bre 1919  7 avril 1920 303']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b683c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_encoded_extexts = images_encoded[~images_encoded['id'].isin(['1_1', '1_3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d04a03ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_example =  \"\"\"\n",
    "#     Recognize the texts from the image like the examples.\n",
    "#     ```plaintext\n",
    "#     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0bdb0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example1_text or exmple_texts\n",
    "prompt_example_text = f\"\"\"\n",
    "                        The ```plaintext block is the example transcription of the example image you saw:\n",
    "\n",
    "                        Transcription:\n",
    "                        ```plaintext\n",
    "                        {example_texts}\n",
    "                        ```\n",
    "                        Compare what you read initially and the solution key in ```plaintext block. Recreate the content of the table in this image. Only that, no other information from you.\n",
    "\n",
    "                        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "721c10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callOpenAI_example(prompt, NExample=1, base64_image=None, max_tokens=5000):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_API_KEY}\"\n",
    "    } \n",
    "    model_vision = \"gpt-4o\"\n",
    "\n",
    "    if NExample == 1:\n",
    "        payload = {\n",
    "            \"model\": model_vision, \n",
    "            \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "                \n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{example1}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": example1_text\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "                ]\n",
    "            }\n",
    "            ],\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    if NExample == 2:\n",
    "               payload = {\n",
    "            \"model\": model_vision, \n",
    "            \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "                \n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{example1}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": example1_text\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{example2}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": example2_text\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "                ]\n",
    "            }\n",
    "            ],\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    try:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except:\n",
    "        print(response.json()[\"error\"][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adc4a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callAnthropic_example(prompt, NExample=1, base64_image=None, max_tokens=5000):\n",
    "    if NExample == 1:\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=max_tokens,\n",
    "            system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": example1}},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example1_text,\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt,\n",
    "                        },\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": base64_image}}\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "        \n",
    "    if NExample == 2:\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=max_tokens,\n",
    "            system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": example1}},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example1_text,\n",
    "                        },\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": example2}},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example2_text,\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt,\n",
    "                        },\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": base64_image}}\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "    return response.to_dict()[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "663dc214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>line</th>\n",
       "      <th>encoded</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>/9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>/9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>/9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>/9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>/9j/4QY7RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>/9j/4QY3RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>/9j/4QWhRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>/9j/4QUtRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>/9j/4QX3RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     file  line                                            encoded     id\n",
       "0       1     0  /9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_0\n",
       "2       1     2  /9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_2\n",
       "4       1     4  /9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_4\n",
       "5       1     5  /9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_5\n",
       "6       1     6  /9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...    1_6\n",
       "..    ...   ...                                                ...    ...\n",
       "278    20     9  /9j/4QY7RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...   20_9\n",
       "279    20    10  /9j/4QY3RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...  20_10\n",
       "280    20    11  /9j/4QWhRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...  20_11\n",
       "281    20    12  /9j/4QUtRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...  20_12\n",
       "282    20    13  /9j/4QX3RXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...  20_13\n",
       "\n",
       "[281 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_encoded_twoshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caa07d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 1_0, already processed.\n",
      "Skipping 1_2, already processed.\n",
      "Skipping 1_4, already processed.\n",
      "Skipping 1_5, already processed.\n",
      "Skipping 1_6, already processed.\n",
      "Skipping 1_7, already processed.\n",
      "Skipping 1_8, already processed.\n",
      "Skipping 1_9, already processed.\n",
      "Skipping 1_10, already processed.\n",
      "Skipping 1_11, already processed.\n",
      "Skipping 1_12, already processed.\n",
      "Skipping 1_13, already processed.\n",
      "Skipping 2_0, already processed.\n",
      "Skipping 2_1, already processed.\n",
      "Skipping 2_2, already processed.\n",
      "Skipping 2_3, already processed.\n",
      "Skipping 2_4, already processed.\n",
      "Skipping 2_5, already processed.\n",
      "Skipping 2_6, already processed.\n",
      "Skipping 2_7, already processed.\n",
      "Skipping 2_8, already processed.\n",
      "Skipping 2_9, already processed.\n",
      "Skipping 2_10, already processed.\n",
      "Skipping 2_11, already processed.\n",
      "Skipping 2_12, already processed.\n",
      "Skipping 2_13, already processed.\n",
      "Skipping 2_14, already processed.\n",
      "Skipping 3_0, already processed.\n",
      "Skipping 3_1, already processed.\n",
      "Skipping 3_2, already processed.\n",
      "Skipping 3_3, already processed.\n",
      "Skipping 3_4, already processed.\n",
      "Skipping 3_5, already processed.\n",
      "Skipping 3_6, already processed.\n",
      "Skipping 3_7, already processed.\n",
      "Skipping 3_8, already processed.\n",
      "Skipping 3_9, already processed.\n",
      "Skipping 3_10, already processed.\n",
      "Skipping 3_11, already processed.\n",
      "Skipping 3_12, already processed.\n",
      "Skipping 3_13, already processed.\n",
      "Skipping 4_0, already processed.\n",
      "Skipping 4_1, already processed.\n",
      "Skipping 4_2, already processed.\n",
      "Skipping 4_3, already processed.\n",
      "Skipping 4_4, already processed.\n",
      "Skipping 4_5, already processed.\n",
      "Skipping 4_6, already processed.\n",
      "Skipping 4_7, already processed.\n",
      "Skipping 4_8, already processed.\n",
      "Skipping 4_9, already processed.\n",
      "Skipping 4_10, already processed.\n",
      "Skipping 4_11, already processed.\n",
      "Skipping 4_12, already processed.\n",
      "Skipping 4_13, already processed.\n",
      "Skipping 5_0, already processed.\n",
      "Skipping 5_1, already processed.\n",
      "Skipping 5_2, already processed.\n",
      "Skipping 5_3, already processed.\n",
      "Skipping 5_4, already processed.\n",
      "Skipping 5_5, already processed.\n",
      "Skipping 5_6, already processed.\n",
      "Skipping 5_7, already processed.\n",
      "Skipping 5_8, already processed.\n",
      "Skipping 5_9, already processed.\n",
      "Skipping 5_10, already processed.\n",
      "Skipping 5_11, already processed.\n",
      "Skipping 5_12, already processed.\n",
      "Skipping 5_13, already processed.\n",
      "Skipping 5_14, already processed.\n",
      "Skipping 6_0, already processed.\n",
      "Skipping 6_1, already processed.\n",
      "Skipping 6_2, already processed.\n",
      "Skipping 6_3, already processed.\n",
      "Skipping 6_4, already processed.\n",
      "Skipping 6_5, already processed.\n",
      "Skipping 6_6, already processed.\n",
      "Skipping 6_7, already processed.\n",
      "Skipping 6_8, already processed.\n",
      "Skipping 6_9, already processed.\n",
      "Skipping 6_10, already processed.\n",
      "Skipping 6_11, already processed.\n",
      "Skipping 6_12, already processed.\n",
      "Skipping 6_13, already processed.\n",
      "Skipping 6_14, already processed.\n",
      "Skipping 7_0, already processed.\n",
      "Skipping 7_1, already processed.\n",
      "Skipping 7_2, already processed.\n",
      "Skipping 7_3, already processed.\n",
      "Skipping 7_4, already processed.\n",
      "Skipping 7_5, already processed.\n",
      "Skipping 7_6, already processed.\n",
      "Skipping 7_7, already processed.\n",
      "Skipping 7_8, already processed.\n",
      "Skipping 7_9, already processed.\n",
      "Skipping 7_10, already processed.\n",
      "Skipping 7_11, already processed.\n",
      "Skipping 7_12, already processed.\n",
      "Skipping 7_13, already processed.\n",
      "Skipping 8_0, already processed.\n",
      "Skipping 8_1, already processed.\n",
      "Skipping 8_2, already processed.\n",
      "Skipping 8_3, already processed.\n",
      "Skipping 8_4, already processed.\n",
      "Skipping 8_5, already processed.\n",
      "Skipping 8_6, already processed.\n",
      "Skipping 8_7, already processed.\n",
      "Skipping 8_8, already processed.\n",
      "Skipping 8_9, already processed.\n",
      "Skipping 8_10, already processed.\n",
      "Skipping 8_11, already processed.\n",
      "Skipping 8_12, already processed.\n",
      "Skipping 8_13, already processed.\n",
      "Skipping 9_0, already processed.\n",
      "Skipping 9_1, already processed.\n",
      "------- Start processing file 9_2 -------\n",
      "------- Finished processing file 9_2 in 5.9803338050842285 seconds -------\n",
      "------- Start processing file 9_3 -------\n",
      "------- Finished processing file 9_3 in 3.9433650970458984 seconds -------\n",
      "------- Start processing file 9_4 -------\n",
      "------- Finished processing file 9_4 in 3.562434196472168 seconds -------\n",
      "------- Start processing file 9_5 -------\n",
      "------- Finished processing file 9_5 in 2.991117238998413 seconds -------\n",
      "------- Start processing file 9_6 -------\n",
      "------- Finished processing file 9_6 in 3.1565940380096436 seconds -------\n",
      "------- Start processing file 9_7 -------\n",
      "------- Finished processing file 9_7 in 5.729647874832153 seconds -------\n",
      "------- Start processing file 9_8 -------\n",
      "------- Finished processing file 9_8 in 3.4771833419799805 seconds -------\n",
      "------- Start processing file 9_9 -------\n",
      "------- Finished processing file 9_9 in 6.223984718322754 seconds -------\n",
      "------- Start processing file 9_10 -------\n",
      "------- Finished processing file 9_10 in 5.2583959102630615 seconds -------\n",
      "------- Start processing file 9_11 -------\n",
      "------- Finished processing file 9_11 in 3.8259871006011963 seconds -------\n",
      "------- Start processing file 9_12 -------\n",
      "------- Finished processing file 9_12 in 5.306185007095337 seconds -------\n",
      "------- Start processing file 9_13 -------\n",
      "------- Finished processing file 9_13 in 6.32213020324707 seconds -------\n",
      "------- Start processing file 10_0 -------\n",
      "------- Finished processing file 10_0 in 9.744650840759277 seconds -------\n",
      "------- Start processing file 10_1 -------\n",
      "------- Finished processing file 10_1 in 5.714744806289673 seconds -------\n",
      "------- Start processing file 10_2 -------\n",
      "------- Finished processing file 10_2 in 6.890163898468018 seconds -------\n",
      "------- Start processing file 10_3 -------\n",
      "------- Finished processing file 10_3 in 3.891219139099121 seconds -------\n",
      "------- Start processing file 10_4 -------\n",
      "------- Finished processing file 10_4 in 4.866461992263794 seconds -------\n",
      "------- Start processing file 10_5 -------\n",
      "------- Finished processing file 10_5 in 2.916826009750366 seconds -------\n",
      "------- Start processing file 10_6 -------\n",
      "------- Finished processing file 10_6 in 7.575764179229736 seconds -------\n",
      "------- Start processing file 10_7 -------\n",
      "------- Finished processing file 10_7 in 5.63365912437439 seconds -------\n",
      "------- Start processing file 10_8 -------\n",
      "------- Finished processing file 10_8 in 2.808666229248047 seconds -------\n",
      "------- Start processing file 10_9 -------\n",
      "------- Finished processing file 10_9 in 3.1302242279052734 seconds -------\n",
      "------- Start processing file 10_10 -------\n",
      "------- Finished processing file 10_10 in 5.32650089263916 seconds -------\n",
      "------- Start processing file 10_11 -------\n",
      "------- Finished processing file 10_11 in 6.144952774047852 seconds -------\n",
      "------- Start processing file 10_12 -------\n",
      "------- Finished processing file 10_12 in 4.399252891540527 seconds -------\n",
      "------- Start processing file 10_13 -------\n",
      "------- Finished processing file 10_13 in 3.9314770698547363 seconds -------\n",
      "------- Start processing file 11_0 -------\n",
      "------- Finished processing file 11_0 in 13.785361051559448 seconds -------\n",
      "------- Start processing file 11_1 -------\n",
      "------- Finished processing file 11_1 in 2.9788870811462402 seconds -------\n",
      "------- Start processing file 11_2 -------\n",
      "------- Finished processing file 11_2 in 6.745999813079834 seconds -------\n",
      "------- Start processing file 11_3 -------\n",
      "------- Finished processing file 11_3 in 6.421127796173096 seconds -------\n",
      "------- Start processing file 11_4 -------\n",
      "------- Finished processing file 11_4 in 6.788288116455078 seconds -------\n",
      "------- Start processing file 11_5 -------\n",
      "------- Finished processing file 11_5 in 3.790985107421875 seconds -------\n",
      "------- Start processing file 11_6 -------\n",
      "------- Finished processing file 11_6 in 5.017904996871948 seconds -------\n",
      "------- Start processing file 11_7 -------\n",
      "------- Finished processing file 11_7 in 7.0630409717559814 seconds -------\n",
      "------- Start processing file 11_8 -------\n",
      "------- Finished processing file 11_8 in 4.811560869216919 seconds -------\n",
      "------- Start processing file 11_9 -------\n",
      "------- Finished processing file 11_9 in 5.514311075210571 seconds -------\n",
      "------- Start processing file 11_10 -------\n",
      "------- Finished processing file 11_10 in 3.7028801441192627 seconds -------\n",
      "------- Start processing file 11_11 -------\n",
      "------- Finished processing file 11_11 in 6.147491216659546 seconds -------\n",
      "------- Start processing file 11_12 -------\n",
      "------- Finished processing file 11_12 in 7.577868223190308 seconds -------\n",
      "------- Start processing file 11_13 -------\n",
      "------- Finished processing file 11_13 in 5.732262134552002 seconds -------\n",
      "------- Start processing file 12_0 -------\n",
      "------- Finished processing file 12_0 in 10.107376337051392 seconds -------\n",
      "------- Start processing file 12_1 -------\n",
      "------- Finished processing file 12_1 in 3.5082921981811523 seconds -------\n",
      "------- Start processing file 12_2 -------\n",
      "------- Finished processing file 12_2 in 7.068670272827148 seconds -------\n",
      "------- Start processing file 12_3 -------\n",
      "------- Finished processing file 12_3 in 5.017258167266846 seconds -------\n",
      "------- Start processing file 12_4 -------\n",
      "------- Finished processing file 12_4 in 5.627704858779907 seconds -------\n",
      "------- Start processing file 12_5 -------\n",
      "------- Finished processing file 12_5 in 9.324676752090454 seconds -------\n",
      "------- Start processing file 12_6 -------\n",
      "------- Finished processing file 12_6 in 12.074795007705688 seconds -------\n",
      "------- Start processing file 12_7 -------\n",
      "------- Finished processing file 12_7 in 6.4600160121917725 seconds -------\n",
      "------- Start processing file 12_8 -------\n",
      "------- Finished processing file 12_8 in 10.400027990341187 seconds -------\n",
      "------- Start processing file 12_9 -------\n",
      "------- Finished processing file 12_9 in 5.264230966567993 seconds -------\n",
      "------- Start processing file 12_10 -------\n",
      "------- Finished processing file 12_10 in 5.5381999015808105 seconds -------\n",
      "------- Start processing file 12_11 -------\n",
      "------- Finished processing file 12_11 in 4.288914918899536 seconds -------\n",
      "------- Start processing file 12_12 -------\n",
      "------- Finished processing file 12_12 in 6.397968292236328 seconds -------\n",
      "------- Start processing file 12_13 -------\n",
      "------- Finished processing file 12_13 in 15.00593876838684 seconds -------\n",
      "------- Start processing file 13_0 -------\n",
      "------- Finished processing file 13_0 in 10.858968257904053 seconds -------\n",
      "------- Start processing file 13_1 -------\n",
      "------- Finished processing file 13_1 in 3.8876490592956543 seconds -------\n",
      "------- Start processing file 13_2 -------\n",
      "------- Finished processing file 13_2 in 6.750146865844727 seconds -------\n",
      "------- Start processing file 13_3 -------\n",
      "------- Finished processing file 13_3 in 6.407724857330322 seconds -------\n",
      "------- Start processing file 13_4 -------\n",
      "------- Finished processing file 13_4 in 6.909870147705078 seconds -------\n",
      "------- Start processing file 13_5 -------\n",
      "------- Finished processing file 13_5 in 5.734596014022827 seconds -------\n",
      "------- Start processing file 13_6 -------\n",
      "------- Finished processing file 13_6 in 6.473451137542725 seconds -------\n",
      "------- Start processing file 13_7 -------\n",
      "------- Finished processing file 13_7 in 7.348659992218018 seconds -------\n",
      "------- Start processing file 13_8 -------\n",
      "------- Finished processing file 13_8 in 5.121712923049927 seconds -------\n",
      "------- Start processing file 13_9 -------\n",
      "------- Finished processing file 13_9 in 16.178709030151367 seconds -------\n",
      "------- Start processing file 13_10 -------\n",
      "------- Finished processing file 13_10 in 7.785699129104614 seconds -------\n",
      "------- Start processing file 13_11 -------\n",
      "------- Finished processing file 13_11 in 9.827254056930542 seconds -------\n",
      "------- Start processing file 13_12 -------\n",
      "------- Finished processing file 13_12 in 8.092918157577515 seconds -------\n",
      "------- Start processing file 13_13 -------\n",
      "------- Finished processing file 13_13 in 5.204737901687622 seconds -------\n",
      "------- Start processing file 14_0 -------\n",
      "------- Finished processing file 14_0 in 9.947041749954224 seconds -------\n",
      "------- Start processing file 14_1 -------\n",
      "------- Finished processing file 14_1 in 6.047850847244263 seconds -------\n",
      "------- Start processing file 14_2 -------\n",
      "------- Finished processing file 14_2 in 7.161050081253052 seconds -------\n",
      "------- Start processing file 14_3 -------\n",
      "------- Finished processing file 14_3 in 6.757159948348999 seconds -------\n",
      "------- Start processing file 14_4 -------\n",
      "------- Finished processing file 14_4 in 4.202188014984131 seconds -------\n",
      "------- Start processing file 14_5 -------\n",
      "------- Finished processing file 14_5 in 5.220997095108032 seconds -------\n",
      "------- Start processing file 14_6 -------\n",
      "------- Finished processing file 14_6 in 10.956701040267944 seconds -------\n",
      "------- Start processing file 14_7 -------\n",
      "------- Finished processing file 14_7 in 7.883196830749512 seconds -------\n",
      "------- Start processing file 14_8 -------\n",
      "------- Finished processing file 14_8 in 13.022675037384033 seconds -------\n",
      "------- Start processing file 14_9 -------\n",
      "------- Finished processing file 14_9 in 18.049484968185425 seconds -------\n",
      "------- Start processing file 14_10 -------\n",
      "------- Finished processing file 14_10 in 5.89401388168335 seconds -------\n",
      "------- Start processing file 14_11 -------\n",
      "------- Finished processing file 14_11 in 6.350977182388306 seconds -------\n",
      "------- Start processing file 14_12 -------\n",
      "------- Finished processing file 14_12 in 5.834558010101318 seconds -------\n",
      "------- Start processing file 14_13 -------\n",
      "------- Finished processing file 14_13 in 8.917028903961182 seconds -------\n",
      "------- Start processing file 15_0 -------\n",
      "------- Finished processing file 15_0 in 8.500107049942017 seconds -------\n",
      "------- Start processing file 15_1 -------\n",
      "------- Finished processing file 15_1 in 7.2813708782196045 seconds -------\n",
      "------- Start processing file 15_2 -------\n",
      "------- Finished processing file 15_2 in 251.0645089149475 seconds -------\n",
      "------- Start processing file 15_3 -------\n",
      "------- Finished processing file 15_3 in 4.713176012039185 seconds -------\n",
      "------- Start processing file 15_4 -------\n",
      "------- Finished processing file 15_4 in 5.32283616065979 seconds -------\n",
      "------- Start processing file 15_5 -------\n",
      "------- Finished processing file 15_5 in 8.701546907424927 seconds -------\n",
      "------- Start processing file 15_6 -------\n",
      "------- Finished processing file 15_6 in 5.22412896156311 seconds -------\n",
      "------- Start processing file 15_7 -------\n",
      "------- Finished processing file 15_7 in 6.039297103881836 seconds -------\n",
      "------- Start processing file 15_8 -------\n",
      "------- Finished processing file 15_8 in 9.523542881011963 seconds -------\n",
      "------- Start processing file 15_9 -------\n",
      "------- Finished processing file 15_9 in 6.451436996459961 seconds -------\n",
      "------- Start processing file 15_10 -------\n",
      "------- Finished processing file 15_10 in 4.099165916442871 seconds -------\n",
      "------- Start processing file 15_11 -------\n",
      "------- Finished processing file 15_11 in 5.630236864089966 seconds -------\n",
      "------- Start processing file 15_12 -------\n",
      "------- Finished processing file 15_12 in 5.322643995285034 seconds -------\n",
      "------- Start processing file 15_13 -------\n",
      "------- Finished processing file 15_13 in 11.367463111877441 seconds -------\n",
      "------- Start processing file 16_0 -------\n",
      "------- Finished processing file 16_0 in 14.53906512260437 seconds -------\n",
      "------- Start processing file 16_1 -------\n",
      "------- Finished processing file 16_1 in 8.400010824203491 seconds -------\n",
      "------- Start processing file 16_2 -------\n",
      "------- Finished processing file 16_2 in 7.986018896102905 seconds -------\n",
      "------- Start processing file 16_3 -------\n",
      "------- Finished processing file 16_3 in 6.98237419128418 seconds -------\n",
      "------- Start processing file 16_4 -------\n",
      "------- Finished processing file 16_4 in 4.692561149597168 seconds -------\n",
      "------- Start processing file 16_5 -------\n",
      "------- Finished processing file 16_5 in 3.4531466960906982 seconds -------\n",
      "------- Start processing file 16_6 -------\n",
      "------- Finished processing file 16_6 in 3.8958680629730225 seconds -------\n",
      "------- Start processing file 16_7 -------\n",
      "------- Finished processing file 16_7 in 5.99665379524231 seconds -------\n",
      "------- Start processing file 16_8 -------\n",
      "------- Finished processing file 16_8 in 6.211111068725586 seconds -------\n",
      "------- Start processing file 16_9 -------\n",
      "------- Finished processing file 16_9 in 3.1727328300476074 seconds -------\n",
      "------- Start processing file 16_10 -------\n",
      "------- Finished processing file 16_10 in 3.8897011280059814 seconds -------\n",
      "------- Start processing file 16_11 -------\n",
      "------- Finished processing file 16_11 in 7.169394016265869 seconds -------\n",
      "------- Start processing file 16_12 -------\n",
      "------- Finished processing file 16_12 in 14.549452066421509 seconds -------\n",
      "------- Start processing file 16_13 -------\n",
      "------- Finished processing file 16_13 in 4.682738780975342 seconds -------\n",
      "------- Start processing file 17_0 -------\n",
      "------- Finished processing file 17_0 in 8.054534912109375 seconds -------\n",
      "------- Start processing file 17_1 -------\n",
      "------- Finished processing file 17_1 in 3.4311649799346924 seconds -------\n",
      "------- Start processing file 17_2 -------\n",
      "------- Finished processing file 17_2 in 8.704256057739258 seconds -------\n",
      "------- Start processing file 17_3 -------\n",
      "------- Finished processing file 17_3 in 6.352062940597534 seconds -------\n",
      "------- Start processing file 17_4 -------\n",
      "------- Finished processing file 17_4 in 4.606400012969971 seconds -------\n",
      "------- Start processing file 17_5 -------\n",
      "------- Finished processing file 17_5 in 6.961977005004883 seconds -------\n",
      "------- Start processing file 17_6 -------\n",
      "------- Finished processing file 17_6 in 5.434214115142822 seconds -------\n",
      "------- Start processing file 17_7 -------\n",
      "------- Finished processing file 17_7 in 8.292062282562256 seconds -------\n",
      "------- Start processing file 17_8 -------\n",
      "------- Finished processing file 17_8 in 5.521790981292725 seconds -------\n",
      "------- Start processing file 17_9 -------\n",
      "------- Finished processing file 17_9 in 7.512086868286133 seconds -------\n",
      "------- Start processing file 17_10 -------\n",
      "------- Finished processing file 17_10 in 8.052038192749023 seconds -------\n",
      "------- Start processing file 17_11 -------\n",
      "------- Finished processing file 17_11 in 7.785217046737671 seconds -------\n",
      "------- Start processing file 17_12 -------\n",
      "------- Finished processing file 17_12 in 5.943120002746582 seconds -------\n",
      "------- Start processing file 17_13 -------\n",
      "------- Finished processing file 17_13 in 8.389983892440796 seconds -------\n",
      "------- Start processing file 18_0 -------\n",
      "------- Finished processing file 18_0 in 11.060918092727661 seconds -------\n",
      "------- Start processing file 18_1 -------\n",
      "------- Finished processing file 18_1 in 4.815776109695435 seconds -------\n",
      "------- Start processing file 18_2 -------\n",
      "------- Finished processing file 18_2 in 4.7630109786987305 seconds -------\n",
      "------- Start processing file 18_3 -------\n",
      "------- Finished processing file 18_3 in 6.3960230350494385 seconds -------\n",
      "------- Start processing file 18_4 -------\n",
      "------- Finished processing file 18_4 in 7.783418893814087 seconds -------\n",
      "------- Start processing file 18_5 -------\n",
      "------- Finished processing file 18_5 in 5.6328136920928955 seconds -------\n",
      "------- Start processing file 18_6 -------\n",
      "------- Finished processing file 18_6 in 6.244452714920044 seconds -------\n",
      "------- Start processing file 18_7 -------\n",
      "------- Finished processing file 18_7 in 7.46194314956665 seconds -------\n",
      "------- Start processing file 18_8 -------\n",
      "------- Finished processing file 18_8 in 11.895967960357666 seconds -------\n",
      "------- Start processing file 18_9 -------\n",
      "------- Finished processing file 18_9 in 8.80305004119873 seconds -------\n",
      "------- Start processing file 18_10 -------\n",
      "------- Finished processing file 18_10 in 14.33561658859253 seconds -------\n",
      "------- Start processing file 18_11 -------\n",
      "------- Finished processing file 18_11 in 9.164054870605469 seconds -------\n",
      "------- Start processing file 18_12 -------\n",
      "------- Finished processing file 18_12 in 8.346434116363525 seconds -------\n",
      "------- Start processing file 18_13 -------\n",
      "------- Finished processing file 18_13 in 7.476744890213013 seconds -------\n",
      "------- Start processing file 19_0 -------\n",
      "------- Finished processing file 19_0 in 10.645689010620117 seconds -------\n",
      "------- Start processing file 19_1 -------\n",
      "------- Finished processing file 19_1 in 4.777076959609985 seconds -------\n",
      "------- Start processing file 19_2 -------\n",
      "------- Finished processing file 19_2 in 5.872556209564209 seconds -------\n",
      "------- Start processing file 19_3 -------\n",
      "------- Finished processing file 19_3 in 3.482455015182495 seconds -------\n",
      "------- Start processing file 19_4 -------\n",
      "------- Finished processing file 19_4 in 4.709019899368286 seconds -------\n",
      "------- Start processing file 19_5 -------\n",
      "------- Finished processing file 19_5 in 5.417733907699585 seconds -------\n",
      "------- Start processing file 19_6 -------\n",
      "------- Finished processing file 19_6 in 6.154391050338745 seconds -------\n",
      "------- Start processing file 19_7 -------\n",
      "------- Finished processing file 19_7 in 7.370662212371826 seconds -------\n",
      "------- Start processing file 19_8 -------\n",
      "------- Finished processing file 19_8 in 6.6995110511779785 seconds -------\n",
      "------- Start processing file 19_9 -------\n",
      "------- Finished processing file 19_9 in 5.179342269897461 seconds -------\n",
      "------- Start processing file 19_10 -------\n",
      "------- Finished processing file 19_10 in 6.555446147918701 seconds -------\n",
      "------- Start processing file 19_11 -------\n",
      "------- Finished processing file 19_11 in 8.23932433128357 seconds -------\n",
      "------- Start processing file 19_12 -------\n",
      "------- Finished processing file 19_12 in 6.219713926315308 seconds -------\n",
      "------- Start processing file 19_13 -------\n",
      "------- Finished processing file 19_13 in 9.296216011047363 seconds -------\n",
      "------- Start processing file 20_0 -------\n",
      "------- Finished processing file 20_0 in 17.816829919815063 seconds -------\n",
      "------- Start processing file 20_1 -------\n",
      "------- Finished processing file 20_1 in 3.4882991313934326 seconds -------\n",
      "------- Start processing file 20_2 -------\n",
      "------- Finished processing file 20_2 in 5.285879135131836 seconds -------\n",
      "------- Start processing file 20_3 -------\n",
      "------- Finished processing file 20_3 in 4.742520093917847 seconds -------\n",
      "------- Start processing file 20_4 -------\n",
      "------- Finished processing file 20_4 in 6.246192216873169 seconds -------\n",
      "------- Start processing file 20_5 -------\n",
      "------- Finished processing file 20_5 in 4.40208888053894 seconds -------\n",
      "------- Start processing file 20_6 -------\n",
      "------- Finished processing file 20_6 in 6.249791145324707 seconds -------\n",
      "------- Start processing file 20_7 -------\n",
      "------- Finished processing file 20_7 in 12.489909172058105 seconds -------\n",
      "------- Start processing file 20_8 -------\n",
      "------- Finished processing file 20_8 in 5.735414028167725 seconds -------\n",
      "------- Start processing file 20_9 -------\n",
      "------- Finished processing file 20_9 in 8.703745126724243 seconds -------\n",
      "------- Start processing file 20_10 -------\n",
      "------- Finished processing file 20_10 in 8.6010901927948 seconds -------\n",
      "------- Start processing file 20_11 -------\n",
      "------- Finished processing file 20_11 in 6.8626580238342285 seconds -------\n",
      "------- Start processing file 20_12 -------\n",
      "------- Finished processing file 20_12 in 5.0549468994140625 seconds -------\n",
      "------- Start processing file 20_13 -------\n",
      "------- Finished processing file 20_13 in 8.458233118057251 seconds -------\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Load previous progress if available\n",
    "try:\n",
    "    with open('claude_two_example_output_progress.json', 'r') as file:\n",
    "        claude_two_example_output = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    claude_two_example_output = {}\n",
    "\n",
    "# Loop through each unique id\n",
    "for id in images_encoded_twoshot['id'].unique():\n",
    "# for id in unable_ids:\n",
    "    # Check if this ID is already processed (Skip this step if you want to re-process for unable_ids) ----------------\n",
    "    if id in claude_two_example_output:\n",
    "        print(f\"Skipping {id}, already processed.\")\n",
    "        continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        print(f'------- Start processing file {id} -------')\n",
    "        \n",
    "        # Call OpenAI/Anthropic and post-processing functions\n",
    "        prompt_example_text += \"Even if it is hard to read the texts from the image, return as much as you can. You must read something. Do not return an apologetic message.\"\n",
    "        # output = callOpenAI_example(prompt=prompt_example_text, NExample=2, base64_image=images_encoded_twoshot[(images_encoded_twoshot['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        output = callAnthropic_example(prompt=prompt_example_text, NExample=2, base64_image=images_encoded_twoshot[(images_encoded_twoshot['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        output_cleaned = callPostProcessing(prompt_parameter=output)\n",
    "        \n",
    "        # Save the output\n",
    "        claude_two_example_output[id] = output_cleaned\n",
    "        \n",
    "        # Save progress after each file\n",
    "        with open('claude_two_example_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_two_example_output, file)\n",
    "        \n",
    "        print(f'------- Finished processing file {id} in {time.time() - start_time} seconds -------')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {id}: {str(e)}\")\n",
    "        # Save the progress and exit the loop in case of an error\n",
    "        with open('claude_two_example_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_two_example_output, file)\n",
    "        break  # Exit the loop on error\n",
    "\n",
    "# Once all IDs are processed, save the final result\n",
    "with open('claude_two_example_output_final.json', 'w') as file:\n",
    "    json.dump(claude_two_example_output, file)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a122d9",
   "metadata": {},
   "source": [
    "### Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ab11e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt_simple = pd.read_csv(path+'/results/postprocessed/gpt_perline_output.csv')\n",
    "# claude_simple =  pd.read_csv(path+'/results/postprocessed/claude_perline_output.csv')\n",
    "gpt_complex = pd.read_csv(path+'/results/postprocessed/gpt_complex_perline_output2.csv')\n",
    "claude_complex =  pd.read_csv(path+'/results/postprocessed/claude_complex_perline_output2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "851ef214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 1_0, already processed.\n",
      "Skipping 1_1, already processed.\n",
      "Skipping 1_2, already processed.\n",
      "Skipping 1_3, already processed.\n",
      "Skipping 1_4, already processed.\n",
      "Skipping 1_5, already processed.\n",
      "Skipping 1_6, already processed.\n",
      "Skipping 1_7, already processed.\n",
      "Skipping 1_8, already processed.\n",
      "Skipping 1_9, already processed.\n",
      "Skipping 1_10, already processed.\n",
      "Skipping 1_11, already processed.\n",
      "Skipping 1_12, already processed.\n",
      "Skipping 1_13, already processed.\n",
      "Skipping 2_0, already processed.\n",
      "Skipping 2_1, already processed.\n",
      "Skipping 2_2, already processed.\n",
      "Skipping 2_3, already processed.\n",
      "Skipping 2_4, already processed.\n",
      "Skipping 2_5, already processed.\n",
      "Skipping 2_6, already processed.\n",
      "Skipping 2_7, already processed.\n",
      "Skipping 2_8, already processed.\n",
      "Skipping 2_9, already processed.\n",
      "Skipping 2_10, already processed.\n",
      "Skipping 2_11, already processed.\n",
      "Skipping 2_12, already processed.\n",
      "Skipping 2_13, already processed.\n",
      "Skipping 2_14, already processed.\n",
      "Skipping 3_0, already processed.\n",
      "Skipping 3_1, already processed.\n",
      "Skipping 3_2, already processed.\n",
      "Skipping 3_3, already processed.\n",
      "Skipping 3_4, already processed.\n",
      "Skipping 3_5, already processed.\n",
      "Skipping 3_6, already processed.\n",
      "Skipping 3_7, already processed.\n",
      "Skipping 3_8, already processed.\n",
      "Skipping 3_9, already processed.\n",
      "Skipping 3_10, already processed.\n",
      "Skipping 3_11, already processed.\n",
      "Skipping 3_12, already processed.\n",
      "Skipping 3_13, already processed.\n",
      "Skipping 4_0, already processed.\n",
      "Skipping 4_1, already processed.\n",
      "Skipping 4_2, already processed.\n",
      "Skipping 4_3, already processed.\n",
      "Skipping 4_4, already processed.\n",
      "Skipping 4_5, already processed.\n",
      "Skipping 4_6, already processed.\n",
      "Skipping 4_7, already processed.\n",
      "Skipping 4_8, already processed.\n",
      "Skipping 4_9, already processed.\n",
      "Skipping 4_10, already processed.\n",
      "Skipping 4_11, already processed.\n",
      "Skipping 4_12, already processed.\n",
      "Skipping 4_13, already processed.\n",
      "Skipping 5_0, already processed.\n",
      "Skipping 5_1, already processed.\n",
      "Skipping 5_2, already processed.\n",
      "Skipping 5_3, already processed.\n",
      "Skipping 5_4, already processed.\n",
      "Skipping 5_5, already processed.\n",
      "Skipping 5_6, already processed.\n",
      "Skipping 5_7, already processed.\n",
      "Skipping 5_8, already processed.\n",
      "Skipping 5_9, already processed.\n",
      "Skipping 5_10, already processed.\n",
      "Skipping 5_11, already processed.\n",
      "Skipping 5_12, already processed.\n",
      "Skipping 5_13, already processed.\n",
      "Skipping 5_14, already processed.\n",
      "Skipping 6_0, already processed.\n",
      "Skipping 6_1, already processed.\n",
      "Skipping 6_2, already processed.\n",
      "Skipping 6_3, already processed.\n",
      "Skipping 6_4, already processed.\n",
      "Skipping 6_5, already processed.\n",
      "Skipping 6_6, already processed.\n",
      "Skipping 6_7, already processed.\n",
      "Skipping 6_8, already processed.\n",
      "Skipping 6_9, already processed.\n",
      "Skipping 6_10, already processed.\n",
      "Skipping 6_11, already processed.\n",
      "Skipping 6_12, already processed.\n",
      "Skipping 6_13, already processed.\n",
      "Skipping 6_14, already processed.\n",
      "Skipping 7_0, already processed.\n",
      "Skipping 7_1, already processed.\n",
      "Skipping 7_2, already processed.\n",
      "Skipping 7_3, already processed.\n",
      "Skipping 7_4, already processed.\n",
      "Skipping 7_5, already processed.\n",
      "Skipping 7_6, already processed.\n",
      "Skipping 7_7, already processed.\n",
      "Skipping 7_8, already processed.\n",
      "Skipping 7_9, already processed.\n",
      "Skipping 7_10, already processed.\n",
      "Skipping 7_11, already processed.\n",
      "Skipping 7_12, already processed.\n",
      "Skipping 7_13, already processed.\n",
      "Skipping 8_0, already processed.\n",
      "Skipping 8_1, already processed.\n",
      "Skipping 8_2, already processed.\n",
      "Skipping 8_3, already processed.\n",
      "Skipping 8_4, already processed.\n",
      "Skipping 8_5, already processed.\n",
      "Skipping 8_6, already processed.\n",
      "Skipping 8_7, already processed.\n",
      "Skipping 8_8, already processed.\n",
      "Skipping 8_9, already processed.\n",
      "Skipping 8_10, already processed.\n",
      "Skipping 8_11, already processed.\n",
      "Skipping 8_12, already processed.\n",
      "Skipping 8_13, already processed.\n",
      "Skipping 9_0, already processed.\n",
      "Skipping 9_1, already processed.\n",
      "Skipping 9_2, already processed.\n",
      "Skipping 9_3, already processed.\n",
      "Skipping 9_4, already processed.\n",
      "Skipping 9_5, already processed.\n",
      "Skipping 9_6, already processed.\n",
      "Skipping 9_7, already processed.\n",
      "Skipping 9_8, already processed.\n",
      "Skipping 9_9, already processed.\n",
      "Skipping 9_10, already processed.\n",
      "Skipping 9_11, already processed.\n",
      "Skipping 9_12, already processed.\n",
      "------- Start processing file 9_13 -------\n",
      "------- Finished processing file 9_13 in 4.5187788009643555 seconds -------\n",
      "Skipping 10_0, already processed.\n",
      "------- Start processing file 10_1 -------\n",
      "------- Finished processing file 10_1 in 3.4782819747924805 seconds -------\n",
      "------- Start processing file 10_2 -------\n",
      "------- Finished processing file 10_2 in 4.187901735305786 seconds -------\n",
      "------- Start processing file 10_3 -------\n",
      "------- Finished processing file 10_3 in 6.054029941558838 seconds -------\n",
      "------- Start processing file 10_4 -------\n",
      "------- Finished processing file 10_4 in 5.224471092224121 seconds -------\n",
      "------- Start processing file 10_5 -------\n",
      "------- Finished processing file 10_5 in 3.420477867126465 seconds -------\n",
      "------- Start processing file 10_6 -------\n",
      "------- Finished processing file 10_6 in 4.212242126464844 seconds -------\n",
      "------- Start processing file 10_7 -------\n",
      "------- Finished processing file 10_7 in 4.384124755859375 seconds -------\n",
      "------- Start processing file 10_8 -------\n",
      "------- Finished processing file 10_8 in 3.804175853729248 seconds -------\n",
      "------- Start processing file 10_9 -------\n",
      "------- Finished processing file 10_9 in 3.853947162628174 seconds -------\n",
      "------- Start processing file 10_10 -------\n",
      "------- Finished processing file 10_10 in 4.284922122955322 seconds -------\n",
      "------- Start processing file 10_11 -------\n",
      "------- Finished processing file 10_11 in 4.323278188705444 seconds -------\n",
      "------- Start processing file 10_12 -------\n",
      "------- Finished processing file 10_12 in 4.51911997795105 seconds -------\n",
      "------- Start processing file 10_13 -------\n",
      "------- Finished processing file 10_13 in 3.8604512214660645 seconds -------\n",
      "Skipping 11_0, already processed.\n",
      "------- Start processing file 11_1 -------\n",
      "------- Finished processing file 11_1 in 4.088183879852295 seconds -------\n",
      "------- Start processing file 11_2 -------\n",
      "------- Finished processing file 11_2 in 4.19830584526062 seconds -------\n",
      "------- Start processing file 11_3 -------\n",
      "------- Finished processing file 11_3 in 4.198432207107544 seconds -------\n",
      "------- Start processing file 11_4 -------\n",
      "------- Finished processing file 11_4 in 3.278395891189575 seconds -------\n",
      "------- Start processing file 11_5 -------\n",
      "------- Finished processing file 11_5 in 3.9985132217407227 seconds -------\n",
      "------- Start processing file 11_6 -------\n",
      "------- Finished processing file 11_6 in 3.9869489669799805 seconds -------\n",
      "------- Start processing file 11_7 -------\n",
      "------- Finished processing file 11_7 in 3.685598134994507 seconds -------\n",
      "------- Start processing file 11_8 -------\n",
      "------- Finished processing file 11_8 in 3.3508150577545166 seconds -------\n",
      "------- Start processing file 11_9 -------\n",
      "------- Finished processing file 11_9 in 4.879892826080322 seconds -------\n",
      "------- Start processing file 11_10 -------\n",
      "------- Finished processing file 11_10 in 3.990602970123291 seconds -------\n",
      "------- Start processing file 11_11 -------\n",
      "------- Finished processing file 11_11 in 3.957642078399658 seconds -------\n",
      "------- Start processing file 11_12 -------\n",
      "------- Finished processing file 11_12 in 5.119674205780029 seconds -------\n",
      "------- Start processing file 11_13 -------\n",
      "------- Finished processing file 11_13 in 4.096029996871948 seconds -------\n",
      "Skipping 12_0, already processed.\n",
      "------- Start processing file 12_1 -------\n",
      "------- Finished processing file 12_1 in 4.402475833892822 seconds -------\n",
      "------- Start processing file 12_2 -------\n",
      "------- Finished processing file 12_2 in 4.609771966934204 seconds -------\n",
      "------- Start processing file 12_3 -------\n",
      "------- Finished processing file 12_3 in 3.891646146774292 seconds -------\n",
      "------- Start processing file 12_4 -------\n",
      "------- Finished processing file 12_4 in 18.46848487854004 seconds -------\n",
      "------- Start processing file 12_5 -------\n",
      "------- Finished processing file 12_5 in 3.943117141723633 seconds -------\n",
      "------- Start processing file 12_6 -------\n",
      "------- Finished processing file 12_6 in 5.168059825897217 seconds -------\n",
      "------- Start processing file 12_7 -------\n",
      "------- Finished processing file 12_7 in 4.876936912536621 seconds -------\n",
      "------- Start processing file 12_8 -------\n",
      "------- Finished processing file 12_8 in 5.221391916275024 seconds -------\n",
      "------- Start processing file 12_9 -------\n",
      "------- Finished processing file 12_9 in 4.9164769649505615 seconds -------\n",
      "------- Start processing file 12_10 -------\n",
      "------- Finished processing file 12_10 in 4.131852865219116 seconds -------\n",
      "------- Start processing file 12_11 -------\n",
      "------- Finished processing file 12_11 in 5.11723518371582 seconds -------\n",
      "------- Start processing file 12_12 -------\n",
      "------- Finished processing file 12_12 in 4.471143960952759 seconds -------\n",
      "------- Start processing file 12_13 -------\n",
      "------- Finished processing file 12_13 in 5.017827987670898 seconds -------\n",
      "Skipping 13_0, already processed.\n",
      "------- Start processing file 13_1 -------\n",
      "------- Finished processing file 13_1 in 4.812385082244873 seconds -------\n",
      "------- Start processing file 13_2 -------\n",
      "------- Finished processing file 13_2 in 4.9164369106292725 seconds -------\n",
      "------- Start processing file 13_3 -------\n",
      "------- Finished processing file 13_3 in 4.373955249786377 seconds -------\n",
      "------- Start processing file 13_4 -------\n",
      "------- Finished processing file 13_4 in 3.6131551265716553 seconds -------\n",
      "------- Start processing file 13_5 -------\n",
      "------- Finished processing file 13_5 in 5.426492929458618 seconds -------\n",
      "------- Start processing file 13_6 -------\n",
      "------- Finished processing file 13_6 in 4.298884153366089 seconds -------\n",
      "------- Start processing file 13_7 -------\n",
      "------- Finished processing file 13_7 in 3.994813919067383 seconds -------\n",
      "------- Start processing file 13_8 -------\n",
      "------- Finished processing file 13_8 in 4.371685743331909 seconds -------\n",
      "Skipping 13_9, already processed.\n",
      "------- Start processing file 13_10 -------\n",
      "------- Finished processing file 13_10 in 6.788352012634277 seconds -------\n",
      "------- Start processing file 13_11 -------\n",
      "------- Finished processing file 13_11 in 4.6079630851745605 seconds -------\n",
      "------- Start processing file 13_12 -------\n",
      "------- Finished processing file 13_12 in 5.328459978103638 seconds -------\n",
      "------- Start processing file 13_13 -------\n",
      "------- Finished processing file 13_13 in 5.234277248382568 seconds -------\n",
      "Skipping 14_0, already processed.\n",
      "------- Start processing file 14_1 -------\n",
      "------- Finished processing file 14_1 in 3.668360948562622 seconds -------\n",
      "------- Start processing file 14_2 -------\n",
      "------- Finished processing file 14_2 in 5.249000072479248 seconds -------\n",
      "------- Start processing file 14_3 -------\n",
      "------- Finished processing file 14_3 in 4.277847051620483 seconds -------\n",
      "------- Start processing file 14_4 -------\n",
      "------- Finished processing file 14_4 in 4.159616708755493 seconds -------\n",
      "------- Start processing file 14_5 -------\n",
      "------- Finished processing file 14_5 in 4.235310792922974 seconds -------\n",
      "------- Start processing file 14_6 -------\n",
      "------- Finished processing file 14_6 in 4.503371953964233 seconds -------\n",
      "------- Start processing file 14_7 -------\n",
      "------- Finished processing file 14_7 in 5.020073890686035 seconds -------\n",
      "------- Start processing file 14_8 -------\n",
      "------- Finished processing file 14_8 in 4.579561948776245 seconds -------\n",
      "------- Start processing file 14_9 -------\n",
      "------- Finished processing file 14_9 in 4.73679780960083 seconds -------\n",
      "------- Start processing file 14_10 -------\n",
      "------- Finished processing file 14_10 in 3.689643144607544 seconds -------\n",
      "------- Start processing file 14_11 -------\n",
      "------- Finished processing file 14_11 in 6.857661008834839 seconds -------\n",
      "------- Start processing file 14_12 -------\n",
      "------- Finished processing file 14_12 in 3.8901748657226562 seconds -------\n",
      "------- Start processing file 14_13 -------\n",
      "------- Finished processing file 14_13 in 6.7566609382629395 seconds -------\n",
      "Skipping 15_0, already processed.\n",
      "------- Start processing file 15_1 -------\n",
      "------- Finished processing file 15_1 in 5.2317633628845215 seconds -------\n",
      "------- Start processing file 15_2 -------\n",
      "------- Finished processing file 15_2 in 4.5568459033966064 seconds -------\n",
      "------- Start processing file 15_3 -------\n",
      "------- Finished processing file 15_3 in 4.345600843429565 seconds -------\n",
      "------- Start processing file 15_4 -------\n",
      "------- Finished processing file 15_4 in 3.9988598823547363 seconds -------\n",
      "------- Start processing file 15_5 -------\n",
      "------- Finished processing file 15_5 in 4.047779083251953 seconds -------\n",
      "------- Start processing file 15_6 -------\n",
      "------- Finished processing file 15_6 in 4.086607933044434 seconds -------\n",
      "------- Start processing file 15_7 -------\n",
      "------- Finished processing file 15_7 in 3.982541084289551 seconds -------\n",
      "------- Start processing file 15_8 -------\n",
      "------- Finished processing file 15_8 in 4.568011999130249 seconds -------\n",
      "------- Start processing file 15_9 -------\n",
      "------- Finished processing file 15_9 in 4.295407056808472 seconds -------\n",
      "------- Start processing file 15_10 -------\n",
      "------- Finished processing file 15_10 in 3.191497325897217 seconds -------\n",
      "------- Start processing file 15_11 -------\n",
      "------- Finished processing file 15_11 in 2.9559600353240967 seconds -------\n",
      "------- Start processing file 15_12 -------\n",
      "------- Finished processing file 15_12 in 3.993644952774048 seconds -------\n",
      "------- Start processing file 15_13 -------\n",
      "------- Finished processing file 15_13 in 4.300524950027466 seconds -------\n",
      "Skipping 16_0, already processed.\n",
      "------- Start processing file 16_1 -------\n",
      "------- Finished processing file 16_1 in 4.096444845199585 seconds -------\n",
      "Skipping 16_2, already processed.\n",
      "------- Start processing file 16_3 -------\n",
      "------- Finished processing file 16_3 in 4.664058208465576 seconds -------\n",
      "------- Start processing file 16_4 -------\n",
      "------- Finished processing file 16_4 in 3.7609620094299316 seconds -------\n",
      "------- Start processing file 16_5 -------\n",
      "------- Finished processing file 16_5 in 3.749936103820801 seconds -------\n",
      "------- Start processing file 16_6 -------\n",
      "------- Finished processing file 16_6 in 4.072468996047974 seconds -------\n",
      "------- Start processing file 16_7 -------\n",
      "------- Finished processing file 16_7 in 3.309048652648926 seconds -------\n",
      "------- Start processing file 16_8 -------\n",
      "------- Finished processing file 16_8 in 5.734472036361694 seconds -------\n",
      "------- Start processing file 16_9 -------\n",
      "------- Finished processing file 16_9 in 4.7066709995269775 seconds -------\n",
      "------- Start processing file 16_10 -------\n",
      "------- Finished processing file 16_10 in 3.9973392486572266 seconds -------\n",
      "------- Start processing file 16_11 -------\n",
      "------- Finished processing file 16_11 in 4.403064012527466 seconds -------\n",
      "------- Start processing file 16_12 -------\n",
      "------- Finished processing file 16_12 in 5.882168769836426 seconds -------\n",
      "------- Start processing file 16_13 -------\n",
      "------- Finished processing file 16_13 in 4.460268020629883 seconds -------\n",
      "Skipping 17_0, already processed.\n",
      "------- Start processing file 17_1 -------\n",
      "------- Finished processing file 17_1 in 3.788515090942383 seconds -------\n",
      "------- Start processing file 17_2 -------\n",
      "------- Finished processing file 17_2 in 5.016230821609497 seconds -------\n",
      "------- Start processing file 17_3 -------\n",
      "------- Finished processing file 17_3 in 4.501795053482056 seconds -------\n",
      "------- Start processing file 17_4 -------\n",
      "------- Finished processing file 17_4 in 4.879002809524536 seconds -------\n",
      "------- Start processing file 17_5 -------\n",
      "------- Finished processing file 17_5 in 4.507422924041748 seconds -------\n",
      "------- Start processing file 17_6 -------\n",
      "------- Finished processing file 17_6 in 3.7890050411224365 seconds -------\n",
      "------- Start processing file 17_7 -------\n",
      "------- Finished processing file 17_7 in 4.812199115753174 seconds -------\n",
      "------- Start processing file 17_8 -------\n",
      "------- Finished processing file 17_8 in 6.040272951126099 seconds -------\n",
      "------- Start processing file 17_9 -------\n",
      "------- Finished processing file 17_9 in 4.709277153015137 seconds -------\n",
      "------- Start processing file 17_10 -------\n",
      "------- Finished processing file 17_10 in 4.711926221847534 seconds -------\n",
      "------- Start processing file 17_11 -------\n",
      "------- Finished processing file 17_11 in 3.572464942932129 seconds -------\n",
      "------- Start processing file 17_12 -------\n",
      "------- Finished processing file 17_12 in 4.51676607131958 seconds -------\n",
      "------- Start processing file 17_13 -------\n",
      "------- Finished processing file 17_13 in 3.887263059616089 seconds -------\n",
      "Skipping 18_0, already processed.\n",
      "------- Start processing file 18_1 -------\n",
      "------- Finished processing file 18_1 in 4.200323820114136 seconds -------\n",
      "------- Start processing file 18_2 -------\n",
      "------- Finished processing file 18_2 in 4.19882607460022 seconds -------\n",
      "------- Start processing file 18_3 -------\n",
      "------- Finished processing file 18_3 in 3.582446813583374 seconds -------\n",
      "------- Start processing file 18_4 -------\n",
      "------- Finished processing file 18_4 in 5.434032201766968 seconds -------\n",
      "------- Start processing file 18_5 -------\n",
      "------- Finished processing file 18_5 in 4.088507890701294 seconds -------\n",
      "------- Start processing file 18_6 -------\n",
      "------- Finished processing file 18_6 in 6.554315090179443 seconds -------\n",
      "------- Start processing file 18_7 -------\n",
      "------- Finished processing file 18_7 in 4.909409999847412 seconds -------\n",
      "------- Start processing file 18_8 -------\n",
      "------- Finished processing file 18_8 in 4.921012878417969 seconds -------\n",
      "------- Start processing file 18_9 -------\n",
      "------- Finished processing file 18_9 in 3.66916823387146 seconds -------\n",
      "------- Start processing file 18_10 -------\n",
      "------- Finished processing file 18_10 in 6.374696969985962 seconds -------\n",
      "------- Start processing file 18_11 -------\n",
      "------- Finished processing file 18_11 in 5.325391054153442 seconds -------\n",
      "------- Start processing file 18_12 -------\n",
      "------- Finished processing file 18_12 in 6.554369688034058 seconds -------\n",
      "------- Start processing file 18_13 -------\n",
      "------- Finished processing file 18_13 in 4.603408098220825 seconds -------\n",
      "Skipping 19_0, already processed.\n",
      "------- Start processing file 19_1 -------\n",
      "------- Finished processing file 19_1 in 4.633074998855591 seconds -------\n",
      "------- Start processing file 19_2 -------\n",
      "------- Finished processing file 19_2 in 3.1455390453338623 seconds -------\n",
      "------- Start processing file 19_3 -------\n",
      "------- Finished processing file 19_3 in 5.219139099121094 seconds -------\n",
      "------- Start processing file 19_4 -------\n",
      "------- Finished processing file 19_4 in 3.70662784576416 seconds -------\n",
      "------- Start processing file 19_5 -------\n",
      "------- Finished processing file 19_5 in 4.691181182861328 seconds -------\n",
      "------- Start processing file 19_6 -------\n",
      "------- Finished processing file 19_6 in 4.814079999923706 seconds -------\n",
      "------- Start processing file 19_7 -------\n",
      "------- Finished processing file 19_7 in 4.082614898681641 seconds -------\n",
      "------- Start processing file 19_8 -------\n",
      "------- Finished processing file 19_8 in 3.800102949142456 seconds -------\n",
      "------- Start processing file 19_9 -------\n",
      "------- Finished processing file 19_9 in 3.298182249069214 seconds -------\n",
      "------- Start processing file 19_10 -------\n",
      "------- Finished processing file 19_10 in 3.9988508224487305 seconds -------\n",
      "------- Start processing file 19_11 -------\n",
      "------- Finished processing file 19_11 in 4.682307243347168 seconds -------\n",
      "------- Start processing file 19_12 -------\n",
      "------- Finished processing file 19_12 in 6.988734006881714 seconds -------\n",
      "------- Start processing file 19_13 -------\n",
      "------- Finished processing file 19_13 in 5.811883211135864 seconds -------\n",
      "Skipping 20_0, already processed.\n",
      "------- Start processing file 20_1 -------\n",
      "------- Finished processing file 20_1 in 4.505818128585815 seconds -------\n",
      "------- Start processing file 20_2 -------\n",
      "------- Finished processing file 20_2 in 3.7904858589172363 seconds -------\n",
      "------- Start processing file 20_3 -------\n",
      "------- Finished processing file 20_3 in 4.50445294380188 seconds -------\n",
      "------- Start processing file 20_4 -------\n",
      "------- Finished processing file 20_4 in 4.909791946411133 seconds -------\n",
      "------- Start processing file 20_5 -------\n",
      "------- Finished processing file 20_5 in 4.304340839385986 seconds -------\n",
      "------- Start processing file 20_6 -------\n",
      "------- Finished processing file 20_6 in 4.937065124511719 seconds -------\n",
      "------- Start processing file 20_7 -------\n",
      "------- Finished processing file 20_7 in 3.884999990463257 seconds -------\n",
      "------- Start processing file 20_8 -------\n",
      "------- Finished processing file 20_8 in 3.7735650539398193 seconds -------\n",
      "------- Start processing file 20_9 -------\n",
      "------- Finished processing file 20_9 in 5.033324956893921 seconds -------\n",
      "------- Start processing file 20_10 -------\n",
      "------- Finished processing file 20_10 in 4.377002954483032 seconds -------\n",
      "------- Start processing file 20_11 -------\n",
      "------- Finished processing file 20_11 in 4.514448165893555 seconds -------\n",
      "------- Start processing file 20_12 -------\n",
      "------- Finished processing file 20_12 in 4.916759014129639 seconds -------\n",
      "------- Start processing file 20_13 -------\n",
      "------- Finished processing file 20_13 in 5.5274670124053955 seconds -------\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Load previous progress if available\n",
    "try:\n",
    "    with open('claude_refine_complex_output_progress.json', 'r') as file:\n",
    "        claude_refine_complex_output = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    claude_refine_complex_output = {}\n",
    "\n",
    "# Loop through each unique id\n",
    "for id in images_encoded['id'].unique():\n",
    "# for id in header_ids+typo_ids:\n",
    "# for id in unable_ids:\n",
    "    # Check if this ID is already processed (Skip this step if you want to re-process for unable_ids) ----------------\n",
    "    if id in claude_refine_complex_output:\n",
    "        print(f\"Skipping {id}, already processed.\")\n",
    "        continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        print(f'------- Start processing file {id} -------')\n",
    "        \n",
    "        # Call OpenAI/Anthropic and post-processing functions\n",
    "        response_text = claude_complex[claude_complex['id'] == id].text.values[0]\n",
    "        prompt_refine = f\"\"\"\n",
    "        \n",
    "        Your first draft:\n",
    "        ```plaintext\n",
    "        {response_text}\n",
    "        ```\n",
    "\n",
    "        Errors: \n",
    "        Your first transcription you made in ```plaintext block contains some errors.\n",
    "        \n",
    "        Task:\n",
    "        Refine your first trasncription in ```plaintext block. \n",
    "        Make sure to read the names of the people and the location as well as the dates and the numbers correctly.\n",
    "        Transcribe as you see in the image.\n",
    "        ```plaintext\n",
    "        \"\"\"\n",
    "\n",
    "        prompt_refine += \"Even if it is hard to read the texts from the image, return as much as you can. You must read something. Do not return an apologetic message.\"\n",
    "        # output = callOpenAI(prompt=prompt_refine, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        output = callAnthropic(prompt=prompt_refine, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        output_cleaned = callPostProcessing(prompt_parameter=output)\n",
    "        \n",
    "        # Save the output\n",
    "        claude_refine_complex_output[id] = output_cleaned\n",
    "        \n",
    "        # Save progress after each file\n",
    "        with open('claude_refine_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_refine_complex_output, file)\n",
    "        \n",
    "        print(f'------- Finished processing file {id} in {time.time() - start_time} seconds -------')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {id}: {str(e)}\")\n",
    "        # Save the progress and exit the loop in case of an error\n",
    "        with open('claude_refine_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_refine_complex_output, file)\n",
    "        break  # Exit the loop on error\n",
    "\n",
    "# Once all IDs are processed, save the final result\n",
    "with open('claude_refine_complex_output_final.json', 'w') as file:\n",
    "    json.dump(claude_refine_complex_output, file)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b34c7",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "683579cb-2bae-4a69-8271-ce4e67519e52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1_0': \"N°  \\nDATE DU DÉPÔT des déclarations  \\nDÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES.: NOMS  \\nDÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES.: PRÉNOMS  \\nDÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES.: DOMICILES  \\nDATE DU DÉCÈS ou du jugement d'envoi en possession, en cas d'absence  \\nNOMS, PRÉNOMS et demeures des parties déclarantes  \\nDROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE: ACTIF  \\nDROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE: PASSIF  \\nDROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE: RESTANT NET  \\nDROIT DE MUTATION par décès: VALEUR des immeubles  \\nNUMÉROS des DÉCLARATIONS: Primitives  \\nNUMÉROS des DÉCLARATIONS: Supplémentaires  \\nDATE: de l'expiration du délai de rectification  \\nDATE: de l'exigibilité des droits  \\nNUMÉROS de la consignation des droits au sommier n° 28  \\nRECETTE des droits et amendes.: DATE  \\nRECETTE des droits et amendes.: N°  \\nCAUTIONNEMENTS: Numéros de la consignation au sommier n°30  \\nOBSERVATIONS (Les déclarations qui figurent à l'état n°413 doivent être émargées en conséquence, dans la présente colonne)\",\n",
       " '1_1': 'Arrêté le vingt huit octobre 1919 servais',\n",
       " '1_2': 'Arrêté le vingt neuf octobre 1919 servais',\n",
       " '1_3': '398 trente octobre Herrent Alphonse Joseph ochain 30 8bre 1913 Herrent Désiré & autres 2280 1085 1195 11 30/315 15 9bre 1914 feuillet 365',\n",
       " '1_4': \"398² Lefebvre Jules Bruxelles Ixelles Chaussée d'Ixelles 244 241 799\",\n",
       " '1_5': 'Arrêté le trente octobre 1919 servais',\n",
       " '1_6': 'Arrêté le trente un octobre 1919 Servais',\n",
       " '1_7': 'Arrêté le premier novembre 1919 Toussaint Servais',\n",
       " '1_8': 'Arrêté le deux novembre 1919 Dimanche Servais',\n",
       " '1_9': '399 6 mai 9 fev Desmedt Jeanne Nivelles 13 mai 1914 Desmedt Celine rentière 9110 520 8910 15 8bre 13 mars 10 fevrier 35',\n",
       " '1_10': '400 Monseur Pascal Henri Philippe 4 8bre 1918 Nouveau Délais 69060 34478 34582 15 32 4 avril 1919',\n",
       " '1_11': \"401 8 Bouly Henri Ouvrier l' 20 février Bouly-Marie Père 2374 2374 15 8 20 Août non passible 1879\",\n",
       " '1_12': 'Arrêté le trois novembre 1919 devereux',\n",
       " '1_13': '402 Godart Rombals Marie 11 mai Plesson Gustave 17237 17737 55 76 31 22 mai 1919 21 novembre 1920',\n",
       " '2_0': \"N° d'ordre  \\nDATE DU DÉPÔT des déclarations.  \\nDÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES.: NOMS.  \\nPRÉNOMS.  \\nDOMICILES  \\nDATE DU DÉCÈS ou du jugement d'envoi en possession, en cas d'absence.  \\nNOMS, PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES.  \\nDROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE.: ACTIF. (2)  \\nPASSIF. (2)  \\nRESTANT NET. (2)  \\nDROIT DE MUTATION par décès: VALEUR des immeubles. (2)  \\nNUMÉROS des DÉCLARATIONS: Primitives.  \\nSupplémentaires.  \\nDATE: de l'expiration du délai de rectification.  \\nde l'exigibilité des droits.  \\nNUMÉROS de la consignation des droits au sommier n° 28  \\nRECETTE des DROITS ET AMENDES.: DATE  \\nN°s  \\nCAUTIONNEMENTS.: Numéros de la consignation au sommier n°30  \\nOBSERVATIONS (Les déclarations qui figurent à l'état n°413 doivent être émargées en conséquence, dans la présente colonne.)\",\n",
       " '2_1': '1419',\n",
       " '2_2': \"403 quatre 92 Bayot Antoinette Marie d'Aubly 11 mai 919 Bayot Henri d'aubert 16971 5233 11700 16.919.919 16 mai 919\",\n",
       " '2_3': '405e Paulus Adolphe Nivelles 25 février 1919 Paulus Léopold 2971 2971 481 10 Août 1920',\n",
       " '2_4': '404 Vandermeers Louis Oscar Elbert 4 avril 1918 Bruxelles Boursval 500 500 16 30 7 janvier 1919 non passible',\n",
       " '2_5': 'Arrêté le quatre novembre 1919 servais',\n",
       " '2_6': '405 cinq 764 Lemoine Joseph Ath 24 Août Domien julesse & autres 1885 1885 18 Août 26 août 1889 non fournie',\n",
       " '2_7': \"406 30 Monnaye Julie Dampremy le 9 8 1911 Monnaye Cécile à Jumet Cessation d'usufruit 11 février 97\",\n",
       " '2_8': '105 de Godeau Clément Dottignies 7 8b 47 Godeau Hortense veuve 500 500 18 8bre 7 avril non passible 1911',\n",
       " '2_9': 'Arrêté le cinq novembre 1919 servais',\n",
       " '2_10': 'Arrêté le dix novembre 1949 servais',\n",
       " '2_11': '408 sept 9bre Fontaine Florent Cutsys 15 octobre 1928 Rousseaux Armande 848 225 202 18 9bre 25 avril non passible',\n",
       " '2_12': '409 5 Allard Prosper Nivelles 16 avril 1919 Bellens Marie 9420 9420 17 5 16 juin 1920 25 message 54',\n",
       " '2_13': 'Arrêté le sept novembre 1919 servais',\n",
       " '2_14': '410 Paul plus Delontte gustave 22/12/1909 16 mai 1919 Delville Edouard Zulte 11451 369 11087 20 30 16 mars 1920 29 février 1920',\n",
       " '3_0': \"N° d'ordre DATE DU DÉPÔT des déclarations. DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES.: NOM. PRÉNOMS. DOMICILES. DATE DU DÉCÈS ou du jugement d'envoi en possession, en cas d'absence. NOMS, PRÉNOMS et demeures des parties déclarantes. DROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE.: ACTIF. (2) PASSIF. (2) RESTANT NET. (2) DROIT DE MUTATION par décès: VALEUR des immeubles. (2) NUMÉROS des déclarations: Primitives. Supplémentaires. DATE: de l'expiration du délai de rectification. de l'exigibilité des droits. NUMÉROS de la consignation des droits au sommier n° 28 RECETTE des droits et amendes.: DATE N°s CAUTIONNEMENTS.: NUMÉROS de la consignation au sommier n°30 OBSERVATIONS (Les déclarations qui figurent à l'état n°413 doivent être émargées en conséquence, dans la présente colonne.)\",\n",
       " '3_1': '411 Paul 26/3/39 Houtelet Henri Waterloo 25/3/39 Epouse Huve 3978 3978 20/9/39 20 juillet non fournie',\n",
       " '3_2': '412 30 Chabreau Henri Emile 6 8/1919 Capelle Antoinette et autres 78692 78692 20 30 6 octobre 19 8/1919 201 202 203 204 205',\n",
       " '3_3': '412 3 Reynens Louis officier 4 avril 1916 Gilles ordre - 1296 - 1296 280 - - 31 mars 1920 549',\n",
       " '3_4': 'Arrêté le huit novembre 1919 servais',\n",
       " '3_5': 'Arrêté le neuf novembre 1919 Dimanche Servais',\n",
       " '3_6': '413 dec 9/1919 Mathieu Emerana Désiré 11 mai 1919 Beauvechain Leopold 14934 14934 22 dec 1919 11 mai 1920',\n",
       " '3_7': \"414 32 Caminiau Adeline Marie 27 juillet 1919 Dépêche Secrét. d'Etat 25391 25391 41.52 32 2 mai 1920 13 mars 1920 59 100\",\n",
       " '3_8': '415 5 Dubru Amandine Albert 6 juin 1949 décédée femme x autre 500 355 144 26 5 6 avril 949 non payable',\n",
       " '3_9': 'Arrêté le dix novembre 1919 servais',\n",
       " '3_10': '416 aug. 9/82 Heuvels Emmanuel Nivelle 22 mai 1917 Saffon Louis 7561 586 6975 25 Déc. 1917 15 mai 1917',\n",
       " '3_11': '417 2 Basigant Marie 47 2 Bruyenne Eugénie 1264 4264 23 2 15 2 5 mars 1920 52',\n",
       " '3_12': '4112 Campinaire Renard taillé 29/3/1915 Gillis Eugène 22295 23750 361',\n",
       " '3_13': 'Arrêté le 4 mars novembre 1919 servais',\n",
       " '4_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS RECETTE CAUTION- d'ordre NOMS. PRÉNOMS. DOMICILES jugement d'envoi DEMEURES DES PARTIES DÉCLARANTES. et de par décès DÉCLARATIONS NUMÉROS ACTIF. PASSIF. RESTANT IMMEUBLES. au sommier n° 30\",\n",
       " '4_1': 'Arrêté le deux novembre 1919 servais',\n",
       " '4_2': '418 Cloquet Célestine Wauthier 28 mai 1919 Décédé aliéné 5500 - 5500 29 3/4 44 28 mars 5 mars 1920',\n",
       " '4_3': '419 3° Vincent Edouard Denis 3 avril 1911 Bréfort Emile à autre 22600 22600 3° 3° 3 juin 1911 3 mars 1914 945 10 5° 300',\n",
       " '4_4': 'Arrêté le treize novembre 1919 servais',\n",
       " '4_5': 'Arrêté le quinze novembre 1919 servais',\n",
       " '4_6': '420 quinge Boisdenghien Rosalie quesnoit 17 mai 1919 décès Renaix veuve 1938 1938 607 24 36 1/2 15 mars 1940 1 août 38',\n",
       " '4_7': '420² Lambotte Ernest Waterloo 7 février 1911 Lambotte Emile 258',\n",
       " '4_8': 'Arrêté le quinze novembre 1919 servais',\n",
       " '4_9': 'Arrêté le 2 novembre 1919 Dimanche servais',\n",
       " '4_10': 'Arrêté le 2nd sept novembre 1919 servais',\n",
       " '4_11': '420 3 décembre Rousseau Charles Gh Nivelles 21 mars 1919 Rousseau Louis 24.800 24.800 780 1949',\n",
       " '4_12': '421 Lehamg Henri Euthie 2 aout 1915 Neufchapeau Bras Arlon 1922 210 3912 28 Aout 49 2 juin 1915 3 aout 1920 24 49 5 385',\n",
       " '4_13': 'Arrêté le dix huit novembre 1919 servais',\n",
       " '5_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS RECETTE CAUTION- OBSERVATIONS d'ordre des NOM. PRÉNOMS DOMICILES ou du ET en ligne collatérale et de DE MUTATION des DATE NEMENTS. déclarations jugement d'envoi DEMEURES DES PARTIES DÉCLARANTES. MUTATION EN LIGNE DIRECTE. par décès DÉCLARATIONS ACTIF. PASSIF. RESTANT VALEUR Primitives. Supplémentaires. de de Numéros DATE N°s Numéros en cas d'absence. (2) (2) NET. (2) des l'expiration l'exigibilité de la consignation de la consignation immeubles. du délai des droits. des droits au au sommier rectification. n° 28 n° 30\",\n",
       " '5_1': '1919',\n",
       " '5_2': '425 neuf Sleemans Charles Otto 27 avril 1917 Boussu Hainaut 5888 214 5675 39 10 24/14 322 17 19 janvier 1918 24',\n",
       " '5_3': '435 3 Burij Léontine Maria Catharina 4 janvier 1912 Burij Marie Leontine 500 500 10 août 241 9 janv. 1913',\n",
       " '5_4': '4234 3° Pieterbons Remi J. Henri Wilhelm 17 février 1913 Deux garçons rentiers Duffel 21/2/1913 249 4917',\n",
       " '5_5': '422 5 Pietersons Jean Gn. 26 mars 1898 - - 366 245 121 31 Aug 25 mars 1920 non fournie',\n",
       " '5_6': '423 Desaeger Henri Bertha Arthur 20 mai 1919 Ghislenghien Attel 2895 2895 30 25 17 mars 60',\n",
       " '5_7': 'Arrêté le dix neuf novembre 1913 Servais',\n",
       " '5_8': '424 vingt 9bre Hantier Firmin Nivelles épicier décès juillet avant 86101 86101 7bre 2 janvier 1923 1922 1923 16 juillet 83',\n",
       " '5_9': '485 5e Delaitre Céline Catherine Rosine 26 mars 1924 Louvain Jean Bte et autre 500 500 1 5e 26 mars 1924 non fournie',\n",
       " '5_10': 'Arrêté le vingt novembre 1919 Servais',\n",
       " '5_11': '425² Pierrot Julien 22/12/1940 à Gérard Beauraing constable Déclaration rectificative 223 1944',\n",
       " '5_12': '426 3° Fontignies Ath Athan Depain 1914 Bartholomé Edouard veuve 2261 2261 1 3° 20 avril 1920 10 juillet 20',\n",
       " '5_13': '429 8 Moens Joseph Calais expulsé Liège déc. d autres 1595 3095 3- 28 mai 1929 non payable',\n",
       " '5_14': '428 Semal Henri Nivelles 15 juin 1924 Guyot alice et autres 4,000 4,000 334/1 3x 16 août 1924 16 août 1924 79',\n",
       " '6_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE NUMÉROS RECETTE CAUTION- des DÉCLARATIONS. NOMS. PRÉNOMS. DOMICILES. ou du jugement ET DEMEURES DES EN LIGNE COLLATÉRALE DE des de la des NEMENTS d'envoi PARTIES ET MUTATION DÉCLARATIONS consignation DROITS ET AMENDES. en possession, DÉCLARANTES. par décès des droits au sommier en cas n° 28 d'absence.\",\n",
       " '6_1': '1911',\n",
       " '6_2': '150 vingt quatre juin Lambert Valentin Rebecq 16 mars 1921 Gérard Camille et autres 12880 1609 11271 16 mars 1922 19',\n",
       " '6_3': '151 Lerseau Adolphine Charleroy 3 mars 97 Vanspré Rosalie & autres 6768 6860 7869/4 157 16 - 97',\n",
       " '6_4': '152 5 Vanpée Frédéric 29/8/920 9 4100 594 6504 non passible',\n",
       " '6_5': '153 Delabij Joachim Joseph Exupère Léopold Joachim Antoine Henri 1890 fév 1891',\n",
       " '6_6': 'Arrêté Le vingt quatre juin 1920 servais',\n",
       " '6_7': '153² Charlier Hosdain Nestor 8 avril 1920 Henri Jules à Bon 341',\n",
       " '6_8': 'Arrêté le vingt-cinq juin 1921 servais',\n",
       " '6_9': 'Arrêté le vingt-six juin 1921 Dimanche Servais',\n",
       " '6_10': '154 Froment Roger Nivelles 28 février Van Dormael Juliette 90705 3369 87336 3075 janvier 239 1926',\n",
       " '6_11': '155 Devreux Jean Ste Léonard épicier Rèves Hainaut canton 26/6 248 non passible',\n",
       " '6_12': '156 Seolas Jean Joseph Wautier 6 Août Décédé juge de paix autres 2691 2691 id',\n",
       " '6_13': 'Arrêté le vingt sept février 1921 servais',\n",
       " '6_14': '157 vingt huit 8 Declercque Marie-Emma Rosalie 29 8bre 1910 Declercque Adelaide 14.066 3326 10.740 9.649.20.28',\n",
       " '7_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. DATE DU DÉCÈS DROITS DE SUCCESSION DROIT NUMÉROS RECETTE CAUTION d'ordre des NOMS, PRÉNOMS ou du en ligne collatérale DE MUTATION des DATE NEMENTS DÉCLARATIONS. NOMS. PRÉNOMS. DOMICILES jugement d'envoi et de par décès. DÉCLARATIONS. Numéros en possession, MUTATION EN LIGNE DIRECTE. VALEUR de la en cas d'absence. IMMEUBLES. consignation au sommier n° 30 OBSERVATIONS.\",\n",
       " '7_1': 'Arrêté le dix-sept juin 1920 servais',\n",
       " '7_2': '145 cinquième Luyer Charles Louis Original 15 8/1920 Van assche julienne x enfants 50188 1418 58732 28 8/1921 28 2/1921 30',\n",
       " '7_3': 'Arrêté le dix sept juin 1921 Servais',\n",
       " '7_4': '146 des Paul finis Masson Jean Bte Baulers 19 Abgra Porte Eloise 12905 598 12020 31-11-41 114',\n",
       " '7_5': 'Arrêté le 30 avril juin 1921 servais',\n",
       " '7_6': 'Arrêté le 30 mai juin 1901 Dimanche soir',\n",
       " '7_7': 'Arrêté le vingt juin 1921 servais',\n",
       " '7_8': '115 vingt-un juin Lebblicq Jason Ste Ghislain 13 mars 1920 Veuve Marie Dhaese et autres 4950 336 4614 non passible',\n",
       " '7_9': 'Arrêté le vingt-un juin 1921 servais',\n",
       " '7_10': 'Arrêté le vingt deux juin 1923 servais',\n",
       " '7_11': 'Arrêté le vingt trois juin 1920 servais',\n",
       " '7_12': '148 vingt quatre Dasset Emmanuel Gérard Bruxelles Gérin Emile r autres 4/8/1 1133 1612 100 6 janvier 1912',\n",
       " '7_13': '149 de Liegelaert Laurent Th. Regina 18 mai 1926 Huygens-Elisabeth & autres 6378 2568 3811 non fournie',\n",
       " '8_0': \"N° d'ordre  \\nDATE DU DÉPÔT des déclarations  \\nDÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES:  \\nNOMS  \\nPRÉNOMS  \\nDOMICILES  \\nDATE DU DÉCÈS ou du jugement d'envoi en possession, en cas d'absence.  \\nNOMS, PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES  \\nDROITS DE SUCCESSION en ligne collatérale et de mutation en ligne directe:  \\nACTIF (2)  \\nPASSIF (2)  \\nRESTANT NET (2)  \\nDROIT DE MUTATION par décès:  \\nVALEUR des IMMEUBLES (2)  \\nNUMÉROS DES DÉCLARATIONS:  \\nPRIMITIVES  \\nSUPPLÉMENTAIRES  \\nDATE:  \\nde l'expiration du délai de rectification  \\nde l'exigibilité des droits  \\nNUMÉROS de la consignation des droits au sommier n° 28  \\nRECETTE des droits et amendes:  \\nDATE  \\nN°  \\nCAUTIONNEMENTS:  \\nNuméros de la consignation au sommier n° 30  \\nOBSERVATIONS (Les déclarations qui figurent à l'état n° 413 doivent être émargées en conséquence, dans la présente colonne.)\",\n",
       " '8_1': 'Arrêté le vingt-un novembre 1919 servais',\n",
       " '8_2': '429 vingt deux novembre Beth Louis Otto 28 mai 1919 Héritier Louis 9000 9000 5 janvier 1920 26 mars 1919 15 8/20 300 15 8/20 300',\n",
       " '8_3': '430 8° Huart Paul 19 8bre 1913 Huart Joseph et autres 44207 1861 42346 3 8° 19 avril 1914 4 avril 1914 362 1 juin 1914 942',\n",
       " '8_4': \"431 3° Romain Félicie 9 1937 8/19 Wanlin Livret d'ouvrier 10/15 10 38 5 0 10 juillet 1938 15/3°1939 130\",\n",
       " '8_5': '1532 5 Poliart Léon 3/8/1918 Veuve Clément Laurette 915 111 632 1532 5 15 août 1919 3 avril 1919 73',\n",
       " '8_6': '133 Poliart Arthur 19 5 a 945 441 674 135 5 50 19 5 5 71',\n",
       " '8_7': '434 Houtmeyers Henri 20/4/1923 38 ans 1/2 Belgique Duffel 1834 78 1878 3 21 mars 1 avril 1923 78',\n",
       " '8_8': '455 Thibaut Beau Louis Germant 5 9bre 1919 époux Benis & autres 11290 11290 455 5 7bre 1920 non passible',\n",
       " '8_9': '436 5 Gaussin Eva Bruxelles 22/6/1915 Gaussin Daniel 1020 722 298 5 50 20 avril 1919 non passible',\n",
       " '8_10': '437 30 Delanney Clémentine 2 28 mars 1918 Bossut adrien 6154 644 513 1 30 28 février 1919 14-11-21 148',\n",
       " '8_11': '438 Debutte Jules 20 octobre 29 fév 48 Debutte alfred 3988 1483 2505 75 29 avril 15 mai 1920 15 1929 août 1920 565',\n",
       " '8_12': 'Arrêté le vingt trois novembre 1919 servais',\n",
       " '8_13': 'Arrêté le vingt-trois novembre 1919 (Dimanche) Servais',\n",
       " '9_0': '1 15 Juin 1922 Vanderhaegen Alphonse Bruxelles 15 Mai 1922 Vanderhaegen Alphonse, Bruxelles 1,000 - 1,000 - 1 - 15 Août 1922 15 Novembre 1922 1 15 Novembre 1922 1 - -',\n",
       " '9_1': 'Arrêté le vingt quatre novembre 1919 servais',\n",
       " '9_2': '439 vingt-cinq Gossiaux Adelain Jos Plancenoit 20 7 1911 Gostiaux Sophie a autres 804 5015 6 janvier 20 juillet 1920 5 mai 1920 615',\n",
       " '9_3': 'Arrêté le vingt cinq novembre 1919 (illisible)',\n",
       " '9_4': 'Arrêté le vingt trois novembre 1909 (servais)',\n",
       " '9_5': 'Arrêté le vingt-sept novembre 1919 servais',\n",
       " '9_6': 'Arrêté le vingt huit novembre 1919 servais',\n",
       " '9_7': 'Arrêté le vingt-neuf novembre 1919 Servais',\n",
       " '9_8': 'Arrêté le trente novembre 1919 Dimanche servais',\n",
       " '9_9': '439 1/2 Sainblane Joseph huissier Anvers 1 février 1914 Sainblane Georges & autres 5596 5596 206 1914',\n",
       " '9_10': '1293 5 Saintelane Bonavent 13 5 73 2830 2830 107 1911',\n",
       " '9_11': 'Arrêté le premier décembre 1919 (servais)',\n",
       " '9_12': '439 4 deux 54 Charlier Jean Bte Alphonse 29/8/1915 Chevalier Juliette Veuve Fontier Lucien 5000 5000 91 199',\n",
       " '9_13': 'Jeudi 8 décembre 1919 Servais',\n",
       " '10_0': 'N° Date du dépôt Désignation des personnes décédées ou absentes Noms Prénoms Domiciles Date du décès Droits de succession Recette Observations',\n",
       " '10_1': 'Arrêté le trois décembre 1919 servais',\n",
       " '10_2': '4395 Knops Valentine Nicolle 7/4/1911 Bourse (Lierre) x veuve Delft insuffisance 38 23.36/40.330 17 avril/30 oct',\n",
       " '10_3': 'Arrêté le quatre décembre 1919 Servais',\n",
       " '10_4': '440 cinq octobre Defalque Eugene Namur le 5 juin 1911 Wanfercée Baulet 4102 4202 16 janvier 1920 3 mai 1920 96',\n",
       " '10_5': 'Arrêté le vingt décembre 1919 servais',\n",
       " '10_6': '411 bis 584 Jacqmin Cécile Ophain 27 juillet 1914 Joseph François 58611 58611 108758 38 27 mai 1920 16 février 1916',\n",
       " '10_7': '445 8 Voussure Léon Renaix 18 Juillet 1914 Gillis André 41 41 28',\n",
       " '10_8': 'Lundi le 2 décembre 1919 servais',\n",
       " '10_9': 'Arrêté le 31 décembre 1919 Rimambly servais',\n",
       " '10_10': '941 Vanbiesbroeck de Lahenne Emile Nivelles 7/6/1918 Servais Marie 628 628 133 19.7',\n",
       " '10_11': 'Arrêté le huit décembre 1919 servais',\n",
       " '10_12': '4414 neuf sta Heuvels Alphonsine Nicelle 6 février 1919 Parents décédés 585 197',\n",
       " '10_13': '445 Goisse Adolphe 6 janvier 1919 Rouvenel Clara 910 910 204',\n",
       " '11_0': \"N° d'ordre DATE DU DÉPÔT des DÉCLARATIONS DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES: NOMS. PRÉNOMS. DOMICILES. DATE DU DÉCÈS ou du jugement d'envoi en possession, en cas d'absence. NOMS, PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES. DROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE: ACTIF. (2) PASSIF. (2) RESTANT NET. (2) DROIT DE MUTATION PAR DÉCÈS: VALEUR des IMMEUBLES. (2) NUMÉROS des DÉCLARATIONS: PRIMITIVES. SUPPLÉMENTAIRES. DATE: de l'expiration du délai de rectification. de l'exigibilité des droits. NUMÉROS de la consignation des droits au sommier n° 28 RECETTE des DROITS ET AMENDES: DATE N°s CAUTIONNEMENTS: NUMÉROS de la consignation au sommier n°30 OBSERVATIONS (Les déclarations qui figurent à l'état n°413 doivent être émargées en conséquence, dans la présente colonne.)\",\n",
       " '11_1': 'Arrêté le vingt décembre 1919 servais',\n",
       " '11_2': 'Arrêté le 31 décembre 1919 servais',\n",
       " '11_3': '445 bis Dewez Jean Waterloo 9 8/43 Dewey Germaine 921 921 4/6 1949',\n",
       " '11_4': 'Arrêté le vingt décembre 1919 servais',\n",
       " '11_5': '445 aout 32 Belise Vital Quarant 1 8/43 Cappens Camille 2593 2593 10',\n",
       " '11_6': 'Arrêté le douze décembre 1919 (servais)',\n",
       " '11_7': 'Arrêté le treize décembre 1919 servais',\n",
       " '11_8': 'Arrêté le 31 octobre 1919 servais',\n",
       " '11_9': 'Arrêté le quinze décembre 1919 Servais',\n",
       " '11_10': 'Arrêté le deux décembre 1939 Servais',\n",
       " '11_11': '8 Boisdenghien Henri generet 15 mai Debois Docteur à Aiseau 4239 0 4239 0 619 1899',\n",
       " '11_12': 'Arrêté le six sept décembre 1919 servais',\n",
       " '11_13': 'Arrêté le dix huit décembre 1919 Servais',\n",
       " '12_0': \"N° d'ordre: [blank] Date du dépot des déclarations: [blank] Désignation des personnes décédées ou absentes: Nom: [blank] Prénoms: [blank] Domiciles: [blank] Date du décès ou du jugement d'envoi en possession, en cas d'absence: [blank] Noms, Prénoms et demeures des parties déclarantes: [blank] Droits de succession en ligne collatérale et de mutation en ligne directe: Actif: [blank] Passif: [blank] Restant NET: [blank] Droit de mutation par décès: Valeur des immeubles: [blank] Numéros des déclarations: Primitives: [blank] Supplémentaires: [blank] Date: de l'expiration du délai de rectification: [blank] de l'exigibilité des droits: [blank] Numéros de la consignation des droits au sommier n° 28: [blank] Recette des droits et amendes: Date: [blank] N°: [blank] Cautionnements: Numéros de la consignation au sommier n°30: [blank] Observations: [blank]\",\n",
       " '12_1': '9 1848 22 août 1848 Devillers Joséphine Fleurus 9 février 1918 Devillers Julie à Fleurus 495 1919',\n",
       " '12_2': '41 10 35 Clabecq Fernand Mathieu Francisque Delcuve Emile 16 291 1919',\n",
       " '12_3': 'Arrêté le dix neuf décembre 1919 servais',\n",
       " '12_4': 'Arrêté le vingt et unième 1919 servais',\n",
       " '12_5': 'Arrêté le vingt-un décembre 1919 Dimanche servais',\n",
       " '12_6': '442 vingt deux Gilbert Clémence veuve 19 2 1917 Soignies rue neuve 7 armand 7291 7291 1 février 20 février 1920 7 juillet 97',\n",
       " '12_7': '442² 8 Paesmans Henri Bruxelles 6 mars Paesmans Henri 1881 1180 945 4 Août 31 28 3 57 1917',\n",
       " '12_8': '442³ 5 Minne Maria Ghysel 2 avril Désirée jules 1646 . 1646 648 \" \" 7 janvier 8 1925 1926',\n",
       " '12_9': '4424 5 Malbieu Constance Elise 11 mars 1914 Bousquiaux (époux) 149741 149741 413 1919',\n",
       " '12_10': 'Arrêté le vingt-deux décembre 1919 servais',\n",
       " '12_11': 'Arrêté le vingt-trois décembre 1929 servais',\n",
       " '12_12': '1405 Cauwenberg Victor Joseph Bandes 16.8.911 Gembloux célibataire rentier 262 - 262 305 1911',\n",
       " '12_13': '543 Anthoine Alphonse Aubry 20 Août 1919 Patteet Maurice Ghlin et autre 1826 1826 expirant 26 avril 1920 exigible',\n",
       " '13_0': \"N°  \\nDATE DU DÉPÔT des DÉCLARATIONS  \\nDÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES.: NOMS  \\nDÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES.: PRÉNOMS  \\nDÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES.: DOMICILES  \\nDATE DU DÉCÈS ou du jugement d'envoi en possession, en cas d'absence  \\nNOMS, PRÉNOMS et demeures des PARTIES DÉCLARANTES  \\nDROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE.: ACTIF  \\nDROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE.: PASSIF  \\nDROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE.: RESTANT NET  \\nDROIT DE MUTATION par décès: VALEUR des IMMEUBLES  \\nNUMÉROS des DÉCLARATIONS: PRIMITIVES  \\nNUMÉROS des DÉCLARATIONS: SUPPLÉMENTAIRES  \\nDATE: de l'expiration du délai de rectification  \\nDATE: de l'exigibilité des droits  \\nNUMÉROS de la consignation des droits au sommier n° 28  \\nRECETTE des droits et amendes.: DATE  \\nRECETTE des droits et amendes.: N°s  \\nCAUTIONNEMENTS.: Numéros de la consignation au sommier n°30  \\nOBSERVATIONS. (Les déclarations qui figurent à l'état n°413 doivent être émargées en conséquence, dans la présente colonne)\",\n",
       " '13_1': 'Arrêté le vingt-quatre décembre 1919 servais',\n",
       " '13_2': 'Arrêté le vingt-neuf décembre 1919 Noël servais',\n",
       " '13_3': '14043 Thibault Alexis Louis épicier 5/4/43 Leysele décédé à autres 1940 415/1919',\n",
       " '13_4': 'Arrêté le vingt-six décembre 1919 servais',\n",
       " '13_5': '464 Wautkier Cécile Pauline 20 juin 91 Bossuu Abel 11689 11689 17 février 28 avril 29 avril 91 1920 1920 1920',\n",
       " '13_6': '445 Jacquet Emmerence Roseline 29 Jacquet Emile 58298 2373 56202 7 29 18 avril 1920 38',\n",
       " '13_7': 'Arrêté le vingt-sept décembre 1919 servais',\n",
       " '13_8': 'Arrêté le vingt-huit décembre 1919 Permanence donnée',\n",
       " '13_9': \"446 Vanglaire Guillaume Prosper 5 7 1944 Bruxelles Boul d'anvers 100 700 9 30 17 juillet 1920 non fournie\",\n",
       " '13_10': 'Arrêté le vingt neuf décembre 1919 servais\\n\\n1916 - 39\\n1918 - 418\\n1919 - 388 . 191 220 268 . 368 . 402\\n      948 . 813 . 932 . 935 . 938',\n",
       " '13_11': \"Arrêté le trente décembre 1919 servais Succession d'appartenant de 1919 68 395 1918 68 394 396 396\",\n",
       " '13_12': '446² Plasman Désiré Maurice 10 mars Veny Remy & autres 158 158 1918 81 114 116 142 122 177 1918 341 360 366 370 410',\n",
       " '13_13': 'Arrêté le trente-un décembre 1918 servais',\n",
       " '14_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. DATE DU DÉCÈS DROITS DE SUCCESSION DROIT NUMÉROS DATE RECETTE CAUTIONNEMENTS OBSERVATIONS des déclarations. NOMS. PRÉNOMS. DOMICILES. ou du jugement d'envoi en possession en cas d'absence. NOMS, PRÉNOMS et demeures des parties déclarantes EN LIGNE COLLATÉRALE et de MUTATION EN LIGNE DIRECTE. DE MUTATION par décès. des DÉCLARATIONS de l'expiration du délai de rectification. de l'exigibilité des droits. de la consignation des droits au sommier n° 28 des droits et amendes. NUMÉROS de la consignation au sommier n° 30 (Les déclarations qui figurent à l'état n° 413 doivent être émargées en conséquence, dans la présente colonne.)\",\n",
       " '14_1': 'Arrêté le premier janvier 1920 Circulation Servais',\n",
       " '14_2': '1 deux janvier Severin Jules menuisier à puers delarivière Josephine et 36762 36762 5/6/2 15/3 février 6 mars 1920 juillet 1919 4920 autres 1919',\n",
       " '14_3': '2 Dumont Louise Rosalie Fleury-julette 369 10 10 10 5 14 janvier 1920',\n",
       " '14_4': 'Arrêté le deux janvier 1920 servais',\n",
       " '14_5': 'Arrêté le trois janvier 1920 servais',\n",
       " '14_6': 'Arrêté le quatre janvier 1910 Demeester Servais',\n",
       " '14_7': '3 aout janvier Houlin Edgard Aubry 7 juillet Somme décédé Aubry 111.72 111.72 108 16 janvier 4 mai 22 juillet 1920 1920 1920 526',\n",
       " '14_8': '3e Séverin Jules Ouvrier 6 juillet décédé 1917 34.745 1920',\n",
       " '14_9': '33 Wanderpepen Louis Nivelles 29/8/73 Rentier Seules 1615 1615 707 27 janvier 1916 1920',\n",
       " '14_10': 'Arrêté le vingt janvier 1920 servais',\n",
       " '14_11': '4 septembre Scolas Victoire Joseph Barras 22/8/1944 Rossignol Joseph & autres 9039 9039 15 fevrier 22 juillet spécial 120 1920 1920 1920',\n",
       " '14_12': 'Arrêté le 31 janvier 1920 servais',\n",
       " '14_13': 'Arrêté le 31 janvier 1920 servais',\n",
       " '15_0': \"I understand your request for me to read and transcribe the text from the image even if it's difficult. However the image provided does not contain any handwritten or detailed text to transcribe. It appears to be only the header row of a table showing column titles in printed French text. There is no data or handwritten entries visible in this particular image to read or transcribe. The column headers are clearly visible and match the structure you've described in your instructions but there are no filled-in rows below these headers.\",\n",
       " '15_1': '34 Paul François Lefebvre Laurent Cullige 30/8/1913 Héritiers Euphémie veuve 6510 6510 1447 23/8/1914 24/8/1914',\n",
       " '15_2': 'Arrêté le huit janvier 1920 servais',\n",
       " '15_3': 'Arrêté le neuf janvier 1920 Servais',\n",
       " '15_4': 'Arrêté le dix janvier 1920 servais',\n",
       " '15_5': 'Arrêté le vingt janvier 1920 Duysenche servais',\n",
       " '15_6': '5 daup janv Denck Henri Bonarial 2 mai Arquennes Julien cadet 1200 1200 20 24 fevrier 6 mars 1920 1920',\n",
       " '15_7': 'Arrêté le onze janvier 1920 servais',\n",
       " '15_8': '6 Lacroix Louis Catherin Négociant Officier 21/7 Stanberg usde autel 3641 3641 20 7° 15 mai 1863 non fournis',\n",
       " '15_9': 'Arrêté le trois janvier 1920 Servais',\n",
       " '15_10': 'Arrêté le quatre janvier 1920 servais',\n",
       " '15_11': 'Arrêté le quinze janvier 1920 servais',\n",
       " '15_12': 'Arrêté le deux janvier 1920 servais',\n",
       " '15_13': '7 Schillebeeckx Nicolas Bruxelles 29 juillet Bodengheim Albert 2 août 14625 14625 28 février 29 mars 1 août 1920 270',\n",
       " '16_0': '1 3 Janvier 1922 Vanderhaegen Alphonse Bruxelles 24 Décembre 1921 Vanderhaegen Alphonse, Bruxelles 1,000 - 1,000 - 1 - 3 Juillet 1922 24 Juin 1922 1 24 Juin 1922 1 - -',\n",
       " '16_1': '8 22/9/922 Leclercq Fleuron Marie Anderlues 6/10/919 Leclercq Victor et autres 8468 8468 1916 22 janvier - 6 juillet 1923 non prescrit',\n",
       " '16_2': '9 Gervis Esterphard Gustave Séraphin Castiau Marie Anderlues 3 juillet 1918',\n",
       " '16_3': '9^e 2^e Oreq alphonse gén a 25 8^b 1911 Gembloux Namur Gand 384 4 janvier 50 1919',\n",
       " '16_4': 'Arrêté le dix sept janvier 1930 servais',\n",
       " '16_5': 'Arrêté le dix huit janvier 1920 Dimanche Servais',\n",
       " '16_6': 'Arrêté le trois neuf janvier 1920 servais',\n",
       " '16_7': 'Arrêté le vingt janvier 1920 servais',\n",
       " '16_8': '93 Becquet Barral Rosalie 3 mariage Becquet (Rose) 585 1919',\n",
       " '16_9': 'Arrêté le vingt un janvier 1920 servais',\n",
       " '16_10': 'Arrêté le vingt deux janvier 1930 servais',\n",
       " '16_11': 'Arrêté le vingt trois janvier 1920 servais',\n",
       " '16_12': '10 vingt/quatre Durieux Henri Nestor 4 juillet 1949 Durieux Louis - 141 563 8185 149748 1950 1950 3 avril 1950 3 juillet 1950',\n",
       " '16_13': 'Arrêté le vingt quatre janvier mil neuf cent vingt',\n",
       " '17_0': \"N° d'ordre  \\nDATE DU DÉPÔT des DÉCLARATIONS  \\nDÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES: NOMS, PRÉNOMS, DOMICILES  \\nDATE DU DÉCÈS ou du jugement d'envoi en possession, en cas d'absence.  \\nNOMS, PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES  \\nDROITS DE SUCCESSION en ligne collatérale et de MUTATION EN LIGNE DIRECTE: ACTIF, PASSIF, RESTANT NET  \\nDROIT DE MUTATION par décès: VALEUR des immeubles  \\nNUMÉROS des DÉCLARATIONS  \\nDATE  \\nNUMÉROS de la consignation des droits au sommier n° 28  \\nRECETTE des DROITS ET AMENDES  \\nCAUTIONNEMENTS  \\nOBSERVATIONS  \",\n",
       " '17_1': 'Arrêté le vingt cinq janvier 1920 Dimanche servais',\n",
       " '17_2': '102 vingt-deux janvier Deflandre Gustave Henri Emile 22/8/1913 Auderghem Belgique 440 50 198/1914',\n",
       " '17_3': '10³ Ypersiel Julien Ghislain Rombaux 18 Août 1918 Charleroi coiffeur 280 280 15/1919',\n",
       " '17_4': 'Arrêté le vingt-six janvier 1920 Servais',\n",
       " '17_5': '10 4 janvier Cordeau Louis Maxime 31 janvier Cordeau Adonis 300 300 191 - - 21 janvier 1918',\n",
       " '17_6': 'Arrêté le vingt-huit janvier 1920 servais',\n",
       " '17_7': '10 vingt huit janvier Dececk Désiré Eugène 26 février 1917 Mesvin Ciply 544. 544. 533',\n",
       " '17_8': '405 Decook Isabelle 10 8bre/15 1916',\n",
       " '17_9': '11 3° Bolendries Anastasie Nivelles 13/8/1917 Bolendries Virginie 590 398 198 11 mars 1920 13 avril 1920 2 avril 1920 760',\n",
       " '17_10': 'Arrêté le vingt huit janvier 1920 servais',\n",
       " '17_11': 'Arrêté le vingt neuf janvier 1920 servais',\n",
       " '17_12': '11e Rousseau Charles Gm Nivelles St maurice Rousseau Jeanne 1500 500 1000',\n",
       " '17_13': '115 Dedoncker Vital Eugène 24 août Gouvernement du Hainaut 4487 1568 9340 137 41',\n",
       " '18_0': '1 15 Janvier 1901 Vanderhaegen Rosalie Gand 1 Janvier 1901 Vanderhaegen Edmond négociant à Gand 1,000 - 1,000 - 1 - 15 Avril 1901 15 Juillet 1901 1 15 Juillet 1901 1 - -',\n",
       " '18_1': 'Arrêté le trente janvier 1920 servais',\n",
       " '18_2': 'Arrêté le trente un janvier 1920 servais',\n",
       " '18_3': 'Arrêté le premier février 1920 Dimanche servais',\n",
       " '18_4': \"12 deux fevrier Carlier Victor Quarant 15 fevrier 1912 Rentier veuf d'Ameil 6795 309 6486 7 novembre 15 Aout 15 fevrier 1913\",\n",
       " '18_5': 'Arrêté le deux février 1920 Servais',\n",
       " '18_6': 'Arrêté le Trois février 1920 servais',\n",
       " '18_7': '13 quatre mars 1920 Longe Célestin Bassin S 29 juillet Selay Henri et autre 1634 1634 15 3 25 juin 1920 non passible',\n",
       " '18_8': '14 Legain Emile Oscar Flormont 5 9/1917 Longfils Nelly Castro 1978 3266 6691 19° 19° 3° 1 76419 9 3/1921 135',\n",
       " '18_9': 'Arrêté le quatre février 1920 servais',\n",
       " '18_10': '15 août février Raincy Decès Catherine Pauline 5 avril Boussemart Alphonse Nestor 4390 4390 18 8e 5 juin 1926 non prescrite',\n",
       " '18_11': '15e 5 Denys Marie Virginie Ghislaine épouse Lemaire Emile 1925 supplémentaire 201 1925 5 février 32',\n",
       " '18_12': '15³ Vanhoolebrouck Georges Charles Alphonse 29 mars 1949 Cuypers Emile 5575 5575 304',\n",
       " '18_13': '454 Sainblanc Joseph Auguste Chatelet 7 février 1949 Veuve Hubert et autres 2280 2280 2097,99',\n",
       " '19_0': '1 15 Janvier 1907 Vanderhaegen Alphonse Gand 9 Décembre 1906 Vanderhaegen Alphonse négociant à Gand 1,000 - 1,000 - 1 - 15 Avril 1907 15 Juillet 1907 1 15 Juillet 1907 1 - -',\n",
       " '19_1': 'Arrêté le cinq février 1920 servais',\n",
       " '19_2': 'Arrêté le 22 février 1920 servais',\n",
       " '19_3': 'Arrêté le sept février 1920 servais',\n",
       " '19_4': 'Arrêté le huit février 1920 Dimanche servais',\n",
       " '19_5': 'Arrêté le neuf février 1920 servais',\n",
       " '19_6': '16 six février Soupart Cornelius Nivelles 11 avril 1927 Receveur François à Ohain 39101 39101 26 et mars 11 juin 215 40 215 1928 1928 11 5 1928 178 11 5 1928 178',\n",
       " '19_7': '16a Favre [illegible] Eulalie 2 Août 1915 Trois enfants et autres 1200 1200 90/1916 24 mars 1920 49',\n",
       " '19_8': '163 Siraux Augustin Delory Thomas Coupienne Emile 1025 1025 174/1911',\n",
       " '19_9': 'Arrêté le 31 Janvier 1920 servais',\n",
       " '19_10': 'Arrêté le onze février 1920 servais',\n",
       " '19_11': '17 août 30 Vaneutsem Adeline Bruxelles 13 août 1929 Vaneutsem Charles & autre 73.628 73.628 161 27 mars 1930 27 juillet 1930 20 juillet 1930 230',\n",
       " '19_12': 'Arrêté le douze février 1920 servais',\n",
       " '19_13': '18 Honnijadis Jules Vienne 22 Août Recton de Vienne Bernal 71.507 25 3 25 Août 1923',\n",
       " '20_0': \"N°  \\nDATE DU DÉPÔT  \\nDÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES:  \\nNOMS, PRÉNOMS  \\nDROITS DE SUCCESSION  \\nDROIT  \\nNUMÉROS  \\nDATE  \\nRECETTE  \\nCAUTION-  \\nOBSERVATIONS  \\nd'ordre  \\ndes  \\nNOMS.  \\nPRÉNOMS  \\nDOMICILES  \\nou du  \\nET  \\nDE LIGNE COLLATÉRALE  \\nDE MUTATION  \\ndes  \\nde  \\ndes  \\nNEMENTS.  \\ndéclarations.  \\nJUGEMENT D'ENVOI  \\nDEMEURES DES PARTIES DÉCLARANTES.  \\nET DE MUTATION EN LIGNE DIRECTE  \\nPAR DÉCÈS  \\nDÉCLARATIONS  \\nl'expiration  \\nDROITS ET AMENDES.  \\nen possession  \\nACTIF.  \\nPASSIF.  \\nRESTANT  \\nVALEUR  \\nPrimitives.  \\nSupplémen-  \\ndu délai  \\nDATE  \\nN°  \\nNuméros de la  \\nen cas d'absence.  \\n(2)  \\n(2)  \\nNET.  \\ndes  \\ntaires.  \\nde  \\nconsignation  \\n(2)  \\nIMMEUBLES.  \\nrectification.  \\nau sommier  \\n(2)  \\nn° 30  \",\n",
       " '20_1': 'Arrêté le deux février 1920 servais',\n",
       " '20_2': 'Arrêté le quinze juin 1920 servais',\n",
       " '20_3': 'Arrêté le quinze février 1920 Dimanche servais',\n",
       " '20_4': 'Arrêté le dix-sept février 1920 servais',\n",
       " '20_5': '18² du 24 juin Cabireau Louis tiller 5 maison Beauchamp louis 2 enfants declaration suppletoire 29/5 919',\n",
       " '20_6': '183 Beebes Jules 7 14/8/1918 Despl. f. Gustave xavier 103 563 356/1919',\n",
       " '20_7': 'Arrêté le dix sept janvier 1920 servais',\n",
       " '20_8': 'Arrêté le dix huit janvier 1910 servais',\n",
       " '20_9': '10 décembre 30 Pétriaux Camille Morville 22 avril 1919 Robert Cordantier 6390 31 mars 1920 28 juin 1920 10 juillet 1920 118',\n",
       " '20_10': '10² 5 Dubois Alexandre épicier 5/8/1919 Dubois Jean Bte et autres 310 310 162/1919',\n",
       " '20_11': 'Arrêté le dix neuf février 1920 servais',\n",
       " '20_12': 'Arrêté le vingt février 1920 servais',\n",
       " '20_13': '3 Remience Leon Sta Bruxelles 8 fevrier 1916 Remience Jeanne 400 400 100 9'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claude_complex_output\n",
    "# gpt_two_example_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1f689f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "unable_ids = [id for id, content in claude_complex_output.items() if \"unable\" in content or \"I apologize\" in content or \"The image\" in content or \"sorry\" in content]\n",
    "print(unable_ids, len(unable_ids), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51068bb4",
   "metadata": {},
   "source": [
    "### To run with the saved json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40f2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(path+'/notebooks/json/claude_output_final.json', 'r') as file:\n",
    "        # claude_simple_output = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e2d9533c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_0</td>\n",
       "      <td>N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_1</td>\n",
       "      <td>The image shows a handwritten line of text tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_2</td>\n",
       "      <td>Nivelles le vingt neuf octobre 1919 (décédé)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_3</td>\n",
       "      <td>398 trente Herrent Alphonse J. orphelin 18 8br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_4</td>\n",
       "      <td>398² Lefebvre Jules Brasseur Jemappes Bouillé ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_9</td>\n",
       "      <td>10 Pétriaux Camille Nestor 22 avril 1914 Solda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>10 2/5 Dubois Alexandre épicier 1/8/1919 décéd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>Donné le dix neuf février 1920 dix neuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>Soumis à vingt francs 79 20 centimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>19 Remience Leon Gta Bruxelles 8 fevrier 1946 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0      1_0  N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...\n",
       "1      1_1  The image shows a handwritten line of text tha...\n",
       "2      1_2       Nivelles le vingt neuf octobre 1919 (décédé)\n",
       "3      1_3  398 trente Herrent Alphonse J. orphelin 18 8br...\n",
       "4      1_4  398² Lefebvre Jules Brasseur Jemappes Bouillé ...\n",
       "..     ...                                                ...\n",
       "278   20_9  10 Pétriaux Camille Nestor 22 avril 1914 Solda...\n",
       "279  20_10  10 2/5 Dubois Alexandre épicier 1/8/1919 décéd...\n",
       "280  20_11            Donné le dix neuf février 1920 dix neuf\n",
       "281  20_12               Soumis à vingt francs 79 20 centimes\n",
       "282  20_13  19 Remience Leon Gta Bruxelles 8 fevrier 1946 ...\n",
       "\n",
       "[283 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claude_simple_output_df = pd.DataFrame(claude_simple_output.items(), columns=['id', 'text'])\n",
    "claude_simple_output_df['text'] = claude_simple_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "claude_simple_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d265a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_complex_output_df.to_csv(path+'/results/postprocessed/claude_complex_perline_output2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736b773",
   "metadata": {},
   "source": [
    "# CER/BLEU calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2f6551",
   "metadata": {},
   "source": [
    "## ground truth df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a4c03dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "text_path = path+'/data/transcriptions'\n",
    "file_list = glob(os.path.join(text_path, 'transcription_ex*.txt'))\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in file_list:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    lines = content.split('\\n')\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'line': range(0, len(lines)),  # Line numbers starting from 0\n",
    "        'text': lines\n",
    "    })\n",
    "    \n",
    "    name = os.path.basename(file)\n",
    "    name = name.split('.')[0]\n",
    "    df['file'] = name.split('ex')[1]\n",
    "    df['file'] = df['file'].astype(int)\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "90b2da7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N' d'ordre Date du dépot des déclarations Dési...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Nom. Prénoms Domiciles Actif. (2) Passif. (2) ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arrêté le vingt huit octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>arrêté le vingt neuf octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>398 trente octobre Herrent Alphones gh Ophain ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>10</td>\n",
       "      <td>19 dix neuf d Pétriaux Coralie Nivelles 22 av...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>11</td>\n",
       "      <td>19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>12</td>\n",
       "      <td>Arrêté le dix neuf février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>13</td>\n",
       "      <td>Arrêté le vingt février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>14</td>\n",
       "      <td>19^3 vingt un février Remience Jean Bte Nivell...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     line                                               text  file\n",
       "0       0  N' d'ordre Date du dépot des déclarations Dési...     1\n",
       "1       1  Nom. Prénoms Domiciles Actif. (2) Passif. (2) ...     1\n",
       "2       2   arrêté le vingt huit octobre 1919 servais    ...     1\n",
       "3       3   arrêté le vingt neuf octobre 1919 servais    ...     1\n",
       "4       4  398 trente octobre Herrent Alphones gh Ophain ...     1\n",
       "..    ...                                                ...   ...\n",
       "298    10   19 dix neuf d Pétriaux Coralie Nivelles 22 av...    20\n",
       "299    11  19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...    20\n",
       "300    12          Arrêté le dix neuf février 1920 servais      20\n",
       "301    13             Arrêté le vingt février 1920 servais      20\n",
       "302    14  19^3 vingt un février Remience Jean Bte Nivell...    20\n",
       "\n",
       "[303 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "df = df.sort_values(by=['file', 'line']).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a98c96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the text values of line number 0 and 1 (the two lines of the header)\n",
    "for file in df['file'].unique():\n",
    "    header_lines = df[(df['file'] == file) & (df['line'].isin([0, 1]))]\n",
    "    df.loc[header_lines.index[0], 'text'] = header_lines.iloc[0]['text'] + \" \" + header_lines.iloc[1]['text']\n",
    "df = df[df['line'] != 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d6d3fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['line'] != 0, 'line'] -= 1  # Adjust line numbers after removing the second line of the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dae62cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for file 6, two lines are used for some column.. we need to merge them\n",
    "# doubled_line = df[(df['file'] == 6) & (df['line'].isin([3, 4]))]\n",
    "# df.loc[doubled_line.index[0], 'text'] = doubled_line.iloc[0]['text'] + \" \" + doubled_line.iloc[1]['text']\n",
    "# df.drop(doubled_line.index[1], inplace=True)\n",
    "# df.loc[(df['file'] == 6) & (df['line'] > 4), 'line'] -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d8abb06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N' d'ordre Date du dépot des déclarations Dési...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>arrêté le vingt huit octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arrêté le vingt neuf octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>398 trente octobre Herrent Alphones gh Ophain ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>arrêté le trente octobre 1919 servais        ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>arrêté le trente un octobre 1919 servais     ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>arrêté le premier novembre 1919 Toussaint ser...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>arrêté le deux novembre 1919 Dimanche servais...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>399 trois 9bre Desmedt Jeanne Nivelles 13 mai ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>400 d Monseur Raoul Oscar Clabecq 1 8b 1918 Mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>401 d Bouty Henri Braine l'Alleud 26 février 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>arrêté le trois novembre 1919 servais        ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>402 quatre 9bre Godart Renelde Braine l'Alleud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    line                                               text  file\n",
       "0      0  N' d'ordre Date du dépot des déclarations Dési...     1\n",
       "1      1   arrêté le vingt huit octobre 1919 servais    ...     1\n",
       "2      2   arrêté le vingt neuf octobre 1919 servais    ...     1\n",
       "3      3  398 trente octobre Herrent Alphones gh Ophain ...     1\n",
       "4      4  398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...     1\n",
       "5      5   arrêté le trente octobre 1919 servais        ...     1\n",
       "6      6   arrêté le trente un octobre 1919 servais     ...     1\n",
       "7      7   arrêté le premier novembre 1919 Toussaint ser...     1\n",
       "8      8   arrêté le deux novembre 1919 Dimanche servais...     1\n",
       "9      9  399 trois 9bre Desmedt Jeanne Nivelles 13 mai ...     1\n",
       "10    10  400 d Monseur Raoul Oscar Clabecq 1 8b 1918 Mo...     1\n",
       "11    11  401 d Bouty Henri Braine l'Alleud 26 février 1...     1\n",
       "12    12   arrêté le trois novembre 1919 servais        ...     1\n",
       "13    13  402 quatre 9bre Godart Renelde Braine l'Alleud...     1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['file']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "68922e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N' d'ordre Date du dépot des déclarations Dési...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>arrêté le vingt huit octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arrêté le vingt neuf octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>398 trente octobre Herrent Alphones gh Ophain ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>9</td>\n",
       "      <td>19 dix neuf d Pétriaux Coralie Nivelles 22 av...</td>\n",
       "      <td>20</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>10</td>\n",
       "      <td>19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...</td>\n",
       "      <td>20</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>11</td>\n",
       "      <td>Arrêté le dix neuf février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>12</td>\n",
       "      <td>Arrêté le vingt février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>13</td>\n",
       "      <td>19^3 vingt un février Remience Jean Bte Nivell...</td>\n",
       "      <td>20</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     line                                               text  file     id\n",
       "0       0  N' d'ordre Date du dépot des déclarations Dési...     1    1_0\n",
       "1       1   arrêté le vingt huit octobre 1919 servais    ...     1    1_1\n",
       "2       2   arrêté le vingt neuf octobre 1919 servais    ...     1    1_2\n",
       "3       3  398 trente octobre Herrent Alphones gh Ophain ...     1    1_3\n",
       "4       4  398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...     1    1_4\n",
       "..    ...                                                ...   ...    ...\n",
       "278     9   19 dix neuf d Pétriaux Coralie Nivelles 22 av...    20   20_9\n",
       "279    10  19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...    20  20_10\n",
       "280    11          Arrêté le dix neuf février 1920 servais      20  20_11\n",
       "281    12             Arrêté le vingt février 1920 servais      20  20_12\n",
       "282    13  19^3 vingt un février Remience Jean Bte Nivell...    20  20_13\n",
       "\n",
       "[283 rows x 4 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'] = df['file'].astype(str) + '_' + df['line'].astype(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7fc07b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 1, Last Line: 13\n",
      "File: 2, Last Line: 14\n",
      "File: 3, Last Line: 13\n",
      "File: 4, Last Line: 13\n",
      "File: 5, Last Line: 14\n",
      "File: 6, Last Line: 14\n",
      "File: 7, Last Line: 13\n",
      "File: 8, Last Line: 13\n",
      "File: 9, Last Line: 13\n",
      "File: 10, Last Line: 13\n",
      "File: 11, Last Line: 13\n",
      "File: 12, Last Line: 13\n",
      "File: 13, Last Line: 13\n",
      "File: 14, Last Line: 13\n",
      "File: 15, Last Line: 13\n",
      "File: 16, Last Line: 13\n",
      "File: 17, Last Line: 13\n",
      "File: 18, Last Line: 13\n",
      "File: 19, Last Line: 13\n",
      "File: 20, Last Line: 13\n"
     ]
    }
   ],
   "source": [
    "for file in df['file'].unique():\n",
    "    last_line = df[df['file'] == file]['line'].max()\n",
    "    print(f\"File: {file}, Last Line: {last_line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8837aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path+'/data/transcription_perline_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fb89e02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283 283\n"
     ]
    }
   ],
   "source": [
    "print(df['id'].nunique(), claude_output_df['id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c1c9e",
   "metadata": {},
   "source": [
    "## Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e387c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method = 'zero-shot_simple-prompt'\n",
    "# model = 'claude-3-5-sonnet-20240620'\n",
    "# model = 'trOCR'\n",
    "# pred_path = path+f'/data/transcriptions'\n",
    "# file_list = glob(os.path.join(pred_path, '*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e85c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_list = []\n",
    "# for file in file_list:\n",
    "#     with open(file, 'r', encoding='utf-8') as f:\n",
    "#         content = f.read()\n",
    "#         content = content.replace('\\n', ' ')\n",
    "#         content = content.replace('\\t', ' ')\n",
    "\n",
    "\n",
    "#     pred = pd.DataFrame({\n",
    "#         'text': [content]\n",
    "#     })\n",
    "\n",
    "#     name = os.path.basename(file)\n",
    "#     name = name.split('.txt')[0]\n",
    "#     file = name.split('ex')[1]\n",
    "#     pred['file'] = file\n",
    "#     pred['file'] = pred['file'].astype(int)\n",
    "#     pred_list.append(pred)\n",
    "# pred = pd.concat(pred_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f5f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred.to_csv(path+'/transcriptions_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "897e931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'/data/transcriptions_all_noheader.csv')\n",
    "# df= pd.read_csv(path+'/data/transcriptions_perline_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b0be671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "cer_metric =load(\"cer\")\n",
    "bleu_metric = load(\"bleu\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c05a9600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "# files = glob(os.path.join(path+'/results/postprocessed/whole-scan_experiments', '*.csv'))\n",
    "# files = glob(os.path.join(path+'/results/postprocessed/per-line_experiments', '*.csv'))\n",
    "files = glob(os.path.join(path+'/results/postprocessed/whole-scan_experiments/No_header', '*_noheader.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "928e9f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/whole-scan_experiments/No_header/claude_one_example_whole_output_noheader.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/whole-scan_experiments/No_header/claude_two_example_whole_output_noheader.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/whole-scan_experiments/No_header/gpt_one_example_whole_output_noheader.csv',\n",
       " '/Users/serenekim/Desktop/PhD/img-analysis_seorin_project/results/postprocessed/whole-scan_experiments/No_header/gpt_two_example_whole_output_noheader.csv']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f3123db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[~df['id'].str.contains('_0', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "637acb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing claude_one_example...\n",
      "Processing claude_two_example...\n",
      "Processing gpt_one_example...\n",
      "Processing gpt_two_example...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unidecode\n",
    "# sub = 'id' # 'id' for per-line\n",
    "sub = 'file' #'file' for whole-scan, \n",
    "\n",
    "bleu_perline = pd.DataFrame()\n",
    "cer_perline = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    pred = pd.read_csv(file)\n",
    "    df_filtered = df[df[sub].isin(pred[sub].unique())] \n",
    "\n",
    "    name = os.path.basename(file)\n",
    "    name = name.split('_whole')[0] #for whole-scan\n",
    "    # name = name.split('_perline')[0] #for per-line\n",
    "\n",
    "    print(f\"Processing {name}...\")\n",
    "\n",
    "    bleu_scores = []  \n",
    "    cer_scores = [] \n",
    "\n",
    "    for id in df_filtered[sub].unique():\n",
    "    # for id in df_filtered[~df_filtered['id'].str.contains('_0', na=False)]['id'].unique(): #without header\n",
    "        # Extract the text as a single string, not as an array\n",
    "        pred_text = pred[pred[sub] == id]['text'].values\n",
    "        ref_text = df_filtered[df_filtered[sub] == id]['text'].values\n",
    "\n",
    "        # Ensure the predictions and references are passed as a list of strings\n",
    "        if len(pred_text) > 0 and len(ref_text) > 0:  # Check if both texts are not empty\n",
    "            pred_text = pred_text[0]\n",
    "            ref_text = ref_text[0]\n",
    "\n",
    "            # Check for NaN values \n",
    "            if pd.notna(pred_text) and pd.notna(ref_text):\n",
    "                # Remove multiple consecutive hyphens (e.g., \"----\" or \"- - - - -\")\n",
    "                pred_text = re.sub(r'[-\\s]+', ' ', pred_text)\n",
    "                ref_text = re.sub(r'[-\\s]+', ' ', ref_text)\n",
    "\n",
    "                 # Remove single hyphens between words (e.g., \"vingt-et-un\" -> \"vingt et un\")\n",
    "                pred_text = re.sub(r'\\b(\\w+)-(\\w+)\\b', r'\\1 \\2', pred_text)\n",
    "                ref_text = re.sub(r'\\b(\\w+)-(\\w+)\\b', r'\\1 \\2', ref_text)\n",
    "\n",
    "                # Strip white spaces\n",
    "                pred_text = pred_text.strip()\n",
    "                ref_text = ref_text.strip()\n",
    "                \n",
    "                # Normalize: uncapitalize and remove accents (Try 3 different normalizations)\n",
    "                # pred_text = pred_text.lower()\n",
    "                # ref_text = ref_text.lower()\n",
    "                # pred_text = unidecode.unidecode(pred_text)\n",
    "                # ref_text = unidecode.unidecode(ref_text)\n",
    "                \n",
    "                pred_text = unidecode.unidecode(pred_text).lower()\n",
    "                ref_text = unidecode.unidecode(ref_text).lower()\n",
    "\n",
    "                # Ensure texts are not empty after stripping\n",
    "                if pred_text and ref_text:\n",
    "                    bleu_metrics = bleu_metric.compute(predictions=[pred_text], references=[ref_text], max_order=4)\n",
    "                    cer_metrics = cer_metric.compute(predictions=[pred_text], references=[ref_text])\n",
    "                else:\n",
    "                    bleu_metrics = {'bleu': 0.0}  # Assign a default value if texts are empty\n",
    "                    cer_metrics = 1.0\n",
    "            else:\n",
    "                bleu_metrics = {'bleu': 0.0}  # Assign a default value if texts are NaN\n",
    "                cer_metrics = 1.0\n",
    "        else:\n",
    "            bleu_metrics = {'bleu': 0.0}  # Assign a default value if texts are empty\n",
    "            cer_metrics = 1.0\n",
    "\n",
    "        bleu_scores.append({\n",
    "                'model': name,\n",
    "                'id': id,\n",
    "                **bleu_metrics\n",
    "            })\n",
    "        cer_scores.append({\n",
    "                'model': name,\n",
    "                'id': id,\n",
    "                'cer': cer_metrics\n",
    "            })\n",
    "\n",
    "    bleu_perline = pd.concat([bleu_perline, pd.DataFrame(bleu_scores)], ignore_index=True)\n",
    "    cer_perline = pd.concat([cer_perline, pd.DataFrame(cer_scores)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc16b3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['claude_one_example', 'claude_two_example', 'gpt_one_example',\n",
       "       'gpt_two_example'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cer_perline['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d77448a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_perline.replace({'model': {'gpt': 'gpt_simple', 'claude': 'claude_simple',\n",
    "                               'trOCR': 'TrOCR', 'pytesseractOCR': 'Pytesseract',\n",
    "                               'kerasOCR': 'KerasOCR', 'easyOCR': 'EasyOCR',\n",
    "                               'gpt_refine_complex_output': 'gpt_refine_complex', 'claude_refine_complex_output': 'claude_refine_complex'}}, inplace=True)\n",
    "cer_perline.replace({'model': {'gpt': 'gpt_simple', 'claude': 'claude_simple',\n",
    "                               'trOCR': 'TrOCR', 'pytesseractOCR': 'Pytesseract',\n",
    "                               'kerasOCR': 'KerasOCR', 'easyOCR': 'EasyOCR',\n",
    "                               'gpt_refine_complex_output': 'gpt_refine_complex', 'claude_refine_complex_output': 'claude_refine_complex'}}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e3d731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_perline.to_csv(path+'/results/scores_comparisons/bleu_whole-scan_all_n4_normalized_noheader.csv', index=False)\n",
    "cer_perline.to_csv(path+'/results/scores_comparisons/cer_whole-scan_all_normalized_noheader.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8774a8e",
   "metadata": {},
   "source": [
    "### BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e5be7601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.8091067115702212,\n",
       " 'precisions': [0.8571428571428571, 0.8333333333333334, 0.8, 0.75],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.0,\n",
       " 'translation_length': 7,\n",
       " 'reference_length': 7}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric.compute(predictions=['Arrêté le vingt cinq novembre 1919 Servais'], references=['Arrêté le vingt cinq novembre 1919 servais'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "968b6c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_gpt = pd.DataFrame(bleu_gpt).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc301e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>precisions</th>\n",
       "      <th>brevity_penalty</th>\n",
       "      <th>length_ratio</th>\n",
       "      <th>translation_length</th>\n",
       "      <th>reference_length</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.025, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.06081</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>40</td>\n",
       "      <td>152</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_3</th>\n",
       "      <td>0.137596</td>\n",
       "      <td>[0.38461538461538464, 0.2, 0.125, 0.0434782608...</td>\n",
       "      <td>0.962269</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.449329</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_9</th>\n",
       "      <td>0.259849</td>\n",
       "      <td>[0.5454545454545454, 0.38095238095238093, 0.25...</td>\n",
       "      <td>0.955563</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_10</th>\n",
       "      <td>0.150923</td>\n",
       "      <td>[0.45, 0.2631578947368421, 0.1111111111111111,...</td>\n",
       "      <td>0.904837</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_13</th>\n",
       "      <td>0.163304</td>\n",
       "      <td>[0.5, 0.3076923076923077, 0.25, 0.181818181818...</td>\n",
       "      <td>0.564718</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           bleu                                         precisions  \\\n",
       "1_0         0.0                             [0.025, 0.0, 0.0, 0.0]   \n",
       "1_1         1.0                               [1.0, 1.0, 1.0, 1.0]   \n",
       "1_2         1.0                               [1.0, 1.0, 1.0, 1.0]   \n",
       "1_3    0.137596  [0.38461538461538464, 0.2, 0.125, 0.0434782608...   \n",
       "1_4         0.0                               [0.1, 0.0, 0.0, 0.0]   \n",
       "...         ...                                                ...   \n",
       "20_9   0.259849  [0.5454545454545454, 0.38095238095238093, 0.25...   \n",
       "20_10  0.150923  [0.45, 0.2631578947368421, 0.1111111111111111,...   \n",
       "20_11       1.0                               [1.0, 1.0, 1.0, 1.0]   \n",
       "20_12       1.0                               [1.0, 1.0, 1.0, 1.0]   \n",
       "20_13  0.163304  [0.5, 0.3076923076923077, 0.25, 0.181818181818...   \n",
       "\n",
       "      brevity_penalty length_ratio translation_length reference_length     id  \n",
       "1_0           0.06081     0.263158                 40              152    1_0  \n",
       "1_1               1.0          1.0                  7                7    1_1  \n",
       "1_2               1.0          1.0                  7                7    1_2  \n",
       "1_3          0.962269     0.962963                 26               27    1_3  \n",
       "1_4          0.449329     0.555556                 10               18    1_4  \n",
       "...               ...          ...                ...              ...    ...  \n",
       "20_9         0.955563     0.956522                 22               23   20_9  \n",
       "20_10        0.904837     0.909091                 20               22  20_10  \n",
       "20_11             1.0          1.0                  7                7  20_11  \n",
       "20_12             1.0          1.0                  6                6  20_12  \n",
       "20_13        0.564718     0.636364                 14               22  20_13  \n",
       "\n",
       "[283 rows x 7 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_gpt['id'] = bleu_gpt.index\n",
    "bleu_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42415cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_gpt.to_csv(path+'/results/scores_comparisons/eval_perline/bleu_claude_two_example_perline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4efe09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bd8ab74",
   "metadata": {},
   "source": [
    "### CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9933242",
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_gpt = pd.DataFrame(cer_gpt.items(), columns=['id', 'cer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84bd52c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5713106915175424 2.935498085710415\n"
     ]
    }
   ],
   "source": [
    "print(cer_gpt['cer'].mean(), cer_gpt['cer'].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fba7876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_gpt.to_csv(path+'/results/scores_comparisons/eval_perline/cer_claude_two_example_perline.csv', float_format=\"%.6f\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783bfe80",
   "metadata": {},
   "source": [
    "# OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd1af15-25ff-4636-800b-599ef2d986f1",
   "metadata": {},
   "source": [
    "## EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e1baa4c9-2e16-47bf-aed6-47a4c0de1807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def easyOCR(image_path):\n",
    "    reader = easyocr.Reader(['fr'])\n",
    "    img = cv2.imread(image_path)\n",
    "    results = reader.readtext(img)\n",
    "    output = []\n",
    "    for res in results:\n",
    "        det, conf = res[1], res[2]\n",
    "        output.append((det, round(conf, 2))) \n",
    "    text = ' '.join([i[0] for i in output])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "474cc34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "easyOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = easyOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        easyOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b45d798e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>line_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_00</td>\n",
       "      <td>DÉSIGNATION DES PERSONNES DÉCÉDÉES OU AlSENTES...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_01</td>\n",
       "      <td>~Bcrta` 8 oetolz 1919 d4earuey vicytAul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_02</td>\n",
       "      <td>Jbsucala &amp; veyhmeuf ouoba  tg19 [eevœy</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_03</td>\n",
       "      <td>891 ta HBevcenk ~Bepkonssjk oj hain Hgoucoal Y...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_04</td>\n",
       "      <td>TulL Bouuù Q \"Janer ~aobà Bhuile RRXR 26 aplul...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_09</td>\n",
       "      <td>J9 ùcà nuf&gt; Sebiaw bo2nbi YÉvepQu X anel Bebel...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>4 49 0 : @ubovs ssexanbz Yuemaut ubuùd *ean [l...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>Jvuté &amp; oi = neuf fasles19:0 Huclai</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>Jarsalé -   vms] Hinsenq %0 djeceia |</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>3 [9' vrqkun )a4| Semience Run Gl Yusvellen Le...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text  file_name  \\\n",
       "0     1_00  DÉSIGNATION DES PERSONNES DÉCÉDÉES OU AlSENTES...          1   \n",
       "1     1_01            ~Bcrta` 8 oetolz 1919 d4earuey vicytAul          1   \n",
       "2     1_02             Jbsucala & veyhmeuf ouoba  tg19 [eevœy          1   \n",
       "3     1_03  891 ta HBevcenk ~Bepkonssjk oj hain Hgoucoal Y...          1   \n",
       "4     1_04  TulL Bouuù Q \"Janer ~aobà Bhuile RRXR 26 aplul...          1   \n",
       "..     ...                                                ...        ...   \n",
       "278  20_09  J9 ùcà nuf> Sebiaw bo2nbi YÉvepQu X anel Bebel...         20   \n",
       "279  20_10  4 49 0 : @ubovs ssexanbz Yuemaut ubuùd *ean [l...         20   \n",
       "280  20_11                Jvuté & oi = neuf fasles19:0 Huclai         20   \n",
       "281  20_12              Jarsalé -   vms] Hinsenq %0 djeceia |         20   \n",
       "282  20_13  3 [9' vrqkun )a4| Semience Run Gl Yusvellen Le...         20   \n",
       "\n",
       "     line_name     id  \n",
       "0            0    1_0  \n",
       "1            1    1_1  \n",
       "2            2    1_2  \n",
       "3            3    1_3  \n",
       "4            4    1_4  \n",
       "..         ...    ...  \n",
       "278          9   20_9  \n",
       "279         10  20_10  \n",
       "280         11  20_11  \n",
       "281         12  20_12  \n",
       "282         13  20_13  \n",
       "\n",
       "[283 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# easyOCR_output_df = pd.read_csv(path+'/results/postprocessed/easyOCR_perline_output.csv')\n",
    "easyOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6f85318b-55be-419d-b80a-0e8c5b861779",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_00</td>\n",
       "      <td>DATE I IÉcis DROITS DF SUCCESSION DROIT NUMÉRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_01</td>\n",
       "      <td>soceti &amp; tù déeemebza. 919 Yuepiy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_02</td>\n",
       "      <td>5 1439 DaLenlize Yiceppu #9lugu | Benuue YLama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10_03</td>\n",
       "      <td>Jaxat' € deeemlaac919 Fuupùa quebu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10_04</td>\n",
       "      <td>[4ho ceæy _ (ekalque Pnag;nl  Yjuuy Wv&amp;ezlbz (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>9_09</td>\n",
       "      <td>69*2.4 Scinllane Pots+a Gxz9&amp; SasBBoe Gpmzeyen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>9_10</td>\n",
       "      <td>kag' 0: Sainllane Bwun' à 26r' 1sr \"9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>9_11</td>\n",
       "      <td>Joaak + fnmauu dceehu 1919 Yeoeok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>9_12</td>\n",
       "      <td>[4Jg %eu 3- CBaslice fe At Z8ma 2e+eygu | Jwti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>9_13</td>\n",
       "      <td>~outi &amp; Jeun 1919 fuwsuik Lg déclerations recl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text\n",
       "0    10_00  DATE I IÉcis DROITS DF SUCCESSION DROIT NUMÉRO...\n",
       "1    10_01                  soceti & tù déeemebza. 919 Yuepiy\n",
       "2    10_02  5 1439 DaLenlize Yiceppu #9lugu | Benuue YLama...\n",
       "3    10_03                 Jaxat' € deeemlaac919 Fuupùa quebu\n",
       "4    10_04  [4ho ceæy _ (ekalque Pnag;nl  Yjuuy Wv&ezlbz (...\n",
       "..     ...                                                ...\n",
       "278   9_09  69*2.4 Scinllane Pots+a Gxz9& SasBBoe Gpmzeyen...\n",
       "279   9_10              kag' 0: Sainllane Bwun' à 26r' 1sr \"9\n",
       "280   9_11                  Joaak + fnmauu dceehu 1919 Yeoeok\n",
       "281   9_12  [4Jg %eu 3- CBaslice fe At Z8ma 2e+eygu | Jwti...\n",
       "282   9_13  ~outi & Jeun 1919 fuwsuik Lg déclerations recl...\n",
       "\n",
       "[283 rows x 2 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easyOCR_output_df = pd.DataFrame(easyOCR_output.items(), columns=['file', 'text'])\n",
    "easyOCR_output_df[['file_name', 'line_name']] = easyOCR_output_df['file'].str.split('_', expand=True)\n",
    "easyOCR_output_df[['file_name', 'line_name']] = easyOCR_output_df[['file_name', 'line_name']].astype(int)\n",
    "easyOCR_output_df = easyOCR_output_df.sort_values(by=['file_name', 'line_name']).reset_index(drop=True)\n",
    "easyOCR_output_df['text'] = easyOCR_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "easyOCR_output_df['id'] = easyOCR_output_df['file_name'].astype(str) + '_' + easyOCR_output_df['line_name'].astype(str)\n",
    "easyOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "512ffd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "easyOCR_output_df.to_csv(path+'/results/postprocessed/easyOCR_perline_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09134009-83a9-4ed0-b724-d9a4096ebe7d",
   "metadata": {},
   "source": [
    "## Pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e86c0ee3-034b-446d-aa51-3e5e6e348fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pytesseractOCR(image_path):\n",
    "    try:\n",
    "        image = PILImage.open(image_path)\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text\n",
    "    except:\n",
    "        print(\"[ERROR] pytesseractOCR failed! (should be installed)\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f596a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseractOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = pytesseractOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        pytesseractOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8149b7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>line_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_00</td>\n",
       "      <td>|  = | DATE DU DEPOT  des  DECLARATIONS.  DESI...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_01</td>\n",
       "      <td>ft alt alta</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_02</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_03</td>\n",
       "      <td>a cnte |Abevcenk a dette  Son &lt;a  1040’  i ee ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_04</td>\n",
       "      <td>L  3  be oi  7  Nf »- p</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_09</td>\n",
       "      <td>149 28 auf  Si elaiawx  Ve  |  | Wvebly eu ty ...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>; a : oe ssa  song  o  Sannin nomena  ie 3 (0....</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>|  aul</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>Caen torah Winéorg ty dieser’  es  oe  aaa. pa...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>+ i 4 | pane um ‘ uy R | £5 dée! t ctfleati ec...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text  file_name  \\\n",
       "0     1_00  |  = | DATE DU DEPOT  des  DECLARATIONS.  DESI...          1   \n",
       "1     1_01                                       ft alt alta           1   \n",
       "2     1_02                                                             1   \n",
       "3     1_03  a cnte |Abevcenk a dette  Son <a  1040’  i ee ...          1   \n",
       "4     1_04                          L  3  be oi  7  Nf »- p            1   \n",
       "..     ...                                                ...        ...   \n",
       "278  20_09  149 28 auf  Si elaiawx  Ve  |  | Wvebly eu ty ...         20   \n",
       "279  20_10  ; a : oe ssa  song  o  Sannin nomena  ie 3 (0....         20   \n",
       "280  20_11                                            |  aul          20   \n",
       "281  20_12  Caen torah Winéorg ty dieser’  es  oe  aaa. pa...         20   \n",
       "282  20_13  + i 4 | pane um ‘ uy R | £5 dée! t ctfleati ec...         20   \n",
       "\n",
       "     line_name     id  \n",
       "0            0    1_0  \n",
       "1            1    1_1  \n",
       "2            2    1_2  \n",
       "3            3    1_3  \n",
       "4            4    1_4  \n",
       "..         ...    ...  \n",
       "278          9   20_9  \n",
       "279         10  20_10  \n",
       "280         11  20_11  \n",
       "281         12  20_12  \n",
       "282         13  20_13  \n",
       "\n",
       "[283 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytesseractOCR_output_df = pd.DataFrame(pytesseractOCR_output.items(), columns=['file', 'text'])\n",
    "pytesseractOCR_output_df[['file_name', 'line_name']] = pytesseractOCR_output_df['file'].str.split('_', expand=True)\n",
    "pytesseractOCR_output_df[['file_name', 'line_name']] = pytesseractOCR_output_df[['file_name', 'line_name']].astype(int)\n",
    "pytesseractOCR_output_df = pytesseractOCR_output_df.sort_values(by=['file_name', 'line_name']).reset_index(drop=True)\n",
    "pytesseractOCR_output_df['text'] = pytesseractOCR_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "pytesseractOCR_output_df['id'] = pytesseractOCR_output_df['file_name'].astype(str) + '_' + pytesseractOCR_output_df['line_name'].astype(str)\n",
    "pytesseractOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f26931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseractOCR_output_df.to_csv(path+'/results/postprocessed/pytesseractOCR_perline_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061630dd-6446-4a62-9b39-bd87c86a99f4",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "Not good for non-english?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e561f951-54a9-4d73-b778-41f9dbcdbe0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kerasOCR(image_path):\n",
    "    pipeline = keras_ocr.pipeline.Pipeline()\n",
    "    image = keras_ocr.tools.read(image_path)\n",
    "    prediction_groups = pipeline.recognize([image])\n",
    "    words = []\n",
    "    for line in prediction_groups[0]:\n",
    "        for word in line:\n",
    "            try:\n",
    "                if isinstance(word[0], str):\n",
    "                    words.append(word[0])\n",
    "            except IndexError:\n",
    "                continue\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71e1e880",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m kerasOCR_output \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(image_folder):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      4\u001b[0m         image_path \u001b[38;5;241m=\u001b[39m image_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m image\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "kerasOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = kerasOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        kerasOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "82c872cd-131c-4bc4-96cf-2dd2e62e0f59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for /Users/serenekim/.keras-ocr/craft_mlt_25k.h5\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: resize_bilinear (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.image.resize(...method=ResizeMethod.BILINEAR...)` instead.\n",
      "Looking for /Users/serenekim/.keras-ocr/crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 806ms/step\n",
      "1/1 [==============================] - 1s 751ms/step\n",
      "d r p o a g\n"
     ]
    }
   ],
   "source": [
    "test_keras = kerasOCR(image_path=test_path)\n",
    "print(test_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf6c0a",
   "metadata": {},
   "source": [
    "## TrOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cde01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor\n",
    "from transformers import VisionEncoderDecoderModel\n",
    "import torch\n",
    "\n",
    "def trOCR(image_path):\n",
    "    processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "\n",
    "    image = PILImage.open(image_path)\n",
    "\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "    \n",
    "    # Set device (GPU or CPU)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)  # Move model to the device\n",
    "    pixel_values = pixel_values.to(device)  # Move image tensor to the same device\n",
    "    \n",
    "    try:\n",
    "        generated_ids = model.generate(pixel_values, max_length=400)  # Limit max length\n",
    "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return generated_text\n",
    "    except IndexError as e:\n",
    "        print(f\"IndexError: {e}\")\n",
    "        return \"Error: Index out of range during generation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27ab20c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/serenekim/.pyenv/versions/3.12.0/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = trOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        trOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caa3c0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>line_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_00</td>\n",
       "      <td>treat of the first time of the French Parliame...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_01</td>\n",
       "      <td># almost be weighted rather any standard for t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_02</td>\n",
       "      <td># almost the original module you formerly ... ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_03</td>\n",
       "      <td>THE GREAT BRONDSOME \" AIRMARK GABIT PARADE HAN...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_04</td>\n",
       "      <td>After Congress plan himself tough back down to...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_09</td>\n",
       "      <td>Manager Atkinson had made many awareness of th...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>After the Democratic gubernatorial judge took ...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>the best time of fourteen songs with the first...</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>\" To absorb confidence being a total of 1 000 ...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>After the Renaissance season would change thei...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text  file_name  \\\n",
       "0     1_00  treat of the first time of the French Parliame...          1   \n",
       "1     1_01  # almost be weighted rather any standard for t...          1   \n",
       "2     1_02  # almost the original module you formerly ... ...          1   \n",
       "3     1_03  THE GREAT BRONDSOME \" AIRMARK GABIT PARADE HAN...          1   \n",
       "4     1_04  After Congress plan himself tough back down to...          1   \n",
       "..     ...                                                ...        ...   \n",
       "278  20_09  Manager Atkinson had made many awareness of th...         20   \n",
       "279  20_10  After the Democratic gubernatorial judge took ...         20   \n",
       "280  20_11  the best time of fourteen songs with the first...         20   \n",
       "281  20_12  \" To absorb confidence being a total of 1 000 ...         20   \n",
       "282  20_13  After the Renaissance season would change thei...         20   \n",
       "\n",
       "     line_name     id  \n",
       "0            0    1_0  \n",
       "1            1    1_1  \n",
       "2            2    1_2  \n",
       "3            3    1_3  \n",
       "4            4    1_4  \n",
       "..         ...    ...  \n",
       "278          9   20_9  \n",
       "279         10  20_10  \n",
       "280         11  20_11  \n",
       "281         12  20_12  \n",
       "282         13  20_13  \n",
       "\n",
       "[283 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trOCR_output_df = pd.DataFrame(trOCR_output.items(), columns=['file', 'text'])\n",
    "trOCR_output_df[['file_name', 'line_name']] = trOCR_output_df['file'].str.split('_', expand=True)\n",
    "trOCR_output_df[['file_name', 'line_name']] = trOCR_output_df[['file_name', 'line_name']].astype(int)\n",
    "trOCR_output_df = trOCR_output_df.sort_values(by=['file_name', 'line_name']).reset_index(drop=True)\n",
    "trOCR_output_df['text'] = trOCR_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "trOCR_output_df['id'] = trOCR_output_df['file_name'].astype(str) + '_' + trOCR_output_df['line_name'].astype(str)\n",
    "trOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd3cec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "trOCR_output_df.to_csv(path+'/results/postprocessed/trOCR_perline_output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
