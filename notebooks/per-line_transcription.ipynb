{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c798e7-9579-4c02-88ca-0c57e52c2966",
   "metadata": {},
   "source": [
    "# per-line transcription with LLM & OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069d0fa8-6403-402b-954a-cbc05503eb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import base64\n",
    "import subprocess\n",
    "from IPython.display import display, Image\n",
    "from PIL import Image as PILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f521cad-9da9-4cdf-a63d-f5dd4ca3e4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "import pytesseract\n",
    "import keras_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "857d11aa-8fb9-4f32-a20c-5e418f5154e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = os.path.dirname(os.getcwd()) # Parent directory\n",
    "image_folder = path+'/data/lines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffd293ec-7b82-4145-820e-9e910c7d099d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OpenAI\n",
    "load_dotenv() #get the environment \n",
    "openai_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_client = OpenAI(api_key=openai_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9cc501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "anthropic_client = Anthropic(api_key=anthropic_API_KEY)\n",
    "MODEL_NAME = \"claude-3-5-sonnet-20240620\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4c585-70a5-466a-ac27-f730debebfba",
   "metadata": {},
   "source": [
    "## Read and encode the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e6f97e1-5798-4253-a324-58a38bae7f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b48666f-fd04-4f79-ba1a-8a254e9d81c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        images.append(image)\n",
    "\n",
    "rows = []\n",
    "for image in images:\n",
    "    name = image.split('.')[0]\n",
    "    name_split = name.split('_')[0]\n",
    "    file_name = name_split.split('example')[1]\n",
    "    line_name = name.split('_')[1]\n",
    "    encoded_value = encode_image(image_folder+'/'+image)\n",
    "    rows.append({'file': file_name, 'line': line_name, 'encoded': encoded_value})\n",
    "\n",
    "images_encoded = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c988074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>line</th>\n",
       "      <th>encoded</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/9j/4QZBRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>/9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>/9j/4QYvRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>/9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>/9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>/9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>/9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>/9j/4QWRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>/9j/4QZyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>/9j/4QZRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>/9j/4QZ1RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>/9j/4QVrRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>/9j/4QaFRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...</td>\n",
       "      <td>1_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QcyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>/9j/4QVORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>/9j/4QX+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>/9j/4QY6RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>/9j/4QaQRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>/9j/4QVWRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>/9j/4QZ3RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>/9j/4QXbRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>/9j/4QaORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>/9j/4QWIRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>/9j/4QWARXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>/9j/4QZwRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>/9j/4QZlRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>/9j/4QV+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>/9j/4QbYRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...</td>\n",
       "      <td>2_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>/9j/4QbPRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...</td>\n",
       "      <td>3_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file  line                                            encoded    id\n",
       "0      1     0  /9j/4QczRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_0\n",
       "1      1     1  /9j/4QZBRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_1\n",
       "2      1     2  /9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_2\n",
       "3      1     3  /9j/4QYvRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_3\n",
       "4      1     4  /9j/4QZLRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_4\n",
       "5      1     5  /9j/4QVaRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_5\n",
       "6      1     6  /9j/4QVqRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_6\n",
       "7      1     7  /9j/4QX5RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_7\n",
       "8      1     8  /9j/4QWRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_8\n",
       "9      1     9  /9j/4QZyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...   1_9\n",
       "10     1    10  /9j/4QZRRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_10\n",
       "11     1    11  /9j/4QZ1RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_11\n",
       "12     1    12  /9j/4QVrRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_12\n",
       "13     1    13  /9j/4QaFRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD5YAAA...  1_13\n",
       "14     2     0  /9j/4QcyRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_0\n",
       "15     2     1  /9j/4QVORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_1\n",
       "16     2     2  /9j/4QX+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_2\n",
       "17     2     3  /9j/4QY6RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_3\n",
       "18     2     4  /9j/4QaQRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_4\n",
       "19     2     5  /9j/4QVWRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_5\n",
       "20     2     6  /9j/4QZ3RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_6\n",
       "21     2     7  /9j/4QXbRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_7\n",
       "22     2     8  /9j/4QaORXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_8\n",
       "23     2     9  /9j/4QWIRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...   2_9\n",
       "24     2    10  /9j/4QWARXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_10\n",
       "25     2    11  /9j/4QZwRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_11\n",
       "26     2    12  /9j/4QZlRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_12\n",
       "27     2    13  /9j/4QV+RXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_13\n",
       "28     2    14  /9j/4QbYRXhpZgAATU0AKgAAAAgADQEAAAMAAAABD30AAA...  2_14\n",
       "29     3     0  /9j/4QbPRXhpZgAATU0AKgAAAAgADAEAAAMAAAABFkAAAA...   3_0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_encoded['file'] = images_encoded['file'].astype('int')\n",
    "images_encoded['line'] = images_encoded['line'].astype('int')\n",
    "images_encoded = images_encoded.sort_values(by=['file', 'line']).reset_index(drop=True)\n",
    "images_encoded['id'] = images_encoded['file'].astype(str) + '_' + images_encoded['line'].astype(str)\n",
    "images_encoded.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa240d54",
   "metadata": {},
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd51de42-7ecf-4171-88fd-cc78fb803632",
   "metadata": {},
   "source": [
    "## General API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73f51be1-2815-4280-ab50-4a909baf7016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def callOpenAI(prompt, max_tokens=800, base64_image=None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_API_KEY}\"\n",
    "    } \n",
    "    model_vision = \"gpt-4o\"\n",
    "    payload = {\n",
    "        \"model\": model_vision, \n",
    "        \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "            \n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                }\n",
    "            }\n",
    "            ]\n",
    "        }\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    try:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except:\n",
    "        print(response.json()[\"error\"][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6be70b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callAnthropic(prompt, max_tokens=5000, base64_image=None):\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=max_tokens,\n",
    "        system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\", \n",
    "                            \"media_type\": \"image/jpeg\", \n",
    "                            \"data\": base64_image}},\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt,\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.to_dict()[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a94328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callPostProcessing(max_tokens=800, prompt_parameter = None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_API_KEY}\"\n",
    "    } \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"\"\"This is an output from you. Clean it such that we have no separators and no comment from you: {prompt_parameter}\n",
    "                \"\"\"\n",
    "            }\n",
    "            ]\n",
    "        }\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    try:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except:\n",
    "        print(response.json()[\"error\"][\"message\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b44a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this when OpenAI credits are exhausted\n",
    "def callPostProcessing_anthropic(max_tokens=5000, prompt_parameter = None):\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=max_tokens,\n",
    "        system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"\"\"This is an output from you. Clean it such that we have no separators and no comment from you: {prompt_parameter}\n",
    "                \"\"\"\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.to_dict()[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65f775",
   "metadata": {},
   "source": [
    "### Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56c01d37-e85d-45ee-b6c8-9e92b5078e87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/xy/r3gq5vtd7bx6qb966l0fhh9h0000gn/T/ipykernel_63694/818506988.py:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  prompt_complex = \"\"\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "    Recognize the text from the image:\n",
    "    ```plaintext\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_complex = \"\"\"\n",
    "    Context:\n",
    "        It's an old Belgian document. And you're getting one row of a table from it. It's written in French language and the names of the people are domiciles are Belgian.\n",
    "\n",
    "    Structure:\n",
    "        The table is structured with the two-level headers as follows:\n",
    "        [(\"N' d'ordre\", \" \"),\n",
    "                (\"Date du dépot des déclarations\", \" \"),\n",
    "                (\"Désignation des personnes décédées ou absentes.:\", \"Nom.\"),\n",
    "                (\"Désignation des personnes décédées ou absentes.:\", \"Prénoms\"),\n",
    "                (\"Désignation des personnes décédées ou absentes.:\", \"Domiciles\"), \n",
    "                (\"Date du décès ou du judgement d'envoi en possession, en cas d'absence.\", \" \"),\n",
    "                (\"Noms, Prénoms et demeures des parties déclarantes.\", \" \"),\n",
    "                (\"Droits de succession en ligne collatérale et de mutation en ligne directe.\", \"Actif. (2)\"),\n",
    "                (\"Droits de succession en ligne collatérale et de mutation en ligne directe.\", \"Passif. (2)\"),\n",
    "                (\"Droits de succession en ligne collatérale et de mutation en ligne directe.\", \"Restant NET. (2)\"),\n",
    "                (\"Droit de mutation par déces\", \"Valeur des immeubles. (2)\"), \n",
    "                (\"Numéros des déclarations\", \"Primitives.\"),\n",
    "                (\"Numéros des déclarations\", \"Supplémentaires.\"), \n",
    "                (\"Date\", \"de l'expiration du délai de rectification.\"),\n",
    "                (\"Date\", \"de l'exigibilité des droits.\"),\n",
    "                (\"Numéros de la consignation des droits au sommier n' 28\", \" \"),\n",
    "                (\"Recette des droits et amendes.\", \"Date\"),\n",
    "                (\"Recette des droits et amendes.\", \"N^03\"),\n",
    "                (\"Cautionnements. \", \"Numéros de la consignation au sommier n'30\"),\n",
    "                (\"Observations (les déclarations qui figurent à l'état n'413 doivent être émargées en conséquence, dans la présnete colonne.)\", \" \")] \n",
    "\n",
    "        Some image (hence, some rows) may start with \"Arrêté le \\d{2} \\w+ \\d{4}( \\w+)? servais\" or contain notes.\n",
    "\n",
    "    Task:\n",
    "        Recognize the text from the image. Pay attention to reading each word and number correctly. Return the text as you read it and you must read the text from the image since the image contains texts.\n",
    "    ```plaintext \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2bca041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Start processing file 6_1 -------\n",
      "------- Finished processing file 6_1 in 4.5775532722473145 seconds -------\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Load previous progress if available\n",
    "try:\n",
    "    with open('gpt_complex_output_progress.json', 'r') as file:\n",
    "        claude_complex_output = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    claude_complex_output = {}\n",
    "\n",
    "# Loop through each unique id\n",
    "# for id in images_encoded['id'].unique():\n",
    "for id in unable_ids_1:\n",
    "    # Check if this ID is already processed (Skip this step if you want to re-process for unable_ids) ----------------\n",
    "    # if id in claude_complex_output:\n",
    "    #     print(f\"Skipping {id}, already processed.\")\n",
    "    #     continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        print(f'------- Start processing file {id} -------')\n",
    "        \n",
    "        # Call OpenAI/Anthropic and post-processing functions\n",
    "        prompt_complex += \"Even if it is hard to read the texts from the image, return as much as you can. You must read something. Do not return an apologetic message.\"\n",
    "        # output = callOpenAI(prompt=prompt_complex, max_tokens=800, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0])\n",
    "        output = callAnthropic(prompt=prompt_complex, max_tokens=800, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0])\n",
    "        output_cleaned = callPostProcessing(prompt_parameter=output)\n",
    "        \n",
    "        # Save the output\n",
    "        claude_complex_output[id] = output_cleaned\n",
    "        \n",
    "        # Save progress after each file\n",
    "        with open('claude_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_complex_output, file)\n",
    "        \n",
    "        print(f'------- Finished processing file {id} in {time.time() - start_time} seconds -------')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {id}: {str(e)}\")\n",
    "        # Save the progress and exit the loop in case of an error\n",
    "        with open('claude_complex_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_complex_output, file)\n",
    "        break  # Exit the loop on error\n",
    "\n",
    "# Once all IDs are processed, save the final result\n",
    "with open('claude_complex_output_final.json', 'w') as file:\n",
    "    json.dump(claude_complex_output, file)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc31c4e8",
   "metadata": {},
   "source": [
    "### Few-shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24130132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'/data/transcription_perline_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95afd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = images_encoded[images_encoded['id'] == '1_1'].encoded.values[0]\n",
    "example2 = images_encoded[images_encoded['id'] == '1_2'].encoded.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c14ff3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_encoded_oneshot = images_encoded[~images_encoded['id'].isin(['1_1'])]\n",
    "images_encoded_twoshot = images_encoded[~images_encoded['id'].isin(['1_1', '1_2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbaa3fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "example1_text = df[df['id'] == '1_1'].text.values[0]\n",
    "example2_text = df[df['id'] == '1_2'].text.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "998fc479",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_texts =  [example1_text, df[df['id'] ==  '1_3'].text.values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b683c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_encoded_extexts = images_encoded[~images_encoded['id'].isin(['1_1', '1_3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d04a03ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_example =  \"\"\"\n",
    "    Recognize the texts from the image like the examples.\n",
    "    ```plaintext\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0bdb0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example1_text or exmple_texts\n",
    "prompt_example_text = f\"\"\"\n",
    "                        The ```plaintext block is the example transcription of the example image you saw:\n",
    "\n",
    "                        Transcription:\n",
    "                        ```plaintext\n",
    "                        {example_texts}\n",
    "                        ```\n",
    "                        Compare what you read initially and the solution key in ```plaintext block. Recreate the content of the table in this image. Only that, no other information from you.\n",
    "\n",
    "                        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "721c10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callOpenAI_example(prompt, example1, example2=None, NExample=1, base64_image=None, max_tokens=5000):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_API_KEY}\"\n",
    "    } \n",
    "    model_vision = \"gpt-4o\"\n",
    "\n",
    "    if NExample == 1:\n",
    "        payload = {\n",
    "            \"model\": model_vision, \n",
    "            \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "                \n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{example1}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": example1_text\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "                ]\n",
    "            }\n",
    "            ],\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    if NExample == 2:\n",
    "               payload = {\n",
    "            \"model\": model_vision, \n",
    "            \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\"\n",
    "                \n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{example1}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": example1_text\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{example2}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": example2_text\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "                ]\n",
    "            }\n",
    "            ],\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    try:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except:\n",
    "        print(response.json()[\"error\"][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adc4a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callAnthropic_example(prompt, example1, example2=None, NExample=1, base64_image=None, max_tokens=5000):\n",
    "    if NExample == 1:\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=max_tokens,\n",
    "            system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": example1}},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example1_text,\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt,\n",
    "                        },\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": base64_image}}\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "        \n",
    "    if NExample == 2:\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=max_tokens,\n",
    "            system = \"You are a helpful assistant who can read old handwriting with a background in history, and you are going to recreate a scanned déclaration de succession from Belgium in a txt format.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": example1}},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example1_text,\n",
    "                        },\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": example2}},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example2_text,\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt,\n",
    "                        },\n",
    "                        {\"type\": \"image\", \n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\", \n",
    "                                \"media_type\": \"image/jpeg\", \n",
    "                                \"data\": base64_image}}\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "    return response.to_dict()[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "81d26f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 1_0, already processed.\n",
      "Skipping 1_2, already processed.\n",
      "Skipping 1_4, already processed.\n",
      "Skipping 1_5, already processed.\n",
      "Skipping 1_6, already processed.\n",
      "Skipping 1_7, already processed.\n",
      "Skipping 1_8, already processed.\n",
      "Skipping 1_9, already processed.\n",
      "Skipping 1_10, already processed.\n",
      "Skipping 1_11, already processed.\n",
      "Skipping 1_12, already processed.\n",
      "Skipping 1_13, already processed.\n",
      "Skipping 2_0, already processed.\n",
      "Skipping 2_1, already processed.\n",
      "Skipping 2_2, already processed.\n",
      "Skipping 2_3, already processed.\n",
      "Skipping 2_4, already processed.\n",
      "Skipping 2_5, already processed.\n",
      "Skipping 2_6, already processed.\n",
      "Skipping 2_7, already processed.\n",
      "Skipping 2_8, already processed.\n",
      "Skipping 2_9, already processed.\n",
      "Skipping 2_10, already processed.\n",
      "Skipping 2_11, already processed.\n",
      "Skipping 2_12, already processed.\n",
      "Skipping 2_13, already processed.\n",
      "Skipping 2_14, already processed.\n",
      "Skipping 3_0, already processed.\n",
      "Skipping 3_1, already processed.\n",
      "Skipping 3_2, already processed.\n",
      "Skipping 3_3, already processed.\n",
      "Skipping 3_4, already processed.\n",
      "Skipping 3_5, already processed.\n",
      "Skipping 3_6, already processed.\n",
      "Skipping 3_7, already processed.\n",
      "Skipping 3_8, already processed.\n",
      "Skipping 3_9, already processed.\n",
      "Skipping 3_10, already processed.\n",
      "Skipping 3_11, already processed.\n",
      "Skipping 3_12, already processed.\n",
      "Skipping 3_13, already processed.\n",
      "Skipping 4_0, already processed.\n",
      "Skipping 4_1, already processed.\n",
      "Skipping 4_2, already processed.\n",
      "Skipping 4_3, already processed.\n",
      "Skipping 4_4, already processed.\n",
      "Skipping 4_5, already processed.\n",
      "Skipping 4_6, already processed.\n",
      "Skipping 4_7, already processed.\n",
      "Skipping 4_8, already processed.\n",
      "Skipping 4_9, already processed.\n",
      "Skipping 4_10, already processed.\n",
      "Skipping 4_11, already processed.\n",
      "Skipping 4_12, already processed.\n",
      "Skipping 4_13, already processed.\n",
      "Skipping 5_0, already processed.\n",
      "Skipping 5_1, already processed.\n",
      "Skipping 5_2, already processed.\n",
      "Skipping 5_3, already processed.\n",
      "Skipping 5_4, already processed.\n",
      "Skipping 5_5, already processed.\n",
      "Skipping 5_6, already processed.\n",
      "Skipping 5_7, already processed.\n",
      "Skipping 5_8, already processed.\n",
      "Skipping 5_9, already processed.\n",
      "Skipping 5_10, already processed.\n",
      "Skipping 5_11, already processed.\n",
      "Skipping 5_12, already processed.\n",
      "Skipping 5_13, already processed.\n",
      "Skipping 5_14, already processed.\n",
      "Skipping 6_0, already processed.\n",
      "Skipping 6_1, already processed.\n",
      "Skipping 6_2, already processed.\n",
      "Skipping 6_3, already processed.\n",
      "Skipping 6_4, already processed.\n",
      "Skipping 6_5, already processed.\n",
      "Skipping 6_6, already processed.\n",
      "Skipping 6_7, already processed.\n",
      "Skipping 6_8, already processed.\n",
      "Skipping 6_9, already processed.\n",
      "Skipping 6_10, already processed.\n",
      "Skipping 6_11, already processed.\n",
      "Skipping 6_12, already processed.\n",
      "Skipping 6_13, already processed.\n",
      "Skipping 6_14, already processed.\n",
      "Skipping 7_0, already processed.\n",
      "Skipping 7_1, already processed.\n",
      "Skipping 7_2, already processed.\n",
      "Skipping 7_3, already processed.\n",
      "Skipping 7_4, already processed.\n",
      "Skipping 7_5, already processed.\n",
      "Skipping 7_6, already processed.\n",
      "Skipping 7_7, already processed.\n",
      "Skipping 7_8, already processed.\n",
      "Skipping 7_9, already processed.\n",
      "Skipping 7_10, already processed.\n",
      "Skipping 7_11, already processed.\n",
      "Skipping 7_12, already processed.\n",
      "Skipping 7_13, already processed.\n",
      "Skipping 8_0, already processed.\n",
      "Skipping 8_1, already processed.\n",
      "Skipping 8_2, already processed.\n",
      "Skipping 8_3, already processed.\n",
      "Skipping 8_4, already processed.\n",
      "Skipping 8_5, already processed.\n",
      "Skipping 8_6, already processed.\n",
      "Skipping 8_7, already processed.\n",
      "Skipping 8_8, already processed.\n",
      "Skipping 8_9, already processed.\n",
      "Skipping 8_10, already processed.\n",
      "Skipping 8_11, already processed.\n",
      "Skipping 8_12, already processed.\n",
      "Skipping 8_13, already processed.\n",
      "Skipping 9_0, already processed.\n",
      "Skipping 9_1, already processed.\n",
      "Skipping 9_2, already processed.\n",
      "Skipping 9_3, already processed.\n",
      "Skipping 9_4, already processed.\n",
      "Skipping 9_5, already processed.\n",
      "Skipping 9_6, already processed.\n",
      "Skipping 9_7, already processed.\n",
      "Skipping 9_8, already processed.\n",
      "Skipping 9_9, already processed.\n",
      "Skipping 9_10, already processed.\n",
      "Skipping 9_11, already processed.\n",
      "Skipping 9_12, already processed.\n",
      "Skipping 9_13, already processed.\n",
      "Skipping 10_0, already processed.\n",
      "Skipping 10_1, already processed.\n",
      "Skipping 10_2, already processed.\n",
      "Skipping 10_3, already processed.\n",
      "Skipping 10_4, already processed.\n",
      "Skipping 10_5, already processed.\n",
      "Skipping 10_6, already processed.\n",
      "Skipping 10_7, already processed.\n",
      "Skipping 10_8, already processed.\n",
      "Skipping 10_9, already processed.\n",
      "Skipping 10_10, already processed.\n",
      "Skipping 10_11, already processed.\n",
      "Skipping 10_12, already processed.\n",
      "Skipping 10_13, already processed.\n",
      "Skipping 11_0, already processed.\n",
      "Skipping 11_1, already processed.\n",
      "Skipping 11_2, already processed.\n",
      "Skipping 11_3, already processed.\n",
      "Skipping 11_4, already processed.\n",
      "Skipping 11_5, already processed.\n",
      "Skipping 11_6, already processed.\n",
      "Skipping 11_7, already processed.\n",
      "Skipping 11_8, already processed.\n",
      "Skipping 11_9, already processed.\n",
      "Skipping 11_10, already processed.\n",
      "Skipping 11_11, already processed.\n",
      "Skipping 11_12, already processed.\n",
      "Skipping 11_13, already processed.\n",
      "Skipping 12_0, already processed.\n",
      "Skipping 12_1, already processed.\n",
      "Skipping 12_2, already processed.\n",
      "Skipping 12_3, already processed.\n",
      "Skipping 12_4, already processed.\n",
      "Skipping 12_5, already processed.\n",
      "Skipping 12_6, already processed.\n",
      "Skipping 12_7, already processed.\n",
      "Skipping 12_8, already processed.\n",
      "Skipping 12_9, already processed.\n",
      "Skipping 12_10, already processed.\n",
      "Skipping 12_11, already processed.\n",
      "Skipping 12_12, already processed.\n",
      "Skipping 12_13, already processed.\n",
      "Skipping 13_0, already processed.\n",
      "Skipping 13_1, already processed.\n",
      "Skipping 13_2, already processed.\n",
      "Skipping 13_3, already processed.\n",
      "Skipping 13_4, already processed.\n",
      "Skipping 13_5, already processed.\n",
      "Skipping 13_6, already processed.\n",
      "Skipping 13_7, already processed.\n",
      "Skipping 13_8, already processed.\n",
      "Skipping 13_9, already processed.\n",
      "Skipping 13_10, already processed.\n",
      "Skipping 13_11, already processed.\n",
      "Skipping 13_12, already processed.\n",
      "Skipping 13_13, already processed.\n",
      "Skipping 14_0, already processed.\n",
      "Skipping 14_1, already processed.\n",
      "Skipping 14_2, already processed.\n",
      "Skipping 14_3, already processed.\n",
      "Skipping 14_4, already processed.\n",
      "Skipping 14_5, already processed.\n",
      "Skipping 14_6, already processed.\n",
      "Skipping 14_7, already processed.\n",
      "Skipping 14_8, already processed.\n",
      "Skipping 14_9, already processed.\n",
      "Skipping 14_10, already processed.\n",
      "Skipping 14_11, already processed.\n",
      "Skipping 14_12, already processed.\n",
      "Skipping 14_13, already processed.\n",
      "Skipping 15_0, already processed.\n",
      "Skipping 15_1, already processed.\n",
      "Skipping 15_2, already processed.\n",
      "Skipping 15_3, already processed.\n",
      "Skipping 15_4, already processed.\n",
      "Skipping 15_5, already processed.\n",
      "Skipping 15_6, already processed.\n",
      "Skipping 15_7, already processed.\n",
      "Skipping 15_8, already processed.\n",
      "Skipping 15_9, already processed.\n",
      "Skipping 15_10, already processed.\n",
      "Skipping 15_11, already processed.\n",
      "Skipping 15_12, already processed.\n",
      "------- Start processing file 15_13 -------\n",
      "------- Finished processing file 15_13 in 5.94258189201355 seconds -------\n",
      "------- Start processing file 16_0 -------\n",
      "------- Finished processing file 16_0 in 21.157794713974 seconds -------\n",
      "------- Start processing file 16_1 -------\n",
      "------- Finished processing file 16_1 in 3.9067039489746094 seconds -------\n",
      "------- Start processing file 16_2 -------\n",
      "------- Finished processing file 16_2 in 4.106365203857422 seconds -------\n",
      "------- Start processing file 16_3 -------\n",
      "------- Finished processing file 16_3 in 5.1054980754852295 seconds -------\n",
      "------- Start processing file 16_4 -------\n",
      "------- Finished processing file 16_4 in 2.8676791191101074 seconds -------\n",
      "------- Start processing file 16_5 -------\n",
      "------- Finished processing file 16_5 in 2.6888859272003174 seconds -------\n",
      "------- Start processing file 16_6 -------\n",
      "------- Finished processing file 16_6 in 3.4551119804382324 seconds -------\n",
      "------- Start processing file 16_7 -------\n",
      "------- Finished processing file 16_7 in 3.0728671550750732 seconds -------\n",
      "------- Start processing file 16_8 -------\n",
      "------- Finished processing file 16_8 in 5.629395008087158 seconds -------\n",
      "------- Start processing file 16_9 -------\n",
      "------- Finished processing file 16_9 in 3.0722429752349854 seconds -------\n",
      "------- Start processing file 16_10 -------\n",
      "------- Finished processing file 16_10 in 3.3456568717956543 seconds -------\n",
      "------- Start processing file 16_11 -------\n",
      "------- Finished processing file 16_11 in 4.203572034835815 seconds -------\n",
      "------- Start processing file 16_12 -------\n",
      "------- Finished processing file 16_12 in 4.543591022491455 seconds -------\n",
      "------- Start processing file 16_13 -------\n",
      "------- Finished processing file 16_13 in 24.160643815994263 seconds -------\n",
      "------- Start processing file 17_0 -------\n",
      "------- Finished processing file 17_0 in 19.759528875350952 seconds -------\n",
      "------- Start processing file 17_1 -------\n",
      "------- Finished processing file 17_1 in 2.561187267303467 seconds -------\n",
      "------- Start processing file 17_2 -------\n",
      "------- Finished processing file 17_2 in 3.480400800704956 seconds -------\n",
      "------- Start processing file 17_3 -------\n",
      "------- Finished processing file 17_3 in 8.801753044128418 seconds -------\n",
      "------- Start processing file 17_4 -------\n",
      "------- Finished processing file 17_4 in 3.178851842880249 seconds -------\n",
      "------- Start processing file 17_5 -------\n",
      "------- Finished processing file 17_5 in 3.78898286819458 seconds -------\n",
      "------- Start processing file 17_6 -------\n",
      "------- Finished processing file 17_6 in 6.5768842697143555 seconds -------\n",
      "------- Start processing file 17_7 -------\n",
      "------- Finished processing file 17_7 in 4.889751672744751 seconds -------\n",
      "------- Start processing file 17_8 -------\n",
      "------- Finished processing file 17_8 in 2.7756271362304688 seconds -------\n",
      "------- Start processing file 17_9 -------\n",
      "------- Finished processing file 17_9 in 7.057153940200806 seconds -------\n",
      "------- Start processing file 17_10 -------\n",
      "------- Finished processing file 17_10 in 3.3230040073394775 seconds -------\n",
      "------- Start processing file 17_11 -------\n",
      "------- Finished processing file 17_11 in 3.6356852054595947 seconds -------\n",
      "------- Start processing file 17_12 -------\n",
      "------- Finished processing file 17_12 in 4.312853097915649 seconds -------\n",
      "------- Start processing file 17_13 -------\n",
      "------- Finished processing file 17_13 in 14.430537939071655 seconds -------\n",
      "------- Start processing file 18_0 -------\n",
      "------- Finished processing file 18_0 in 22.698765993118286 seconds -------\n",
      "------- Start processing file 18_1 -------\n",
      "------- Finished processing file 18_1 in 4.679064989089966 seconds -------\n",
      "------- Start processing file 18_2 -------\n",
      "------- Finished processing file 18_2 in 3.034050941467285 seconds -------\n",
      "------- Start processing file 18_3 -------\n",
      "------- Finished processing file 18_3 in 3.890913963317871 seconds -------\n",
      "------- Start processing file 18_4 -------\n",
      "------- Finished processing file 18_4 in 5.527997255325317 seconds -------\n",
      "------- Start processing file 18_5 -------\n",
      "------- Finished processing file 18_5 in 2.4563241004943848 seconds -------\n",
      "------- Start processing file 18_6 -------\n",
      "------- Finished processing file 18_6 in 5.429161071777344 seconds -------\n",
      "------- Start processing file 18_7 -------\n",
      "------- Finished processing file 18_7 in 4.493053197860718 seconds -------\n",
      "------- Start processing file 18_8 -------\n",
      "------- Finished processing file 18_8 in 4.743189096450806 seconds -------\n",
      "------- Start processing file 18_9 -------\n",
      "------- Finished processing file 18_9 in 3.406776189804077 seconds -------\n",
      "------- Start processing file 18_10 -------\n",
      "------- Finished processing file 18_10 in 3.740316867828369 seconds -------\n",
      "------- Start processing file 18_11 -------\n",
      "------- Finished processing file 18_11 in 3.7884230613708496 seconds -------\n",
      "------- Start processing file 18_12 -------\n",
      "------- Finished processing file 18_12 in 3.582716226577759 seconds -------\n",
      "------- Start processing file 18_13 -------\n",
      "------- Finished processing file 18_13 in 5.4292638301849365 seconds -------\n",
      "------- Start processing file 19_0 -------\n",
      "------- Finished processing file 19_0 in 27.38236904144287 seconds -------\n",
      "------- Start processing file 19_1 -------\n",
      "------- Finished processing file 19_1 in 5.07450795173645 seconds -------\n",
      "------- Start processing file 19_2 -------\n",
      "------- Finished processing file 19_2 in 4.918034076690674 seconds -------\n",
      "------- Start processing file 19_3 -------\n",
      "------- Finished processing file 19_3 in 2.516818046569824 seconds -------\n",
      "------- Start processing file 19_4 -------\n",
      "------- Finished processing file 19_4 in 3.219069004058838 seconds -------\n",
      "------- Start processing file 19_5 -------\n",
      "------- Finished processing file 19_5 in 3.270066976547241 seconds -------\n",
      "------- Start processing file 19_6 -------\n",
      "------- Finished processing file 19_6 in 5.635875225067139 seconds -------\n",
      "------- Start processing file 19_7 -------\n",
      "------- Finished processing file 19_7 in 3.2638959884643555 seconds -------\n",
      "------- Start processing file 19_8 -------\n",
      "------- Finished processing file 19_8 in 4.202173948287964 seconds -------\n",
      "------- Start processing file 19_9 -------\n",
      "------- Finished processing file 19_9 in 9.227932929992676 seconds -------\n",
      "------- Start processing file 19_10 -------\n",
      "------- Finished processing file 19_10 in 2.456164836883545 seconds -------\n",
      "------- Start processing file 19_11 -------\n",
      "------- Finished processing file 19_11 in 5.117528915405273 seconds -------\n",
      "------- Start processing file 19_12 -------\n",
      "------- Finished processing file 19_12 in 4.096599102020264 seconds -------\n",
      "------- Start processing file 19_13 -------\n",
      "------- Finished processing file 19_13 in 7.130596876144409 seconds -------\n",
      "------- Start processing file 20_0 -------\n",
      "------- Finished processing file 20_0 in 14.57844614982605 seconds -------\n",
      "------- Start processing file 20_1 -------\n",
      "------- Finished processing file 20_1 in 7.235894680023193 seconds -------\n",
      "------- Start processing file 20_2 -------\n",
      "------- Finished processing file 20_2 in 3.926284074783325 seconds -------\n",
      "------- Start processing file 20_3 -------\n",
      "------- Finished processing file 20_3 in 4.440130710601807 seconds -------\n",
      "------- Start processing file 20_4 -------\n",
      "------- Finished processing file 20_4 in 2.8315839767456055 seconds -------\n",
      "------- Start processing file 20_5 -------\n",
      "------- Finished processing file 20_5 in 5.014915704727173 seconds -------\n",
      "------- Start processing file 20_6 -------\n",
      "------- Finished processing file 20_6 in 4.401311159133911 seconds -------\n",
      "------- Start processing file 20_7 -------\n",
      "------- Finished processing file 20_7 in 3.838923931121826 seconds -------\n",
      "------- Start processing file 20_8 -------\n",
      "------- Finished processing file 20_8 in 2.8077399730682373 seconds -------\n",
      "------- Start processing file 20_9 -------\n",
      "------- Finished processing file 20_9 in 8.923868894577026 seconds -------\n",
      "------- Start processing file 20_10 -------\n",
      "------- Finished processing file 20_10 in 4.090374946594238 seconds -------\n",
      "------- Start processing file 20_11 -------\n",
      "------- Finished processing file 20_11 in 3.451416015625 seconds -------\n",
      "------- Start processing file 20_12 -------\n",
      "------- Finished processing file 20_12 in 5.149479866027832 seconds -------\n",
      "------- Start processing file 20_13 -------\n",
      "------- Finished processing file 20_13 in 6.9399333000183105 seconds -------\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Load previous progress if available\n",
    "try:\n",
    "    with open('gpt_two_text_example_output_progress.json', 'r') as file:\n",
    "        gpt_two_text_example_output = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    gpt_two_text_example_output = {}\n",
    "\n",
    "# Loop through each unique id\n",
    "for id in images_encoded_extexts['id'].unique():\n",
    "# for id in unable_ids:\n",
    "    # Check if this ID is already processed (Skip this step if you want to re-process for unable_ids) ----------------\n",
    "    if id in gpt_two_text_example_output:\n",
    "        print(f\"Skipping {id}, already processed.\")\n",
    "        continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        print(f'------- Start processing file {id} -------')\n",
    "        \n",
    "        # Call OpenAI/Anthropic and post-processing functions\n",
    "        prompt_example_text += \"Even if it is hard to read the texts from the image, return as much as you can. You must read something. Do not return an apologetic message.\"\n",
    "        output = callOpenAI(prompt=prompt_example_text, base64_image=images_encoded_extexts[(images_encoded_extexts['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        # output = callAnthropic(prompt=prompt_example_text, base64_image=images_encoded_oneshot[(images_encoded_oneshot['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        output_cleaned = callPostProcessing_anthropic(prompt_parameter=output)\n",
    "        \n",
    "        # Save the output\n",
    "        gpt_two_text_example_output[id] = output_cleaned\n",
    "        \n",
    "        # Save progress after each file\n",
    "        with open('gpt_two_text_example_output_progress.json', 'w') as file:\n",
    "            json.dump(gpt_two_text_example_output, file)\n",
    "        \n",
    "        print(f'------- Finished processing file {id} in {time.time() - start_time} seconds -------')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {id}: {str(e)}\")\n",
    "        # Save the progress and exit the loop in case of an error\n",
    "        with open('gpt_two_text_example_output_progress.json', 'w') as file:\n",
    "            json.dump(gpt_two_text_example_output, file)\n",
    "        break  # Exit the loop on error\n",
    "\n",
    "# Once all IDs are processed, save the final result\n",
    "with open('gpt_two_text_example_output_final.json', 'w') as file:\n",
    "    json.dump(gpt_two_text_example_output, file)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a122d9",
   "metadata": {},
   "source": [
    "### Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab11e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_simple = pd.read_csv(path+'/results/postprocessed/gpt_perline_output.csv')\n",
    "claude_simple =  pd.read_csv(path+'/results/postprocessed/claude_perline_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "851ef214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 1_0, already processed.\n",
      "Skipping 1_1, already processed.\n",
      "Skipping 1_2, already processed.\n",
      "Skipping 1_3, already processed.\n",
      "Skipping 1_4, already processed.\n",
      "Skipping 1_5, already processed.\n",
      "Skipping 1_6, already processed.\n",
      "Skipping 1_7, already processed.\n",
      "Skipping 1_8, already processed.\n",
      "Skipping 1_9, already processed.\n",
      "Skipping 1_10, already processed.\n",
      "Skipping 1_11, already processed.\n",
      "Skipping 1_12, already processed.\n",
      "Skipping 1_13, already processed.\n",
      "Skipping 2_0, already processed.\n",
      "Skipping 2_1, already processed.\n",
      "Skipping 2_2, already processed.\n",
      "Skipping 2_3, already processed.\n",
      "Skipping 2_4, already processed.\n",
      "Skipping 2_5, already processed.\n",
      "Skipping 2_6, already processed.\n",
      "Skipping 2_7, already processed.\n",
      "Skipping 2_8, already processed.\n",
      "Skipping 2_9, already processed.\n",
      "Skipping 2_10, already processed.\n",
      "Skipping 2_11, already processed.\n",
      "Skipping 2_12, already processed.\n",
      "Skipping 2_13, already processed.\n",
      "Skipping 2_14, already processed.\n",
      "Skipping 3_0, already processed.\n",
      "Skipping 3_1, already processed.\n",
      "Skipping 3_2, already processed.\n",
      "Skipping 3_3, already processed.\n",
      "Skipping 3_4, already processed.\n",
      "Skipping 3_5, already processed.\n",
      "Skipping 3_6, already processed.\n",
      "Skipping 3_7, already processed.\n",
      "Skipping 3_8, already processed.\n",
      "Skipping 3_9, already processed.\n",
      "Skipping 3_10, already processed.\n",
      "Skipping 3_11, already processed.\n",
      "Skipping 3_12, already processed.\n",
      "Skipping 3_13, already processed.\n",
      "Skipping 4_0, already processed.\n",
      "Skipping 4_1, already processed.\n",
      "Skipping 4_2, already processed.\n",
      "Skipping 4_3, already processed.\n",
      "Skipping 4_4, already processed.\n",
      "Skipping 4_5, already processed.\n",
      "Skipping 4_6, already processed.\n",
      "Skipping 4_7, already processed.\n",
      "Skipping 4_8, already processed.\n",
      "Skipping 4_9, already processed.\n",
      "Skipping 4_10, already processed.\n",
      "Skipping 4_11, already processed.\n",
      "Skipping 4_12, already processed.\n",
      "Skipping 4_13, already processed.\n",
      "Skipping 5_0, already processed.\n",
      "Skipping 5_1, already processed.\n",
      "Skipping 5_2, already processed.\n",
      "Skipping 5_3, already processed.\n",
      "Skipping 5_4, already processed.\n",
      "Skipping 5_5, already processed.\n",
      "Skipping 5_6, already processed.\n",
      "Skipping 5_7, already processed.\n",
      "Skipping 5_8, already processed.\n",
      "Skipping 5_9, already processed.\n",
      "Skipping 5_10, already processed.\n",
      "Skipping 5_11, already processed.\n",
      "Skipping 5_12, already processed.\n",
      "Skipping 5_13, already processed.\n",
      "Skipping 5_14, already processed.\n",
      "Skipping 6_0, already processed.\n",
      "Skipping 6_1, already processed.\n",
      "Skipping 6_2, already processed.\n",
      "Skipping 6_3, already processed.\n",
      "Skipping 6_4, already processed.\n",
      "Skipping 6_5, already processed.\n",
      "Skipping 6_6, already processed.\n",
      "Skipping 6_7, already processed.\n",
      "Skipping 6_8, already processed.\n",
      "Skipping 6_9, already processed.\n",
      "Skipping 6_10, already processed.\n",
      "Skipping 6_11, already processed.\n",
      "Skipping 6_12, already processed.\n",
      "Skipping 6_13, already processed.\n",
      "Skipping 6_14, already processed.\n",
      "Skipping 7_0, already processed.\n",
      "Skipping 7_1, already processed.\n",
      "Skipping 7_2, already processed.\n",
      "Skipping 7_3, already processed.\n",
      "Skipping 7_4, already processed.\n",
      "Skipping 7_5, already processed.\n",
      "Skipping 7_6, already processed.\n",
      "Skipping 7_7, already processed.\n",
      "Skipping 7_8, already processed.\n",
      "Skipping 7_9, already processed.\n",
      "Skipping 7_10, already processed.\n",
      "Skipping 7_11, already processed.\n",
      "Skipping 7_12, already processed.\n",
      "Skipping 7_13, already processed.\n",
      "Skipping 8_0, already processed.\n",
      "Skipping 8_1, already processed.\n",
      "Skipping 8_2, already processed.\n",
      "Skipping 8_3, already processed.\n",
      "Skipping 8_4, already processed.\n",
      "Skipping 8_5, already processed.\n",
      "Skipping 8_6, already processed.\n",
      "Skipping 8_7, already processed.\n",
      "Skipping 8_8, already processed.\n",
      "Skipping 8_9, already processed.\n",
      "Skipping 8_10, already processed.\n",
      "Skipping 8_11, already processed.\n",
      "Skipping 8_12, already processed.\n",
      "Skipping 8_13, already processed.\n",
      "Skipping 9_0, already processed.\n",
      "Skipping 9_1, already processed.\n",
      "Skipping 9_2, already processed.\n",
      "Skipping 9_3, already processed.\n",
      "Skipping 9_4, already processed.\n",
      "Skipping 9_5, already processed.\n",
      "Skipping 9_6, already processed.\n",
      "Skipping 9_7, already processed.\n",
      "Skipping 9_8, already processed.\n",
      "Skipping 9_9, already processed.\n",
      "Skipping 9_10, already processed.\n",
      "Skipping 9_11, already processed.\n",
      "Skipping 9_12, already processed.\n",
      "Skipping 9_13, already processed.\n",
      "Skipping 10_0, already processed.\n",
      "Skipping 10_1, already processed.\n",
      "Skipping 10_2, already processed.\n",
      "Skipping 10_3, already processed.\n",
      "Skipping 10_4, already processed.\n",
      "Skipping 10_5, already processed.\n",
      "Skipping 10_6, already processed.\n",
      "Skipping 10_7, already processed.\n",
      "Skipping 10_8, already processed.\n",
      "Skipping 10_9, already processed.\n",
      "Skipping 10_10, already processed.\n",
      "Skipping 10_11, already processed.\n",
      "Skipping 10_12, already processed.\n",
      "Skipping 10_13, already processed.\n",
      "Skipping 11_0, already processed.\n",
      "Skipping 11_1, already processed.\n",
      "Skipping 11_2, already processed.\n",
      "Skipping 11_3, already processed.\n",
      "Skipping 11_4, already processed.\n",
      "Skipping 11_5, already processed.\n",
      "Skipping 11_6, already processed.\n",
      "Skipping 11_7, already processed.\n",
      "Skipping 11_8, already processed.\n",
      "Skipping 11_9, already processed.\n",
      "Skipping 11_10, already processed.\n",
      "Skipping 11_11, already processed.\n",
      "Skipping 11_12, already processed.\n",
      "Skipping 11_13, already processed.\n",
      "Skipping 12_0, already processed.\n",
      "Skipping 12_1, already processed.\n",
      "Skipping 12_2, already processed.\n",
      "Skipping 12_3, already processed.\n",
      "Skipping 12_4, already processed.\n",
      "Skipping 12_5, already processed.\n",
      "Skipping 12_6, already processed.\n",
      "Skipping 12_7, already processed.\n",
      "Skipping 12_8, already processed.\n",
      "Skipping 12_9, already processed.\n",
      "Skipping 12_10, already processed.\n",
      "Skipping 12_11, already processed.\n",
      "Skipping 12_12, already processed.\n",
      "Skipping 12_13, already processed.\n",
      "Skipping 13_0, already processed.\n",
      "Skipping 13_1, already processed.\n",
      "Skipping 13_2, already processed.\n",
      "Skipping 13_3, already processed.\n",
      "Skipping 13_4, already processed.\n",
      "Skipping 13_5, already processed.\n",
      "Skipping 13_6, already processed.\n",
      "Skipping 13_7, already processed.\n",
      "Skipping 13_8, already processed.\n",
      "Skipping 13_9, already processed.\n",
      "Skipping 13_10, already processed.\n",
      "Skipping 13_11, already processed.\n",
      "Skipping 13_12, already processed.\n",
      "Skipping 13_13, already processed.\n",
      "Skipping 14_0, already processed.\n",
      "Skipping 14_1, already processed.\n",
      "Skipping 14_2, already processed.\n",
      "Skipping 14_3, already processed.\n",
      "Skipping 14_4, already processed.\n",
      "Skipping 14_5, already processed.\n",
      "Skipping 14_6, already processed.\n",
      "Skipping 14_7, already processed.\n",
      "Skipping 14_8, already processed.\n",
      "Skipping 14_9, already processed.\n",
      "Skipping 14_10, already processed.\n",
      "Skipping 14_11, already processed.\n",
      "Skipping 14_12, already processed.\n",
      "Skipping 14_13, already processed.\n",
      "Skipping 15_0, already processed.\n",
      "Skipping 15_1, already processed.\n",
      "Skipping 15_2, already processed.\n",
      "Skipping 15_3, already processed.\n",
      "Skipping 15_4, already processed.\n",
      "Skipping 15_5, already processed.\n",
      "Skipping 15_6, already processed.\n",
      "Skipping 15_7, already processed.\n",
      "Skipping 15_8, already processed.\n",
      "Skipping 15_9, already processed.\n",
      "Skipping 15_10, already processed.\n",
      "Skipping 15_11, already processed.\n",
      "Skipping 15_12, already processed.\n",
      "Skipping 15_13, already processed.\n",
      "Skipping 16_0, already processed.\n",
      "Skipping 16_1, already processed.\n",
      "Skipping 16_2, already processed.\n",
      "Skipping 16_3, already processed.\n",
      "Skipping 16_4, already processed.\n",
      "Skipping 16_5, already processed.\n",
      "Skipping 16_6, already processed.\n",
      "Skipping 16_7, already processed.\n",
      "Skipping 16_8, already processed.\n",
      "Skipping 16_9, already processed.\n",
      "Skipping 16_10, already processed.\n",
      "Skipping 16_11, already processed.\n",
      "Skipping 16_12, already processed.\n",
      "Skipping 16_13, already processed.\n",
      "Skipping 17_0, already processed.\n",
      "Skipping 17_1, already processed.\n",
      "Skipping 17_2, already processed.\n",
      "Skipping 17_3, already processed.\n",
      "Skipping 17_4, already processed.\n",
      "Skipping 17_5, already processed.\n",
      "Skipping 17_6, already processed.\n",
      "Skipping 17_7, already processed.\n",
      "Skipping 17_8, already processed.\n",
      "Skipping 17_9, already processed.\n",
      "Skipping 17_10, already processed.\n",
      "------- Start processing file 17_11 -------\n",
      "------- Finished processing file 17_11 in 6.669886350631714 seconds -------\n",
      "------- Start processing file 17_12 -------\n",
      "------- Finished processing file 17_12 in 4.837033033370972 seconds -------\n",
      "------- Start processing file 17_13 -------\n",
      "------- Finished processing file 17_13 in 4.545418977737427 seconds -------\n",
      "------- Start processing file 18_0 -------\n",
      "------- Finished processing file 18_0 in 10.540526866912842 seconds -------\n",
      "------- Start processing file 18_1 -------\n",
      "------- Finished processing file 18_1 in 3.5943360328674316 seconds -------\n",
      "------- Start processing file 18_2 -------\n",
      "------- Finished processing file 18_2 in 4.3163230419158936 seconds -------\n",
      "------- Start processing file 18_3 -------\n",
      "------- Finished processing file 18_3 in 4.170706033706665 seconds -------\n",
      "------- Start processing file 18_4 -------\n",
      "------- Finished processing file 18_4 in 4.999938011169434 seconds -------\n",
      "------- Start processing file 18_5 -------\n",
      "------- Finished processing file 18_5 in 4.210438966751099 seconds -------\n",
      "------- Start processing file 18_6 -------\n",
      "------- Finished processing file 18_6 in 4.099009037017822 seconds -------\n",
      "------- Start processing file 18_7 -------\n",
      "------- Finished processing file 18_7 in 5.027102947235107 seconds -------\n",
      "------- Start processing file 18_8 -------\n",
      "------- Finished processing file 18_8 in 5.289112091064453 seconds -------\n",
      "------- Start processing file 18_9 -------\n",
      "------- Finished processing file 18_9 in 4.221029758453369 seconds -------\n",
      "------- Start processing file 18_10 -------\n",
      "------- Finished processing file 18_10 in 5.429013013839722 seconds -------\n",
      "------- Start processing file 18_11 -------\n",
      "------- Finished processing file 18_11 in 4.50619912147522 seconds -------\n",
      "------- Start processing file 18_12 -------\n",
      "------- Finished processing file 18_12 in 4.284410715103149 seconds -------\n",
      "------- Start processing file 18_13 -------\n",
      "------- Finished processing file 18_13 in 4.9300291538238525 seconds -------\n",
      "------- Start processing file 19_0 -------\n",
      "------- Finished processing file 19_0 in 10.044271230697632 seconds -------\n",
      "------- Start processing file 19_1 -------\n",
      "------- Finished processing file 19_1 in 4.087384939193726 seconds -------\n",
      "------- Start processing file 19_2 -------\n",
      "------- Finished processing file 19_2 in 3.89253830909729 seconds -------\n",
      "------- Start processing file 19_3 -------\n",
      "------- Finished processing file 19_3 in 4.504947185516357 seconds -------\n",
      "------- Start processing file 19_4 -------\n",
      "------- Finished processing file 19_4 in 4.062621831893921 seconds -------\n",
      "------- Start processing file 19_5 -------\n",
      "------- Finished processing file 19_5 in 4.129364967346191 seconds -------\n",
      "------- Start processing file 19_6 -------\n",
      "------- Finished processing file 19_6 in 5.839254856109619 seconds -------\n",
      "------- Start processing file 19_7 -------\n",
      "------- Finished processing file 19_7 in 5.116454124450684 seconds -------\n",
      "------- Start processing file 19_8 -------\n",
      "------- Finished processing file 19_8 in 4.184307098388672 seconds -------\n",
      "------- Start processing file 19_9 -------\n",
      "------- Finished processing file 19_9 in 4.027806043624878 seconds -------\n",
      "------- Start processing file 19_10 -------\n",
      "------- Finished processing file 19_10 in 3.770923137664795 seconds -------\n",
      "------- Start processing file 19_11 -------\n",
      "------- Finished processing file 19_11 in 4.50344181060791 seconds -------\n",
      "------- Start processing file 19_12 -------\n",
      "------- Finished processing file 19_12 in 4.711019992828369 seconds -------\n",
      "------- Start processing file 19_13 -------\n",
      "------- Finished processing file 19_13 in 5.473191022872925 seconds -------\n",
      "------- Start processing file 20_0 -------\n",
      "------- Finished processing file 20_0 in 8.864022970199585 seconds -------\n",
      "------- Start processing file 20_1 -------\n",
      "------- Finished processing file 20_1 in 4.29682469367981 seconds -------\n",
      "------- Start processing file 20_2 -------\n",
      "------- Finished processing file 20_2 in 4.40491509437561 seconds -------\n",
      "------- Start processing file 20_3 -------\n",
      "------- Finished processing file 20_3 in 4.504993915557861 seconds -------\n",
      "------- Start processing file 20_4 -------\n",
      "------- Finished processing file 20_4 in 4.301217079162598 seconds -------\n",
      "------- Start processing file 20_5 -------\n",
      "------- Finished processing file 20_5 in 5.115876913070679 seconds -------\n",
      "------- Start processing file 20_6 -------\n",
      "------- Finished processing file 20_6 in 3.5897159576416016 seconds -------\n",
      "------- Start processing file 20_7 -------\n",
      "------- Finished processing file 20_7 in 3.5395257472991943 seconds -------\n",
      "------- Start processing file 20_8 -------\n",
      "------- Finished processing file 20_8 in 5.161586046218872 seconds -------\n",
      "------- Start processing file 20_9 -------\n",
      "------- Finished processing file 20_9 in 6.144286155700684 seconds -------\n",
      "------- Start processing file 20_10 -------\n",
      "------- Finished processing file 20_10 in 4.402112007141113 seconds -------\n",
      "------- Start processing file 20_11 -------\n",
      "------- Finished processing file 20_11 in 4.848299980163574 seconds -------\n",
      "------- Start processing file 20_12 -------\n",
      "------- Finished processing file 20_12 in 4.471951007843018 seconds -------\n",
      "------- Start processing file 20_13 -------\n",
      "------- Finished processing file 20_13 in 4.665459871292114 seconds -------\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Load previous progress if available\n",
    "try:\n",
    "    with open('claude_refine_output_progress.json', 'r') as file:\n",
    "        claude_refine_output = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    claude_refine_output = {}\n",
    "\n",
    "# Loop through each unique id\n",
    "for id in images_encoded['id'].unique():\n",
    "# for id in unable_ids:\n",
    "    # Check if this ID is already processed (Skip this step if you want to re-process for unable_ids) ----------------\n",
    "    if id in claude_refine_output:\n",
    "        print(f\"Skipping {id}, already processed.\")\n",
    "        continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        print(f'------- Start processing file {id} -------')\n",
    "        \n",
    "        # Call OpenAI/Anthropic and post-processing functions\n",
    "        response_text = claude_simple[claude_simple['id'] == id].text.values[0]\n",
    "        prompt_refine = f\"\"\"\n",
    "        \n",
    "        Your first draft:\n",
    "        ```plaintext\n",
    "        {response_text}\n",
    "        ```\n",
    "\n",
    "        Errors: \n",
    "        Your first transcription you made in ```plaintext block contains some errors.\n",
    "        \n",
    "        Task:\n",
    "        Refine your first trasncription in ```plaintext block. \n",
    "        Make sure to read the names of the people and the location as well as the dates and the numbers correctly.\n",
    "        Transcribe as you see in the image.\n",
    "        ```plaintext\n",
    "        \"\"\"\n",
    "\n",
    "        prompt_refine += \"Even if it is hard to read the texts from the image, return as much as you can. You must read something. Do not return an apologetic message.\"\n",
    "        # output = callOpenAI(prompt=prompt_refine, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        output = callAnthropic(prompt=prompt_refine, base64_image=images_encoded[(images_encoded['id'] == id)].encoded.values[0], max_tokens=800)\n",
    "        output_cleaned = callPostProcessing(prompt_parameter=output)\n",
    "        \n",
    "        # Save the output\n",
    "        claude_refine_output[id] = output_cleaned\n",
    "        \n",
    "        # Save progress after each file\n",
    "        with open('claude_refine_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_refine_output, file)\n",
    "        \n",
    "        print(f'------- Finished processing file {id} in {time.time() - start_time} seconds -------')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {id}: {str(e)}\")\n",
    "        # Save the progress and exit the loop in case of an error\n",
    "        with open('claude_refine_output_progress.json', 'w') as file:\n",
    "            json.dump(claude_refine_output, file)\n",
    "        break  # Exit the loop on error\n",
    "\n",
    "# Once all IDs are processed, save the final result\n",
    "with open('claude_refine_output_final.json', 'w') as file:\n",
    "    json.dump(claude_refine_output, file)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b34c7",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "683579cb-2bae-4a69-8271-ce4e67519e52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS DROITS DE SUCCESSION DROIT NUMÉROS RECETTE CAUTIONNEMENTS DÉCLARATIONS NOMS PRÉNOMS DOMICILES JUGEMENT D'ENVOI NOMS PRÉNOMS EN LIGNE COLLATÉRALE DE MUTATION des DATE DROITS ET AMENDES OBSERVATIONS EN POSSESSION ET DEMEURES DES PARTIES DÉCLARANTES MUTATION EN LIGNE DIRECTE des ACTIF PASSIF RESTANT IMMEUBLES\",\n",
       " '1_1': 'Décédé le vingt-huit octobre 1919 (époux veuf)',\n",
       " '1_2': 'Nivelles le vingt neuf octobre 1919 (décédé)',\n",
       " '1_3': '398 trente Herrent Alphonse J. orphelin 18 8bre 1913 Herrent Henri & autres 2200 1095 1105 11 9bre 1915 feuillet 365 octobre',\n",
       " '1_4': '398² Lefebvre Jules Brasseur célibat Jemappes Bouillé Amélie xxxx xxxx 210 1919',\n",
       " '1_5': 'Arrêté le présent extrait le 29 1919 janvier',\n",
       " '1_6': 'Moreste le trente un octobre 1919 décédé',\n",
       " '1_7': 'Jeudi le 2 premier novembre 1919 Toussaint Francis',\n",
       " '1_8': 'Sosoye Le deux novembre 1919 Dimanche Journal',\n",
       " '1_9': '399 Gros 9/10 Desmedt Jeanne Nivelles 13 mai 2022 décédée Célib. rentière 9110 520 39 10 15 8bre 13 mars 10 feuil. 35 1914 1923 1924',\n",
       " '1_10': '400 Monseur Pascal Henri Ghislain 4 8bre 1918 Négociant Célibat 690.00 344.78 344.78 18 32 4 août 1949',\n",
       " '1_11': \"401 d° Bouly Henri Ouvrier l' célibat. 20 février 1879 Bouly Marie, fille 2274 2274 15 d° 26 Avril 1919 non passible\",\n",
       " '1_12': 'Avelgem le trois novembre 1919 décédée',\n",
       " '1_13': \"402 Hainaut Godart\\n\\nLes déclarations rectificatives et supplémentaires portent le numéro de la déclaration qui les précède, suivi d'un exposant.\\n\\nRoeulx majeur 11 mai Plisnier Gustave\\n\\n17639 17739 55 76 30 22 mai 1919 21 août 1919 184\",\n",
       " '2_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS NOMS PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE RECETTE CAUTIONNEMENTS des NOMS PRÉNOMS DOMICILES ou de ET OU LIGNE COLLATÉRALE DE des de des NEMENTS DÉCLARATIONS l'ouverture DEMEURES DES ET DE MUTATION MUTATION DÉCLARATIONS DROITS ET de la PARTIES EN LIGNE DIRECTE succession DÉCLARANTES ACTIF PASSIF RESTANT NET\",\n",
       " '2_1': '1419',\n",
       " '2_2': \"403 quatre gbis Bayot Antoinette Marie 11 mai 1919 Bayot Henri d'autre 16971 5235 11700 16971 16 mai Célestine d'albert part 4575 5260 1921 240\",\n",
       " '2_3': '405e De Paulus Adolphus Nivelles 25 février Rentier Jemappes 1871 1871 481 - - 10.844,84\\n                        1919                       1919',\n",
       " '2_4': '404 5° Vandermeers Louis Oscar Elbert 4 avril Bruxelles Bruxelles 500 500 16 30 5 janvier non passible 1918 1963',\n",
       " '2_5': 'Mardi le quatre novembre 1919 décédé',\n",
       " '2_6': '405 cinq 784 Lemoine Joseph Ath 24 Août Domicile julesse & autres 1885 1885 18 Août 26 avril 1949 non foncière',\n",
       " '2_7': \"406 30 Monnaye Julie Ramillies le 5 7bre 1911 Monnaye Alexis à Jauche Cessation d'usufruit 11 février 24\",\n",
       " '2_8': '105 de Godeau Clément Aisquinzy 7 8bre 47 Godeau Hortense xavière 500 500 18 8bre 7 avril non mariée Saintblanc 1891 1941',\n",
       " '2_9': 'Jemelle le cinq novembre 1919 enreg',\n",
       " '2_10': 'Décédé le dix novembre 1949 à Jumet',\n",
       " '2_11': '408 sept Fontaine Florent Euloge 15 octobre Pensionnaire communale 848 202 202 18 fév 5 avril non passible 1858 1919 1919',\n",
       " '2_12': '409 5° Allard Prosper Nivelles 16 avril Sellier Marie 9720 9720 19 3° 10 juin 25 message 54 1879 1920',\n",
       " '2_13': 'Arrêté le sept novembre 1919 Souvenir',\n",
       " '2_14': \"410 Sauf plus Deloutte 8 Les déclarations rectificatives et supplémentaires portent le numéro de la déclaration qui les précède affecté d'un exposant Circ n° 1374 § 5 note 1 Justinien 22/12/1909 16 mai 1919 Schaerbeek Edouard Victor 11451 369 12067 20 30 16 mars 29 février 1920 1920 Négliger les centimes\",\n",
       " '3_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS DROITS DE SUCCESSION DROIT NUMÉROS RECETTE CAUTION d'ordre des ou du NOMS, PRÉNOMS DE MUTATION des des NEMENTS, des DÉCLARATIONS. NOMS. PRÉNOMS. DOMICILES. jugement d'envoi ET EN LIGNE DIRECTE VALEUR déclarations DATE AMENDES en possession DEMEURES DES PARTIES DÉCLARANTES. ACTIF PASSIF RESTANT de l'exercice OBSERVATIONS. ou cas d'absence. NET l'enregistrement ou et du des droits. bordereau N°\",\n",
       " '3_1': '411 Hurtelet Henri Wadeleux 25/8/1917 Seraing (Liège) 1918 1918 20 8h 1/2 20 juillet 1920 non fournie',\n",
       " '3_2': '412 30 Chateau Revenu Imposé 5234 65699 Chapelle Orangerie et autres 78692 78692 20 30 6 octobre 18 869,20 205 207 209 22 1 522',\n",
       " '3_3': '412 3 Reynens Louis ouvrier 4 avril 1916 Gellik onder 1296 1296 288 31 mars 1920',\n",
       " '3_4': 'Donné le huit novembre 1919 (Souveil)',\n",
       " '3_5': 'Samedi le neuf novembre 1919 Dimanche Fernand',\n",
       " '3_6': '413 dec gbr 1911 Mathieu Emerance Thérèse 11 mei Bouwvakker Leopold 14934 14934 22 Aug 11 mei 1911 1949',\n",
       " '3_7': '414 32 Caminiau Adeline Marie et Juliette Delperdie Soeurs & autres 25391 25391 14 32 32 2 mai 1926 13 mars 1929 3 mai 1929 15 32 100',\n",
       " '3_8': '415 5° Dubru Amandine Albert 6 juin 1949 décédée jeune autre 500 88 144 26 5° 6 avril 940 non passible',\n",
       " '3_9': 'Arrêté le dix novembre 1919 dix-neuf',\n",
       " '3_10': '416 aug. 9/82 Heuvels Emmanuel Nivelles 22 mai 1914 Serfon Louis 7561 588 6973 25 3/4 pp annuel 18 mai 1915 ♂',\n",
       " '3_11': '117 de Basigant Marie a 47 de Bergeyck Eugenie 1264 4264 23 de 15 de 5 mars 1940 52',\n",
       " '3_12': 'Campinaire 221 Beauraing 29 mars Gillis Eugene 22295 22295 361 414',\n",
       " '3_13': \"Reçu le 4 mars novembre 1949 déclaré\\n\\n(1) Les déclarations rectificatives et supplémentaires portent le numéro de la déclaration qu'ils rectifient, affecté d'un exposant. (Circ. n° 1374, § 5, note 11).\\n\\n(3) Négliger les centimes.\",\n",
       " '4_0': \"N° DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS NOMS PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS RECETTE CAUTION d'ordre ou du jugement ET EN LIGNE COLLATÉRALE DE des DATE NEMENT DATE DU DÉPÔT d'envoi en MUTATION EN LIGNE DIRECTE MUTATION DÉCLARATIONS de la de la possession ET ou sur décès VALEUR déclaration DÉCLARATION NOMS PRÉNOMS DOMICILES DEMEURES DES PARTIES DÉCLARANTES ACTIF PASSIF RESTANT des DATE N° NET IMMEUBLES (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14)\",\n",
       " '4_1': 'Arrêté le deux novembre 1919 clôturé',\n",
       " '4_2': '418 Enreg 954 Cloquet Célestine Vauthier 28 mai Décédé célib 1500 . 4500 29 8bre 44 28 mars 5 mai 46 55 1919 1922',\n",
       " '4_3': '419 3e Vincent Edouard Denis 3 avril 1911 Rapport émolus et autre 22600 22600 3e 3e 3 juin 1911 3 mars 1914 3/5 16 5e 2/5',\n",
       " '4_4': 'Arrêté le treize novembre 1919 dix-neuf',\n",
       " '4_5': 'Arrêté le quinze novembre 1919 Conseil',\n",
       " '4_6': '420 quinze Boisdenghien Rosalie Quesnoit 17 mai 1879 célibataire décédée 1938 1938 60a 24j 36,40 15mars 1939 1940 1 août 38',\n",
       " '4_7': '420² Lambotte Ernest Waterloo 17 février 1911 Lambotte Emile 258 1914',\n",
       " '4_8': 'Arrêté le quinze novembre 1919 Gratis',\n",
       " '4_9': 'Décédé le deux novembre 1919 Dimanche matin',\n",
       " '4_10': 'Arrêté le 2nd sept novembre 1919 Soixante',\n",
       " '4_11': '420 Rousseau Charles Gn Nivelles 21 mars Pensionné Veuf 54.500 54.500 110 1919 1919',\n",
       " '4_12': '421 3° Lehameg Henri Euthie 2 aout 1916 Neufchateau Bernabi 1922 210 3912 28 8b 1919 2 juin 1975 3 avril 1920 24 19 5 385',\n",
       " '4_13': \"Soixante & dix huit novembre 1919 enregé\\n\\n(1) Les déclarations rectificatives et supplémentaires portent le numéro de la déclaration qui les précède suivi d'un exposant Instr. n° 1574 § 5 note 11\",\n",
       " '5_0': \"N° D'ORDRE DATE DU DÉPÔT des DÉCLARATIONS DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES: NOMS, PRÉNOMS, DOMICILES DATE DU DÉCÈS ou de L'ENVOI EN POSSESSION NOMS, PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES DROITS DE SUCCESSION: MUTATION EN LIGNE DIRECTE: ACTIF, PASSIF, RESTANT NET DROIT DE MUTATION par décès NUMÉROS des DÉCLARATIONS VALEUR des IMMEUBLES RECETTE: DATE, N° CAUTION-NEMENTS, DROITS EN SUSPENS OBSERVATIONS\\n\\n(Les déclarations sont figurées à l'état n°14 et inscrites dans le registre n°25)\",\n",
       " '5_1': '1919',\n",
       " '5_2': '423 neuf Sleemans Charles Otto 24 avril Pensier Célestine 5888 244 5888 . 39 . . 10294/4 322 novembre 1917 47 10 janvier 24',\n",
       " '5_3': '295 3° Burey Léonard Marie à Namur 6 janvier 1912 Cinq cents actions 500 500 10 août 241 9 juin 1920',\n",
       " '5_4': '4214  3°  Pietersons  Petrus Joannes Wilhelmus  † Puers  deux germains restés  Décln supp 24/3/1915  249\\n                      17 fevr 1915                                                                  1915',\n",
       " '5_5': '422 5 Pietersons Leon Gn 26 maart 1898 166 225 101 31 Aug 25 maart non fournie 1920 1920',\n",
       " '5_6': '423 5 Desaeger Henri Bertha Arthur 20 mai 1919 Blankenberghe Veuf 2895 2895 30 50 25 5 17 mars 60 1940',\n",
       " '5_7': 'Arendonk le dix neuf novembre 1913 (treize)',\n",
       " '5_8': '424 vingt 9bre Hantier Firmin Nivelles épicier Décès publié au rôle 86101 86101 Mle 7 janvier 223 mars 16 juillet 83 919 1920 1920 1920',\n",
       " '5_9': '485 5e Delaitre Céline Catherine Rosine 26 mars 1849 Louvignies Quesnoy Nord 5900 5900 + 5e 26 mars 1924 non mariée',\n",
       " '5_10': 'Donné le vingt novembre 1919 Conseil',\n",
       " '5_11': '425² Longhespeé Pierrot Julien 22/12/1910 à Gent Conducteur autobus Décédé célibataire 22/3/1974',\n",
       " '5_12': '426 3e Fontignies Arthur St Josse Bartholomé Edouard 2261 2261 1 3e 26 avril 10 mai 924 38 ten Noode veuve 1924',\n",
       " '5_13': '429 d Moens Joseph Calais expulsé Liège déc. d autres 1595 5095 1 3 28 mai non fautif 1914 1919',\n",
       " '5_14': '428 x Semal Henri Nivelles 15 juin Epoux alice Laubry 4.000 4.000 334 1 x 16 août 16 août 1924 1924 1924 40',\n",
       " '6_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES. DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE NUMÉROS RECETTE CAUTION- OBSERVATIONS. d'ordre des NOMS. PRÉNOMS. DOMICILES. ou de ET OU D'ENVOI EN POSSESSION DE MUTATION des de la des NEMENTS DÉCLARATIONS. l'ouverture DEMEURES DES PARTIES DÉCLARANTES. ET MUTATION EN LIGNE DIRECTE par décès DÉCLARATIONS RECETTE DROITS ET AMENDES d'absence ou de l'envoi en possession. ACTIF. PASSIF. RESTANT NET (1) (2) (3) (4)\",\n",
       " '6_1': '1911',\n",
       " '6_2': '150 vingt quatre Lambert Valentin Nicolas 16 mars Grand Auviller et autres 15890 1609 26789 16 mars juin 1921 1922 19',\n",
       " '6_3': '151 Lerseau Christophe charbon fourrage denrées beurre & autres 6768 6860 7869,44 157 16 - 97',\n",
       " '6_4': '152 5° Vanpée Frederic a 29.8.1920 9 4100 594 6904 non passible',\n",
       " '6_5': '153 Dr Delabij Joachim Joseph cultivateur Lejardin Joachim Rosine Marie 1828 586 1828 270 frimaire',\n",
       " '6_6': 'Arrêté Le vingt quatre juin 1920 terme 2',\n",
       " '6_7': '153² Charlier Hosdent Nestor 8 avril 1920 Henri Jules & Don 341 100 1020',\n",
       " '6_8': 'Arrêté le vingt-cinq juin mil neuf cent',\n",
       " '6_9': 'Arrêté le vingt-six juin 1921 Dimanche Joseph',\n",
       " '6_10': '154 Froment Roger Nivelles 28.8.1911 Van Dormael Juliette 50.705 3.369 18.546 30,5 janvier 239 1936',\n",
       " '6_11': '155 o Devreux Jean Bte Beauraing Epouse Renard Henriette coutur. 21/10 2468 248 non produite\\n                Custinne 1928',\n",
       " '6_12': '156 Scolas Jean Joseph Ouvrier 6 Août Scolas Jules fils autres 2691 2691 id',\n",
       " '6_13': 'Arrêté le vingt sept février 1921 (clôturé)',\n",
       " '6_14': '157 vingt huit 8 Declercque Marie-Emma Veuve 29 8bre 1910 Deftingue Adolphe 14.066 3326 12.919 9.649,25',\n",
       " '7_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS DROITS DE SUCCESSION DROIT NUMÉROS RECETTE des ou du DE MUTATION des DÉCLARATIONS NOMS PRÉNOMS DOMICILES jugement d'absence NOMS PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES sur décès ACTIF PASSIF RESTANT VALEUR de de NET des de l'enregistrement l'acquit IMMEUBLES perception des droits des droits OBSERVATIONS (Les déclarations sont déposées à l'état n° 43 annexé à ces sommiers; elles y sont classées dans le présent numéro d'ordre)\",\n",
       " '7_1': 'Arrêté le degré gratis 19 20 décemb.',\n",
       " '7_2': '145 Septfques Luyer Charles Louis Original 15 8/1920 Van acker julienne x veuve 50.88 1418 52306 28 8/bre 1921 16 9bre 31',\n",
       " '7_3': 'Meulebeke den sept-juni 1921 ontvangen',\n",
       " '7_4': '146 des Saintfuery Masson Jean Bte Boucher 19 Abigail Porte Louise 12905 878 12020 31-11-41 149',\n",
       " '7_5': 'Nevele le 3e Avril juin 1921 (onvraag)',\n",
       " '7_6': 'Soest le dix neuf juin 1921 Dimanche soir et',\n",
       " '7_7': 'Nivelles le vingt-juin 1921 décédé',\n",
       " '7_8': '145 vingt cinq juin Leblicq Jason Bte Ransart 13 mars Veuve Marie Dhaese et autres 1950 336 1620 son frère 1860',\n",
       " '7_9': 'Société du vingt-un juin 1921 dissoute',\n",
       " '7_10': 'Absent du pays depuis 1923 décédé',\n",
       " '7_11': 'Brecht Vrijdag 7 juni 1929 overleden',\n",
       " '7_12': '148 vingt quatre Dasset Emmanuel Garçon Bruxelles Grains Denrées & autres 4781 1133 1512 100 6 janvier 1842 205',\n",
       " '7_13': '149 de Kiegelart Laurent Jh Ogino 18 mai 1926 Huygens-Elisabeth x autres 6578 558 3111 non produit',\n",
       " '8_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS RECETTE CAUTION d'ordre des NOMS PRÉNOMS DOMICILES ou de l'envoi ET MUTATION EN LIGNE DIRECTE DE MUTATION DES DATE de la NEMENTS DÉCLARATIONS en possession DEMEURES DES PARTIES DÉCLARANTES ACTIF PASSIF RESTANT NET VALEUR par décès DÉCLARATIONS perception DROITS ET AMENDES IMMEUBLES de succession OBSERVATIONS\",\n",
       " '8_1': 'Soumis le vingt un novembre 1919 enregistré',\n",
       " '8_2': '429 vingt deux Beth Jeanne Otta 28 mars Fleuret Louis 1000 . 1000 5 janvier 26 mars 15 8bre 300 novembre 1919 1920 1919 25 7bre 300 600',\n",
       " '8_3': '430 8e Huart Ida o 19 8bre 1913 Huart Joseph & autres 44207 1861 42346 3 8e 19 avril 1917 4 avril 1918 3ème 1 juin 1918 4ème',\n",
       " '8_4': '431 3° Romain Félicie 3 1874 bras Veuve Livrai x autres 1918 10 28 5 0 10 juillet 1930 15730,79',\n",
       " '8_5': '1532 5 Poliart Léon \" 35849/11 Maison Grange écuries 915 111 632 1865 5 7bre 15 avril 1879 3 avril 1883',\n",
       " '8_6': '133 Poliart Arthur 19 50 a 945 441 642 1387 50 19 50 0 71',\n",
       " '8_7': '434 Jr Houtmeyers Henri célibataire 38 ans 1/2 Belgique Duffel 1834 78 1878 3e 21 mars 1 avril 1878 78',\n",
       " '8_8': '455 dr Thibaut Beau Louis épinard 5 9bre 1919 époux Denis & autres 11250 11250 455 dr 5 7bre 1920 non passible',\n",
       " '8_9': '436 5 Gaussin Eva Bruxelles 22/8/1915 Gaussin Daniel 1020 722 298 5 50 20 avril 1949 non fournie',\n",
       " '8_10': '437 30 Delanney Clémentine 2 28 mars Décès à déclarer 6154 644 513 1 30 29 janvier 14-11-21 148 1918 1919',\n",
       " '8_11': '438 Debutte Jules 20 octobre Aq[illegible] Debutte alfred 3968 4963 2445 1 5 29 avril 15 mai 1920 n° 1929 15 aout 1921 565',\n",
       " '8_12': 'Décédé le vingt trois novembre 1919 à Bruxelles',\n",
       " '8_13': 'Nivelles Le vingt trois novembre 1919 Dimanche Serein',\n",
       " '9_0': \"N° DATE DU DÉPÔT des DÉCLARATIONS DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS ou de L'ABSENT PRÉSUMÉ en perception DROITS DE SUCCESSION DROIT DE MUTATION par décès NUMÉROS des DÉCLARATIONS DATE RECETTE DROITS ET AMENDES OBSERVATIONS NOMS PRÉNOMS DOMICILES NOMS, PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES MUTATION EN LIGNE DIRECTE VALEUR IMMOBILIÈRE ACTIF PASSIF RESTANT NET\",\n",
       " '9_1': 'Averti le vingt quatre novembre 1919 (signé)',\n",
       " '9_2': '439 vingt cinq Gossiaux Antoine Jos Pharmacien 20 7bre 1841 Bastien Sophie s autres 804 5215 6 janvier 20 juillet 3 mai 1918 68 1920 1920',\n",
       " '9_3': 'Décédé le vingt cinq novembre mil neuf cent dix neuf',\n",
       " '9_4': 'Décédé le vingt trois novembre 1919 (Bruxelles)',\n",
       " '9_5': 'Ixelles le vingt-sept novembre 1929 décédé',\n",
       " '9_6': 'Décédé le vingt huit novembre 1919 (veuve)',\n",
       " '9_7': 'Arrêté le vingt neuf novembre 1919 (Signé)',\n",
       " '9_8': 'Soixante le trente novembre 1919 dimanche décédé',\n",
       " '9_9': '439 1/2 Sainblane Joseph maçon 1 février Senzeilles Georges & 5596 5596 206 journalier 1914 autres 1/14',\n",
       " '9_10': '1293 5. Saintlane Communal 43 50 73 2830 2830 107 1911',\n",
       " '9_11': 'Arrêté le premier décembre 1919 Signature',\n",
       " '9_12': '4294 deux Charlier Jean Bte célibat. 29/8/1915 - Chauveheid Juliette, Elise Vve Charlier 5000 5000 91\\n                                                                                                 199',\n",
       " '9_13': \"Jeudi 8 deux décembre 1919 Verviers\\n\\n(1) Les déclarations rectificatives et supplémentaires portent le numéro de la déclaration qu'ils rectifient ou\",\n",
       " '10_0': \"N°   DATE DU DÉPÔT   DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES.   DATE DU DÉCÈS   DROITS DE SUCCESSION   DROIT   NUMÉROS   RECETTE   CAUTION-   OBSERVATIONS.  \\nd'ordre   des   NOMS,   PRÉNOMS   DOMICILES.   ou de   NOMS, PRÉNOMS   EN LIGNE COLLATÉRALE   DE MUTATION   des   DATE   NEMENTS  \\n     DÉCLARATIONS.         l'absence,   ET   et de   SUR ACTES.   DÉCLARATIONS.        \\n            en possession.   DEMEURES DES PARTIES DÉCLARANTES.   MUTATION EN LIGNE DIRECTE              \\n               ACTIF.   PASSIF.   RESTANT   VALEUR              \\n                     NET.   des              \\n                        IMMEUBLES.\",\n",
       " '10_1': 'décédé le trois décembre 1919 domicilié',\n",
       " '10_2': '4395 Knops Valentine Nicolle 7/8/1911 Berchem (Anvers) x veuve Décédée célibataire 28 9 1979 28.361,40 Frs 17 centimes 585',\n",
       " '10_3': 'Jeudi le quatre décembre 1919 décédé',\n",
       " '10_4': '440 cinq cent Defalque Eugene Marié 5 juin 1911 Wanfercée Baulet 4102 1220 16 janvier 1920 3 mai 1920 96',\n",
       " '10_5': 'Souvret-Ressaix décembre 1919 décédé',\n",
       " '10_6': '418 bis 584 Jacqmin Cécile épouse 27 juillet Joseph François 58611 68611 102.75 3% 27 mai 16 juin 914 1915 1916',\n",
       " '10_7': '4452 8 Voussure Léon Ouvrier 1er Février 1874 Gilly Centre 41 41 28',\n",
       " '10_8': 'Lundi 8 décembre 1919 Conseil',\n",
       " '10_9': 'Décédé le 23 septembre 1919 à Rimancho (Isère)',\n",
       " '10_10': '5413 Vanbrabant de Salieuve Emile Nivelles 7/6/1918 Domicile Marie 628 628 133 19.7',\n",
       " '10_11': 'Décédé le huit décembre 1919 épouse',\n",
       " '10_12': '4414 neuf six Heuvels Alphonsine Rosalie 6 Janvier 1919 Parents Décès déclar. successions 435 1919',\n",
       " '10_13': '4415 x Goisse Adolphe \" 6 janvier Bouquiaux clara 710 710 264 1919 1919',\n",
       " '11_0': \"N° DATE DU DÉPÔT des DÉCLARATIONS DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS ou de la présomption d'absence NOMS, PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES DROITS DE SUCCESSION DROIT DE MUTATION par décès NUMÉROS des DÉCLARATIONS RECETTE OBSERVATIONS NOMS. PRÉNOMS. DOMICILES. en LIGNE COLLATÉRALE et de MUTATION EN LIGNE DIRECTE VALEUR ACTIF. PASSIF. RESTANT NET. DATE NUMÉROS du registre DROITS ET AMENDES. DATE N° (1) (2) (3) (4)\",\n",
       " '11_1': 'Arrêté le vingt décembre 1919 Soixant',\n",
       " '11_2': 'Arrêté le dix décembre 1919 dix-neuf',\n",
       " '11_3': '441 Dewez Jean Waterloo 9 8bre 1813 Berny Jenneret 921 921 4re 1919',\n",
       " '11_4': 'Arrêté le vingt décembre 1919 (dix-neuf)',\n",
       " '11_5': '448 Belise Vital garçon 1 8bre 1843 Cappens Cath. 2593 2593 10',\n",
       " '11_6': 'Décédé le douze décembre 1919 douze',\n",
       " '11_7': 'Brecht le trois décembre 1949 (décédé)',\n",
       " '11_8': 'Arrêté le présent relevé le 29 novembre 1919 (signature illisible)',\n",
       " '11_9': 'Décédé le quinze décembre 1919 à Bruxelles',\n",
       " '11_10': 'Arrêté le deux décembre 1929 (clôturé)',\n",
       " '11_11': '8 441 Boisdenghien Henri garçon 18 mai 1849 Debois Pauline & autres 42396 42396 6ta 1849',\n",
       " '11_12': 'Décédé le six sept décembre 1919 à Seraing',\n",
       " '11_13': \"Soumis le dix huit décembre 1919 Soumis\\n\\n(1) Les déclarations rectificatives et supplémentaires portent le numéro de la déclaration qu'elles modifient.\",\n",
       " '12_0': \"N° DATE DU DÉPÔT des DÉCLARATIONS DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES NOMS PRÉNOMS DOMICILES DATE DU DÉCÈS ou du JUGEMENT D'ENVOI en possession ou fixation DROITS DE SUCCESSION NOMS PRÉNOMS et DEMEURES DES PARTIES DÉCLARANTES EN LIGNE COLLATÉRALE et de MUTATION EN LIGNE DIRECTE ACTIF PASSIF RESTANT NET DROIT DE MUTATION par décès NUMÉROS des DÉCLARATIONS RECETTE DATE NUMÉRO du REGISTRE DE LA RECETTE DATE de l'enregistrement des droits NUMÉROS du SOMMIER et de L'ARTICLE OBSERVATIONS (Les déclarations sont inscrites à l'encre noire et les recettes à l'encre rouge dans la présente colonne)\",\n",
       " '12_1': \"1448 Devillers Josephine Marie 9 Février décédée fille célibataire 30 Septembre 1448 1898 L'Alleux 1919 1919\",\n",
       " '12_2': '4910 35 Clabecq Fernand Nestor François Désiré Léon 16 291 1919',\n",
       " '12_3': 'Arrêté le dix neuf décembre 1919 feuille',\n",
       " '12_4': 'Ixelles le vingt-six mai 1919 vingt',\n",
       " '12_5': 'Arrêté le vingt-un octobre 1919 Dimanche soir',\n",
       " '12_6': '462 vingt deux Gilbert Clementine celibat 20/2/1917 Leopoldsburg Hasseltweg 2 actuell 7e 7291 7291 2 fevrier 20 fevrier 1 semaine 97 1970',\n",
       " '12_7': '442² 8 Paesmans Henri Berchem 6¹ 13 mars Paesmans Henri 1881 1950 245 4 Avril 51 avril 1917 1917 25 3° 57',\n",
       " '12_8': '4423 5° Minne Maria Ghysel 2 avril veuve jules 1646 . 1646 618 7 janvier 8 1875 917 1920',\n",
       " '12_9': '462° 5° Walbieu Constance Elise 11 mars Pensionnaire (Asyle) 149741 149741 415 1914 1919',\n",
       " '12_10': 'Herselt le vingt deux décembre 1919 enreg',\n",
       " '12_11': 'Jeudi le vingt trois décembre 1929 [Signature]',\n",
       " '12_12': '1405 Cauwenberg Victor Joseph Charles 16.8.911 Gembloux célibataire 262 262 305 1919',\n",
       " '12_13': '543 Anthoine Alphonse Auberge 40 8/9/79 Paturages Marié Clémence Dubuisson 1826 1826 décédé 26 avril 1920 non faite',\n",
       " '13_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS NOMS PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS RECETTE CAUTION- OBSERVATIONS d'ordre des ou de ET LEURS COLLATÉRAUX DE MUTATION des DATE NEMENTS, des DÉCLARATIONS NOMS PRÉNOMS DOMICILES l'ouvert d'envoi DEMEURE DES PARTIES DÉCLARANTES MUTATION EN LIGNE DIRECTE Loi du 27 DÉCLARATIONS de de DROITS (Les déclarations qui figurent à l'état en possession ACTIF PASSIF RESTANT décembre 1817 l'enregistrement l'exigibilité EN SUSPENS n°131 doivent être portées en rouge fr fr NET VALEUR Successions Mutations du délai des droits dans la présente colonne) fr DES DATE N° IMMEUBLES\",\n",
       " '13_1': 'Jeudi les vingt-quatre décembre 1919, Jumet',\n",
       " '13_2': 'Hasselt 23 vingt-quatre décembre 1929 Noël fermé',\n",
       " '13_3': '14083 enregistré Thibault Beau-Louis épicier 5 8bre 93 Légat Univ. & autres 1450 515/1919',\n",
       " '13_4': 'Arendonk le vingt-six Décembre 1919 Sceau',\n",
       " '13_5': '464 verpleegde Waubier Elise Pauline 29 juin 91 Boussu célib 11689 11689 17 févr 28 avril 29 avril 91 1920 1920 1920',\n",
       " '13_6': '445 Jacquet Emerencienne Pélagie 29 j° Jacquet Emile 58298 2373 56202 7 j° 29 j° 18 avril 1920 38',\n",
       " '13_7': 'Décédé le vingt-sept décembre 1919 à Bruxelles',\n",
       " '13_8': 'Décédé le vingt-huit décembre 1919 Demeuré inconnu',\n",
       " '13_9': '446 second part Vanglaire Guillaume Prosper 8 7bre 1844 receveur-buraliste retraité 100 700 9 30 15 juillet 1920 non fournie',\n",
       " '13_10': 'Reçu le vingt neuf décembre 1919 Soixante\\n\\nVersées 1919 perceptions pour\\n1916 - 39\\n1918 - 415\\n1919 - 588 . 191 220 268 . 368 . 402\\n      588 . 815 . 932 . 933 . 935',\n",
       " '13_11': \"Roulé le trente décembre 1919 [illegible] Succession d'appartenant de 1919 . 68 . 395 1918 218 . 591 286 . 986\",\n",
       " '13_12': '462 2 centimes Plasman Désiré Maurice Ecaussin 10 mars 1919 Veny Remy & autres 158 158 316 316 1919 491 498 497 500 506 511 516 522 527',\n",
       " '13_13': 'Soixante-six centimes décembre 1919 douze le bénéficiaire Les déclarations rectificatives et supplémentaires portent le numéro de la déclaration qui les précède',\n",
       " '14_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS DROITS DE SUCCESSION DROIT NUMÉROS DATE RECETTE CAUTION OBSERVATIONS des NOMS, PRÉNOMS, DOMICILES ou du NOMS, PRÉNOMS EN LIGNE COLLATÉRALE DE des NEMENT DÉCLARATIONS jugement d'envoi ET DE MUTATION DÉCLARATIONS DROITS ET AMENDES en possession HÉRITIERS DES PARTIES DÉCLARANTES MUTATION EN LIGNE DIRECTE ACTIF, PASSIF, RESTANT (f) NET (d) (e) (f)\",\n",
       " '14_1': 'Arrêté le premier janvier 1820 Déclaration Surveil',\n",
       " '14_2': '1 deux janvier Séverin Jules maçon à jumet célibataire né le 5 juin 36762 36762 5/6/2 épuisé le 4920 1899 1920 15 février 6 mai 19 1920 1920',\n",
       " '14_3': '2 J° Dumont Louise Rosalie 3 J° Fleury-palette x auto 569 10 50 10 50 3 50 14 janvier 1920',\n",
       " '14_4': 'décédé le deux janvier 1920 dix neuf',\n",
       " '14_5': 'Anvers le trois janvier 1920 dossier',\n",
       " '14_6': 'Arrêté à quatre-vingt-dix Demander Serail',\n",
       " '14_7': '3 Houlin Edgard Albert 7 juillet Somme allouée rentes 111.72 111.72 100 16 février 1 mai 25 juillet 1939 1940 1940 1 juin 1940',\n",
       " '14_8': '3e Séverin Jules Ouvrier 6 juillet Séverin 1879 34.145 1920 célibat. 1919',\n",
       " '14_9': '3e de Wanderpepen Louis Nivelles 29/8/73 Rentier Seules 1615 1615 707 27 janvier 1916 99',\n",
       " '14_10': 'Souvret le vingt janvier 1920 Soussigné',\n",
       " '14_11': '4 janvier Scolas Victoire Joseph Baronne 22/8/1844 Rooselbergh Joseph 9039 9039 15 francs 22 juillet quittée célibat autres 1920 1920 120',\n",
       " '14_12': 'Décédé le 8 de janvier 1920 déclaré',\n",
       " '14_13': \"Reçu le 8 septembre 1920 Série N° (1) Les déclarations rectificatives et supplémentaires portent le numéro de la déclaration qu'elles modifient, affecté d'un exposant (bis, ter, etc.)\",\n",
       " '15_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS NOMS PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE NUMÉROS RECETTE CAUTION DÉCLARATIONS NOMS PRÉNOMS DOMICILES DÉCÈS D'ENVOI DEMEURES DES PARTIES DÉCLARANTES et de PAR DÉCÈS DÉCLARATIONS ARTICLES DROITS ET AMENDES OBSERVATIONS en possession MUTATION EN LIGNE DIRECTE VALEUR registre ACTIF PASSIF RESTANT IMMEUBLES de perception NET des droits\",\n",
       " '15_1': '34. Paul Henri Lefebvre Laurent Célibat. 30 9bre 1920 Nismes Exploitant agricole 4510 4510 1445 . . 23 9bre 1944 24 9bre 1944',\n",
       " '15_2': 'Anvers le huit janvier 1920 décédé',\n",
       " '15_3': 'Soumis le neuf janvier 1920 Bruxelles',\n",
       " '15_4': 'Bevecele dix janvier 1920 décédé',\n",
       " '15_5': 'Décédé le vingt janvier 1920 Cinquante deux ans',\n",
       " '15_6': '5 deup jeunes Denck Henri Brasseur 2 mai Arquebuse fusil carab. 1200 1200 26°24 fevrier 6 mars 1919 1920 1920',\n",
       " '15_7': 'Jemappes le onze janvier 1920 dix neuf',\n",
       " '15_8': '6 Lacroix Reçu le Mémoire Négocial 29/3/23 Flémalloy usine à cuivre 3641 3641 20 3° 15.000.000 non fournis',\n",
       " '15_9': 'Décédé le treize janvier 1920 (Conseil)',\n",
       " '15_10': 'Soude le quatorze janvier 1920 décédé',\n",
       " '15_11': 'Décédé le quinze janvier 1920 (décès)',\n",
       " '15_12': 'Ixelles le deux janvier 1920 Enreg.',\n",
       " '15_13': '7 Schillebeeckx Michiel Weduwe Brouwer Dalhain 29 juillet Redemptien alfons x aut 14625 14625 29 fevrier 29 mai 1920 1 avril 1920 270 1919 Dalhain',\n",
       " '16_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE RECETTE CAUTIONNEMENTS OBSERVATIONS NOMS, PRÉNOMS DOMICILES ou du DÉPART D'ENVOI DEMEURES DES PARTIES DÉCLARANTES ET DE MUTATION EN LIGNE DIRECTE ACTIF PASSIF RESTANT NET VALEUR\",\n",
       " '16_1': '8 diep/1946 Leclercq Fleuron Marie 6 8/6/19 Tubize Victor + autres 3468 3468 1946 20 janvier - 6 juillet non produit 1946',\n",
       " '16_2': \"9 Gervis Evelphore Désiré septemb Castienne Marie Pensionné d'invalide 2 août 1918\",\n",
       " '16_3': '9e 2 Oreye alphonse jn a 25 8bre 1911 Genoels-Elderen 587 1 fevrier 50 1912',\n",
       " '16_4': 'Samedi le dix sept janvier 1920 Douai',\n",
       " '16_5': 'Boussu le dix huit janvier 1920 dimanche matin',\n",
       " '16_6': 'Revesti le dix neuf janvier 1920 Soumis',\n",
       " '16_7': 'Moorsel le vingt janvier 1920 décédé',\n",
       " '16_8': '93 Becquet Marcel Firmin 3e mariage Poupard Rose Sans profession 588 1917',\n",
       " '16_9': 'Donné le vingt un janvier 1920 enreg',\n",
       " '16_10': 'Soixante dix neuf mille quatre cent vingt francs',\n",
       " '16_11': 'Soixante-dix-sept francs 77.20 décimes',\n",
       " '16_12': '10 vingt quatre Durieux Henri Nestor 4 juillet Durieux Louis 141 53 888 145940 1er Anvers 4 avril 1919 Jules 1920 3 avril 1920',\n",
       " '16_13': \"Soixante-dix-sept mille quatre cent vingt deux francs\\n\\nLes déclarations rectificatives et supplémentaires portent le numéro de la déclaration qui les précède, affecté d'un exposant. Circ. n° 1574, § 5, note 11.\\n\\nNégliger les centimes.\",\n",
       " '17_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS NOMS PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE RECETTE CAUTION OBSERVATIONS d'ordre des DÉCLARATIONS NOMS PRÉNOMS DOMICILES ou du JUGEMENT D'ABSENCE ET DE TOUTE NATURE Y COMPRIS DE MUTATION des des NEMENT en cas d'absence DEMEURES DES PARTIES DÉCLARANTES MUTATION EN LIGNE DIRECTE par décès DÉCLARATIONS ACTIF PASSIF RESTANT VALEUR des NET IMPOSABLE biens soumis (1) (2) (3) au droit DATE N° de l'enregistrement des droits\",\n",
       " '17_1': 'Arrêté le vingt cinq janvier 1920 Dimanche soir',\n",
       " '17_2': '102 vingt-deux Deflandre Gustave désiré Emile 22/8/918 Boulonnais Belgique 440 500 - 198/919 janvier',\n",
       " '17_3': '10³ 5° Ypersiel Julien Ghislain Rentier 18 8bre 1858 Charmes célibat. 250 . 250 15 7917',\n",
       " '17_4': 'Arrêté le vingt-six janvier 1920 (Signé)',\n",
       " '17_5': \"10. Cordeau Louis Maxime 21 janvier Tailleur d'habits 300 300 10 janvier 21 janvier janvier 1917 1918 1918\",\n",
       " '17_6': 'Overleden te Antwerpen januari 1920 onwettig',\n",
       " '17_7': \"10 vingt huit Dececk Désiré Eugène 26 janvier Meslin l'Evêque 544 544 593 janvier 1917 1918\",\n",
       " '17_8': '405 d Decook Adèle 10 8bre 15 176 4918',\n",
       " '17_9': '11 3° Bolendries Anastasie Nivelles 13 7bre 1849 Bolendries Virginie 590 398 1185 11 mars 13 avril 2 avril 1920 760 1920 1920',\n",
       " '17_10': 'Arrêté le vingt huit Janvier 1920 Soumis',\n",
       " '17_11': 'Soixante-dix-neuf francs cinquante centimes',\n",
       " '17_12': '11e Rousseau Charles Gve Nivelles St maçon Rameau Jeanne 1500 500 2000',\n",
       " '17_13': '115 Dedoncker Vital Cutsem le 24 9/11 Gouvernement du Chili 1448 1568 93.60 157 41',\n",
       " '18_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS NOMS, PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE RECETTE CAUTIONS des NOMS, PRÉNOMS, DOMICILES ou de ET ou DE des des FOURNIES OBSERVATIONS DÉCLARATIONS l'ouverture DEMEURES DES LIGNE COLLATÉRALE MUTATION DÉCLARATIONS DROITS ET de l'envoi PARTIES ET par AMENDES en possession, DÉCLARANTES MUTATION EN LIGNE décès ou cas DIRECTE d'absence ACTIF PASSIF RESTANT NET VALEUR des BIENS DÉCLARÉS\",\n",
       " '18_1': 'Arrêté le trente janvier 1920 (signé)',\n",
       " '18_2': 'Arrêté le trente un janvier 1920 (signé)',\n",
       " '18_3': 'Arrêté le présent feuillet 1920 Dimanche douze',\n",
       " '18_4': \"12 deux février Carlier Victor épousant 15 février Rentier veuf d'Anni. 6775 309 1085 7 mois et 15 jours 16 février 35 1912 1912 1920\",\n",
       " '18_5': 'Arrêté le deux février 1920 Soumis',\n",
       " '18_6': 'Décédé le Trois février 1920 (déclaré)',\n",
       " '18_7': '13 quatre vingt Longe Célestin Brasseur 5° 29 juillet Deloye Florent et autres 1636 1644 15 3° 25 juin non partagé 220 célibat. 94 ½ ½ 940',\n",
       " '18_8': '14 Segain Louise Anna Pharaïlde S 9/4/77 Leupegem Pêche ouvrière 1978 3266 6691 19° 17° 3° 7 46419 0 31031 137',\n",
       " '18_9': 'Ixelles le quatre février 1920 dix neuf',\n",
       " '18_10': \"15 vingt février Rainez Décès Catherine Rosalie 5 avril Roosebeke alphonse 4500 4500 18 3e 5 juin 1920 non parentes d'Estaing 1919 rentier\",\n",
       " '18_11': '15e 5 Denys Marie Virginie Ghislaine épouse Lemaire Emile décès enregistré 201 5 février 32 1935',\n",
       " '18_12': '15 3 Vanhoolebrouck Georges Charles Alphonse 29 maart Cayman Emile 5575 5575 304 1949 1/15',\n",
       " '18_13': '454 Saintblanc Joseph Auguste Charleroi 7 février Cinq Héritiers ou autres 2280 2280 207 1949 1.99',\n",
       " '19_0': \"N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES DATE DU DÉCÈS NOMS PRÉNOMS DROITS DE SUCCESSION DROIT NUMÉROS DATE RECETTE CAUTION d'ordre des ou de NOMS PRÉNOMS EN LIGNE COLLATÉRALE DE NUMÉROS des de NEMENT DÉCLARATIONS l'ouverture de et de MUTATION DÉCLARATION des la DROITS ET AMENDES OBSERVATIONS présomption DOMICILES EN LIGNE DIRECTE PAR ÉTAT ARTICLES recettes en cas d'absence DEMEURES DES PARTIES DÉCLARANTES ACTIF PASSIF RESTANT VALEUR des NET IMMEUBLES (1) (2) (3) (4)\",\n",
       " '19_1': 'Arrêté le cinq février 1920 (vingt)',\n",
       " '19_2': 'Boussu-lez-Mons 1920 (Hainaut)',\n",
       " '19_3': 'Arrêté le sept février 1920 (Signé)',\n",
       " '19_4': 'Boussu-lez-haut 6 juin 1920 Dimanche décédé',\n",
       " '19_5': 'Arrêté le neuf février 1920 dix-neuf',\n",
       " '19_6': '16 six feuv Soupart Corneille Nivelles 11 avril 1847 Rentier français à Nivelles 39101 39101 26 et mars 11 juin 25750 frs 133 1920 1920 1920 11500 frs 138',\n",
       " '19_7': \"16a Favre Alphonse Jph Cuisinier 2 Août 1855 Bois d'Haine et autres 1200 1200 30/1916 24 mars 1920 49\",\n",
       " '19_8': '163 5 Siraux Augustin Albery Thomas Couturier Emile 1015 1015 174 1911',\n",
       " '19_9': 'Arrêté le dix février 1920 dix-neuf',\n",
       " '19_10': 'Arrêté le onze février 1920 clôturé',\n",
       " '19_11': '17 Vaneutsem Adeline Marie G. 73 ans Bruxelles Charles x veuve 73.628 73.628 161 27 mars 27 juin 20 juillet 270 1929 1929 1929 1929',\n",
       " '19_12': 'Droits de Succession perçus 1920 [signature]',\n",
       " '19_13': '18 Honnijadis Jules Veuve 22 Boul. Charlemagne Bruxel. 21.507 25 7 21 fevrier 1949',\n",
       " '20_0': \"N° DATE DU DÉPÔT des déclarations DÉSIGNATION DES PERSONNES DÉCÉDÉES OU ABSENTES NOMS PRÉNOMS DOMICILES DATE DU DÉCÈS ou du JUGEMENT D'ENVOI en possession ou d'absence NOMS PRÉNOMS ET DEMEURES DES PARTIES DÉCLARANTES DROITS DE SUCCESSION OU LIGNE COLLATÉRALE ET DE MUTATION EN LIGNE DIRECTE ACTIF PASSIF RESTANT NET DROIT DE MUTATION par décès NUMÉROS des DÉCLARATIONS DATE de l'expiration du délai de l'enregistrement des droits RECETTE des DROITS ET AMENDES DATE N° CAUTIONNEMENTS DATE N° OBSERVATIONS\",\n",
       " '20_1': 'Anvers le deux février 1920 enreg.',\n",
       " '20_2': 'Soumis le quinze Janvier 1920 Serard',\n",
       " '20_3': 'Décédé le quinze février 1920 dimanche Jemelle',\n",
       " '20_4': 'Souvret-le-dix-sept février 1920 décédé',\n",
       " '20_5': '182 des défunts Cabureau Louis titer 5 maison Marchienne thuin 2 déclaration supplétive 495 474',\n",
       " '20_6': '183 Beebes Jules 7 14.8.1918 Despl. f. Gustave xavier 503 563 356/1919',\n",
       " '20_7': 'Décédé le dix sept janvier 1920 Bruxelles',\n",
       " '20_8': 'Heurelt le dix huit janvier 1910 (Signé)',\n",
       " '20_9': '10 Pétriaux Camile Nestor 22 avril 1914 Soldat-Combattant 6390 31 mars 1920 28 juin 1920 10 juillet 1920 115',\n",
       " '20_10': '10 2/5 Dubois Alexandre épicier 1/8/1919 décédé Jean Bte à Auvelais 310 310 100/1919',\n",
       " '20_11': 'Donné le dix neuf février 1920 dix neuf',\n",
       " '20_12': 'Soumis à vingt francs 79 20 centimes',\n",
       " '20_13': \"19 Remience Leon Gta Bruxelles 8 fevrier 1946 Rentière Jeanne 400 400 100 9 4 3 Les déclarations rectificatives et supplémentaires portent le numéro de la déclaration qui les précède, suivi d'un\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claude_refine_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1f689f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "unable_ids = [id for id, content in claude_refine_output.items() if \"unable\" in content or \"I apologize\" in content or \"The image\" in content or \"sorry\" in content]\n",
    "print(unable_ids, len(unable_ids), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51068bb4",
   "metadata": {},
   "source": [
    "### To run with the saved json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81581278",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_refine_output_df = pd.DataFrame(claude_refine_output.items(), columns=['id', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2d9533c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_0</td>\n",
       "      <td>N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_1</td>\n",
       "      <td>Décédé le vingt-huit octobre 1919 (époux veuf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_2</td>\n",
       "      <td>Nivelles le vingt neuf octobre 1919 (décédé)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_3</td>\n",
       "      <td>398 trente Herrent Alphonse J. orphelin 18 8br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_4</td>\n",
       "      <td>398² Lefebvre Jules Brasseur célibat Jemappes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_9</td>\n",
       "      <td>10 Pétriaux Camile Nestor 22 avril 1914 Soldat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>10 2/5 Dubois Alexandre épicier 1/8/1919 décéd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>Donné le dix neuf février 1920 dix neuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>Soumis à vingt francs 79 20 centimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>19 Remience Leon Gta Bruxelles 8 fevrier 1946 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0      1_0  N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...\n",
       "1      1_1     Décédé le vingt-huit octobre 1919 (époux veuf)\n",
       "2      1_2       Nivelles le vingt neuf octobre 1919 (décédé)\n",
       "3      1_3  398 trente Herrent Alphonse J. orphelin 18 8br...\n",
       "4      1_4  398² Lefebvre Jules Brasseur célibat Jemappes ...\n",
       "..     ...                                                ...\n",
       "278   20_9  10 Pétriaux Camile Nestor 22 avril 1914 Soldat...\n",
       "279  20_10  10 2/5 Dubois Alexandre épicier 1/8/1919 décéd...\n",
       "280  20_11            Donné le dix neuf février 1920 dix neuf\n",
       "281  20_12               Soumis à vingt francs 79 20 centimes\n",
       "282  20_13  19 Remience Leon Gta Bruxelles 8 fevrier 1946 ...\n",
       "\n",
       "[283 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claude_refine_output_df['text'] = claude_refine_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "claude_refine_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d265a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_refine_output_df.to_csv(path+'/results/postprocessed/claude_refine_output_perline_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736b773",
   "metadata": {},
   "source": [
    "# CER/BLEU calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2f6551",
   "metadata": {},
   "source": [
    "## ground truth df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a4c03dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "text_path = path+'/data/transcriptions'\n",
    "file_list = glob(os.path.join(text_path, 'transcription_ex*.txt'))\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in file_list:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    lines = content.split('\\n')\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'line': range(0, len(lines)),  # Line numbers starting from 0\n",
    "        'text': lines\n",
    "    })\n",
    "    \n",
    "    name = os.path.basename(file)\n",
    "    name = name.split('.')[0]\n",
    "    df['file'] = name.split('ex')[1]\n",
    "    df['file'] = df['file'].astype(int)\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "90b2da7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N' d'ordre Date du dépot des déclarations Dési...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Nom. Prénoms Domiciles Actif. (2) Passif. (2) ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arrêté le vingt huit octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>arrêté le vingt neuf octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>398 trente octobre Herrent Alphones gh Ophain ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>10</td>\n",
       "      <td>19 dix neuf d Pétriaux Coralie Nivelles 22 av...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>11</td>\n",
       "      <td>19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>12</td>\n",
       "      <td>Arrêté le dix neuf février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>13</td>\n",
       "      <td>Arrêté le vingt février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>14</td>\n",
       "      <td>19^3 vingt un février Remience Jean Bte Nivell...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     line                                               text  file\n",
       "0       0  N' d'ordre Date du dépot des déclarations Dési...     1\n",
       "1       1  Nom. Prénoms Domiciles Actif. (2) Passif. (2) ...     1\n",
       "2       2   arrêté le vingt huit octobre 1919 servais    ...     1\n",
       "3       3   arrêté le vingt neuf octobre 1919 servais    ...     1\n",
       "4       4  398 trente octobre Herrent Alphones gh Ophain ...     1\n",
       "..    ...                                                ...   ...\n",
       "298    10   19 dix neuf d Pétriaux Coralie Nivelles 22 av...    20\n",
       "299    11  19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...    20\n",
       "300    12          Arrêté le dix neuf février 1920 servais      20\n",
       "301    13             Arrêté le vingt février 1920 servais      20\n",
       "302    14  19^3 vingt un février Remience Jean Bte Nivell...    20\n",
       "\n",
       "[303 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "df = df.sort_values(by=['file', 'line']).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a98c96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the text values of line number 0 and 1 (the two lines of the header)\n",
    "for file in df['file'].unique():\n",
    "    header_lines = df[(df['file'] == file) & (df['line'].isin([0, 1]))]\n",
    "    df.loc[header_lines.index[0], 'text'] = header_lines.iloc[0]['text'] + \" \" + header_lines.iloc[1]['text']\n",
    "df = df[df['line'] != 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d6d3fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['line'] != 0, 'line'] -= 1  # Adjust line numbers after removing the second line of the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dae62cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for file 6, two lines are used for some column.. we need to merge them\n",
    "# doubled_line = df[(df['file'] == 6) & (df['line'].isin([3, 4]))]\n",
    "# df.loc[doubled_line.index[0], 'text'] = doubled_line.iloc[0]['text'] + \" \" + doubled_line.iloc[1]['text']\n",
    "# df.drop(doubled_line.index[1], inplace=True)\n",
    "# df.loc[(df['file'] == 6) & (df['line'] > 4), 'line'] -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d8abb06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N' d'ordre Date du dépot des déclarations Dési...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>arrêté le vingt huit octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arrêté le vingt neuf octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>398 trente octobre Herrent Alphones gh Ophain ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>arrêté le trente octobre 1919 servais        ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>arrêté le trente un octobre 1919 servais     ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>arrêté le premier novembre 1919 Toussaint ser...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>arrêté le deux novembre 1919 Dimanche servais...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>399 trois 9bre Desmedt Jeanne Nivelles 13 mai ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>400 d Monseur Raoul Oscar Clabecq 1 8b 1918 Mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>401 d Bouty Henri Braine l'Alleud 26 février 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>arrêté le trois novembre 1919 servais        ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>402 quatre 9bre Godart Renelde Braine l'Alleud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    line                                               text  file\n",
       "0      0  N' d'ordre Date du dépot des déclarations Dési...     1\n",
       "1      1   arrêté le vingt huit octobre 1919 servais    ...     1\n",
       "2      2   arrêté le vingt neuf octobre 1919 servais    ...     1\n",
       "3      3  398 trente octobre Herrent Alphones gh Ophain ...     1\n",
       "4      4  398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...     1\n",
       "5      5   arrêté le trente octobre 1919 servais        ...     1\n",
       "6      6   arrêté le trente un octobre 1919 servais     ...     1\n",
       "7      7   arrêté le premier novembre 1919 Toussaint ser...     1\n",
       "8      8   arrêté le deux novembre 1919 Dimanche servais...     1\n",
       "9      9  399 trois 9bre Desmedt Jeanne Nivelles 13 mai ...     1\n",
       "10    10  400 d Monseur Raoul Oscar Clabecq 1 8b 1918 Mo...     1\n",
       "11    11  401 d Bouty Henri Braine l'Alleud 26 février 1...     1\n",
       "12    12   arrêté le trois novembre 1919 servais        ...     1\n",
       "13    13  402 quatre 9bre Godart Renelde Braine l'Alleud...     1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['file']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "68922e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N' d'ordre Date du dépot des déclarations Dési...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>arrêté le vingt huit octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arrêté le vingt neuf octobre 1919 servais    ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>398 trente octobre Herrent Alphones gh Ophain ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>9</td>\n",
       "      <td>19 dix neuf d Pétriaux Coralie Nivelles 22 av...</td>\n",
       "      <td>20</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>10</td>\n",
       "      <td>19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...</td>\n",
       "      <td>20</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>11</td>\n",
       "      <td>Arrêté le dix neuf février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>12</td>\n",
       "      <td>Arrêté le vingt février 1920 servais</td>\n",
       "      <td>20</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>13</td>\n",
       "      <td>19^3 vingt un février Remience Jean Bte Nivell...</td>\n",
       "      <td>20</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     line                                               text  file     id\n",
       "0       0  N' d'ordre Date du dépot des déclarations Dési...     1    1_0\n",
       "1       1   arrêté le vingt huit octobre 1919 servais    ...     1    1_1\n",
       "2       2   arrêté le vingt neuf octobre 1919 servais    ...     1    1_2\n",
       "3       3  398 trente octobre Herrent Alphones gh Ophain ...     1    1_3\n",
       "4       4  398^2 d Lefévre Jules Braine l'Alleud 8 Janvie...     1    1_4\n",
       "..    ...                                                ...   ...    ...\n",
       "278     9   19 dix neuf d Pétriaux Coralie Nivelles 22 av...    20   20_9\n",
       "279    10  19^2 d Dubois Alexandre Quenast 7b 1919 Dubois...    20  20_10\n",
       "280    11          Arrêté le dix neuf février 1920 servais      20  20_11\n",
       "281    12             Arrêté le vingt février 1920 servais      20  20_12\n",
       "282    13  19^3 vingt un février Remience Jean Bte Nivell...    20  20_13\n",
       "\n",
       "[283 rows x 4 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'] = df['file'].astype(str) + '_' + df['line'].astype(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7fc07b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 1, Last Line: 13\n",
      "File: 2, Last Line: 14\n",
      "File: 3, Last Line: 13\n",
      "File: 4, Last Line: 13\n",
      "File: 5, Last Line: 14\n",
      "File: 6, Last Line: 14\n",
      "File: 7, Last Line: 13\n",
      "File: 8, Last Line: 13\n",
      "File: 9, Last Line: 13\n",
      "File: 10, Last Line: 13\n",
      "File: 11, Last Line: 13\n",
      "File: 12, Last Line: 13\n",
      "File: 13, Last Line: 13\n",
      "File: 14, Last Line: 13\n",
      "File: 15, Last Line: 13\n",
      "File: 16, Last Line: 13\n",
      "File: 17, Last Line: 13\n",
      "File: 18, Last Line: 13\n",
      "File: 19, Last Line: 13\n",
      "File: 20, Last Line: 13\n"
     ]
    }
   ],
   "source": [
    "for file in df['file'].unique():\n",
    "    last_line = df[df['file'] == file]['line'].max()\n",
    "    print(f\"File: {file}, Last Line: {last_line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8837aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path+'/data/transcription_perline_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fb89e02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283 283\n"
     ]
    }
   ],
   "source": [
    "print(df['id'].nunique(), claude_output_df['id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c1c9e",
   "metadata": {},
   "source": [
    "## Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "897e931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'/data/transcription_perline_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b0be671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "cer_metric =load(\"cer\")\n",
    "bleu_metric = load(\"bleu\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b2c6e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_simple = pd.read_csv(path+'/results/postprocessed/claude_one_text_example_perline_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0f2fbcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_0</td>\n",
       "      <td>N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_2</td>\n",
       "      <td>arrêté le vingt neuf octobre 1919 servais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_3</td>\n",
       "      <td>398 Octobre Herrent Alphonse Joseph orphelin 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_4</td>\n",
       "      <td>398² Lefebvre Jules Brasseur Jemappes Nicolle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_5</td>\n",
       "      <td>arrêté le vingt huit octobre 1919 servais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>20_9</td>\n",
       "      <td>10 décembre 1930 Pelaians Cambi Morelle 22 avr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_10</td>\n",
       "      <td>10² 5 Dubois Alexandre épicier 5/8/1919 décédé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_11</td>\n",
       "      <td>arrêté le dix neuf février 1920 servais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_12</td>\n",
       "      <td>arrêté le vingt huit octobre 1919 servais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_13</td>\n",
       "      <td>19 vingt huit Remience Lem 87a Nivelles 8 fevr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0      1_0  N° DATE DU DÉPÔT DÉSIGNATION DES PERSONNES DÉC...\n",
       "1      1_2          arrêté le vingt neuf octobre 1919 servais\n",
       "2      1_3  398 Octobre Herrent Alphonse Joseph orphelin 1...\n",
       "3      1_4  398² Lefebvre Jules Brasseur Jemappes Nicolle ...\n",
       "4      1_5          arrêté le vingt huit octobre 1919 servais\n",
       "..     ...                                                ...\n",
       "277   20_9  10 décembre 1930 Pelaians Cambi Morelle 22 avr...\n",
       "278  20_10  10² 5 Dubois Alexandre épicier 5/8/1919 décédé...\n",
       "279  20_11            arrêté le dix neuf février 1920 servais\n",
       "280  20_12          arrêté le vingt huit octobre 1919 servais\n",
       "281  20_13  19 vingt huit Remience Lem 87a Nivelles 8 fevr...\n",
       "\n",
       "[282 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "637acb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_example = df[~df['id'].isin(['1_1'])] #two eamples: '1_1', '1_2' or '1_1', '1_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "84956ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_gpt = {}\n",
    "cer_gpt = {}\n",
    "\n",
    "for id in df_example['id'].unique():\n",
    "    # Extract the text as a single string, not as an array\n",
    "    pred_text = c_simple[c_simple['id'] == id]['text'].values[0]\n",
    "    ref_text = df_example[df_example['id'] == id]['text'].values[0]\n",
    "\n",
    "    # Ensure the predictions and references are passed as a list of strings\n",
    "    if pred_text and ref_text:  # Check if both texts are not empty (which happens for some OCR outputs)\n",
    "        bleu_gpt[id] = bleu_metric.compute(predictions=[pred_text], references=[ref_text])\n",
    "    else:\n",
    "        bleu_gpt[id] = {'bleu': 0.0}  # Assign a default value if texts are empty\n",
    "    cer_gpt[id] = cer_metric.compute(predictions=[pred_text], references=[ref_text])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8774a8e",
   "metadata": {},
   "source": [
    "### BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "968b6c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_gpt = pd.DataFrame(bleu_gpt).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57842d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15490614052057017 0.052481467008593366\n"
     ]
    }
   ],
   "source": [
    "print(bleu_gpt['bleu'].mean(), bleu_gpt['bleu'].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc301e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>precisions</th>\n",
       "      <th>brevity_penalty</th>\n",
       "      <th>length_ratio</th>\n",
       "      <th>translation_length</th>\n",
       "      <th>reference_length</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1_0</th>\n",
       "      <td>0.222939</td>\n",
       "      <td>[0.4713375796178344, 0.26282051282051283, 0.18...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.032895</td>\n",
       "      <td>157</td>\n",
       "      <td>152</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.5, 0.2, 0.0, 0.0]</td>\n",
       "      <td>0.846482</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_2</th>\n",
       "      <td>0.614788</td>\n",
       "      <td>[0.7142857142857143, 0.6666666666666666, 0.6, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.3333333333333333, 0.11764705882352941, 0.06...</td>\n",
       "      <td>0.606531</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.16666666666666666, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.606531</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_9</th>\n",
       "      <td>0.279971</td>\n",
       "      <td>[0.7058823529411765, 0.5, 0.3333333333333333, ...</td>\n",
       "      <td>0.702619</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.4444444444444444, 0.23529411764705882, 0.06...</td>\n",
       "      <td>0.800737</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.6666666666666666, 0.4, 0.0, 0.0]</td>\n",
       "      <td>0.846482</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.5, 0.3333333333333333, 0.0, 0.0]</td>\n",
       "      <td>0.606531</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_13</th>\n",
       "      <td>0.098854</td>\n",
       "      <td>[0.2857142857142857, 0.17647058823529413, 0.06...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.590909</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           bleu                                         precisions  \\\n",
       "1_0    0.222939  [0.4713375796178344, 0.26282051282051283, 0.18...   \n",
       "1_1         0.0                               [0.5, 0.2, 0.0, 0.0]   \n",
       "1_2    0.614788  [0.7142857142857143, 0.6666666666666666, 0.6, ...   \n",
       "1_3         0.0  [0.3333333333333333, 0.11764705882352941, 0.06...   \n",
       "1_4         0.0               [0.16666666666666666, 0.0, 0.0, 0.0]   \n",
       "...         ...                                                ...   \n",
       "20_9   0.279971  [0.7058823529411765, 0.5, 0.3333333333333333, ...   \n",
       "20_10       0.0  [0.4444444444444444, 0.23529411764705882, 0.06...   \n",
       "20_11       0.0                [0.6666666666666666, 0.4, 0.0, 0.0]   \n",
       "20_12       0.0                [0.5, 0.3333333333333333, 0.0, 0.0]   \n",
       "20_13  0.098854  [0.2857142857142857, 0.17647058823529413, 0.06...   \n",
       "\n",
       "      brevity_penalty length_ratio translation_length reference_length     id  \n",
       "1_0               1.0     1.032895                157              152    1_0  \n",
       "1_1          0.846482     0.857143                  6                7    1_1  \n",
       "1_2               1.0          1.0                  7                7    1_2  \n",
       "1_3          0.606531     0.666667                 18               27    1_3  \n",
       "1_4          0.606531     0.666667                 12               18    1_4  \n",
       "...               ...          ...                ...              ...    ...  \n",
       "20_9         0.702619      0.73913                 17               23   20_9  \n",
       "20_10        0.800737     0.818182                 18               22  20_10  \n",
       "20_11        0.846482     0.857143                  6                7  20_11  \n",
       "20_12        0.606531     0.666667                  4                6  20_12  \n",
       "20_13             1.0     1.590909                 35               22  20_13  \n",
       "\n",
       "[283 rows x 7 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_gpt['id'] = bleu_gpt.index\n",
    "bleu_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08307b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.177439</td>\n",
       "      <td>0.055104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.141127</td>\n",
       "      <td>0.061132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.130628</td>\n",
       "      <td>0.065208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113774</td>\n",
       "      <td>0.075295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.053774</td>\n",
       "      <td>0.021708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.02104</td>\n",
       "      <td>0.00664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0493</td>\n",
       "      <td>0.024737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.082314</td>\n",
       "      <td>0.024111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.153848</td>\n",
       "      <td>0.050009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.138769</td>\n",
       "      <td>0.045599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.130456</td>\n",
       "      <td>0.060616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.103612</td>\n",
       "      <td>0.038593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.027487</td>\n",
       "      <td>0.003069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.095029</td>\n",
       "      <td>0.036141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.158274</td>\n",
       "      <td>0.050995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.215742</td>\n",
       "      <td>0.07927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.091116</td>\n",
       "      <td>0.059989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.173502</td>\n",
       "      <td>0.073912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.236675</td>\n",
       "      <td>0.114028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.08479</td>\n",
       "      <td>0.029987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean       var\n",
       "file                    \n",
       "1     0.177439  0.055104\n",
       "2     0.141127  0.061132\n",
       "3     0.130628  0.065208\n",
       "4     0.113774  0.075295\n",
       "5     0.053774  0.021708\n",
       "6      0.02104   0.00664\n",
       "7       0.0493  0.024737\n",
       "8     0.082314  0.024111\n",
       "9     0.153848  0.050009\n",
       "10    0.138769  0.045599\n",
       "11    0.130456  0.060616\n",
       "12    0.103612  0.038593\n",
       "13    0.027487  0.003069\n",
       "14    0.095029  0.036141\n",
       "15    0.158274  0.050995\n",
       "16    0.215742   0.07927\n",
       "17    0.091116  0.059989\n",
       "18    0.173502  0.073912\n",
       "19    0.236675  0.114028\n",
       "20     0.08479  0.029987"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_gpt['file'] = bleu_gpt['id'].str.split('_').str[0].astype(int)\n",
    "bleu_gpt.groupby('file')['bleu'].agg(['mean', 'var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42415cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_gpt.to_csv(path+'/results/scores_comparisons/eval/bleu_trOCR_perline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd8ab74",
   "metadata": {},
   "source": [
    "### CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c9933242",
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_gpt = pd.DataFrame(cer_gpt.items(), columns=['id', 'cer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1e813684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_0</td>\n",
       "      <td>0.885609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_3</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_4</td>\n",
       "      <td>0.540230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_5</td>\n",
       "      <td>0.243243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1_6</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1_7</td>\n",
       "      <td>0.040816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1_8</td>\n",
       "      <td>0.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1_9</td>\n",
       "      <td>0.376923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1_10</td>\n",
       "      <td>0.663158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1_11</td>\n",
       "      <td>0.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1_12</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1_13</td>\n",
       "      <td>0.446154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2_0</td>\n",
       "      <td>0.827798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2_1</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2_2</td>\n",
       "      <td>0.433566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2_3</td>\n",
       "      <td>0.465347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2_4</td>\n",
       "      <td>0.299065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2_5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2_6</td>\n",
       "      <td>0.450820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2_7</td>\n",
       "      <td>0.351852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2_8</td>\n",
       "      <td>0.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2_9</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2_10</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2_11</td>\n",
       "      <td>0.347107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2_12</td>\n",
       "      <td>0.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2_13</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2_14</td>\n",
       "      <td>0.512000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3_0</td>\n",
       "      <td>0.826568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3_1</td>\n",
       "      <td>0.432432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3_2</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3_3</td>\n",
       "      <td>0.340426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3_4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3_5</td>\n",
       "      <td>0.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3_6</td>\n",
       "      <td>0.273585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3_7</td>\n",
       "      <td>0.507576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3_8</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3_9</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3_10</td>\n",
       "      <td>0.388430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3_11</td>\n",
       "      <td>0.346154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3_12</td>\n",
       "      <td>0.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3_13</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4_0</td>\n",
       "      <td>0.862239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4_1</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4_2</td>\n",
       "      <td>0.352000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4_3</td>\n",
       "      <td>0.423423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4_4</td>\n",
       "      <td>0.236842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4_5</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4_6</td>\n",
       "      <td>0.396947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4_7</td>\n",
       "      <td>0.217949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       cer\n",
       "0    1_0  0.885609\n",
       "1    1_2  0.000000\n",
       "2    1_3  0.400000\n",
       "3    1_4  0.540230\n",
       "4    1_5  0.243243\n",
       "5    1_6  0.200000\n",
       "6    1_7  0.040816\n",
       "7    1_8  0.044444\n",
       "8    1_9  0.376923\n",
       "9   1_10  0.663158\n",
       "10  1_11  0.305556\n",
       "11  1_12  0.054054\n",
       "12  1_13  0.446154\n",
       "13   2_0  0.827798\n",
       "14   2_1  0.500000\n",
       "15   2_2  0.433566\n",
       "16   2_3  0.465347\n",
       "17   2_4  0.299065\n",
       "18   2_5  0.000000\n",
       "19   2_6  0.450820\n",
       "20   2_7  0.351852\n",
       "21   2_8  0.544000\n",
       "22   2_9  0.027778\n",
       "23  2_10  0.028571\n",
       "24  2_11  0.347107\n",
       "25  2_12  0.290000\n",
       "26  2_13  0.027778\n",
       "27  2_14  0.512000\n",
       "28   3_0  0.826568\n",
       "29   3_1  0.432432\n",
       "30   3_2  0.588235\n",
       "31   3_3  0.340426\n",
       "32   3_4  0.000000\n",
       "33   3_5  0.044444\n",
       "34   3_6  0.273585\n",
       "35   3_7  0.507576\n",
       "36   3_8  0.238095\n",
       "37   3_9  0.028571\n",
       "38  3_10  0.388430\n",
       "39  3_11  0.346154\n",
       "40  3_12  0.478261\n",
       "41  3_13  0.277778\n",
       "42   4_0  0.862239\n",
       "43   4_1  0.166667\n",
       "44   4_2  0.352000\n",
       "45   4_3  0.423423\n",
       "46   4_4  0.236842\n",
       "47   4_5  0.125000\n",
       "48   4_6  0.396947\n",
       "49   4_7  0.217949"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cer_gpt.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "84bd52c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3560293278104556 0.07418452178113498\n"
     ]
    }
   ],
   "source": [
    "print(cer_gpt['cer'].mean(), cer_gpt['cer'].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fba7876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_gpt.to_csv(path+'/results/scores_comparisons/cer_claude_one_text_example_perline.csv', float_format=\"%.6f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2c79e467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.323091</td>\n",
       "      <td>0.071592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.340379</td>\n",
       "      <td>0.055958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.340754</td>\n",
       "      <td>0.051930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.295472</td>\n",
       "      <td>0.046730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.422537</td>\n",
       "      <td>0.056606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.387325</td>\n",
       "      <td>0.045909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.301438</td>\n",
       "      <td>0.051626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.360079</td>\n",
       "      <td>0.028633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.237097</td>\n",
       "      <td>0.069011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.357840</td>\n",
       "      <td>0.060633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.492793</td>\n",
       "      <td>0.491963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.474888</td>\n",
       "      <td>0.028887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.353460</td>\n",
       "      <td>0.056363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.328072</td>\n",
       "      <td>0.074323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.317233</td>\n",
       "      <td>0.065329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.369605</td>\n",
       "      <td>0.065728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.354184</td>\n",
       "      <td>0.058792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.372415</td>\n",
       "      <td>0.055234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.364230</td>\n",
       "      <td>0.053118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.319473</td>\n",
       "      <td>0.038383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean       var\n",
       "file                    \n",
       "1     0.323091  0.071592\n",
       "2     0.340379  0.055958\n",
       "3     0.340754  0.051930\n",
       "4     0.295472  0.046730\n",
       "5     0.422537  0.056606\n",
       "6     0.387325  0.045909\n",
       "7     0.301438  0.051626\n",
       "8     0.360079  0.028633\n",
       "9     0.237097  0.069011\n",
       "10    0.357840  0.060633\n",
       "11    0.492793  0.491963\n",
       "12    0.474888  0.028887\n",
       "13    0.353460  0.056363\n",
       "14    0.328072  0.074323\n",
       "15    0.317233  0.065329\n",
       "16    0.369605  0.065728\n",
       "17    0.354184  0.058792\n",
       "18    0.372415  0.055234\n",
       "19    0.364230  0.053118\n",
       "20    0.319473  0.038383"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cer_gpt['file'] = cer_gpt['id'].str.split('_').str[0].astype(int)\n",
    "cer_gpt.groupby('file')['cer'].agg(['mean', 'var'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783bfe80",
   "metadata": {},
   "source": [
    "# OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd1af15-25ff-4636-800b-599ef2d986f1",
   "metadata": {},
   "source": [
    "## EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bdaf499-ac45-438e-bb41-04d45d53f78c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[43mtest_path\u001b[49m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(test_image)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_path' is not defined"
     ]
    }
   ],
   "source": [
    "test_image = cv2.imread(test_path)\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e1baa4c9-2e16-47bf-aed6-47a4c0de1807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def easyOCR(image_path):\n",
    "    reader = easyocr.Reader(['fr'])\n",
    "    img = cv2.imread(image_path)\n",
    "    results = reader.readtext(img)\n",
    "    output = []\n",
    "    for res in results:\n",
    "        det, conf = res[1], res[2]\n",
    "        output.append((det, round(conf, 2))) \n",
    "    text = ' '.join([i[0] for i in output])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "474cc34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "easyOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = easyOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        easyOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b45d798e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>line_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_00</td>\n",
       "      <td>DÉSIGNATION DES PERSONNES DÉCÉDÉES OU AlSENTES...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_01</td>\n",
       "      <td>~Bcrta` 8 oetolz 1919 d4earuey vicytAul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_02</td>\n",
       "      <td>Jbsucala &amp; veyhmeuf ouoba  tg19 [eevœy</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_03</td>\n",
       "      <td>891 ta HBevcenk ~Bepkonssjk oj hain Hgoucoal Y...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_04</td>\n",
       "      <td>TulL Bouuù Q \"Janer ~aobà Bhuile RRXR 26 aplul...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_09</td>\n",
       "      <td>J9 ùcà nuf&gt; Sebiaw bo2nbi YÉvepQu X anel Bebel...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>4 49 0 : @ubovs ssexanbz Yuemaut ubuùd *ean [l...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>Jvuté &amp; oi = neuf fasles19:0 Huclai</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>Jarsalé -   vms] Hinsenq %0 djeceia |</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>3 [9' vrqkun )a4| Semience Run Gl Yusvellen Le...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text  file_name  \\\n",
       "0     1_00  DÉSIGNATION DES PERSONNES DÉCÉDÉES OU AlSENTES...          1   \n",
       "1     1_01            ~Bcrta` 8 oetolz 1919 d4earuey vicytAul          1   \n",
       "2     1_02             Jbsucala & veyhmeuf ouoba  tg19 [eevœy          1   \n",
       "3     1_03  891 ta HBevcenk ~Bepkonssjk oj hain Hgoucoal Y...          1   \n",
       "4     1_04  TulL Bouuù Q \"Janer ~aobà Bhuile RRXR 26 aplul...          1   \n",
       "..     ...                                                ...        ...   \n",
       "278  20_09  J9 ùcà nuf> Sebiaw bo2nbi YÉvepQu X anel Bebel...         20   \n",
       "279  20_10  4 49 0 : @ubovs ssexanbz Yuemaut ubuùd *ean [l...         20   \n",
       "280  20_11                Jvuté & oi = neuf fasles19:0 Huclai         20   \n",
       "281  20_12              Jarsalé -   vms] Hinsenq %0 djeceia |         20   \n",
       "282  20_13  3 [9' vrqkun )a4| Semience Run Gl Yusvellen Le...         20   \n",
       "\n",
       "     line_name     id  \n",
       "0            0    1_0  \n",
       "1            1    1_1  \n",
       "2            2    1_2  \n",
       "3            3    1_3  \n",
       "4            4    1_4  \n",
       "..         ...    ...  \n",
       "278          9   20_9  \n",
       "279         10  20_10  \n",
       "280         11  20_11  \n",
       "281         12  20_12  \n",
       "282         13  20_13  \n",
       "\n",
       "[283 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# easyOCR_output_df = pd.read_csv(path+'/results/postprocessed/easyOCR_perline_output.csv')\n",
    "easyOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6f85318b-55be-419d-b80a-0e8c5b861779",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_00</td>\n",
       "      <td>DATE I IÉcis DROITS DF SUCCESSION DROIT NUMÉRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_01</td>\n",
       "      <td>soceti &amp; tù déeemebza. 919 Yuepiy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_02</td>\n",
       "      <td>5 1439 DaLenlize Yiceppu #9lugu | Benuue YLama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10_03</td>\n",
       "      <td>Jaxat' € deeemlaac919 Fuupùa quebu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10_04</td>\n",
       "      <td>[4ho ceæy _ (ekalque Pnag;nl  Yjuuy Wv&amp;ezlbz (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>9_09</td>\n",
       "      <td>69*2.4 Scinllane Pots+a Gxz9&amp; SasBBoe Gpmzeyen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>9_10</td>\n",
       "      <td>kag' 0: Sainllane Bwun' à 26r' 1sr \"9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>9_11</td>\n",
       "      <td>Joaak + fnmauu dceehu 1919 Yeoeok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>9_12</td>\n",
       "      <td>[4Jg %eu 3- CBaslice fe At Z8ma 2e+eygu | Jwti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>9_13</td>\n",
       "      <td>~outi &amp; Jeun 1919 fuwsuik Lg déclerations recl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text\n",
       "0    10_00  DATE I IÉcis DROITS DF SUCCESSION DROIT NUMÉRO...\n",
       "1    10_01                  soceti & tù déeemebza. 919 Yuepiy\n",
       "2    10_02  5 1439 DaLenlize Yiceppu #9lugu | Benuue YLama...\n",
       "3    10_03                 Jaxat' € deeemlaac919 Fuupùa quebu\n",
       "4    10_04  [4ho ceæy _ (ekalque Pnag;nl  Yjuuy Wv&ezlbz (...\n",
       "..     ...                                                ...\n",
       "278   9_09  69*2.4 Scinllane Pots+a Gxz9& SasBBoe Gpmzeyen...\n",
       "279   9_10              kag' 0: Sainllane Bwun' à 26r' 1sr \"9\n",
       "280   9_11                  Joaak + fnmauu dceehu 1919 Yeoeok\n",
       "281   9_12  [4Jg %eu 3- CBaslice fe At Z8ma 2e+eygu | Jwti...\n",
       "282   9_13  ~outi & Jeun 1919 fuwsuik Lg déclerations recl...\n",
       "\n",
       "[283 rows x 2 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easyOCR_output_df = pd.DataFrame(easyOCR_output.items(), columns=['file', 'text'])\n",
    "easyOCR_output_df[['file_name', 'line_name']] = easyOCR_output_df['file'].str.split('_', expand=True)\n",
    "easyOCR_output_df[['file_name', 'line_name']] = easyOCR_output_df[['file_name', 'line_name']].astype(int)\n",
    "easyOCR_output_df = easyOCR_output_df.sort_values(by=['file_name', 'line_name']).reset_index(drop=True)\n",
    "easyOCR_output_df['text'] = easyOCR_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "easyOCR_output_df['id'] = easyOCR_output_df['file_name'].astype(str) + '_' + easyOCR_output_df['line_name'].astype(str)\n",
    "easyOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "512ffd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "easyOCR_output_df.to_csv(path+'/results/postprocessed/easyOCR_perline_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09134009-83a9-4ed0-b724-d9a4096ebe7d",
   "metadata": {},
   "source": [
    "## Pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e86c0ee3-034b-446d-aa51-3e5e6e348fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pytesseractOCR(image_path):\n",
    "    try:\n",
    "        image = PILImage.open(image_path)\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text\n",
    "    except:\n",
    "        print(\"[ERROR] pytesseractOCR failed! (should be installed)\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f596a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseractOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = pytesseractOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        pytesseractOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8149b7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>line_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_00</td>\n",
       "      <td>|  = | DATE DU DEPOT  des  DECLARATIONS.  DESI...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_01</td>\n",
       "      <td>ft alt alta</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_02</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_03</td>\n",
       "      <td>a cnte |Abevcenk a dette  Son &lt;a  1040’  i ee ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_04</td>\n",
       "      <td>L  3  be oi  7  Nf »- p</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_09</td>\n",
       "      <td>149 28 auf  Si elaiawx  Ve  |  | Wvebly eu ty ...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>; a : oe ssa  song  o  Sannin nomena  ie 3 (0....</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>|  aul</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>Caen torah Winéorg ty dieser’  es  oe  aaa. pa...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>+ i 4 | pane um ‘ uy R | £5 dée! t ctfleati ec...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text  file_name  \\\n",
       "0     1_00  |  = | DATE DU DEPOT  des  DECLARATIONS.  DESI...          1   \n",
       "1     1_01                                       ft alt alta           1   \n",
       "2     1_02                                                             1   \n",
       "3     1_03  a cnte |Abevcenk a dette  Son <a  1040’  i ee ...          1   \n",
       "4     1_04                          L  3  be oi  7  Nf »- p            1   \n",
       "..     ...                                                ...        ...   \n",
       "278  20_09  149 28 auf  Si elaiawx  Ve  |  | Wvebly eu ty ...         20   \n",
       "279  20_10  ; a : oe ssa  song  o  Sannin nomena  ie 3 (0....         20   \n",
       "280  20_11                                            |  aul          20   \n",
       "281  20_12  Caen torah Winéorg ty dieser’  es  oe  aaa. pa...         20   \n",
       "282  20_13  + i 4 | pane um ‘ uy R | £5 dée! t ctfleati ec...         20   \n",
       "\n",
       "     line_name     id  \n",
       "0            0    1_0  \n",
       "1            1    1_1  \n",
       "2            2    1_2  \n",
       "3            3    1_3  \n",
       "4            4    1_4  \n",
       "..         ...    ...  \n",
       "278          9   20_9  \n",
       "279         10  20_10  \n",
       "280         11  20_11  \n",
       "281         12  20_12  \n",
       "282         13  20_13  \n",
       "\n",
       "[283 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytesseractOCR_output_df = pd.DataFrame(pytesseractOCR_output.items(), columns=['file', 'text'])\n",
    "pytesseractOCR_output_df[['file_name', 'line_name']] = pytesseractOCR_output_df['file'].str.split('_', expand=True)\n",
    "pytesseractOCR_output_df[['file_name', 'line_name']] = pytesseractOCR_output_df[['file_name', 'line_name']].astype(int)\n",
    "pytesseractOCR_output_df = pytesseractOCR_output_df.sort_values(by=['file_name', 'line_name']).reset_index(drop=True)\n",
    "pytesseractOCR_output_df['text'] = pytesseractOCR_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "pytesseractOCR_output_df['id'] = pytesseractOCR_output_df['file_name'].astype(str) + '_' + pytesseractOCR_output_df['line_name'].astype(str)\n",
    "pytesseractOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f26931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseractOCR_output_df.to_csv(path+'/results/postprocessed/pytesseractOCR_perline_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061630dd-6446-4a62-9b39-bd87c86a99f4",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "Not good for non-english?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e561f951-54a9-4d73-b778-41f9dbcdbe0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kerasOCR(image_path):\n",
    "    pipeline = keras_ocr.pipeline.Pipeline()\n",
    "    image = keras_ocr.tools.read(image_path)\n",
    "    prediction_groups = pipeline.recognize([image])\n",
    "    words = []\n",
    "    for line in prediction_groups[0]:\n",
    "        for word in line:\n",
    "            try:\n",
    "                if isinstance(word[0], str):\n",
    "                    words.append(word[0])\n",
    "            except IndexError:\n",
    "                continue\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e1e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = kerasOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        kerasOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "82c872cd-131c-4bc4-96cf-2dd2e62e0f59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for /Users/serenekim/.keras-ocr/craft_mlt_25k.h5\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: resize_bilinear (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.image.resize(...method=ResizeMethod.BILINEAR...)` instead.\n",
      "Looking for /Users/serenekim/.keras-ocr/crnn_kurapan.h5\n",
      "1/1 [==============================] - 1s 806ms/step\n",
      "1/1 [==============================] - 1s 751ms/step\n",
      "d r p o a g\n"
     ]
    }
   ],
   "source": [
    "test_keras = kerasOCR(image_path=test_path)\n",
    "print(test_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf6c0a",
   "metadata": {},
   "source": [
    "## TrOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cde01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor\n",
    "from transformers import VisionEncoderDecoderModel\n",
    "import torch\n",
    "\n",
    "def trOCR(image_path):\n",
    "    processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "\n",
    "    image = PILImage.open(image_path)\n",
    "\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "    \n",
    "    # Set device (GPU or CPU)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)  # Move model to the device\n",
    "    pixel_values = pixel_values.to(device)  # Move image tensor to the same device\n",
    "    \n",
    "    try:\n",
    "        generated_ids = model.generate(pixel_values, max_length=400)  # Limit max length\n",
    "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return generated_text\n",
    "    except IndexError as e:\n",
    "        print(f\"IndexError: {e}\")\n",
    "        return \"Error: Index out of range during generation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27ab20c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/serenekim/.pyenv/versions/3.12.0/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trOCR_output = {}\n",
    "for image in os.listdir(image_folder):\n",
    "    if image.endswith('.jpg'):\n",
    "        image_path = image_folder + '/' + image\n",
    "        text = trOCR(image_path)\n",
    "        name = image.split('.')[0]\n",
    "        name = name.split('example')[1]\n",
    "        trOCR_output[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caa3c0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>line_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_00</td>\n",
       "      <td>treat of the first time of the French Parliame...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_01</td>\n",
       "      <td># almost be weighted rather any standard for t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_02</td>\n",
       "      <td># almost the original module you formerly ... ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_03</td>\n",
       "      <td>THE GREAT BRONDSOME \" AIRMARK GABIT PARADE HAN...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_04</td>\n",
       "      <td>After Congress plan himself tough back down to...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20_09</td>\n",
       "      <td>Manager Atkinson had made many awareness of th...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>20_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20_10</td>\n",
       "      <td>After the Democratic gubernatorial judge took ...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20_11</td>\n",
       "      <td>the best time of fourteen songs with the first...</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>20_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20_12</td>\n",
       "      <td>\" To absorb confidence being a total of 1 000 ...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>20_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20_13</td>\n",
       "      <td>After the Renaissance season would change thei...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>20_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                               text  file_name  \\\n",
       "0     1_00  treat of the first time of the French Parliame...          1   \n",
       "1     1_01  # almost be weighted rather any standard for t...          1   \n",
       "2     1_02  # almost the original module you formerly ... ...          1   \n",
       "3     1_03  THE GREAT BRONDSOME \" AIRMARK GABIT PARADE HAN...          1   \n",
       "4     1_04  After Congress plan himself tough back down to...          1   \n",
       "..     ...                                                ...        ...   \n",
       "278  20_09  Manager Atkinson had made many awareness of th...         20   \n",
       "279  20_10  After the Democratic gubernatorial judge took ...         20   \n",
       "280  20_11  the best time of fourteen songs with the first...         20   \n",
       "281  20_12  \" To absorb confidence being a total of 1 000 ...         20   \n",
       "282  20_13  After the Renaissance season would change thei...         20   \n",
       "\n",
       "     line_name     id  \n",
       "0            0    1_0  \n",
       "1            1    1_1  \n",
       "2            2    1_2  \n",
       "3            3    1_3  \n",
       "4            4    1_4  \n",
       "..         ...    ...  \n",
       "278          9   20_9  \n",
       "279         10  20_10  \n",
       "280         11  20_11  \n",
       "281         12  20_12  \n",
       "282         13  20_13  \n",
       "\n",
       "[283 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trOCR_output_df = pd.DataFrame(trOCR_output.items(), columns=['file', 'text'])\n",
    "trOCR_output_df[['file_name', 'line_name']] = trOCR_output_df['file'].str.split('_', expand=True)\n",
    "trOCR_output_df[['file_name', 'line_name']] = trOCR_output_df[['file_name', 'line_name']].astype(int)\n",
    "trOCR_output_df = trOCR_output_df.sort_values(by=['file_name', 'line_name']).reset_index(drop=True)\n",
    "trOCR_output_df['text'] = trOCR_output_df['text'].replace(['\\n', '\\t'], ' ', regex=True)\n",
    "trOCR_output_df['id'] = trOCR_output_df['file_name'].astype(str) + '_' + trOCR_output_df['line_name'].astype(str)\n",
    "trOCR_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd3cec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "trOCR_output_df.to_csv(path+'/results/postprocessed/trOCR_perline_output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
